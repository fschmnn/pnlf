{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project1 PNLF Postproduction <a class=\"tocSkip\">\n",
    "    \n",
    "After running `PNLF production.ipynb`, this notebook can be used to create plots that contain the results of all galaxies and the LaTeX output tables that are used in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "     \n",
    "First we load a bunch of common packages that are used across the project. More specific packages that are only used in one section are loaded later to make it clear where they belong to (this also applies to all custom moduls that were written for this project)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload modules after they have been modified\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pnlf.packages import *\n",
    "\n",
    "from pnlf.constants import tab10, single_column, two_column\n",
    "from pnlf.auxiliary import filter_table\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we use the `logging` module to handle informations and warnings (this does not always work as expected in jupyter notebooks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout,format='%(levelname)s: %(message)s',level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we need to specify the path to the raw data\n",
    "basedir = Path('..')\n",
    "data_raw = Path('a:')/'Archive'\n",
    "data_ext = Path('a:')/'Archive'\n",
    "    \n",
    "# the table with the measured distances\n",
    "results = ascii.read(basedir/'data'/'interim'/ 'results.txt',format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "results.add_index('name')\n",
    "\n",
    "# the parameters that were used\n",
    "with open(basedir / 'data' / 'interim' / 'parameters.yml') as yml_file:\n",
    "    parameters = yaml.load(yml_file,Loader=yaml.FullLoader)    \n",
    "    \n",
    "# some general parameters of the galaxy sample\n",
    "sample_table = ascii.read(basedir/'data'/'interim'/'sample.txt')\n",
    "sample_table.add_index('name')\n",
    "sample_table['SkyCoord'] = SkyCoord(sample_table['R.A.'],sample_table['Dec.'])\n",
    "\n",
    "# the catalogue with the PNe (and SNRs)\n",
    "with fits.open(basedir/'data'/'catalogues'/'nebulae.fits') as hdul:\n",
    "    catalogue = Table(hdul[1].data)\n",
    "catalogue['SkyCoord'] = SkyCoord(catalogue['RaDec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in results[np.abs(results['(m-M)']-results['(m-M)_SNR'])>0.05]:\n",
    "    print(f\"{row['name']}: d(m-M) = {row['(m-M)']-row['(m-M)_SNR']:.2f}, sigma = {(row['(m-M)']-row['(m-M)_SNR'])/row['err-(m-M)']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### LaTeX sample table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from astropy.table import join \n",
    "\n",
    "abundance_gradients = ascii.read(basedir/'data'/'external'/'radial_abundance_gradients.txt',\n",
    "                                names=['name','R0','g_r25'])\n",
    "abundance_gradients.add_index('name')\n",
    "\n",
    "extinction = ascii.read(basedir/'data'/'external'/'extinction.txt')\n",
    "extinction.add_index('name')\n",
    "\n",
    "# 12+logOH at mean position of PNe\n",
    "logOH = []\n",
    "rmean = []\n",
    "for name in abundance_gradients['name']:\n",
    "    completeness = parameters[name]['completeness_limit']\n",
    "    catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "    catalogue['overluminous'] = catalogue['overluminous'].astype(bool)\n",
    "    catalogue['SkyCoord'] = SkyCoord(catalogue['RaDec'])\n",
    "    catalogue = catalogue[(catalogue['type']=='PN') & (~catalogue['exclude']) & (~catalogue['overluminous']) & (catalogue['mOIII']<completeness)]\n",
    "\n",
    "    center = sample_table.loc[name]['SkyCoord']\n",
    "    posang = sample_table.loc[name]['posang']\n",
    "    inclination = sample_table.loc[name]['Inclination']\n",
    "    eccentricity = np.sin(inclination*u.deg).value\n",
    "    r25 = sample_table.loc[name]['r25']*u.arcmin\n",
    "    catalogue['r'] = catalogue['SkyCoord'].separation(center)\n",
    "    rmean.append(np.mean(catalogue['r']/r25).decompose())\n",
    "        \n",
    "abundance_gradients['rmean'] = rmean\n",
    "abundance_gradients['12+logOH'] = abundance_gradients['R0'] + abundance_gradients['rmean']*abundance_gradients['g_r25']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "filename = basedir / 'data' / 'external' / 'phangs_sample_table_v1p6.fits'\n",
    "with fits.open(filename) as hdul:\n",
    "    sample = Table(hdul[1].data)\n",
    "\n",
    "#galaxies = sample_table[sample_table['HAS_MUSE']==1]['NAME']\n",
    "sample = sample[sample['survey_muse_status']!='not_in_survey']\n",
    "sample['name'] = [x.upper() for x in sample['name']]\n",
    "\n",
    "\n",
    "sample.rename_columns(['morph_string','orient_incl','orient_posang','size_r25'],\n",
    "                      ['Type','Inclination','posang','r25'])\n",
    "\n",
    "coord = SkyCoord(sample['orient_ra']*u.degree,sample['orient_dec']*u.degree)\n",
    "sample['R.A.'],sample['Dec.'] = zip(*[x.split(' ') for x in coord.to_string(style='hmsdms',precision=2)])\n",
    "sample['mass'] = np.log10(sample['props_mstar'])\n",
    "sample['SFR'] = np.log10(sample['props_sfr'])\n",
    "\n",
    "err_up = 10 ** (np.log10(sample['dist']) + sample['dist_unc']) - sample['dist']\n",
    "err_down = sample['dist'] - 10 ** (np.log10(sample['dist']) - sample['dist_unc'])\n",
    "sample['(m-M)'] = Distance(sample['dist']*u.Mpc).distmod.value\n",
    "sample['err(m-M)'] = 5/np.log(10)*err_up / sample['dist']\n",
    "sample['r25']/=60\n",
    "\n",
    "sample['(m-M)'].info.format = '%.2f' \n",
    "sample['err(m-M)'].info.format = '%.2f' \n",
    "sample['r25'].info.format = '%.2f' \n",
    "sample['mass'].info.format = '%.2f' \n",
    "sample['SFR'].info.format = '%.2f' \n",
    "\n",
    "columns = ['name','Type','R.A.','Dec.','(m-M)','err(m-M)','Inclination','posang','r25','mass','SFR']\n",
    "tbl = join(sample[columns],abundance_gradients,keys='name')\n",
    "tbl['E(B-V)'] = [extinction.loc[name]['E(B-V)'] for name in tbl['name']]\n",
    "# from sample table\n",
    "tbl['PSF'] = [0.72,0.73,0.74,0.63,0.82,0.49,0.65,0.8,0.64,0.72,\n",
    "                  0.85,0.74,0.77,0.58,0.58,0.64,0.44,0.73,0.79]\n",
    "tbl['AO'] = ['e' if parameters[name]['power_index']==2.3 else '' for name in tbl['name'] ]\n",
    "tbl['PSF'] = [f'${psf}$' if e else f'${psf}^\\mathrm{{AO}}$' for psf,e in zip(tbl['PSF'],tbl['AO'])] \n",
    "tbl['12+logOH'].info.format = '%.2f' \n",
    "\n",
    "with open(basedir / 'data' / 'interim' / 'sample.txt','w',newline='\\n') as f:\n",
    "    ascii.write(tbl,f,format='fixed_width_two_line',overwrite=True,delimiter_pad=' ',position_char='=')\n",
    "    \n",
    "del tbl[['R0','rmean','g_r25','mass','SFR','AO']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "latexdict = {'tabletype': 'table*',\n",
    "'header_start': '\\\\toprule\\\\toprule',\n",
    "'header_end': '\\\\midrule',\n",
    "'data_end': '\\\\bottomrule',\n",
    "'caption': f'Galaxy sample',\n",
    "'units': {'R.A.':'(J2000)','Dec.':'(J2000)','Inclination':'deg','Distance':'$\\si{\\mega\\parsec}$',\n",
    "          'r25':'arcmin'},\n",
    "'preamble': '\\\\centering',\n",
    "'tablefoot': f'\\\\label{{tbl:sample}}'\n",
    "            }\n",
    " \n",
    "tbl['name'] = [f'\\\\galaxyname{{{row[\"name\"][:-4]}}}{{{row[\"name\"][-4:]}}}' for row in tbl]\n",
    "#tbl['(m-M)'] = [f'{row[\"(m-M)\"]:.2f}\\pm{row[\"err(m-M)\"]:.2f}' for row in tbl]\n",
    "    \n",
    "with open(basedir / 'data' / 'interim' /'sample.tex','w',newline='\\n') as f:\n",
    "    ascii.write(tbl,f,Writer=ascii.Latex, latexdict=latexdict,overwrite=True,exclude_names=['Name'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### LaTeX result table\n",
    "\n",
    "this uses the result table and prints out a LaTeX table (only the data part) that can be used in the final document. In another step, we merge the individual catalogues for PN and SNR identifications. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# with SI units\n",
    "tbl_out = ''\n",
    "results.sort('name')\n",
    "for row in results:\n",
    "    name = f'\\\\galaxyname{{{row[\"name\"][:-4]}}}{{{row[\"name\"][-4:]}}}'\n",
    "    tbl_out += f'{name} & {row[\"N_PN\"]} & {row[\"N_SNRorPN\"]} '\n",
    "    tbl_out += f'& $\\\\uncertainty{{{row[\"(m-M)\"]:.2f}}}{{{row[\"err+(m-M)\"]:.2f}}}{{{row[\"err-(m-M)\"]:.2f}}}$ '\n",
    "    tbl_out += f'& $\\\\uncertainty{{{row[\"(m-M)_SNR\"]:.2f}}}{{{row[\"err+(m-M)_SNR\"]:.2f}}}{{{row[\"err-(m-M)_SNR\"]:.2f}}}$ '\n",
    "    tbl_out += f'& $\\\\uncertainty{{{row[\"d/Mpc\"]:.2f}}}{{{row[\"err+d/Mpc\"]:.2f}}}{{{row[\"err-d/Mpc\"]:.2f}}}$ \\\\\\\\\\n'\n",
    "    #tbl_out += f'& {row[\"alpha\"]:.2f}\\\\\\\\\\n'\n",
    "    #tbl_out += f'& $\\\\uncertainty{{{row[\"dis_SNR\"]:.2f}}}{{{row[\"dis_SNR_plus\"]:.2f}}}{{{row[\"dis_SNR_minus\"]:.2f}}}$ '\n",
    "    #tbl_out += f'& $\\\\uncertainty{{{row[\"dis_SNR_Mpc\"]:.2f}}}{{{row[\"dis_SNR_Mpc_plus\"]:.2f}}}{{{row[\"dis_SNR_Mpc_minus\"]:.2f}}}$\\\\\\\\\\n'\n",
    "    \n",
    "print(tbl_out)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# without SI units\n",
    "tbl_out = ''\n",
    "results.sort('name')\n",
    "for row in results:\n",
    "    print(f'\\\\setvalue{{mag/{row[\"name\"]} =\\\\SI[parse-numbers=false]{{\\\\uncertainty{{{row[\"(m-M)\"]:.2f}}}{{{row[\"err+(m-M)\"]:.2f}}}{{{row[\"err-(m-M)\"]:.2f}}}}}{{\\\\mag}}}}')\n",
    "print(' ')\n",
    "for row in results:\n",
    "    print(f'\\\\setvalue{{Mpc/{row[\"name\"]} =\\\\SI[parse-numbers=false]{{\\\\uncertainty{{{row[\"d/Mpc\"]:.2f}}}{{{row[\"err+d/Mpc\"]:.2f}}}{{{row[\"err-d/Mpc\"]:.2f}}}}}{{\\\\mega\\\\parsec}}}}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tbl_out = ''\n",
    "results.sort('name')\n",
    "for row in results:\n",
    "    print(f'\\\\setvalue{{mag/{row[\"name\"]} = \\\\uncertainty{{{row[\"(m-M)\"]:.2f}}}{{{row[\"err+(m-M)\"]:.2f}}}{{{row[\"err-(m-M)\"]:.2f}}}}}')\n",
    "print(' ')\n",
    "for row in results:\n",
    "    print(f'\\\\setvalue{{Mpc/{row[\"name\"]} = \\\\uncertainty{{{row[\"d/Mpc\"]:.2f}}}{{{row[\"err+d/Mpc\"]:.2f}}}{{{row[\"err-d/Mpc\"]:.2f}}}}}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# save to file\n",
    "for col in ['(m-M)','err+(m-M)','err-(m-M)','d/Mpc','err+d/Mpc','err-d/Mpc']:\n",
    "    results[col].info.format = '%.2f'\n",
    "\n",
    "distance_modulus = []\n",
    "distance_parsec = []\n",
    "for row in results:\n",
    "    distance_modulus.append(f'{row[\"(m-M)\"]:.2f} + {row[\"err-(m-M)\"]:.2f} - {row[\"err+(m-M)\"]:.2f}')\n",
    "    distance_parsec.append(f'{row[\"d/Mpc\"]:.2f} + {row[\"err+d/Mpc\"]:.2f} - {row[\"err-d/Mpc\"]:.2f}')\n",
    "results['mu'] = distance_modulus\n",
    "results['d/Mpc'] = distance_parsec\n",
    "                           \n",
    "filename = basedir / 'data' / 'interim' / f'distances.txt'\n",
    "with open(filename,'w',newline='\\n') as f:\n",
    "    ascii.write(results[['name','mu','d/Mpc']],\n",
    "                f,format='fixed_width',delimiter='\\t',overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Combine Catalogues to single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tbl_lst = []\n",
    "for name in results['name']:\n",
    "    with fits.open(basedir/'data'/'catalogues'/f'{name}_classifications.fits') as hdul:\n",
    "        tmp = Table(hdul[1].data)    \n",
    "        tmp.add_column(name,name='gal_name',index=0)\n",
    "    tbl_lst.append(tmp)\n",
    "catalogue = vstack(tbl_lst)\n",
    "\n",
    "# the object in NGC0628 is excluded in our sample\n",
    "matched_objects = [('NGC0628',886,'Kreckel-SNR-8'),\n",
    "                   ('NGC3351',1216,'Ciardullo-PN-5'),\n",
    "                   ('NGC3627',749,'Ciardullo-PN-35')]\n",
    "\n",
    "notes = []\n",
    "for row in catalogue:\n",
    "    note = []\n",
    "    if row['SNRorPN']:\n",
    "        pass\n",
    "        #note.append('PN')\n",
    "    if row['overluminous']:\n",
    "        note.append('OL')\n",
    "    if row['exclude']:\n",
    "        note.append('EX')\n",
    "\n",
    "    for name,idx,label in matched_objects:\n",
    "        if row['gal_name']==name and row['id']==idx:\n",
    "            note.append(label)\n",
    "        \n",
    "    notes.append(','.join(note))\n",
    "catalogue['note'] = notes\n",
    "\n",
    "\n",
    "# save complete catalogue\n",
    "columns = ['gal_name','id','type','x','y','RA','DEC','fwhm','mOIII','dmOIII',\n",
    "           'HB4861','HB4861_err', 'OIII5006','OIII5006_err', 'HA6562','HA6562_err', \n",
    "           'NII6583','NII6583_err', 'SII6716','SII6716_err', 'SII6730','SII6730_err',\n",
    "           'note']\n",
    "\n",
    "# we save all objects (nice table for collaborators)\n",
    "hdu = fits.BinTableHDU(catalogue,name='nebulae catalogue')\n",
    "hdu.writeto(basedir/'data'/'catalogues'/f'nebulae.fits',overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "the catalogue for the journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "columns = ['gal_name','id','type','RA','DEC','mOIII','dmOIII','logOIII/Ha','d(logOIII/Ha)',\n",
    "           'logNII/Ha','d(logNII/Ha)','logSII/Ha','d(logSII/Ha)','note']\n",
    "\n",
    "catalogue['SkyCoord'] = SkyCoord(catalogue['RaDec'])\n",
    "catalogue['RA'],catalogue['DEC'] = zip(*[x.split(' ') for x in catalogue['SkyCoord'].to_string(style='hmsdms',precision=2)])\n",
    "\n",
    "catalogue['logOIII/Ha']   = np.log10(catalogue['OIII5006_flux']/catalogue['HA6562_flux'])\n",
    "catalogue['d(logOIII/Ha)']= 1/np.log(10) * np.sqrt( (catalogue['HA6562_flux_err'] / catalogue['HA6562_flux'])**2 + (catalogue['OIII5006_flux_err'] / catalogue['OIII5006_flux'])**2)\n",
    "\n",
    "#catalogue['Ha/NII']    = catalogue['HA6562']/catalogue['NII6583']\n",
    "#catalogue['d(Ha/NII)'] = catalogue['HA6562'] / catalogue['NII6583'] * np.sqrt( (catalogue['NII6583_err'] / catalogue['NII6583'])**2 + (catalogue['HA6562_err'] / catalogue['HA6562'])**2)\n",
    "\n",
    "#catalogue['Ha/SII']    = catalogue['HA6562']/catalogue['SII']\n",
    "#catalogue['d(Ha/SII)'] = catalogue['HA6562'] / catalogue['SII'] * np.sqrt( (catalogue['SII_err'] / catalogue['SII'])**2 + (catalogue['HA6562_err'] / catalogue['HA6562'])**2)\n",
    "\n",
    "catalogue['logNII/Ha']    = np.log10(catalogue['NII6583_flux']/catalogue['HA6562_flux'])\n",
    "catalogue['d(logNII/Ha)'] = 1/np.log(10) * np.sqrt( (catalogue['NII6583_flux_err'] / catalogue['NII6583_flux'])**2 + (catalogue['HA6562_flux_err'] / catalogue['HA6562_flux'])**2)\n",
    "\n",
    "catalogue['logSII/Ha']    = np.log10(catalogue['SII_flux']/catalogue['HA6562_flux'])\n",
    "catalogue['d(logSII/Ha)'] = 1/np.log(10) * np.sqrt( (catalogue['SII_flux_err'] / catalogue['SII_flux'])**2 + (catalogue['HA6562_flux_err'] / catalogue['HA6562_flux'])**2)\n",
    "\n",
    "for col in ['x','y','mOIII','dmOIII','logOIII/Ha','d(logOIII/Ha)','logNII/Ha','d(logNII/Ha)','logSII/Ha','d(logSII/Ha)']:\n",
    "    catalogue[col].info.format = '%.2f' \n",
    "catalogue.sort(['gal_name','mOIII']) \n",
    "\n",
    "# we only use PN or SNR that could be PN\n",
    "SNRorPN =  ((catalogue['type']=='PN')|((catalogue['type']=='SNR')&(catalogue['SNRorPN'])))\n",
    "criteria = SNRorPN & (catalogue['mOIII']<28) & catalogue['OIII5006_detection'] & (~catalogue['exclude']) # | catalogue['overluminous'])\n",
    "\n",
    "\n",
    "for name in np.unique(catalogue['gal_name']):\n",
    "    N = len(catalogue[(criteria) & (catalogue['gal_name']==name)])\n",
    "    catalogue['id'][(criteria) & (catalogue['gal_name']==name)] = np.arange(1,N+1)\n",
    "    \n",
    "# save only PNe\n",
    "export = catalogue[columns][criteria].copy()\n",
    "# adjust the completness limit for those two galaxies\n",
    "export = export[~(np.isin(export['gal_name'],['NGC2835','NGC3627']) & (export['mOIII']>=27.5))]\n",
    "with open(basedir/'data'/'catalogues'/'PN_candidates.txt','w',newline='\\n') as f:\n",
    "    ascii.write(export,f,format='fixed_width_two_line',overwrite=True,delimiter_pad=' ',position_char='=')\n",
    "\n",
    "doc = f'''PNe catalogue for Scheuermann et al. (2021)\n",
    "\n",
    "This catalogue was created with the following code:\n",
    "https://github.com/fschmnn/pnlf\n",
    "last update: {date.today().strftime(\"%b %d, %Y\")}\n",
    "'''    \n",
    "\n",
    "primary_hdu = fits.PrimaryHDU()\n",
    "for i,comment in enumerate(doc.split('\\n')):\n",
    "    if i==0:\n",
    "        primary_hdu.header['COMMENT'] = comment\n",
    "    else:\n",
    "        primary_hdu.header[''] = comment\n",
    "#table_hdu   = fits.BinTableHDU(export,name='catalogue')\n",
    "#hdul = fits.HDUList([primary_hdu, table_hdu])\n",
    "#hdul.writeto(basedir/'data'/'catalogues'/f'PN_catalogue.fits',overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create LaTeX table for a single galaxy (for paper)\n",
    "tmp = ascii.read(basedir/'data'/'catalogues'/'PN_candidates.txt')\n",
    "tmp = tmp[tmp['gal_name']=='NGC0628']\n",
    "#with open(basedir / 'data' / 'catalogues' /'NGC0628_nebulae.tex','w',newline='\\n') as f:\n",
    "ascii.write(tmp[-5:],sys.stdout,Writer=ascii.Latex,overwrite=True,exclude_names=['x','y','fwhm'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "columns = ['gal_name','id','type','x','y','RA','DEC','fwhm','mOIII','dmOIII','MOIII','dMOIII','HB4861_flux','HB4861_flux_err','HB4861_SIGMA','OIII5006_flux','OIII5006_flux_err','OIII5006_SIGMA','HA6562_flux','HA6562_flux_err','HA6562_SIGMA','NII6583_flux','NII6583_flux_err','NII6583_SIGMA','SII6716_flux','SII6716_flux_err','SII6716_SIGMA','SII6730_flux','SII6730_flux_err','SII6730_SIGMA','EBV_balmer','HB4861_flux_corr','HB4861_flux_corr_err','OIII5006_flux_corr','OIII5006_flux_corr_err','HA6562_flux_corr','HA6562_flux_corr_err','NII6583_flux_corr','NII6583_flux_corr_err','SII6716_flux_corr','SII6716_flux_corr_err','SII6730_flux_corr','SII6730_flux_corr_err','note']\n",
    "\n",
    "primary_hdu = fits.PrimaryHDU()\n",
    "for i,comment in enumerate(doc.split('\\n')):\n",
    "    if i==0:\n",
    "        primary_hdu.header['COMMENT'] = comment\n",
    "    else:\n",
    "        primary_hdu.header[''] = comment\n",
    "table_hdu   = fits.BinTableHDU(export[columns],name='catalogue')\n",
    "hdul = fits.HDUList([primary_hdu, table_hdu])\n",
    "hdul.writeto(basedir/'data'/'catalogues'/f'PN_catalogue_Enrico.fits',overwrite=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### id of other surveys in note column\n",
    "\n",
    "the referee suggested to add a remark in the note column when an object is classified differently. Here I compare the catalogue to the literature and add this note."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from astropy.coordinates import match_coordinates_sky # match sources against existing catalog\n",
    "from astropy.coordinates import Angle                 # work with angles (e.g. 1°2′3″)\n",
    "from astropy.table import vstack\n",
    "\n",
    "from pnlf.load_references import NGC628, \\\n",
    "                                   pn_NGC628_kreckel, \\\n",
    "                                   snr_NGC628_kreckel, \\\n",
    "                                   pn_NGC628_herrmann, \\\n",
    "                                   NGC628_kreckel, \\\n",
    "                                   pn_NGC5068_herrmann, \\\n",
    "                                   pn_NGC3351_ciardullo, \\\n",
    "                                   pn_NGC3627_ciardullo,\\\n",
    "                                   pn_NGC0628_roth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "matchcoord = catalogue[catalogue['gal_name']=='NGC0628'].copy()\n",
    "\n",
    "for catalogcoord, label in zip([pn_NGC628_herrmann,pn_NGC628_kreckel,snr_NGC628_kreckel,pn_NGC0628_roth],\n",
    "                               ['Hpn','Kpn','Ksnr','Rpn']):\n",
    "\n",
    "    idx, sep, _  = match_coordinates_sky(matchcoord['SkyCoord'],catalogcoord['SkyCoord'])\n",
    "    matchcoord[label] = catalogcoord[idx]['ID']\n",
    "    matchcoord[label][sep>0.5*u.arcsec] = ''\n",
    "    \n",
    "matchcoord[['id','mOIII','type','Hpn','Kpn','Ksnr','Rpn']][(matchcoord['type']=='PN') & (matchcoord['mOIII']<28)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "matchcoord = catalogue[catalogue['gal_name']=='NGC3627'].copy()\n",
    "\n",
    "idx, sep, _  = match_coordinates_sky(matchcoord['SkyCoord'],pn_NGC3627_ciardullo['SkyCoord'])\n",
    "matchcoord['idx'] = idx\n",
    "matchcoord['sep'] = sep.to(u.arcsec)\n",
    "matchcoord['id_ci'] = pn_NGC3627_ciardullo['ID'][idx]\n",
    "matchcoord['mOIII_ci'] = pn_NGC3627_ciardullo['mOIII'][idx]\n",
    "    \n",
    "matchcoord.sort('mOIII')\n",
    "matchcoord[['id','id_ci','type','mOIII','mOIII_ci','sep']][matchcoord['sep']<=1*u.arcsec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "matchcoord = catalogue[catalogue['gal_name']=='NGC3351'].copy()\n",
    "\n",
    "idx, sep, _  = match_coordinates_sky(matchcoord['SkyCoord'],pn_NGC3351_ciardullo['SkyCoord'])\n",
    "matchcoord['idx'] = idx\n",
    "matchcoord['sep'] = sep.to(u.arcsec)\n",
    "matchcoord['id_ci'] = pn_NGC3351_ciardullo['ID'][idx]\n",
    "matchcoord['mOIII_ci'] = pn_NGC3351_ciardullo['mOIII'][idx]\n",
    "\n",
    "    \n",
    "matchcoord.sort('mOIII')\n",
    "matchcoord[['id','id_ci','type','mOIII','mOIII_ci','sep']][matchcoord['sep']<=1*u.arcsec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "matchcoord = catalogue[catalogue['gal_name']=='NGC5068'].copy()\n",
    "\n",
    "idx, sep, _  = match_coordinates_sky(matchcoord['SkyCoord'],pn_NGC5068_herrmann['SkyCoord'])\n",
    "matchcoord['idx'] = idx\n",
    "matchcoord['sep'] = sep.to(u.arcsec)\n",
    "matchcoord['id_h'] = pn_NGC5068_herrmann['ID'][idx]\n",
    "matchcoord['mOIII_h'] = pn_NGC5068_herrmann['mOIII'][idx]\n",
    "\n",
    "#matchcoord['id_ciardullo'] = pn_NGC3627_ciardullo[idx]['ID'].astype(str)\n",
    "#matchcoord['id_ciardullo'][sep>1*u.arcsec] = ''\n",
    "    \n",
    "matchcoord.sort('mOIII')\n",
    "matchcoord[['id','id_h','type','mOIII','mOIII_h','sep']][matchcoord['sep']<=1*u.arcsec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.char.lstrip(matchcoord['Hpn'],'M74-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "matchcoord.sort('mOIII')\n",
    "\n",
    "matchcoord[(matchcoord['type']=='PN')][['id','mOIII','type','Hpn','Kpn','Ksnr','Rpn']][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined plots\n",
    "\n",
    "this section creates plots where all galaxies are combined into one figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Single PNLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.analyse import MaximumLikelihood1D, pnlf, cdf\n",
    "from pnlf.plot.pnlf import plot_pnlf\n",
    "from pnlf.auxiliary import mu_to_parsec\n",
    "from scipy.stats import kstest\n",
    "\n",
    "name = 'NGC4254'\n",
    "\n",
    "catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "if catalogue_file.is_file():\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "\n",
    "binsize = 0.4 #parameters[name]['binsize']\n",
    "completeness_limit = parameters[name]['completeness_limit']\n",
    "mu = parameters[name]['mu']\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# fit the data\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "data = catalogue['mOIII'][(catalogue['type']=='PN') & (catalogue['mOIII']<completeness_limit)]\n",
    "err = catalogue['dmOIII'][(catalogue['type']=='PN') & (catalogue['mOIII']<completeness_limit)]\n",
    "\n",
    "fitter = MaximumLikelihood1D(pnlf,data,err=err,mhigh=completeness_limit,Mmax=-4.47)\n",
    "mu,mu_p,mu_m = fitter([29])\n",
    "\n",
    "d,(dp,dm)=mu_to_parsec(mu,[mu_p,mu_m])\n",
    "print('{:.2f} + {:.2f} - {:.2f}'.format(mu,mu_p,mu_m))\n",
    "print('{:.2f} + {:.2f} - {:.2f}'.format(d,dp,dm))\n",
    "\n",
    "ks,pv = kstest(data,cdf,args=(mu,completeness_limit))\n",
    "print(f'{name}: statistic={ks:.3f}, pvalue={pv:.3f}')\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "#plot PNLF\n",
    "# ----------------------------------------------------------------------\n",
    "filename = None #basedir / 'reports' / f'{galaxy.name}' / f'{galaxy.name}_PNLF'\n",
    "ax1,ax2 = plot_pnlf(catalogue['mOIII'][(catalogue['type']=='PN')],mu,completeness_limit,\n",
    "                 binsize=binsize,mhigh=29,filename=filename,color=tab10[0])\n",
    "label = f'$(m-M)={mu:.2f}^{{+{mu_p:.2f}}}_{{-{mu_m:.2f}}}$'\n",
    "ax1.text(0.07,0.8,label, transform=ax1.transAxes,fontsize=8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Combined PNLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.plot.pnlf import _plot_pnlf\n",
    "\n",
    "nbins = {'IC5332':5,'NGC0628':6,'NGC1087':3,'NGC1300':2,'NGC1365':3,\n",
    "         'NGC1385':4,'NGC1433':3,'NGC1512':3,'NGC1566':3,'NGC1672':2,\n",
    "         'NGC2835':3,'NGC3351':6,'NGC3627':3,'NGC4254':5,'NGC4303':4,\n",
    "         'NGC4321':4,'NGC4535':3,'NGC5068':5,'NGC7496':3}\n",
    "\n",
    "names = results['name']\n",
    "nrows = 4\n",
    "ncols = 5\n",
    "filename = basedir / 'reports' / f'all_galaxies_PNLF_presentation'\n",
    "\n",
    "#----------------------------------------------\n",
    "# DO NOT MODIFY BELOW\n",
    "#----------------------------------------------\n",
    "if nrows*ncols<len(names):\n",
    "    raise ValueError('not enough subplots for selected objects') \n",
    "width = 8.5 #two_column\n",
    "fig, axes = plt.subplots(nrows=nrows,ncols=ncols,figsize=(width,width/ncols*nrows))\n",
    "axes_iter = iter(axes.flatten())\n",
    "Mmax = -4.47\n",
    "\n",
    "# loop over the galaxies we want to plot\n",
    "for name in names:  \n",
    "\n",
    "    with fits.open(basedir / 'data' / 'catalogues' / f'{name}_classifications.fits') as hdul:\n",
    "        sub = Table(hdul[1].data)\n",
    "    sub['SkyCoord'] = SkyCoord(sub['RaDec'])\n",
    "    sub = sub[~np.isnan(sub['mOIII']) & sub['OIII5006_detection']]\n",
    "    \n",
    "    # get the next axis and find position on the grid\n",
    "    ax = next(axes_iter)\n",
    "    if nrows>1 and ncols>1:\n",
    "        i, j = np.where(axes == ax)\n",
    "        i,j=i[0],j[0]\n",
    "    elif ncols>1:\n",
    "        i,j = 0, np.where(axes==ax)[0]\n",
    "    elif nrows>1:\n",
    "        i,j = np.where(axes==ax)[0],0\n",
    "    else:\n",
    "        i,j=0,0\n",
    "        \n",
    "    # pre-process the data for the plot and read additional parameters\n",
    "    data = sub[(sub['type']=='PN') & (~sub['exclude'])]['mOIII']\n",
    "    mask = sub[(sub['type']=='PN') & (~sub['exclude'])]['overluminous']\n",
    "    \n",
    "    mu = results.loc[name]['(m-M)']\n",
    "    mu_p = results.loc[name]['err+(m-M)']\n",
    "    mu_m = results.loc[name]['err-(m-M)']\n",
    "\n",
    "    completeness = parameters[name]['completeness_limit']\n",
    "\n",
    "    mlow = Mmax+mu\n",
    "    binsize = (completeness-mlow) / nbins[name]\n",
    "    mhigh = completeness+1.5*binsize\n",
    "    \n",
    "    ax=_plot_pnlf(data,mu,completeness,mask,binsize=binsize,mhigh=mhigh,ax=ax,ms=3)\n",
    "\n",
    "        \n",
    "    ylim=ax.get_ylim()\n",
    "    y2 = ylim[1]*1.7\n",
    "    if y2>100:y2=99\n",
    "    ax.set_ylim([0.7,y2])\n",
    "    if name in ['NGC1433','NGC1512']:\n",
    "        ax.set_ylim([None,99])\n",
    "    if name=='NGC1385':\n",
    "        ax.set_ylim([None,12])        \n",
    "    \n",
    "    if name=='NGC2835':\n",
    "        ax.text(0.2,0.07,f'{name}', transform=ax.transAxes,fontsize=7)        \n",
    "    else:\n",
    "        ax.text(0.63,0.07,f'{name}', transform=ax.transAxes,fontsize=7)\n",
    "    \n",
    "    label = f'$(m-M)={mu:.2f}^{{+{mu_p:.2f}}}_{{-{mu_m:.2f}}}$'\n",
    "    ax.text(0.05,0.88,label, transform=ax.transAxes,fontsize=6)\n",
    "    \n",
    "    #ax.set_xlim([mu-5,completeness+0.5])\n",
    "    # add labels to the axis\n",
    "    if i==nrows-1:\n",
    "        ax.set_xlabel(r'$m_{[\\mathrm{O}\\,\\tiny{\\textsc{iii}}]}$ / mag')\n",
    "    if j==0:\n",
    "        ax.set_ylabel(r'$N_\\mathrm{PN}$')\n",
    "    #ax.set_title(name)\n",
    "    #ax.set(xlim=[24,28.5])\n",
    "    \n",
    "axes[3,3].set_xlabel(r'$m_{[\\mathrm{O}\\,\\tiny{\\textsc{iii}}]}$ / mag')\n",
    "ax = next(axes_iter)\n",
    "#ax.remove()\n",
    "h,l = fig.axes[0].get_legend_handles_labels()\n",
    "ax.axis('off')\n",
    "ax.legend(h,l,fontsize=7,loc='center left',frameon=False)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.15, hspace=0.15)\n",
    "#plt.tight_layout()\n",
    "#plt.savefig(filename.with_suffix('.pdf'),bbox_inches='tight')\n",
    "plt.savefig(filename.with_suffix('.png'),bbox_inches='tight',dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Combined cumulative PNLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.plot.pnlf import _plot_cum_pnlf\n",
    "from pnlf.analyse import cdf\n",
    "from scipy.stats import kstest\n",
    "\n",
    "names = results['name']\n",
    "nrows = 4\n",
    "ncols = 5\n",
    "filename = basedir / 'reports' / f'all_galaxies_PNLF_cum_presentation'\n",
    "\n",
    "#----------------------------------------------\n",
    "# DO NOT MODIFY BELOW\n",
    "#----------------------------------------------\n",
    "if nrows*ncols<len(names):\n",
    "    raise ValueError('not enough subplots for selected objects')\n",
    "width = 8.5 #two_column\n",
    "fig, axes = plt.subplots(nrows=nrows,ncols=ncols,figsize=(width,width/ncols*nrows))\n",
    "axes_iter = iter(axes.flatten())\n",
    "\n",
    "binsize=0.1\n",
    "Mmax = -4.47\n",
    "color = 'tab:red'\n",
    "\n",
    "for name in names:  \n",
    "        \n",
    "    with fits.open(basedir / 'data' / 'catalogues' / f'{name}_classifications.fits') as hdul:\n",
    "        sub = Table(hdul[1].data)\n",
    "    sub['SkyCoord'] = SkyCoord(sub['RaDec'])\n",
    "    sub = sub[~np.isnan(sub['mOIII']) & sub['OIII5006_detection']]\n",
    "    \n",
    "    # get the next axis\n",
    "    ax = next(axes_iter)\n",
    "    # find current position on the grid\n",
    "    i, j = np.where(axes == ax)\n",
    "    i,j=i[0],j[0]\n",
    "    \n",
    "    data = sub[(sub['type']=='PN') & (~sub['exclude']) & (~sub['overluminous'])]['mOIII']\n",
    "    mu = results.loc[name]['(m-M)']\n",
    "    completeness = parameters[name]['completeness_limit']\n",
    "\n",
    "    print(name,len(data[data<completeness]))\n",
    "\n",
    "    ks,pv = kstest(data[data<completeness],cdf,args=(mu,completeness))\n",
    "    #print(f'{name}: {len(data[data<completeness])}, {ks:.2f}, {pv:.2f}')\n",
    "    ks,pv = results.loc[name]['KS'],results.loc[name]['pvalue']\n",
    "    \n",
    "    ax=_plot_cum_pnlf(data,mu,completeness,ax=ax,binsize=None,ms=1.5)\n",
    "    if name=='NGC1300':\n",
    "        ax.set(xlim=[27,None])\n",
    "        ax.text(0.03,0.07,f'{name}', transform=ax.transAxes,fontsize=7)\n",
    "    else:\n",
    "        ax.text(0.61,0.07,f'{name}', transform=ax.transAxes,fontsize=7)\n",
    "\n",
    "    ax.text(0.10,0.88,f'$D_{{max}}={ks:.3f}$', transform=ax.transAxes,fontsize=7)\n",
    "    ax.text(0.06,0.78,f'$p$-value$\\ ={pv:.2f}$',transform=ax.transAxes,fontsize=7)\n",
    "    \n",
    "    if name in ['NGC1087','NGC1300']:\n",
    "        ax.set_yticks([0,5,10,15])\n",
    "        \n",
    "    # add labels to the axis\n",
    "    if i==nrows-1:\n",
    "        ax.set_xlabel(r'$m_{[\\mathrm{OIII}]}$ / mag')\n",
    "    if j==0:\n",
    "        ax.set_ylabel(r'Cumulative N')\n",
    "    \n",
    "    \n",
    "    #ax.set_title(name)\n",
    "axes[3,3].set_xlabel(r'$m_{[\\mathrm{OIII}]}$ / mag')\n",
    "ax = next(axes_iter)\n",
    "#ax.remove()\n",
    "\n",
    "#h,l = fig.axes[0].get_legend_handles_labels()\n",
    "ax.axis('off')\n",
    "#ax.legend(h,l,fontsize=7,loc='center left',frameon=False)\n",
    "    \n",
    "plt.subplots_adjust(wspace=0.22, hspace=0.22)\n",
    "#plt.tight_layout()\n",
    "#plt.savefig(filename.with_suffix('.pdf'),bbox_inches='tight')\n",
    "plt.savefig(filename.with_suffix('.png'),bbox_inches='tight',dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "together with SNR (and without loading each catalogue by itself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nebulae = ascii.read(basedir/'data'/'catalogues'/'nebulae.txt')\n",
    "nebulae['SkyCoord'] = SkyCoord(nebulae['RA'],nebulae['DEC'])\n",
    "nebulae['SNRorPN'] = [True if 'PN' in row else False for row in nebulae['note']]\n",
    "nebulae['OL'] = [True if 'OL' in row else False for row in nebulae['note']]\n",
    "nebulae = nebulae[~nebulae['OL']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "from pnlf.analyse import cdf\n",
    "\n",
    "names = results['name']\n",
    "names = ['NGC1087','NGC1365','NGC1385','NGC1512','NGC4321']\n",
    "nrows = 2\n",
    "ncols = 3\n",
    "filename = basedir / 'reports' / f'all_galaxies_PNLF_SNR_cum'\n",
    "\n",
    "#----------------------------------------------\n",
    "# DO NOT MODIFY BELOW\n",
    "#----------------------------------------------\n",
    "if nrows*ncols<len(names):\n",
    "    raise ValueError('not enough subplots for selected objects')\n",
    "width = two_column\n",
    "fig, axes = plt.subplots(nrows=nrows,ncols=ncols,figsize=(width,width/ncols*nrows))\n",
    "axes_iter = iter(axes.flatten())\n",
    "\n",
    "binsize=0.1\n",
    "Mmax = -4.47\n",
    "color = 'tab:red'\n",
    "\n",
    "for name in names:  \n",
    "    \n",
    "    # get the next axis\n",
    "    ax = next(axes_iter)\n",
    "    # find current position on the grid\n",
    "    i, j = np.where(axes == ax)\n",
    "    i,j=i[0],j[0]\n",
    "    \n",
    "    mu = results.loc[name]['(m-M)']\n",
    "    completeness = parameters[name]['completeness_limit']\n",
    "    \n",
    "    data1 = nebulae[(nebulae['gal_name']==name) & (nebulae['type']=='PN')]['mOIII']\n",
    "    data2 = nebulae[(nebulae['gal_name']==name) & ((nebulae['type']=='PN')|((nebulae['type']=='SNR')&nebulae['SNRorPN']))]['mOIII']\n",
    "\n",
    "    data1 = data1[data1<completeness]\n",
    "    data2 = data2[data2<completeness]\n",
    "    N1,N2 = len(data1),len(data2)      \n",
    "    #print(f'{name}: PN: {N1}, PN and SNR: {N2}')\n",
    "\n",
    "    ax.plot(data1,np.arange(1,N1+1,1),ls='-',mfc=tab10[0],mec=tab10[0],ms=1,marker='o',label='PN')\n",
    "    ax.plot(data2,np.arange(1,N2+1,1),ls='-',mfc=tab10[1],mec=tab10[1],ms=1,marker='o',label='PN+SNR')\n",
    "    \n",
    "    # plot the fit\n",
    "    ax.plot(data1,N1*cdf(data1,mu,completeness),ls=':',color='k',label='fit')\n",
    "    ax.plot(data2,N2*cdf(data2,results.loc[name]['mu_SNR'],completeness),ls=':',color='k')\n",
    "    \n",
    "    ks,pv = ks_2samp(data1,data2)\n",
    "    #ks,pv = kstest(data[data<completeness],cdf,args=(mu,completeness))\n",
    "    ax.text(0.55,0.08,f'{name}', transform=ax.transAxes,fontsize=7)\n",
    "    ax.text(0.1,0.78,f'$p$-value$={pv:.2f}$',transform=ax.transAxes,fontsize=7)\n",
    "    ax.text(0.1,0.88,f'$D_{{max}}={ks:.3f}$', transform=ax.transAxes,fontsize=7)\n",
    "\n",
    "    # add labels to the axis\n",
    "    if i==nrows-1:\n",
    "        ax.set_xlabel(r'$m_{[\\mathrm{OIII}]}$ / mag')\n",
    "    if j==0:\n",
    "        ax.set_ylabel(r'Cumulative N')\n",
    "    \n",
    "    #ax.set_title(name)\n",
    "axes[0,2].set_xlabel(r'$m_{[\\mathrm{OIII}]}$ / mag')\n",
    "ax = next(axes_iter)\n",
    "#ax.remove()\n",
    "\n",
    "h,l = fig.axes[0].get_legend_handles_labels()\n",
    "ax.axis('off')\n",
    "ax.legend(h,l,fontsize=7,loc='center left',frameon=False)\n",
    "    \n",
    "plt.subplots_adjust(wspace=0.22, hspace=0.22)\n",
    "#plt.tight_layout()\n",
    "plt.savefig(filename.with_suffix('.pdf'),bbox_inches='tight')\n",
    "#plt.savefig(filename.with_suffix('.png'),bbox_inches='tight',dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Combine line diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.analyse import PNLF\n",
    "\n",
    "style = {'SNR':{\"marker\":'o',\"ms\":3,\"mfc\":'None',\"mec\":tab10[0],'ls':'none','ecolor':tab10[0]},\n",
    "         'SNRorPN':{\"marker\":'o',\"ms\":4,\"mfc\":'white',\"mec\":'tab:green','ls':'none','ecolor':'tab:green'},\n",
    "         'HII':{\"marker\":'+',\"ms\":3,\"mec\":tab10[1],'ls':'none'},\n",
    "         'PN':{\"marker\":'o',\"ms\":2,\"mfc\":'black','mec':'black','ls':'none','ecolor':'black'}\n",
    "        }\n",
    "Mmax=-4.47\n",
    "color = 'tab:red'\n",
    "\n",
    "# define the figure with the number of subplots\n",
    "nrows = 5\n",
    "ncols = 4\n",
    "width = two_column\n",
    "fig, axes_arr = plt.subplots(nrows=nrows,ncols=ncols,figsize=(width,width/ncols*nrows))\n",
    "axes = iter(axes_arr.flatten())\n",
    "\n",
    "\n",
    "names = ['IC5332','NGC0628','NGC1566','NGC3351','NGC3627','NGC5068']\n",
    "\n",
    "# loop over the galaxies we want to plot\n",
    "for name in results['name']:  \n",
    "       \n",
    "    # read in the data\n",
    "    catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "    if catalogue_file.is_file():\n",
    "        catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "        catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "        for col in catalogue.columns:\n",
    "            if col.endswith('detection'):\n",
    "                catalogue[col] = catalogue[col]=='True'\n",
    "    else:\n",
    "        print(f'no catalogue for {name}')\n",
    "        continue\n",
    "        \n",
    "    # get the next axis\n",
    "    ax = next(axes)\n",
    "    # find current position on the grid\n",
    "    i, j = np.where(axes_arr == ax)\n",
    "    i,j=i[0],j[0]\n",
    "    \n",
    "    # pre-process the data for the plot and read additional parameters\n",
    "    mu = results.loc[name]['(m-M)']\n",
    "    completeness = parameters[name]['completeness_limit']\n",
    "    \n",
    "    # draw line that we use seperate PN from HII\n",
    "    MOIII = np.linspace(-5,1)\n",
    "    OIII_Ha = 10**(-0.37*(MOIII)-1.16)\n",
    "    ax.plot(MOIII,OIII_Ha,c='black',lw=0.6)\n",
    "    ax.axhline(10**4)\n",
    "\n",
    "    if completeness:\n",
    "        ax.axvline(completeness-mu,ls='--',c='grey',lw=0.5)\n",
    "    ax.axvline(Mmax,ls='--',c='grey',lw=0.5)\n",
    "\n",
    "    for t in ['HII','PN','SNR']:\n",
    "        tbl = catalogue[catalogue['type']==t]        \n",
    "        ax.errorbar(tbl['mOIII']-mu,tbl['OIII5006']/(tbl['HA6562']+tbl['NII6583']),**style[t],label=t) \n",
    "\n",
    "        if t=='PN':\n",
    "            # indicate for which PN we don't have a detection in HA6562\n",
    "            tbl = tbl[~tbl['HA6562_detection']]\n",
    "            ax.errorbar(tbl['mOIII']-mu,1.11*tbl['OIII5006']/(tbl['HA6562']+tbl['NII6583']),\n",
    "                         marker=r'$\\uparrow$',ms=4,mec='black',ls='none') \n",
    "        if t=='SNR':\n",
    "            #tbl = tbl[tbl['SNRorPN']] \n",
    "            ax.errorbar(tbl['mOIII']-mu,tbl['OIII5006']/(tbl['HA6562']+tbl['NII6583']), marker='x',ms=2,mec=tab10[0],ls='none') \n",
    "   \n",
    "    # objects that were rejeceted by eye\n",
    "    tbl = catalogue[catalogue['exclude']]\n",
    "    ax.errorbar(tbl['mOIII']-mu,tbl['OIII5006']/(tbl['HA6562']+tbl['NII6583']),marker='o',ms=3,ls='none',color='tab:green',label='rejected') \n",
    "    \n",
    "    \n",
    "    # configure axes \n",
    "    ax.set(xlim=[-5,np.ceil(completeness-mu)],\n",
    "           ylim=[0.03,200],\n",
    "           yscale='log')\n",
    "    \n",
    "    ax.yaxis.set_major_formatter(mpl.ticker.FuncFormatter(lambda y, _: '{:.16g}'.format(y)))\n",
    "\n",
    "    axt = ax.twiny()\n",
    "    xlim1,xlim2 = ax.get_xlim()\n",
    "    axt.set_xticks(np.arange(np.ceil(xlim1+mu),np.floor(xlim2+mu)+1),minor=False)\n",
    "    axt.set(xlim   = [xlim1+mu,xlim2+mu])\n",
    "    \n",
    "    if i==0:\n",
    "        axt.set(xlabel = r'$m_{\\mathrm{[OIII]}}$')\n",
    "    \n",
    "    if i==nrows-1:\n",
    "        ax.set(xlabel=r'$M_{\\mathrm{[OIII]}}$')\n",
    "    if j==0:\n",
    "        ax.set(ylabel=r'[OIII] / $(\\mathrm{H}\\alpha + \\mathrm{[NII]})$')\n",
    "    ax.set_title(name)\n",
    "    \n",
    "    ax.xaxis.set_major_locator(mpl.ticker.MaxNLocator(integer=True))\n",
    "    \n",
    "    \n",
    "h,l = fig.axes[0].get_legend_handles_labels()\n",
    "fig.legend(h, l, bbox_to_anchor=(0., 1.01, 1., .051),loc = 'upper center',ncol=4)\n",
    "\n",
    "plt.tight_layout()\n",
    "filename = basedir / 'reports' / f'all_galaxies_line_diagnostics_new'\n",
    "plt.savefig(filename.with_suffix('.pdf'),bbox_inches='tight')\n",
    "#plt.savefig(filename.with_suffix('.png'),bbox_inches='tight',dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.analyse import PNLF\n",
    "\n",
    "style = {'SNR':{\"marker\":'o',\"ms\":3,\"mfc\":'None',\"mec\":tab10[0],'ls':'none','ecolor':tab10[0]},\n",
    "         'SNRorPN':{\"marker\":'o',\"ms\":4,\"mfc\":'white',\"mec\":'tab:green','ls':'none','ecolor':'tab:green'},\n",
    "         'HII':{\"marker\":'+',\"ms\":3,\"mec\":tab10[1],'ls':'none'},\n",
    "         'PN':{\"marker\":'o',\"ms\":2,\"mfc\":'black','mec':'black','ls':'none','ecolor':'black'}\n",
    "        }\n",
    "Mmax=-4.47\n",
    "color = 'tab:red'\n",
    "\n",
    "# define the figure with the number of subplots\n",
    "nrows = 5\n",
    "ncols = 4\n",
    "width = two_column\n",
    "fig, axes_arr = plt.subplots(nrows=nrows,ncols=ncols,figsize=(width,width/ncols*nrows))\n",
    "axes = iter(axes_arr.flatten())\n",
    "\n",
    "\n",
    "names = ['IC5332','NGC0628','NGC1566','NGC3351','NGC3627','NGC5068']\n",
    "\n",
    "# loop over the galaxies we want to plot\n",
    "for name in results['name']:  \n",
    "       \n",
    "    # read in the data\n",
    "    catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "    if catalogue_file.is_file():\n",
    "        catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "        catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "        for col in catalogue.columns:\n",
    "            if col.endswith('detection'):\n",
    "                catalogue[col] = catalogue[col]=='True'\n",
    "    else:\n",
    "        print(f'no catalogue for {name}')\n",
    "        continue\n",
    "        \n",
    "    # get the next axis\n",
    "    ax = next(axes)\n",
    "    # find current position on the grid\n",
    "    i, j = np.where(axes_arr == ax)\n",
    "    i,j=i[0],j[0]\n",
    "    \n",
    "    # pre-process the data for the plot and read additional parameters\n",
    "    mu = results.loc[name]['(m-M)']\n",
    "    completeness = parameters[name]['completeness_limit']\n",
    "    \n",
    "    # draw line that we use seperate PN from HII\n",
    "    ax.axhline(-0.3979)\n",
    "\n",
    "    if completeness:\n",
    "        ax.axvline(completeness-mu,ls='--',c='grey',lw=0.5)\n",
    "    ax.axvline(Mmax,ls='--',c='grey',lw=0.5)\n",
    "\n",
    "    for t in ['HII','PN','SNR']:\n",
    "        tbl = catalogue[catalogue['type']==t]        \n",
    "        ax.errorbar(tbl['mOIII']-mu,np.log10(tbl['SII']/tbl['HA6562']),\n",
    "                    **style[t],label=t) \n",
    "\n",
    "    # objects that were rejeceted by eye\n",
    "    tbl = catalogue[catalogue['exclude']]\n",
    "    ax.errorbar(tbl['mOIII']-mu,np.log10(tbl['SII']/tbl['HA6562']),\n",
    "                 marker='o',ms=3,mfc='tab:green',ls='none',label='rejected') \n",
    "\n",
    "    # configure axes \n",
    "    ax.set(xlim=[-5,np.ceil(completeness-mu)],\n",
    "           ylim=[-1.5,1],\n",
    "           )\n",
    "    \n",
    "    ax.yaxis.set_major_formatter(mpl.ticker.FuncFormatter(lambda y, _: '{:.16g}'.format(y)))\n",
    "\n",
    "    axt = ax.twiny()\n",
    "    xlim1,xlim2 = ax.get_xlim()\n",
    "    axt.set_xticks(np.arange(np.ceil(xlim1+mu),np.floor(xlim2+mu)+1),minor=False)\n",
    "    axt.set(xlim   = [xlim1+mu,xlim2+mu])\n",
    "    \n",
    "    if i==0:\n",
    "        axt.set(xlabel = r'$m_{\\mathrm{[OIII]}}$')\n",
    "    \n",
    "    if i==nrows-1:\n",
    "        ax.set(xlabel=r'$M_{\\mathrm{[OIII]}}$')\n",
    "    if j==0:\n",
    "        ax.set(ylabel=r'$\\log_{10} \\left(I_{[\\mathrm{S}\\,\\textsc{ii}]} \\; /\\; I_{\\mathrm{H}\\,\\alpha} \\right)$')\n",
    "    ax.set_title(name)\n",
    "    \n",
    "    ax.xaxis.set_major_locator(mpl.ticker.MaxNLocator(integer=True))\n",
    "    \n",
    "    \n",
    "h,l = fig.axes[0].get_legend_handles_labels()\n",
    "fig.legend(h, l, bbox_to_anchor=(0., 1.01, 1., .051),loc = 'upper center',ncol=4)\n",
    "\n",
    "plt.tight_layout()\n",
    "filename = basedir / 'reports' / f'all_galaxies_line_diagnostics_SII'\n",
    "plt.savefig(filename.with_suffix('.pdf'),bbox_inches='tight')\n",
    "#plt.savefig(filename.with_suffix('.png'),bbox_inches='tight',dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Combined Completeness limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = basedir/'data'/'interim'\n",
    "files = [x for x in path.iterdir() if x.stem.endswith('mock_sources')]\n",
    "\n",
    "limit   = 0.8\n",
    "max_sep = 0.3\n",
    "\n",
    "ncols = 5\n",
    "nrows = int(np.ceil(len(files)/ncols))\n",
    "\n",
    "width = 2*two_column\n",
    "fig, axes = plt.subplots(nrows=nrows,ncols=ncols,figsize=(width,width/ncols*nrows))\n",
    "axes_iter = iter(axes.flatten())\n",
    "\n",
    "for file in files:\n",
    "    \n",
    "    ax = next(axes_iter)\n",
    "    i, j = np.where(axes == ax)\n",
    "    i,j=i[0],j[0]\n",
    "    \n",
    "    name = file.stem.split('_')[0]\n",
    "    mock_sources = ascii.read(file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "  \n",
    "    hist = []\n",
    "    width = 0.5\n",
    "    bins = np.arange(26,30,width)\n",
    "\n",
    "    for center in bins:\n",
    "        tmp = mock_sources[(mock_sources['magnitude']>center-width/2) & (mock_sources['magnitude']<=center+width/2)]\n",
    "        if len(tmp)>0:\n",
    "            hist.append(np.sum(tmp['sep']<max_sep)/len(tmp))\n",
    "        else:\n",
    "            hist.append(0)\n",
    "    hist = np.array(hist)\n",
    "    \n",
    "    completeness_limit = np.max(bins[hist>=limit])\n",
    "    \n",
    "    ax.axhline(100*limit,color='black',lw=0.6)\n",
    "\n",
    "    ax.bar(bins[hist>=limit],hist[hist>=limit]*100,width=width*0.9,color=tab10[0])\n",
    "    ax.bar(bins[hist<limit],hist[hist<limit]*100,width=width*0.9,fc='white',ec=tab10[0])\n",
    "    \n",
    "    for b,h in zip(bins,hist):\n",
    "        if b>=26.5:\n",
    "            if h>=0.8:\n",
    "                ax.text(b,5,f'{h*100:.0f}\\%',horizontalalignment='center',color='white',fontsize=6)\n",
    "            else:\n",
    "                ax.text(b,5,f'{h*100:.0f}\\%',horizontalalignment='center',color=tab10[0],fontsize=6)\n",
    "    t = ax.text(0.75,0.92,f'{name}', transform=ax.transAxes,color='black',fontsize=7)\n",
    "    t = ax.text(0.75,0.82,f'cl={completeness_limit:.0f}', transform=ax.transAxes,color='black',fontsize=7)\n",
    "\n",
    "    ax.set(xlim=[26.2,29.8],\n",
    "           ylim=[0,100])\n",
    "    \n",
    "    if i==nrows-1:\n",
    "        ax.set(xlabel='m$_{[\\mathrm{OIII}]}$')\n",
    "    else:\n",
    "        ax.set_xticklabels([])\n",
    "    if j==0:\n",
    "        ax.set(ylabel='percentage of recovered objects')\n",
    "    else:\n",
    "        ax.set_yticklabels([])\n",
    "    \n",
    "    #ax.set_title(f'{name}: cl = {completeness_limit}')\n",
    "    \n",
    "for i in range(nrows*ncols-len(files)):\n",
    "\n",
    "    # remove the empty axes at the bottom\n",
    "    ax = next(axes_iter)\n",
    "    ax.remove()\n",
    "\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "\n",
    "filename = basedir / 'reports' / f'all_galaxies_completeness'\n",
    "plt.savefig(filename.with_suffix('.pdf'),bbox_inches='tight')\n",
    "plt.savefig(filename.with_suffix('.png'),bbox_inches='tight',dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.detection import plot_completeness_limit\n",
    "\n",
    "name = 'NGC0628'\n",
    "\n",
    "file = basedir/'data'/'interim'/f'{name}_mock_sources.txt'\n",
    "\n",
    "limit   = 0.8\n",
    "max_sep = 0.3\n",
    "\n",
    "mock_sources = ascii.read(file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "\n",
    "filename = basedir / 'reports' / name / f'{name}_completness.pdf'\n",
    "\n",
    "plot_completeness_limit(mock_sources,max_sep=max_sep,limit=limit,filename=filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### RGB image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.auxiliary import circular_mask\n",
    "from pnlf.plot.plot import create_RGB\n",
    "from pnlf.io import ReadLineMaps\n",
    "\n",
    "nrows = 5\n",
    "ncols = 4\n",
    "width = two_column\n",
    "fig, axes_arr = plt.subplots(nrows=nrows,ncols=ncols,figsize=(width,width/ncols*nrows))\n",
    "axes = iter(axes_arr.flatten())\n",
    "\n",
    "# loop over the galaxies we want to plot\n",
    "for name in results['name']:  \n",
    "        \n",
    "    # get the next axis\n",
    "    ax = next(axes)\n",
    "    # find current position on the grid\n",
    "    i, j = np.where(axes_arr == ax)\n",
    "    i,j=i[0],j[0]\n",
    "    \n",
    "    #galaxy = galaxies[name]\n",
    "    galaxy = ReadLineMaps(data_raw,name,**parameters[name])\n",
    "    \n",
    "    # define masks as slices\n",
    "    masks = {\n",
    "     'NGC1300' : circular_mask(*galaxy.shape,radius=50),\n",
    "     'NGC1365' : circular_mask(*galaxy.shape,(720,420),radius=200),\n",
    "     #'NGC1433' : circular_mask(*galaxy.shape,radius=100),\n",
    "     'NGC1512' : circular_mask(*galaxy.shape,radius=70),\n",
    "     'NGC1566' : circular_mask(*galaxy.shape,(450,450),radius=100)|circular_mask(*galaxy.shape,(350,150),radius=180),\n",
    "     'NGC1672' : circular_mask(*galaxy.shape,(600,310),radius=60),\n",
    "     #'NGC3627' : circular_mask(*galaxy.shape,(330,740),radius=100),\n",
    "     'NGC3351' : circular_mask(*galaxy.shape,radius=200),\n",
    "     'NGC4321' : circular_mask(*galaxy.shape,(550,450),radius=60),\n",
    "     'NGC4535' : circular_mask(*galaxy.shape,(300,520),radius=100)\n",
    "    }\n",
    "    \n",
    "    mask = np.zeros(galaxy.shape,dtype=bool)\n",
    "    mask |= galaxy.star_mask.astype(bool)\n",
    "    mask[masks.get(galaxy.name,(slice(-1,0),slice(-1,0)))] = True\n",
    "\n",
    "    #img = galaxy.OIII5006_DAP.copy()\n",
    "    img = create_RGB(galaxy.HA6562,galaxy.OIII5006_DAP,galaxy.SII6716,weights=[0.6,1,0.6],percentile=[95,99.,95])\n",
    "    img[mask,...] = (1,1,1) #(1, 165/255, 1/255) \n",
    "\n",
    "    ax.imshow(img,origin='lower')\n",
    "    ax.set_title(name)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "filename = basedir / 'reports' / f'all_objects_rgb'\n",
    "plt.savefig(filename.with_suffix('.pdf'),bbox_inches='tight')\n",
    "#plt.savefig(filename.with_suffix('.png'),bbox_inches='tight',dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Overluminous sources\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "name='NGC7496'\n",
    "catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "if catalogue_file.is_file():\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "    catalogue['overluminous'] = catalogue['overluminous'].astype(bool)\n",
    "catalogue[catalogue['overluminous']][['id','mOIII','type','SNRorPN','overluminous']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### RGB image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.io import ReadLineMaps\n",
    "from pnlf.auxiliary import filter_table\n",
    "from pnlf.plot.utils import radial_profile, growth_curve, create_RGB\n",
    "\n",
    "filename = basedir / 'reports' / f'all_galaxies_overluminous'\n",
    "\n",
    "size = 40\n",
    "\n",
    "with fits.open(basedir/'data'/'catalogues'/'PN_candidates.fits') as hdul:\n",
    "    catalogue = Table(hdul[1].data)\n",
    "sample = catalogue[catalogue['note']=='OL']\n",
    "\n",
    "n_objects = len(sample)\n",
    "print(f'plotting cutouts for {n_objects} objects')\n",
    "ncols = 5\n",
    "nrows = int(np.ceil(n_objects/ncols))\n",
    "\n",
    "width = two_column\n",
    "fig, axes = plt.subplots(nrows=nrows,ncols=ncols,figsize=(width,1.05*width/ncols*nrows))\n",
    "axes_iter = iter(axes.flatten())\n",
    "\n",
    "failed = 0\n",
    "for row in sample:\n",
    "    \n",
    "    name = row['gal_name']\n",
    "    galaxy = ReadLineMaps(data_raw/'MUSE'/'DR2.1'/'MUSEDAP',name,**parameters[name])\n",
    "    \n",
    "    print(row['type'])\n",
    "\n",
    "    ax = next(axes_iter)\n",
    "\n",
    "    x,y = row[['x','y']]\n",
    "    aperture_size=2.5*row['fwhm']/2\n",
    "\n",
    "    star = Cutout2D(galaxy.OIII5006, (x,y), u.Quantity((size, size), u.pixel),wcs=galaxy.wcs)\n",
    "\n",
    "\n",
    "    rgb = create_RGB(galaxy.HA6562,galaxy.OIII5006,galaxy.SII6716,percentile=99)\n",
    "    yslice = slice(int(x-size/2),int(x+size/2))\n",
    "    xslice = slice(int(y-size/2),int(y+size/2))\n",
    "\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks([])\n",
    "\n",
    "    try:\n",
    "        im = ax.imshow(rgb[xslice,yslice,:],origin='lower')\n",
    "    except:\n",
    "        text = f'{name}: {id_change[row[\"id\"]]}'\n",
    "        t = ax.text(0.06,0.87,text, transform=ax.transAxes,color='black',fontsize=7)\n",
    "        continue\n",
    "\n",
    "    '''\n",
    "    norm = simple_norm(star.data,clip=False,percent=99)\n",
    "    im = ax.imshow(star.data,norm=norm,origin='lower',cmap=plt.cm.Reds)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks([])\n",
    "    '''\n",
    "\n",
    "    aperture = CircularAperture((size/2+(x-int(x)),size/2+(y-int(y))),aperture_size)\n",
    "    aperture.plot(color='tab:red',lw=0.8,axes=ax)\n",
    "\n",
    "    profile = radial_profile(star.data,star.input_position_cutout)\n",
    "\n",
    "    ax2 = ax.inset_axes([0.02, 0.02, 0.32, 0.25])\n",
    "    ax2.set_yticks([])\n",
    "    ax2.set_xticks([])  \n",
    "\n",
    "    ax2.plot(profile,color='black')\n",
    "    ax2.axvline(aperture_size,color='tab:red',lw=0.5)\n",
    "\n",
    "    text = f'{name}, {id_change.get(row[\"id\"],row[\"id\"])} ({row[\"type\"]})'\n",
    "    #t = ax.text(0.07,0.87,text, transform=ax.transAxes,color='black',fontsize=5)\n",
    "    ax.set_title(text,loc='left',pad=3,fontsize=6)\n",
    "    ax.set(aspect='equal')\n",
    "    #t.set_bbox(dict(facecolor='white', alpha=1, ec='white'))\n",
    "\n",
    "\n",
    "    if (row['mOIII']<results.loc[name]['(m-M)']-3.97) and False:\n",
    "        for loc in ['bottom','top','right','left']:\n",
    "            ax.spines[loc].set_color('tab:orange')\n",
    "            ax.spines[loc].set_linewidth(1)\n",
    "    #t = ax.text(0.05,0.8,f'mOIII={row[\"mOIII\"]:.1f}', transform=ax.transAxes,color='black',fontsize=8)\n",
    "    #t.set_bbox(dict(facecolor='white', alpha=1, ec='white'))\n",
    "\n",
    "for i in range(nrows*ncols-n_objects+failed):\n",
    "    # remove the empty axes at the bottom\n",
    "    ax = next(axes_iter)\n",
    "    ax.remove()\n",
    "    \n",
    "plt.subplots_adjust(wspace=0.05,hspace=0.17)\n",
    "#plt.tight_layout()\n",
    "if filename:\n",
    "    plt.savefig(filename.with_suffix('.png'),dpi=600)\n",
    "    plt.savefig(filename.with_suffix('.pdf'),dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.photometry import light_in_moffat\n",
    "\n",
    "alpha = 2.3\n",
    "fwhm  = 0.9\n",
    "gamma = fwhm / 2 / np.sqrt(2**(1/alpha)-1)\n",
    "\n",
    "light_in_moffat(3*fwhm/2,alpha,gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.plot.utils import radial_profile, growth_curve\n",
    "from astropy.modeling.models import Gaussian2D,Moffat2D,Const2D\n",
    "\n",
    "y, x = np.mgrid[0:51, 0:51]\n",
    "gm1 = Gaussian2D(100, 25, 25, 3, 3)\n",
    "gm2 = Gaussian2D(50, 30, 35, 4, 4)\n",
    "\n",
    "gm1 = Moffat2D(100, 25, 25, alpha=2.3, gamma=5)\n",
    "gm2 = Moffat2D(100, 30, 30, alpha=2.3, gamma=5)\n",
    "gm3 = Const2D(10)\n",
    "\n",
    "g1 = gm1(x, y) + gm3(x,y) +gm2(x,y)\n",
    "\n",
    "fig,(ax1,ax2,ax3)=plt.subplots(ncols=3,figsize=(9,3))\n",
    "\n",
    "ax1.imshow(g1)\n",
    "ax2.plot(growth_curve(g1,np.array(g1.shape)/2))\n",
    "ax3.plot(radial_profile(g1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "make a plot with growth curve, RGB, OIII and Halpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.plot.plot import create_RGB\n",
    "from pnlf.io import ReadLineMaps\n",
    "from pnlf.auxiliary import filter_table\n",
    "from pnlf.plot.plot import radial_profile\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import datetime\n",
    "\n",
    "filename = basedir / 'reports' / f'all_galaxies_overluminous_full'\n",
    "\n",
    "catalogue_file = basedir / 'data' / 'catalogues' / f'nebulae.txt'\n",
    "if catalogue_file.is_file():\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['overluminous'] = catalogue['note']=='OL'\n",
    "    catalogue['exclude'] = catalogue['note']=='EX'\n",
    "\n",
    "size = 40\n",
    "sample = catalogue[catalogue['overluminous']]\n",
    "\n",
    "ncols = 4\n",
    "nrows = 4\n",
    "\n",
    "width = 8.27\n",
    "N = len(sample)\n",
    "Npage = nrows # number we get on each page\n",
    "\n",
    "with PdfPages(filename.with_suffix('.pdf')) as pdf:\n",
    "\n",
    "    for i in range(int(np.ceil(N/Npage))):\n",
    "        print(f'working on page {i+1}')\n",
    "\n",
    "        sub_sample = sample[i*Npage:(i+1)*Npage]\n",
    "\n",
    "        fig, axes = plt.subplots(nrows=nrows,ncols=ncols,figsize=(width,width/ncols*nrows))\n",
    "\n",
    "        for row, (ax1,ax2,ax3,ax4) in zip(sub_sample,axes):  \n",
    "            \n",
    "            name = row['gal_name']\n",
    "            galaxy = ReadLineMaps(data_raw/'MUSE_DR2'/'MUSEDAP',name,**parameters[name])\n",
    "\n",
    "            x,y = row[['x','y']]\n",
    "            aperture_size=2.5*row['fwhm']/2\n",
    "            aperture = CircularAperture((size/2+(x-int(x)),size/2+(y-int(y))),aperture_size)\n",
    "\n",
    "            star = Cutout2D(galaxy.OIII5006, (x,y), u.Quantity((size, size), u.pixel),wcs=galaxy.wcs)\n",
    "            profile = radial_profile(star.data,star.input_position_cutout)\n",
    "\n",
    "            ax1.plot(profile,color='black')\n",
    "            ax1.axvline(aperture_size,color='tab:red',lw=0.5)\n",
    "            text = f'{name}: ID={row[\"id\"]}'\n",
    "            t = ax1.text(0.07,0.87,text, transform=ax1.transAxes,color='black',fontsize=7)\n",
    "            t.set_bbox(dict(facecolor='white', alpha=1, ec='white'))\n",
    "            ax1.axis('off')\n",
    "            \n",
    "            norm = simple_norm(star.data,clip=False,percent=99)\n",
    "            im = ax2.imshow(star.data,norm=norm,origin='lower',cmap=plt.cm.Greens)\n",
    "            aperture.plot(color='black',lw=0.8,axes=ax2)\n",
    "            ax2.axis('off')\n",
    "\n",
    "            star = Cutout2D(galaxy.HA6562, (x,y), u.Quantity((size, size), u.pixel),wcs=galaxy.wcs)\n",
    "            norm = simple_norm(star.data,clip=False,percent=99)\n",
    "            im = ax3.imshow(star.data,norm=norm,origin='lower',cmap=plt.cm.Reds)\n",
    "            aperture.plot(color='black',lw=0.8,axes=ax3)\n",
    "            ax3.axis('off')\n",
    "\n",
    "            rgb = create_RGB(galaxy.HA6562,galaxy.OIII5006,galaxy.SII6716,percentile=99)\n",
    "            yslice = slice(int(x-size/2),int(x+size/2))\n",
    "            xslice = slice(int(y-size/2),int(y+size/2))\n",
    "\n",
    "            im = ax4.imshow(rgb[xslice,yslice,:],origin='lower')\n",
    "            aperture.plot(color='tab:red',lw=0.8,axes=ax4)\n",
    "\n",
    "            ax4.axis('off')\n",
    "        \n",
    "        for (ax1,ax2,ax3,ax4) in axes[Npage-len(sub_sample):]:\n",
    "            print('removing axis')\n",
    "            ax1.axis('off')    \n",
    "            ax2.axis('off')    \n",
    "            ax3.axis('off')    \n",
    "            ax4.axis('off')    \n",
    "        \n",
    "        plt.subplots_adjust(wspace=-0.1, hspace=0)\n",
    "\n",
    "        \n",
    "\n",
    "        pdf.savefig()  # saves the current figure into a pdf page\n",
    "        plt.close()\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Plot all PNe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "catalogue_file = basedir / 'data' / 'catalogues' / f'nebulae.txt'\n",
    "catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "catalogue['overluminous'] = catalogue['note']=='OL'\n",
    "catalogue['exclude'] = catalogue['note']=='EX'\n",
    "catalogue['SkyCoord'] = SkyCoord(catalogue['RA'],catalogue['DEC'])\n",
    "group_distances = ascii.read(basedir/'data'/'literature distances'/'group_distances.txt')\n",
    "group_distances.add_index('Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "name = 'NGC7496'\n",
    "\n",
    "tmp = catalogue[catalogue['gal_name']==name]\n",
    "\n",
    "print(f\"N_PN = {np.sum(tmp['type']=='PN')}\")\n",
    "print(f\"overluminous N_PN = {np.sum((tmp['type']=='PN') & (tmp['overluminous']))}\")\n",
    "print(f\"excluded N_PN = {np.sum((tmp['type']=='PN') & (tmp['exclude']))}\")\n",
    "\n",
    "print(f\"N_SNR = {np.sum(tmp['type']=='SNR')}\")\n",
    "print(f\"overluminous N_SNR = {np.sum((tmp['type']=='SNR') & (tmp['overluminous']))}\")\n",
    "print(f\"excluded N_SNR = {np.sum((tmp['type']=='SNR') & (tmp['exclude']))}\")\n",
    "print(f\"SNR or PN = {np.sum((tmp['type']=='SNR') & (tmp['exclude']))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.io import ReadLineMaps\n",
    "from pnlf.auxiliary import filter_table\n",
    "from pnlf.plot.cutouts import multipage_cutout_with_profile\n",
    "\n",
    "name = 'NGC4254'\n",
    "\n",
    "filename = basedir / 'reports' / name / f'{name}_PN_cutouts'\n",
    "\n",
    "galaxy = ReadLineMaps(data_raw/'MUSE_DR2'/'MUSEDAP',name,**parameters[name])\n",
    "\n",
    "catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "if catalogue_file.is_file():\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "    catalogue['overluminous'] = catalogue['overluminous'].astype(bool)\n",
    "sample = catalogue[(catalogue['mOIII']<28) & (catalogue['type']=='PN')]\n",
    "sample.sort('mOIII')\n",
    "sample = sample[:24]\n",
    "\n",
    "multipage_cutout_with_profile(galaxy,sample,filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Spectrum of those objects\n",
    "I only downloaded datacubes for the DR1 galaxies (IC5332,NGC0628,NGC1087,NGC1365,NGC1512,NGC1566,NGC1672,NGC2835,NGC3351,NGC3627,NGC4254,NGC4535,NGC5068)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.auxiliary import annulus_mask, circular_mask\n",
    "from pnlf.io import ReadLineMaps\n",
    "from pnlf.auxiliary import filter_table\n",
    "\n",
    "name = 'NGC0628'\n",
    "\n",
    "filename = basedir / 'reports' / name / f'{name}_exclude'\n",
    "region_IDs = exclude[name]\n",
    "xlim=[4750,7000]\n",
    "size = 40\n",
    "\n",
    "print(f'plot spectra for {len(region_IDs)} regions')\n",
    "\n",
    "cube_path = Path('g:\\Archive')/'MUSE'/'DR1'/'datacubes'\n",
    "if name not in [x.stem.split('_')[0] for x in cube_path.iterdir()]:\n",
    "    raise FileNotFoundError(f'no datacube for {name}')\n",
    "with fits.open(cube_path / f'{name}_DATACUBE_FINAL.fits' , memmap=True, mode='denywrite') as hdul:\n",
    "    data_cube   = hdul[1].data\n",
    "    cube_header = hdul[1].header\n",
    "    \n",
    "galaxy = ReadLineMaps(data_raw/'MUSE_DR2'/'MUSEDAP',name,**parameters[name])\n",
    "\n",
    "catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "if catalogue_file.is_file():\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "\n",
    "fig = plt.figure(figsize=(two_column,len(region_IDs)*two_column/4)) \n",
    "gs = mpl.gridspec.GridSpec(len(region_IDs), 2, width_ratios=[1,3]) \n",
    "\n",
    "spectra = {}\n",
    "for i,region_ID in enumerate(region_IDs):\n",
    "    \n",
    "    x,y = filter_table(catalogue,id=region_ID)[['x','y']][0]\n",
    "\n",
    "    ax1 = fig.add_subplot(gs[2*i])\n",
    "    ax2 = fig.add_subplot(gs[2*i+1])\n",
    "    \n",
    "    r = Cutout2D(galaxy.OIII5006, (x,y), u.Quantity((size, size), u.pixel),wcs=galaxy.wcs)\n",
    "    norm = simple_norm(r.data,'linear',clip=False,percent=95)\n",
    "    ax1.imshow(r.data, origin='lower',norm=norm,cmap='Greys')\n",
    "\n",
    "    aperture = CircularAperture(r.position_cutout,8)\n",
    "    aperture.plot(color='tab:red',lw=1,axes=ax1)\n",
    "\n",
    "    t = ax1.text(0.07,0.87,f'{region_ID}', transform=ax1.transAxes,color='black',fontsize=7)\n",
    "    t.set_bbox(dict(facecolor='white', alpha=1, ec='white'))\n",
    "    ax1.set_xticks([])\n",
    "    ax1.set_yticks([])\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        # there will be NaNs in the subcube that is used for the sigma clipping\n",
    "        # astropy will issue a warning which we ignore in this enviornment\n",
    "        circle  = circular_mask(*data_cube.shape[1:],(x,y),4)\n",
    "        annulus = annulus_mask(*data_cube.shape[1:],(x,y),8,12) \n",
    "        _, bkg, _ = sigma_clipped_stats(data_cube[...,annulus],axis=1)\n",
    "    \n",
    "    spectrum = np.sum(data_cube[...,circle],axis=1)    \n",
    "    # the background is the median * the number of non zero pixel\n",
    "    spectrum_without_bkg = spectrum - bkg * np.sum(circle)\n",
    "    \n",
    "    #spectra = np.sum(data_cube[...,int(x)-1:int(x)+1,int(y)-1:int(y)+1],axis=(1,2))    \n",
    "    # the wavelenght coverage of MUSE\n",
    "    wavelength = np.linspace(4749.88,9349.88,data_cube.shape[0]) \n",
    "    \n",
    "    ax2.plot(wavelength,spectrum,color=tab10[1],label='with background')\n",
    "    ax2.plot(wavelength,spectrum_without_bkg,color=tab10[0],label='background subtracted')\n",
    "    #ax2.legend() \n",
    "\n",
    "    ax2.set(xlim=xlim,\n",
    "            ylabel=r'erg\\,/\\,s\\,/\\,\\AA')\n",
    "    if i ==0 :\n",
    "        ax2.set_title(name)\n",
    "    if i == len(region_IDs)-1:\n",
    "        ax2.set(xlabel=r'$\\lambda$\\,/\\,\\AA')\n",
    "    else:\n",
    "        ax2.set_xticklabels([])\n",
    "        \n",
    "    ax2.yaxis.tick_right()\n",
    "    ax2.yaxis.set_ticks_position('both')\n",
    "    ax2.yaxis.set_label_position(\"right\")\n",
    "    \n",
    "    # save spectra\n",
    "    spectra[f'{region_ID}_wavelength'] = wavelength\n",
    "    spectra[f'{region_ID}_spectra'] = spectrum\n",
    "    spectra[f'{region_ID}_bkg'] = bkg * np.sum(circle)\n",
    "    \n",
    "plt.subplots_adjust(wspace=0,hspace=0.05)\n",
    "    \n",
    "if filename:\n",
    "    plt.savefig(filename.with_suffix('.pdf'),dpi=600)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.auxiliary import annulus_mask, circular_mask\n",
    "\n",
    "name = 'NGC0628'\n",
    "\n",
    "cube_path = Path('g:\\Archive')/'MUSE'/'DR1'/'datacubes'\n",
    "if name not in [x.stem.split('_')[0] for x in cube_path.iterdir()]:\n",
    "    raise FileNotFoundError(f'no datacube for {name}')\n",
    "with fits.open(cube_path / f'{name}_DATACUBE_FINAL.fits' , memmap=True, mode='denywrite') as hdul:\n",
    "    data_cube   = hdul[1].data\n",
    "    cube_header = hdul[1].header\n",
    "    \n",
    "catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "if catalogue_file.is_file():\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "    \n",
    "\n",
    "def extract_spectra(cube,header,positions,region_ID,filename):\n",
    "    '''extract spectra from a spectral cube at given positions'''\n",
    "    \n",
    "    logger.info(f'extracting spectrum for {len(positions)} objects')\n",
    "    \n",
    "    wavelength = []\n",
    "    spectrum   = []\n",
    "    background = []\n",
    "    \n",
    "    radii = [22.48, 21.42, 22.12]\n",
    "    \n",
    "    for i,pos in enumerate(positions):\n",
    "        print(f'{i+1} of {len(positions)}')\n",
    "        print(radii[i])\n",
    "        x,y=pos\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            # there will be NaNs in the subcube that is used for the sigma clipping\n",
    "            # astropy will issue a warning which we ignore in this enviornment\n",
    "            circle  = circular_mask(*cube.shape[1:],(x,y),radii[i])\n",
    "            annulus = annulus_mask(*cube.shape[1:],(x,y),23,24) \n",
    "            _, bkg, _ = sigma_clipped_stats(cube[...,annulus],axis=1)\n",
    "\n",
    "        spectrum.append(np.sum(data_cube[...,circle],axis=1))  \n",
    "        background.append(bkg * np.sum(circle))\n",
    "        wavelength.append(np.linspace(header['CRVAL3'],header['CRVAL3']+header['NAXIS3']*header['CD3_3'],header['NAXIS3']))\n",
    "    \n",
    "    spectra = Table(data=[region_ID,wavelength,spectrum,background],\n",
    "                    names=['region_ID','wavelenght','spectrum','bkg'])\n",
    "\n",
    "    hdu = fits.BinTableHDU(spectra,name='spectra')\n",
    "    hdu.writeto(filename,overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#positions = catalogue[catalogue['type']=='PN'][['x','y']]\n",
    "#filename = basedir/'data'/'suspicious'/f'{name}_spectra_liz.fits'\n",
    "#extract_spectra(data_cube,cube_header,positions[:50],catalogue[catalogue['type']=='PN']['id'][:50],filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with fits.open(basedir/'data'/'suspicious'/'{}_spectra.fits'.format(name)) as hdul:\n",
    "    spec = Table(hdul[1].data)\n",
    "spec.add_index('region_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dap_path = Path('g:\\Archive')/'MUSE'/'DR1'/'MUSEDAP'/'NGC0628_MAPS.fits'\n",
    "with fits.open(dap_path) as hdul:\n",
    "    wcs = WCS(hdul['FLUX'].header)\n",
    "    \n",
    "\n",
    "ra  = np.array([24.1623,24.1645,24.1888])\n",
    "dec = np.array([15.7701,15.7958,15.7968])\n",
    "\n",
    "p_sk = SkyCoord(ra*u.degree,dec*u.degree)\n",
    "\n",
    "for sk in p_sk:\n",
    "    p_xy.append(sk.to_pixel(wcs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "filename = basedir/'data'/'suspicious'/f'{name}_spectra_liz.fits'\n",
    "extract_spectra(data_cube,cube_header,positions,[1,2,3],filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "p_xy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x,y = p_xy[0]\n",
    "width = 30\n",
    "sub_cube = data_cube[:,int(x)-width:int(x)+width,int(y)-width:int(y)+width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with fits.open(basedir/'data'/'suspicious'/f'{name}_spectra_liz.fits') as hdul:\n",
    "    spec = Table(hdul[1].data)\n",
    "spec.add_index('region_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "p = positions[0]\n",
    "\n",
    "plt.plot(data_cube[:,int(p[0]),int(p[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sub = catalogue[(np.isin(catalogue['type'],['PN','SNR'])) & (catalogue['mOIII']<28)][['id','x','y','RaDec','mOIII','type']]\n",
    "\n",
    "with open(basedir / 'data' / f'{name}_PN_and_SNR.txt','w',newline='\\n') as f:\n",
    "    ascii.write(sub,f,format='fixed_width_two_line',overwrite=True,delimiter_pad=' ',position_char='=')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from spectral_cube import SpectralCube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for sk in p_sk:\n",
    "    sep=sk.separation(catalogue['SkyCoord'])\n",
    "    row = catalogue[np.argmin(sep)]\n",
    "    print(catalogue[sep.__lt__(Angle('10\"'))]['type'])\n",
    "    print(f'{np.min(sep.to(u.arcsec)):.2f}, {row[\"id\"]}, {row[\"type\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## zero point\n",
    "\n",
    "the zeropoint $M*$ of the PNLF must be measured from galaxies with known distances. Ciardullo+2002 suggested a quadratic dependence on metallicity. Here we try to validate this assumption by comparing our measured distances to TRGB distances and infer $M*$. \n",
    "\n",
    "From **Ferrares+2000**\n",
    "\n",
    "The OIII5007 magnitude of the PNLF, m*, uncorrected for foreground extinction, is listed in column (9) of Table 3. Because PNLF distance moduli are calculated by Ðtting the luminosity function with a standard template (e.g., Ciardullo et al. 1989b), only the Ðnal distance moduli are published. From these we derived m* a posteriori by subtracting the zero point (and the extinction correction, if applied) adopted by the authors. The PNLF distances to the SMC, NGC 3109, and NGC 5253, listed in Table 3, are not well constrained. The planetary nebula (PN) sample in NGC 3109 (Richer & McCall 1992) includes only seven objects, and an upper limit to the distance is derived from the brightest of the PNs observed. Jacoby, Walker, & Ciardullo (1990) advise against the use of the PNLF distance to the SMC because of the small number of PNs deÐning the luminosity function. Finally, the small number of PNs detected in NGC 5253, the presence of strong internal dust extinction, and the galaxyÏs very low metal abundance all conjoin to produce a very ill constrained PNLF magnitude cuto†, unsuitable for distance determinations (Phillips et al. 1992). Uncertainties in the values of m* are summarized, for example, in Jacoby, Ciardullo, & Ford (1990). They include a contribution associated with the Ðtting procedure (of the order of 0.10 mag), photometric zero points (D0.05 mag), the Ðlter response calibration (D0.04 mag), and the uncertain deÐnition of the empirical PNLF (D0.05 mag). Errors in the reddening estimate, which are sometimes included, have been removed (in quadrature) from the present analysis, since we only deal with uncorrected magnitudes.\n",
    "\n",
    "we shift the original prescription from Ciardullo\n",
    "$$\n",
    "dM* = 0.928[O/H]^2 +0.225[O/H]+0.014, \n",
    "$$\n",
    "that uses (Grevesse, 12+logOH=8.87) to (Asplund, 12+logOH=8.69). For this we define the difference d=logOH_asplund-logOH_grevesse. With this we can calculate the new parameters as\n",
    "$$\n",
    "a2 = a1 \\\\\n",
    "b2 = b1+2*a2*d \\\\\n",
    "c2 = c1-a2*d^2+b1*d\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# shift formula from Ciardullo+2002 to a new logOH_sun\n",
    "logOH_sun = 8.69 # from Asplund\n",
    "logOH_sun_old = 8.87 # from Greeves\n",
    "\n",
    "d = logOH_sun - 8.87 # difference between Asplund and Greeves\n",
    "a1,b1,c1 = 0.928,0.225,0.014\n",
    "\n",
    "a2 = a1\n",
    "b2 = b1+2*a1*d\n",
    "c2 = c1-a2*d**2+b2*d\n",
    "\n",
    "deltaM_old = lambda OH: a1*OH**2+b1*OH+c1\n",
    "deltaM = lambda OH: a2*OH**2+b2*OH+c2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "the tables with the abundance gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "catalogue = Table(fits.getdata(basedir/'data'/'catalogues'/f'PN_candidates.fits',ext=1))\n",
    "catalogue['overluminous'] = catalogue['note']=='OL'\n",
    "catalogue['exclude'] = catalogue['note']=='EX'\n",
    "catalogue['SkyCoord'] = SkyCoord(catalogue['RA'],catalogue['DEC'])\n",
    "\n",
    "abundance_gradients = ascii.read(basedir/'data'/'external'/'radial_abundance_gradients.txt',\n",
    "                                names=['name','R0','g_r25'])\n",
    "abundance_gradients.add_index('name')\n",
    "\n",
    "pilyugin = ascii.read(basedir/'data'/'external'/'Pilyugin2014.txt')\n",
    "pilyugin.add_index('name')\n",
    "pilyugin.add_row(['SMC',8.03,0.03,-0.03,0.03]+10*[0])\n",
    "pilyugin.add_row(['LMC',8.35,0.03,-0.05,0.05]+10*[0])\n",
    "# missing are\n",
    "#'NGC3368', 'NGC3627', 'NGC5253'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.auxiliary import project\n",
    "\n",
    "def calc_r25(name,x,y):\n",
    "    '''calculate radius in terms of r25 (deprojected)\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # get the pixel position of the centre\n",
    "    with fits.open(data_ext/'MUSE'/'DR2.1'/'MUSEDAP'/f'{name}_MAPS.fits') as hdul:\n",
    "        wcs = WCS(hdul['FLUX'].header)\n",
    "    centre = sample_table.loc[name]['SkyCoord']\n",
    "    x_cen,y_cen = centre.to_pixel(wcs)\n",
    "    \n",
    "    pa  = sample_table.loc[name]['posang']\n",
    "    inc = sample_table.loc[name]['Inclination']\n",
    "    r25 = sample_table.loc[name]['r25']*u.arcmin\n",
    "    \n",
    "    # deproject\n",
    "    x_depr,y_depr = project(x-x_cen,y-y_cen,pa,inc)\n",
    "    skycoord_depr = SkyCoord.from_pixel(x_depr+x_cen,y_depr+y_cen,wcs)\n",
    "    \n",
    "    # separation to centre\n",
    "    sep = skycoord_depr.separation(centre)\n",
    "    \n",
    "    return (sep/r25).decompose()\n",
    "\n",
    "# to get the abundances for all galaxies (used in the sample table)\n",
    "for name in results['name']:\n",
    "    tmp = catalogue[(catalogue['gal_name']==name) & \n",
    "                    (catalogue['type']=='PN') & \n",
    "                    ~catalogue['overluminous'] \n",
    "                   ]\n",
    "    center = sample_table.loc[name]['SkyCoord']\n",
    "\n",
    "\n",
    "    # the catalogue with the positions\n",
    "\n",
    "    radii = calc_r25(name,tmp['x'],tmp['y'])\n",
    "    rmean = np.mean(radii)\n",
    "\n",
    "    logOH = abundance_gradients.loc[name]['R0'] +rmean*abundance_gradients.loc[name]['g_r25']\n",
    "    print(f'{name}:{logOH:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "the table with our measured zero points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "better_Mmax = {'IC5332': (-4.503,0.122,0.169),\n",
    " 'NGC0628': (-4.527,0.133,0.135),\n",
    " 'NGC1365':  (-4.624,0.071,0.069),\n",
    " 'NGC2835': (-4.360,0.165,0.184),\n",
    " 'NGC3351': (-4.139,0.087,0.103),\n",
    " 'NGC3627':(-4.540,0.096,0.116),\n",
    " 'NGC4321': (-4.337,0.211,0.194),\n",
    " 'NGC5068': (-4.570,0.124,0.204)\n",
    "                }\n",
    "\n",
    "# create the table from the results table\n",
    "sample = results[np.isin(results['name'],list(better_Mmax.keys()))][['name','(m-M)','err+(m-M)','err-(m-M)']].copy()\n",
    "sample.add_index('name')\n",
    "\n",
    "# add columns for the fitted zeropoint\n",
    "sample['M*'] = np.nan\n",
    "sample['err+M*'] = np.nan\n",
    "sample['err-M*'] = np.nan\n",
    "sample['dM*'] = np.nan\n",
    "\n",
    "# calculate the mean position (for the abundances)\n",
    "sample['rmean'] = np.nan\n",
    "sample['rmin'] = np.nan\n",
    "sample['rmax'] = np.nan\n",
    "\n",
    "\n",
    "for row in sample:\n",
    "    name = row['name']\n",
    "    \n",
    "    row[['M*','err+M*','err-M*']] = better_Mmax[name]\n",
    "    \n",
    "    tmp = catalogue[(catalogue['gal_name']==name) & (catalogue['type']=='PN') & ~catalogue['overluminous']]\n",
    "    center = sample_table.loc[name]['SkyCoord']\n",
    "\n",
    "    radii = calc_r25(name,tmp['x'],tmp['y'])\n",
    "    row['rmean'] = np.mean(radii)\n",
    "    row['rmin'] = np.min(radii)\n",
    "    row['rmax'] = np.max(radii)\n",
    "\n",
    "sample['dM*'] = sample['M*'] + 4.47\n",
    "\n",
    "sample = join(sample,abundance_gradients,keys='name')\n",
    "sample['logOH'] = sample['R0'] +sample['rmean']*sample['g_r25']\n",
    "sample['logOHmin'] = sample['R0'] +sample['rmax']*sample['g_r25']\n",
    "sample['logOHmax'] = sample['R0'] +sample['rmin']*sample['g_r25']\n",
    "sample.sort('logOH')\n",
    "\n",
    "for col in sample.columns[1:]:\n",
    "    sample[col].info.format = '%.3f'\n",
    "sample.add_index('name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "the table from Ciardullo+2001 with the zero point based on Cepheids distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from astropy.modeling import models, fitting\n",
    "\n",
    "logOH = np.linspace(7.8,9.5)\n",
    "\n",
    "# table from Ciardullo+2002\n",
    "# NGC5253 has dM* =0.33 in paper, NGC300 dM*=0.15\n",
    "# NGC0224 has M*=-4.66 in paper\n",
    "cepheids = Table({\n",
    " 'name':['LMC','SMC','NGC0224','NGC0300','NGC0598','NGC2403','NGC3031','NGC3351','NGC3368','NGC3627','NGC4258','NGC5253','NGC5457'],\n",
    " 'EBV' : [0.075,0.037,0.062,0.013,0.041,0.040,0.080,0.028,0.025,0.032,0.016,0.056,0.009],\n",
    " '(m-M)' : [18.50,19.01 ,24.38 ,26.53 ,24.56 ,27.48 ,27.75 ,29.85 ,29.97 ,29.86 ,29.44 ,27.56 ,29.13],\n",
    " 'err(m-M)' : [0.0,0.03,0.05,0.07,0.10,0.10,0.08,0.09,0.06,0.08,0.07,0.14,0.11],\n",
    " 'M*': [-4.56,-4.67,-4.5,-4.21,-4.08,-4.41,-4.52,-4.39,-4.65,-4.44,-4.51,-4.05,-4.28],\n",
    " '+M*': [0.13,0.40,0.14,0.67,0.16,0.16,0.12,0.19,0.12,0.12,0.13,0.63,0.15],\n",
    " '-M*' : [0.09,0.17,0.11,0.16,0.14,0.13,0.11,0.13,0.11,0.12,0.11,0.16,0.14],\n",
    " 'logOH': [8.50,8.03,8.98,8.35,8.82,8.80,8.75,9.24,9.20,9.25,8.85,8.15,8.50],\n",
    " 'dM*' : [0.06,0.48,0,0,0,0,0,0,0,0,0,0.0,0.06]\n",
    "})\n",
    "cepheids.add_index('name')\n",
    "# dM* has a different meaning in the Cepheid table (some correction form Dopita+92)\n",
    "cepheids['M*'] += cepheids['dM*']\n",
    "cepheids['dM*'] = cepheids['M*']+4.47\n",
    "\n",
    "\n",
    "model  = models.Polynomial1D(degree=2,c0=0.014, c1=0.225, c2= 0.928)\n",
    "fitter = fitting.LinearLSQFitter()\n",
    "fit = fitter(model,cepheids['logOH']-logOH_sun,cepheids['dM*'],weights=1/cepheids['+M*'])\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "ax.errorbar(cepheids['logOH'],cepheids['M*'],yerr=[cepheids['+M*'],cepheids['-M*']],fmt='o')\n",
    "ax.plot(logOH,-4.47+deltaM(logOH-logOH_sun),'k:',lw=1.2,label='Ciardullo+2002',color='gray',zorder=1)\n",
    "for row in cepheids:\n",
    "    ax.text(row['logOH']+0.01,row['M*'],row['name'],\n",
    "         ha='left',fontsize='7',zorder=4)\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set(xlim=[7.8,9.5],ylim=[-3.6,-5])\n",
    "plt.locator_params(axis='y',nbins=10)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "the abundances in Ciardullo+2001 are measured with different methods. Here we update them with values from Pilyugin+2014 (similar to the prescription that we are using)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f'sample before: {len(cepheids)}')\n",
    "# use metallicities from Pilyugin for Cepheids distances from Ciardullo\n",
    "cepheids = join(pilyugin,cepheids)\n",
    "cepheids.add_index('name')\n",
    "cepheids['logOH_new'] = cepheids['R0_O']+0.25*cepheids['g_r25_O']\n",
    "cepheids['errM*'] = cepheids['+M*']\n",
    "print(f'sample after: {len(cepheids)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### measure M* from our data\n",
    "\n",
    "Fit dM* (from TRGB distances) to log (O/H) to determine the zeropoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from astropy.modeling import models, fitting\n",
    "from pnlf.fit import linearMLE\n",
    "\n",
    "model  = models.Polynomial1D(degree=2,c0=0.014, c1=0.225, c2= 0.928)\n",
    "fitter = fitting.LinearLSQFitter(calc_uncertainties=True)\n",
    "\n",
    "# ----------------------------------------------\n",
    "# fit a constant line\n",
    "# ----------------------------------------------\n",
    "\n",
    "model  = models.Polynomial1D(degree=1,c0=-4.5, c1=0)\n",
    "model.c1.fixed=True\n",
    "sub = sample\n",
    "fit = fitter(model,sub['logOH'],sub['M*'],weights=1/sub['err+M*'])\n",
    "Mmax_fit = fit.c0.value\n",
    "Mmax_errp = fit._stds.stds[0]\n",
    "Mmax_errm = fit._stds.stds[0]\n",
    "print(f'PHANGS: M*={Mmax_fit:.3f}+-{Mmax_errp:.3f}')\n",
    "\n",
    "sub = cepheids[~np.isin(cepheids['name'],['SMC','NGC5253','NGC0300'])]\n",
    "fit = fitter(model,sub['logOH'],sub['M*'],weights=1/sub['+M*'])\n",
    "print(f'Ciardullo: M*={fit.c0.value:.3f}+-{fit._stds.stds[0]:.3f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "sample.sort('logOH')\n",
    "x = np.array(sample['logOH'])\n",
    "y = np.array(sample['M*'])\n",
    "yerr = np.array(sample['err+M*'])\n",
    "names = sample['name']\n",
    "\n",
    "loglikelihood = lambda b: -np.sum(np.log(1/np.sqrt(2*np.pi*yerr**2) * np.exp(-(y-b)**2/(2*yerr**2))))\n",
    "\n",
    "Mmax_fit = minimize(loglikelihood,-4.5).x[0]\n",
    "\n",
    "# calculate errors\n",
    "x_arr =np.linspace(-4.2,-4.8)\n",
    "\n",
    "likelihood = np.exp([-loglikelihood(b) for b in x_arr])\n",
    "valid = ~np.isnan(likelihood) \n",
    "\n",
    "likelihood /= np.abs(np.trapz(likelihood[valid],x_arr [valid]))\n",
    "normalization = np.trapz(likelihood,x_arr )\n",
    "integral = np.array([np.trapz(likelihood[x_arr<=xp],x_arr[x_arr<=xp])/normalization for xp in x_arr[1:]])\n",
    "# 1 sigma interval for cumulative likelihood\n",
    "mid = np.argmin(np.abs(integral-0.5))\n",
    "high = np.argmin(np.abs(integral-0.8415))\n",
    "low = np.argmin(np.abs(integral-0.1585))\n",
    "\n",
    "Mmax_errp = x_arr[high]-Mmax_fit\n",
    "Mmax_errm = Mmax_fit-x_arr[low]\n",
    "        \n",
    "print(f'Mmax = {Mmax_fit:.3f}+{Mmax_errp:.3f}-{Mmax_errm:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "\n",
    "ax.plot(x_arr[:-1],integral)\n",
    "\n",
    "ax.axhline(0.1585,color='black')\n",
    "ax.axhline(0.5,color='black')\n",
    "ax.axhline(0.8415,color='black')\n",
    "\n",
    "#ax.axvline(x_arr[mid],color='black')\n",
    "#ax.axvline(x_arr[low],color='gray')\n",
    "#ax.axvline(x_arr[high],color='gray')\n",
    "\n",
    "ax.axvline(Mmax_fit,color='black')\n",
    "ax.axvline(Mmax_fit-Mmax_errm,color='gray')\n",
    "ax.axvline(Mmax_fit+Mmax_errp,color='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(x_arr[low])\n",
    "print(x_arr[mid])\n",
    "print(x_arr[high])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "or with MCMC\n",
    "\n",
    "https://dfm.io/posts/mixture-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.fit import linearMLE\n",
    "\n",
    "sample = sample\n",
    "x = np.array(sample['logOH'])\n",
    "y = np.array(sample['M*'])\n",
    "yerr = np.array((sample['err+M*']+sample['err-M*'])/2)\n",
    "yerr = np.array(sample['err+M*'])\n",
    "\n",
    "names = list(sample['name'])\n",
    "\n",
    "bounds = [(-1e-5, 1e-5), (-5,-4), (0, 1), (-5,-4), (-5, 2)]\n",
    "p0 = np.array([0.0, -4.5, 0.9, np.mean(y), np.log(np.var(y))])\n",
    "\n",
    "fitter = linearMLE(x,y,yerr,bounds)\n",
    "result = fitter.fit(p0)\n",
    "fitter.outlier()\n",
    "ax = fitter.plot(xlim=[8.3,8.7],ylim=[-5.,-3.8],xlabel='logOH',ylabel='M*')\n",
    "#ax.text(lit_dist.loc['NGC4535']['logOH']-0.01,lit_dist.loc['NGC4535']['M*']+0.03,'NGC4535',\n",
    "#         ha='right',va='top',fontsize=6,zorder=4)\n",
    "#ax.text(lit_dist.loc['NGC3351']['logOH']+0.01,lit_dist.loc['NGC3351']['M*']+0.03,'NGC3351',\n",
    "#         ha='left',va='top',fontsize=6,zorder=4)\n",
    "ax.invert_yaxis()\n",
    "\n",
    "x0 = np.linspace(*[8.3,8.7],100)\n",
    "A = np.vander(x0, 2)\n",
    "lines = np.dot(fitter.sampler.flatchain[:, :2], A.T)\n",
    "quantiles = np.percentile(lines, [16, 84], axis=0)\n",
    "\n",
    "Mmax_fit  = np.mean(fitter.results[\"b\"][0])\n",
    "Mmax_errp = np.mean(quantiles[1]) - Mmax_fit\n",
    "Mmax_errm = Mmax_fit - np.mean(quantiles[0])\n",
    "Mmax_fit, Mmax_errm, Mmax_errp = fitter.results['b']\n",
    "\n",
    "print(f'Mmax = {Mmax_fit:.3f}+{Mmax_errp:.3f}-{Mmax_errm:.3f}')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "post_prob = fitter.outlier(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "\n",
    "ax.hist(fitter.sampler.flatchain[:,1],bins=np.linspace(-4.8,-4.4,50))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "and now the final plot for the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "cmap1 = LinearSegmentedColormap.from_list(\"mycmap\", ['white','tab:orange'])\n",
    "\n",
    "logOH = np.linspace(7.8,9.5)\n",
    "logOH_sun_new = 8.69   # Asplund\n",
    "\n",
    "fig,(ax1,ax2) = plt.subplots(nrows=2,figsize=(single_column,single_column),sharex='col')\n",
    "\n",
    "# plot data from Ciardullo+2002\n",
    "ax1.errorbar(cepheids['logOH_new'],cepheids['M*'],\n",
    "            yerr=[cepheids['+M*'],cepheids['-M*']],capsize=0,\n",
    "            fmt='o',color=tab10[4],mec=tab10[4],ms=2.5,elinewidth=0.5,label='Cepheids',zorder=3)\n",
    "ax1.plot(logOH,-4.47+deltaM(logOH-logOH_sun),'k:',lw=1.2,label='model',color='gray',zorder=1)\n",
    "\n",
    "ax1.text(cepheids.loc['NGC3351']['logOH_new']-0.01,cepheids.loc['NGC3351']['M*'],'NGC3351',\n",
    "         ha='right',va='top',fontsize='4',zorder=4)\n",
    "ax1.text(cepheids.loc['SMC']['logOH_new']+0.01,cepheids.loc['SMC']['M*'],'SMC',\n",
    "         ha='left',fontsize='4',zorder=4)\n",
    "ax1.text(cepheids.loc['LMC']['logOH_new']-0.01,cepheids.loc['LMC']['M*'],'LMC',\n",
    "         ha='right',fontsize='4',zorder=4)\n",
    "\n",
    "# plot our own data\n",
    "sample['xerrp'] = list(sample['logOHmax']-sample['logOH'])\n",
    "sample['xerrm'] = list(sample['logOH']-sample['logOHmin'])\n",
    "ax2.errorbar(sample['logOH'],sample['M*'],\n",
    "             xerr=[sample['xerrm'],sample['xerrp']],\n",
    "             yerr=[sample['err-M*'],sample['err+M*']],\n",
    "            fmt='o',mew=0.5,color=tab10[2],ms=2.5,elinewidth=0.5,label='TRGB',zorder=3)\n",
    "ax2.plot(logOH,-4.47+deltaM(logOH-logOH_sun),'k:',lw=1.2,color='gray',zorder=1)\n",
    "\n",
    "#ax2.scatter(fitter.x, fitter.y, marker=\"o\", s=10,c=fitter.post_prob, cmap=cmap1,\n",
    "#           edgecolors='tab:orange',linewidths=0.5,vmin=0, vmax=1, zorder=1000)\n",
    "\n",
    "#print(Mmax_fit)\n",
    "ax2.fill_between([8,8.8], 2*[Mmax_fit-Mmax_errm],2*[Mmax_fit+Mmax_errp],color=\"silver\",edgecolor='face',alpha=1,zorder=0)    \n",
    "ax2.plot([8,8.8],[Mmax_fit,Mmax_fit],lw=0.8,color='black',label='fit')\n",
    "\n",
    "for name in ['NGC3351']:\n",
    "    ax2.text(sample.loc[name]['logOH']+0.01,sample.loc[name]['M*']-0.05,name,\n",
    "             ha='left',fontsize='4',zorder=4)\n",
    "\n",
    "ax1.locator_params(axis='y',nbins=3)\n",
    "ax2.locator_params(axis='y',nbins=3)\n",
    "\n",
    "#for x in [-4.47,-4.5]:\n",
    "#    ax2.axhline(x,color='blue',lw=0.2)\n",
    "\n",
    "ax1.set(xlim=[8,8.8],ylim=[-5.1,-3.6],ylabel=r'$M^*$ / mag')\n",
    "ax2.set(xlim=[8,8.8],ylim=[-5.1,-3.6],xlabel=r'$12+\\log (\\mathrm{O}/\\mathrm{H})$',ylabel=r'$M^*$ / mag')\n",
    "ax1.invert_yaxis()\n",
    "ax2.invert_yaxis()\n",
    "\n",
    "lines = []\n",
    "labels = []\n",
    "for ax in fig.axes:\n",
    "    h, l = ax.get_legend_handles_labels()\n",
    "    lines.extend(h[::-1])\n",
    "    labels.extend(l[::-1])\n",
    "myorder = [0,2,1,3]\n",
    "lines = [lines[i] for i in myorder]\n",
    "labels = [labels[i] for i in myorder]\n",
    "\n",
    "#ax1.legend(ncol=2)\n",
    "ax2.legend(lines, labels,ncol=1,loc=3)\n",
    "plt.subplots_adjust(wspace=0.05,hspace=0.0)\n",
    "\n",
    "plt.savefig(basedir/'reports'/'zeropoint.pdf',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "the M* that we measure is smaller (fainter) than what we previously used. This would slightly decrease our measured distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "N = 15\n",
    "x0 = np.linspace(0,10)\n",
    "x = np.random.uniform(0,10,N)\n",
    "x.sort()\n",
    "y = -4+2*x+np.random.normal(0,0.51,N)\n",
    "yerr = np.random.normal(1,0.1,N)\n",
    "y[5] +=6\n",
    "\n",
    "bounds = [(-5,5), (-5,5), (0, 1), (-5,5), (-2, 4)]\n",
    "p0 = np.array([0.0, 1, 0.9, 0, np.log(1.0)])\n",
    "\n",
    "fitter = linearMLE(x,y,yerr,bounds)\n",
    "fitter.fit(p0)\n",
    "print('m={:.2f}+{:.2f}-{:.2f}, b={:.2f}+{:.2f}-{:.2f}'.format(*fitter.results['m'],*fitter.results['b']))\n",
    "#print(fitter)\n",
    "outlier=fitter.outlier()\n",
    "ax = fitter.plot(xlim=[0,10],xlabel='x',ylabel='y')\n",
    "ax.plot(x0,-4+2*x0,color='black',lw=1)\n",
    "\n",
    "'''\n",
    "model  = models.Polynomial1D(degree=1,c0=-4, c1=1)\n",
    "LinearLSQFitter = fitting.LinearLSQFitter(calc_uncertainties=True)\n",
    "fit = LinearLSQFitter(model,x,y,weights=1/yerr)\n",
    "ax.plot(x,fit.c0.value+fit.c1.value*x,color='blue',lw=2)\n",
    "print(f'm={fit.c1.value:.2f}+-{fit._stds.stds[1]:.2f}, b={fit.c0.value:.2f}+-{fit._stds.stds[0]:.2f}')\n",
    "ax.set(xlim=[-1,10])\n",
    "'''\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Literature search\n",
    "\n",
    "the following galaxies are in Ciardullo+2002 and in Pilyugin\n",
    "\n",
    "NGC0300, NGC5457 (M101), NGC3031 (M81), NGC2403, NGC0598 (M33), NGC4258, NGC0224 (M31), NGC3351\n",
    "\n",
    "missing are\n",
    "\n",
    "LMC,SMC (from ToribioSanCipriano+2017)\n",
    "\n",
    "NGC5253,NGC3368,NGC3627\n",
    "\n",
    "**this does not work**: the authors use different $M^*$. To properly do this, one has to go through all the papers by hand and find out what values was used. Since some papers used different values for different galaxies (or did not give any value at all) it becomes extremely tedious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# prepare the literature distances\n",
    "messier_to_ngc = {\n",
    "     'M001': 'NGC1952','M002': 'NGC7089','M003': 'NGC5272','M004': 'NGC6121','M005': 'NGC5904',\n",
    "     'M006': 'NGC6405','M007': 'NGC6475','M008': 'NGC6523','M009': 'NGC6333','M010': 'NGC6254',\n",
    "     'M011': 'NGC6705','M012': 'NGC6218','M013': 'NGC6205','M014': 'NGC6402','M015': 'NGC7078',\n",
    "     'M016': 'NGC6611','M017': 'NGC6618','M018': 'NGC6613','M019': 'NGC6273','M020': 'NGC6514',\n",
    "     'M021': 'NGC6531','M022': 'NGC6656','M023': 'NGC6494','M024': 'NGC6603','M026': 'NGC6694',\n",
    "     'M027': 'NGC6853','M028': 'NGC6626','M029': 'NGC6913','M030': 'NGC7099','M031': 'NGC0224',\n",
    "     'M032': 'NGC0221','M033': 'NGC0598','M034': 'NGC1039','M035': 'NGC2168','M036': 'NGC1960',\n",
    "     'M037': 'NGC2099','M038': 'NGC1912','M039': 'NGC7092','M041': 'NGC2287','M042': 'NGC1976',\n",
    "     'M043': 'NGC1982','M044': 'NGC2632','M046': 'NGC2437','M047': 'NGC2422','M048': 'NGC2548',\n",
    "     'M049': 'NGC4472','M050': 'NGC2323','M051': 'NGC5194','M052': 'NGC7654','M053': 'NGC5024',\n",
    "     'M054': 'NGC6715','M055': 'NGC6809','M056': 'NGC6779','M057': 'NGC6720','M058': 'NGC4579',\n",
    "     'M059': 'NGC4621','M060': 'NGC4649','M061': 'NGC4303','M062': 'NGC6266','M063': 'NGC5055',\n",
    "     'M064': 'NGC4826','M065': 'NGC3623','M066': 'NGC3627','M067': 'NGC2682','M068': 'NGC4590',\n",
    "     'M069': 'NGC6637','M070': 'NGC6681','M071': 'NGC6838','M072': 'NGC6981','M073': 'NGC6994',\n",
    "     'M074': 'NGC0628','M075': 'NGC6864','M076': 'NGC0650','M077': 'NGC1068','M078': 'NGC2068',\n",
    "     'M079': 'NGC1904','M080': 'NGC6093','M081': 'NGC3031','M082': 'NGC3034','M083': 'NGC5236',\n",
    "     'M084': 'NGC4374','M085': 'NGC4382','M086': 'NGC4406','M087': 'NGC4486','M088': 'NGC4501',\n",
    "     'M089': 'NGC4552','M090': 'NGC4569','M091': 'NGC4548','M092': 'NGC6341','M093': 'NGC2447',\n",
    "     'M094': 'NGC4736','M095': 'NGC3351','M096': 'NGC3368','M097': 'NGC3587','M098': 'NGC4192',\n",
    "     'M099': 'NGC4254','M100': 'NGC4321','M101': 'NGC5457','M102': 'NGC5866','M103': 'NGC0581',\n",
    "     'M104': 'NGC4594','M105': 'NGC3379','M106': 'NGC4258','M107': 'NGC6171','M108': 'NGC3556',\n",
    "     'M109': 'NGC3992','M110': 'NGC0205'}\n",
    "\n",
    "distances = ascii.read(basedir/'data'/'literature distances'/'latest.csv',delimiter=',',header_start=12,data_start=14)\n",
    "distances.rename_column('Galaxy ID','gal_name')\n",
    "\n",
    "def replace_values_in_string(text, args_dict):\n",
    "    for key in args_dict.keys():\n",
    "        text = text.replace(key, str(args_dict[key]))\n",
    "    return text\n",
    "\n",
    "distances['gal_name'] = [replace_values_in_string(s,{'IC ':'IC','MESSIER ':'M','NGC ':'NGC'}) for s in distances['gal_name']]\n",
    "distances['gal_name'] = [messier_to_ngc.get(s,s) for s in distances['gal_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pnlf_sample = set(filter_table(distances,Method='PNLF')['gal_name'])\n",
    "trgb_sample = set(filter_table(distances,Method='TRGB')['gal_name'])\n",
    "cepheid_sample = set(filter_table(distances,Method='Cepheids')['gal_name'])\n",
    "\n",
    "distance_sample = pnlf_sample & (trgb_sample|cepheid_sample)\n",
    "abundance_sample = set(pilyugin['name'])\n",
    "\n",
    "sample = distance_sample & abundance_sample\n",
    "\n",
    "print(f'PNLF: {len(pnlf_sample)}\\nTRGB: {len(trgb_sample)}\\nCepheids: {len(cepheid_sample)}')\n",
    "print(f'PNLF & (TRGB|Cepheids): {len(distance_sample)}\\nAbundances: {len(abundance_sample)}')\n",
    "print(f'combined: {len(sample)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "combine tables with abundances and distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lit_dist = Table(names=['name','(m-M)_PNLF','err(m-M)_PNLF','(m-M)_ref','err(m-M)_ref',\n",
    "                        'R0','g25','N_PN','N_ref','source'],dtype=[str]+8*[float]+[str])\n",
    "for gal_name in sample-{'NGC0628','NGC3351','NGC5068'}:\n",
    "    pnlf_dist = filter_table(distances,gal_name=gal_name,Method='PNLF')\n",
    "    ref_dist = filter_table(distances,gal_name=gal_name,Method=['TRGB','Cepheids'])\n",
    "    abund = pilyugin.loc[gal_name]\n",
    "    err_pnlf = np.sqrt(np.sum(pnlf_dist['err']**2)/len(pnlf_dist))\n",
    "    err_ref = np.sqrt(np.sum(ref_dist['err']**2)/len(ref_dist))\n",
    "    \n",
    "    lit_dist.add_row([gal_name,\n",
    "                      pnlf_dist['m-M'].mean(),err_pnlf,\n",
    "                      ref_dist['m-M'].mean(),err_ref,\n",
    "                      abund['R0_O'],abund['g_r25_O'],\n",
    "                      len(pnlf_dist),len(ref_dist),'literature'])\n",
    "\n",
    "# we add our own data to the sample\n",
    "for name in ['IC5332','NGC0628','NGC1365','NGC2835','NGC3351','NGC3627','NGC4321','NGC4535','NGC5068']:  \n",
    "    lit_dist.add_row([name,\n",
    "                      results.loc[name]['(m-M)'],results.loc[name]['err-(m-M)'],\n",
    "                      sample_table.loc[name]['(m-M)'],sample_table.loc[name]['err(m-M)'],\n",
    "                      abundance_gradients.loc[name]['R0'],abundance_gradients.loc[name]['g_r25'],\n",
    "                      1,1,'PHANGS'])\n",
    "    \n",
    "lit_dist['logOH'] = lit_dist['R0']+0.25*lit_dist['g25']\n",
    "\n",
    "lit_dist['dM*'] = lit_dist['(m-M)_PNLF']-lit_dist['(m-M)_ref']\n",
    "lit_dist['M*'] = -4.47+lit_dist['dM*']\n",
    "lit_dist['errM*'] = np.sqrt(lit_dist['err(m-M)_PNLF']**2 + lit_dist['err(m-M)_ref'])\n",
    "lit_dist.sort('logOH')\n",
    "lit_dist.add_index('name')\n",
    "\n",
    "# M* for SMC is weird\n",
    "lit_dist.loc['SMC']['M*']  = cepheids.loc['SMC']['M*']\n",
    "lit_dist.loc['SMC']['dM*'] = cepheids.loc['SMC']['dM*']\n",
    "\n",
    "# update the values to the fit\n",
    "for k,v in Mmax_dict.items():\n",
    "    lit_dist.loc[k]['M*'] = v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "additional metallicities (SMC,LMC and NGC5253)\n",
    "https://www.aanda.org/articles/aa/pdf/2013/02/aa20580-12.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from astropy.modeling import models, fitting\n",
    "\n",
    "logOH = np.linspace(7,10)\n",
    "logOH_sun = 8.69   # Asplund\n",
    "deltaM = lambda OH: 0.928*OH**2-0.1091*OH+0.0036\n",
    "\n",
    "# polynom\n",
    "model  = models.Polynomial1D(degree=2,c0=0.014, c1=0.225, c2= 0.928)\n",
    "fitter = fitting.LinearLSQFitter(calc_uncertainties=True)\n",
    "fit = fitter(model,lit_dist['logOH'][lit_dist['source']=='literature']-logOH_sun,\n",
    "             lit_dist['dM*'][lit_dist['source']=='literature'],\n",
    "             weights=1/lit_dist['errM*'][lit_dist['source']=='literature'])\n",
    "#fit = fitter(model,lit_dist['logOH']-logOH_sun,lit_dist['dM*'],weights=1/lit_dist['errM*'])\n",
    "\n",
    "fig,ax = plt.subplots(nrows=1,figsize=(single_column,single_column/1.618))\n",
    "\n",
    "ax.errorbar(lit_dist['logOH'][lit_dist['source']=='literature'],lit_dist['M*'][lit_dist['source']=='literature'],\n",
    "            yerr=lit_dist['errM*'][lit_dist['source']=='literature'],capsize=0,\n",
    "            fmt='o',color=tab10[1],mec=tab10[1],ms=2,elinewidth=0.5,label='literature',zorder=3)\n",
    "ax.errorbar(lit_dist['logOH'][lit_dist['source']=='PHANGS'],lit_dist['M*'][lit_dist['source']=='PHANGS'],\n",
    "            yerr=lit_dist['errM*'][lit_dist['source']=='PHANGS'],capsize=0,\n",
    "            fmt='o',color=tab10[0],mec=tab10[0],ms=2,elinewidth=0.5,label='PHANGS',zorder=3)\n",
    "\n",
    "ax.plot(logOH,-4.47+deltaM(logOH-logOH_sun),ls=':',lw=1.2,label='Ciardullo',color='gray',zorder=1)\n",
    "#ax.plot(logOH, -4.47+fit(logOH-logOH_sun),ls='-',lw=0.8,label='fit',color='black',zorder=1)\n",
    "\n",
    "halign = {'SMC':'right','NGC0055':'left','NGC5068':'left','NGC0598':'left',\n",
    "          'NGC0628':'right','NGC6946':'left','NGC1365':'left','NGC5457':'left'}\n",
    "valign = {'IC0010':'bottom','NGC5068':'bottom','LMC':'bottom','NGC0598':'bottom',\n",
    "          'IC5332':'bottom','NGC6946':'bottom','NGC1365':'bottom','NGC3627':'bottom',\n",
    "          'NGC0628':'bottom','NGC0253':'bottom','SMC':'bottom'}\n",
    "\n",
    "for row in lit_dist:\n",
    "    ax.text(row['logOH'],row['M*'],row['name'],\n",
    "            ha=halign.get(row['name'],'right'),\n",
    "            va=valign.get(row['name'],'top'),\n",
    "            fontsize='3',zorder=4,rotation=90)\n",
    "\n",
    "\n",
    "plt.locator_params(axis='y',nbins=5)\n",
    "\n",
    "# constant\n",
    "model  = models.Polynomial1D(degree=1,c0=-4.5, c1=0)\n",
    "model.c1.fixed=True\n",
    "sub = lit_dist[lit_dist['logOH']>8.3]\n",
    "\n",
    "fit = fitter(model,sub['logOH'][sub['source']=='PHANGS'],sub['M*'][sub['source']=='PHANGS'],weights=1/sub['errM*'][sub['source']=='PHANGS'])\n",
    "print(f'PHANGS: M*={fit.c0.value:.2f}+-{fit._stds.stds[0]:.2f}')\n",
    "\n",
    "fit = fitter(model,sub['logOH'],sub['M*'],weights=1/sub['errM*'])\n",
    "print(f'All: M*={fit.c0.value:.2f}+-{fit._stds.stds[0]:.2f}')\n",
    "\n",
    "ax.axhline(fit.c0.value,ls='-',lw=0.8,color='k',zorder=2,label='fit')\n",
    "\n",
    "'''\n",
    "# linear\n",
    "model  = models.Polynomial1D(degree=1)\n",
    "fit = fitter(model,lit_dist['logOH'],lit_dist['M*'],weights=1/lit_dist['errM*'])\n",
    "ax.plot(logOH,fit(logOH),ls='--',lw=0.8,color='black',zorder=1)\n",
    "'''\n",
    "\n",
    "ax.set(xlim=[8,8.82],ylim=[-5.2,-3.2],ylabel=r'$M^*$ / mag')\n",
    "ax.set(xlim=[8,8.82],ylim=[-5.2,-3.2],xlabel=r'$12+\\log (\\mathrm{O}/\\mathrm{H})$',ylabel=r'$M^*$ / mag')\n",
    "ax.invert_yaxis()\n",
    "ax.legend(ncol=2,loc=4)\n",
    "\n",
    "plt.savefig(basedir/'reports'/'zeropoint_literature.pdf',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(5,5))\n",
    "\n",
    "for row in lit_dist[lit_dist['source']=='literature']:\n",
    "    if row['name'] in cepheids['name']:\n",
    "        ax.scatter(row['M*'],cepheids.loc[row['name']]['M*'])\n",
    "ax.plot([-4.8,-4.1],[-4.8,-4.1],c='k')\n",
    "ax.set(xlabel='M* literature',ylabel='M* Ciardullo+2002')\n",
    "ax.invert_xaxis()\n",
    "ax.invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### fix $(m-M)$ and fit $M*$\n",
    "\n",
    "we fix $(m-M)$ to the TRGB value and leave $M*$ as a free parameter \n",
    "\n",
    "IC5332,NGC0628,NGC1365,NGC1433,NGC1512,NGC1566,NGC2835,NGC3351,NGC3627,NGC4321,NGC5068"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "catalogue = Table(fits.getdata(basedir/'data'/'catalogues'/f'nebulae.fits',ext=1))\n",
    "#catalogue['overluminous'] = catalogue['note']=='OL'\n",
    "#catalogue['exclude'] = catalogue['note']=='EX'\n",
    "catalogue['SkyCoord'] = SkyCoord(catalogue['RaDec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.auxiliary import parsec_to_mu\n",
    "\n",
    "parsec_to_mu(15.44*u.Mpc, 1.62*u.Mpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.analyse import MaximumLikelihood1D, pnlf\n",
    "\n",
    "name = 'NGC2835'\n",
    "\n",
    "trgb_distances = {'IC5332': (29.77,0.1),\n",
    " 'NGC0628': (29.96,0.14),\n",
    " 'NGC1365': (31.46,0.09),\n",
    " 'NGC2835': (30.44,0.17),\n",
    " 'NGC3351': (29.99,0.07),\n",
    " 'NGC3627': (30.27,0.09),\n",
    " 'NGC4321': (30.94,0.23),\n",
    " 'NGC5068': (28.58,0.09)}\n",
    "\n",
    "# literature value and our measured distance\n",
    "mu_trgb, mu_trgb_err = trgb_distances[name]\n",
    "mu_pnlf =  results.loc[name]['(m-M)']\n",
    "dM = mu_pnlf-mu_trgb\n",
    "dM_err = np.sqrt(mu_trgb_err**2+results.loc[name]['err-(m-M)']**2)\n",
    "# the initial guess\n",
    "Mmax0 = -4.47+dM\n",
    "# define a range of values to test\n",
    "Mmax_lst = np.linspace(Mmax0-dM_err,Mmax0+dM_err,6)\n",
    "#Mmax_lst = np.linspace(-4.75,-4.5,5)\n",
    "completeness = parameters[name]['completeness_limit']\n",
    "\n",
    "data = catalogue[(catalogue['gal_name']==name) & (catalogue['type']=='PN') & catalogue['OIII5006_detection'] &\n",
    "             ~catalogue['exclude'] & ~catalogue['overluminous'] & (catalogue['mOIII']<completeness)]\n",
    "\n",
    "dM_lst = []\n",
    "dMerr_lower_lst = []\n",
    "dMerr_upper_lst = []\n",
    "for Mmax in Mmax_lst:\n",
    "    # update zero point\n",
    "    fitter = MaximumLikelihood1D(pnlf,data['mOIII'],err=data['dmOIII'],mhigh=completeness,Mmax=Mmax)\n",
    "    mu,mu_p,mu_m = fitter([30])\n",
    "    dM_lst.append(mu-mu_trgb)\n",
    "    dMerr_lower_lst.append(mu_m)\n",
    "    dMerr_upper_lst.append(mu_p)\n",
    "\n",
    "dM_lst = np.array(dM_lst)\n",
    "dMerr_lower_lst = np.array(dMerr_lower_lst)\n",
    "dMerr_upper_lst = np.array(dMerr_upper_lst)\n",
    "\n",
    "# when we calculate the difference, we need to include the trgb error in the uncertainties\n",
    "dMerr_lower_lst = np.sqrt(mu_trgb_err**2+dMerr_lower_lst**2)\n",
    "dMerr_upper_lst = np.sqrt(mu_trgb_err**2+dMerr_upper_lst**2)\n",
    "\n",
    "Mmax_interp = np.interp(0,dM_lst[::-1],Mmax_lst[::-1])\n",
    "Mmax_lower = Mmax_interp-np.interp(0,dM_lst[::-1]-dMerr_lower_lst[::-1],Mmax_lst[::-1])\n",
    "Mmax_upper = np.interp(0,dM_lst[::-1]+dMerr_upper_lst[::-1],Mmax_lst[::-1])-Mmax_interp\n",
    "\n",
    "print(f'M* = {Mmax_interp:.3f}+{Mmax_upper:.3f}-{Mmax_lower:.3f}')\n",
    "print(f'M* = ({Mmax_interp:.3f},{Mmax_upper:.3f},{Mmax_lower:.3f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "take a look at what we are calculating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "ax.errorbar(Mmax_lst,dM_lst,yerr=[dMerr_lower_lst,dMerr_upper_lst],color='tab:blue')\n",
    "ax.fill_between(Mmax_lst,dM_lst-dMerr_lower_lst,dM_lst+dMerr_upper_lst,color='tab:blue',alpha=0.2)\n",
    "#ax.plot(np.array(Mmax_lst),np.array(dM_lst)-np.array(dMerr_lst),color='tab:blue')\n",
    "#ax.plot(np.array(Mmax_lst),np.array(dM_lst)+np.array(dMerr_lst),color='tab:blue')\n",
    "\n",
    "ax.axhline(0,color='black')\n",
    "ax.plot([Mmax_interp-Mmax_lower,Mmax_interp+Mmax_upper],[0,0],color='tab:red')\n",
    "\n",
    "#ax.axvline(Mmax0,ls='--')\n",
    "ax.axvline(Mmax_interp)\n",
    "\n",
    "ax.set(xlabel='M* / mag',ylabel=r'$(m-M)_\\mathrm{PNLF}-(m-M)_\\mathrm{TRGB}$')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "better_Mmax = {'IC5332': (-4.503,0.122,0.169),\n",
    " 'NGC0628': (-4.527,0.133,0.135),\n",
    " 'NGC1365':  (-4.624,0.071,0.069),\n",
    " 'NGC2835': (-4.360,0.165,0.184),\n",
    " 'NGC3351': (-4.139,0.087,0.103),\n",
    " 'NGC3627':(-4.540,0.096,0.116),\n",
    " 'NGC4321': (-4.337,0.211,0.194),\n",
    " 'NGC5068': (-4.570,0.124,0.204)\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "we use the same fitting algorithm, but fix (m-M) and fit M*\n",
    "\n",
    "**not really working**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.plot.pnlf import plot_pnlf\n",
    "from pnlf.analyse import F, MaximumLikelihood1D\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def pnlf_Mmax(m,Mmax,mu,mhigh):\n",
    "\n",
    "    m = np.atleast_1d(m)\n",
    "    mlow = Mmax+mu\n",
    "    \n",
    "    normalization = 1/(F(mhigh,mu) - F(mlow,mu))    \n",
    "    out = normalization * np.exp(0.307*(m-mu)) * (1-np.exp(3*(Mmax-m+mu)))\n",
    "    out[(m>mhigh) | (m<mlow)] = 0\n",
    "    \n",
    "    return out\n",
    "\n",
    "def gaussian(x,mu,sig):\n",
    "    return 1/np.sqrt(2*np.pi*sig**2) * np.exp(-(x-mu)**2/(2*sig**2))\n",
    "\n",
    "def prior(param):\n",
    "    return gaussian(param,-4.47,0.1)\n",
    "\n",
    "name= 'NGC0628'\n",
    "\n",
    "mu_trgb = sample_table.loc[name]['(m-M)']\n",
    "completeness = parameters[name]['completeness_limit']\n",
    "binsize = parameters[name]['binsize']\n",
    "\n",
    "data = catalogue[(catalogue['gal_name']=='NGC0628') & (catalogue['type']=='PN') & catalogue['OIII5006_detection'] &\n",
    "             ~catalogue['exclude'] & ~catalogue['overluminous'] & (catalogue['mOIII']<28)]\n",
    "\n",
    "fitter = MaximumLikelihood1D(pnlf_Mmax,data['mOIII'],err=data['dmOIII'],\n",
    "                             prior=None,mu=mu_trgb,mhigh=completeness)\n",
    "Mmax,mp,mm = fitter.fit(-4.5)\n",
    "#Mmax = minimize(fitter.likelihood,[-4.47],method=fitter.method).x[0]\n",
    "\n",
    "mlow = Mmax+mu_trgb\n",
    "mhigh = 28.5\n",
    "\n",
    "dMexp =  results.loc[name]['(m-M)']-mu_trgb\n",
    "print(f'expected: Mmax={-4.47+dMexp:.2f}, dMmax={dMexp:.2f}')\n",
    "print(f'{name}: Mmax={Mmax:.2f}, dMmax={Mmax+4.47:.2f}')\n",
    "\n",
    "#axes = plot_pnlf(data['mOIII'],mu_trgb,completeness,binsize=binsize,\n",
    "#                 mhigh=28.5,Mmax=Mmax,filename=None,color=tab10[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fitter = MaximumLikelihood1D(pnlf_Mmax,data['mOIII'],mu=mu_trgb,mhigh=completeness)\n",
    "\n",
    "x_arr = np.linspace(-4,-6,100)\n",
    "evidence = [fitter.evidence(x) for x in x_arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Mmax = np.linspace(-6,-4,100)\n",
    "evidence = [np.sum(np.log(pnlf_Mmax(data['mOIII'],mmax,mu=29.99,mhigh=28))) for mmax in Mmax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nbins = 100\n",
    "x = np.linspace(-4.4,-4.6,nbins)\n",
    "y = np.linspace(29.8,30.3,nbins)\n",
    "\n",
    "X,Y = np.meshgrid(x,y)\n",
    "\n",
    "evidence = np.zeros((len(x),len(y)))\n",
    "\n",
    "for i in range(len(x)):\n",
    "    for j in range(len(y)):\n",
    "        evidence[i,j] = np.sum(np.log(pnlf(data['mOIII'],Y[i,j],Mmax=X[i,j],mhigh=28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for x in [4.4,4.47,4.54]:\n",
    "    idx = np.argmin(np.abs(X[0]+x))\n",
    "    plt.plot(Y[:,idx],evidence[:,idx],label=x)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for y in [29.8,29.9,30,30.1,30.2]:\n",
    "    idx = np.argmin(np.abs(Y[:,1]-y))\n",
    "    print(idx)\n",
    "    plt.plot(X[idx,:],evidence[idx,:],label=y)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(8,8))\n",
    "\n",
    "ax.pcolormesh(X,Y,evidence)\n",
    "ax.axvline(-4.47,color='red')\n",
    "ax.axhline(mu_trgb,color='red')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lim = [29.7,30.3]\n",
    "mu = np.linspace(*lim,100)\n",
    "evidence = [np.sum(np.log(pnlf(data['mOIII'],x,Mmax=-4.37,mhigh=28))) for x in mu]\n",
    "fig,ax=plt.subplots()\n",
    "ax.plot(mu,evidence)\n",
    "ax.set(xlim=lim)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.analyse import MaximumLikelihood1D, pnlf\n",
    "\n",
    "name = 'NGC3351'\n",
    "\n",
    "# get an initial guess\n",
    "mu_trgb = sample_table.loc[name]['(m-M)']\n",
    "mu_pnlf =  results.loc[name]['(m-M)']\n",
    "dM = mu_pnlf-mu_trgb\n",
    "Mmax0 = -4.47+dM\n",
    "completeness = parameters[name]['completeness_limit']\n",
    "\n",
    "data = catalogue[(catalogue['gal_name']==name) & (catalogue['type']=='PN') & catalogue['OIII5006_detection'] &\n",
    "             ~catalogue['exclude'] & ~catalogue['overluminous'] & (catalogue['mOIII']<completeness)]\n",
    "\n",
    "\n",
    "fitter = MaximumLikelihood1D(pnlf,data['mOIII'],err=data['dmOIII'],mhigh=completeness,Mmax=Mmax0)\n",
    "mu,mp,mm = fitter([29])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.analyse import MaximumLikelihood1D, F\n",
    "from pnlf.plot.pnlf import _plot_pnlf\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "names = list(trgb['name'])\n",
    "\n",
    "names.remove('NGC1433')\n",
    "names.remove('NGC1512')\n",
    "\n",
    "nrows = 3\n",
    "ncols = 3\n",
    "filename = None #basedir / 'reports' / f'all_galaxies_PNLF'\n",
    "\n",
    "#----------------------------------------------\n",
    "# DO NOT MODIFY BELOW\n",
    "#----------------------------------------------\n",
    "\n",
    "width = two_column\n",
    "fig, axes = plt.subplots(nrows=nrows,ncols=ncols,figsize=(width,width/ncols*nrows))\n",
    "axes_iter = iter(axes.flatten())\n",
    "\n",
    "trgb['dM*new'] = 0.0\n",
    "for name in names:\n",
    "    \n",
    "    catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "    if catalogue_file.is_file():\n",
    "        catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "        catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "    else:\n",
    "        print(f'no catalogue for {name}')\n",
    "        continue\n",
    "        \n",
    "    # get the next axis and find position on the grid\n",
    "    ax = next(axes_iter)\n",
    "    if nrows>1 and ncols>1:\n",
    "        i, j = np.where(axes == ax)\n",
    "        i,j=i[0],j[0]\n",
    "    elif ncols>1:\n",
    "        i,j = 0, np.where(axes==ax)[0]\n",
    "    elif nrows>1:\n",
    "        i,j = np.where(axes==ax)[0],0\n",
    "    else:\n",
    "        i,j=0,0\n",
    "        \n",
    "    # pre-process the data for the plot and read additional parameters\n",
    "    data = catalogue[(catalogue['type']=='PN') & (~catalogue['exclude'])]['mOIII']\n",
    "    err = catalogue[(catalogue['type']=='PN') & (~catalogue['exclude'])]['dmOIII']\n",
    "\n",
    "    mu_trgb = trgb.loc[name]['trgb_(m-M)']\n",
    "    completeness = parameters[name]['completeness_limit']\n",
    "\n",
    "    binsize = parameters[name]['binsize']\n",
    "\n",
    "    fitter = MaximumLikelihood1D(pnlf_Mmax,data[data<completeness],err=err[data<completeness],prior=prior,mu=mu_trgb,mhigh=completeness)\n",
    "    Mmax = minimize(fitter.likelihood,[-4.47],method=fitter.method).x[0]\n",
    "    \n",
    "    trgb.loc[name]['dM*new'] = Mmax+4.47\n",
    "    \n",
    "    mlow = Mmax+mu_trgb\n",
    "    mhigh = 28.5\n",
    "    \n",
    "    print(f'{name}: Mmax={Mmax:.2f}, dMmax={Mmax+4.47:.2f}')\n",
    "    \n",
    "    ax=_plot_pnlf(data,mu_trgb,completeness,binsize=binsize,mlow=mlow,mhigh=mhigh,ax=ax,ms=3)\n",
    "    ax.text(0.4,0.08,f'{name}', transform=ax.transAxes,fontsize=7)\n",
    "\n",
    "    #ax.set_xlim([mu-5,completeness+0.5])\n",
    "    # add labels to the axis\n",
    "    if i==nrows-1:\n",
    "        ax.set_xlabel(r'$m_{[\\mathrm{OIII}]}$ / mag')\n",
    "    if j==0:\n",
    "        ax.set_ylabel(r'N')\n",
    "    #ax.set_title(name)\n",
    "    #ax.set(xlim=[24,28.5])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Radial Trends \n",
    "\n",
    "measure (m-M) from inner and outer PNe\n",
    "\n",
    "the metallicity and with it $M*$ decreases in the outer regions of the galaxies. A smaller $M*$ should lead to a larger distance. Therefore the PNe in the outer parts should yield a larger distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "abundance_gradients = ascii.read(basedir/'data'/'external'/'radial_abundance_gradients.txt',\n",
    "                                names=['name','R0','g_r25'])\n",
    "abundance_gradients.add_index('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from regions import EllipseSkyRegion\n",
    "\n",
    "name = 'NGC0628'\n",
    "\n",
    "logOH_sun = 8.87\n",
    "deltaM = lambda OH: 0.928*OH**2+0.225*OH+0.014\n",
    "\n",
    "try:\n",
    "    mu_trgb = trgb.loc[name]['trgb_(m-M)']\n",
    "except:\n",
    "    print(f'no TRGB for {name}')\n",
    "    mu_trgb=0\n",
    "completeness = parameters[name]['completeness_limit']\n",
    "binsize = parameters[name]['binsize']\n",
    "\n",
    "catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "if catalogue_file.is_file():\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "    catalogue['overluminous'] = catalogue['overluminous'].astype(bool)\n",
    "\n",
    "catalogue['SkyCoord'] = SkyCoord(catalogue['RaDec'])\n",
    "catalogue = catalogue[(catalogue['type']=='PN') & (~catalogue['exclude']) & (~catalogue['overluminous']) & (catalogue['mOIII']<completeness)]\n",
    "\n",
    "center = sample_table.loc[name]['SkyCoord']\n",
    "posang = sample_table.loc[name]['posang']\n",
    "inclination = sample_table.loc[name]['Inclination']\n",
    "eccentricity = np.sin(inclination*u.deg).value\n",
    "\n",
    "r25 = sample_table.loc[name]['r25']*u.arcmin\n",
    "\n",
    "catalogue['r'] = catalogue['SkyCoord'].separation(center)\n",
    "rmean = np.mean(catalogue['r']/r25).decompose()\n",
    "logOH_rmean = abundance_gradients.loc[name]['R0']+rmean*abundance_gradients.loc[name]['g_r25']\n",
    "\n",
    "print(f'rmean = {rmean:.2f} r25')\n",
    "print(f'dM*={deltaM(logOH_rmean-logOH_sun):.3f}')\n",
    "\n",
    "with fits.open(data_ext/'MUSE_DR2.1'/'MUSEDAP'/f'{name}_MAPS.fits') as hdul:\n",
    "    wcs = WCS(hdul['OIII5006_FLUX '].header)\n",
    "    OIII = hdul['OIII5006_FLUX'].data\n",
    "    Halpha = hdul['HA6562_FLUX'].data\n",
    "    \n",
    "catalogue['region'] = '     '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### split sample into sub-samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def split_radial(catalogue,r25,center,eccentricity,posang,wcs):\n",
    "    threshold = 0.5\n",
    "    tried = set()\n",
    "    while True: \n",
    "        width = threshold*r25\n",
    "        aperture = EllipseSkyRegion(center,\n",
    "                                width=width,\n",
    "                                height=np.sqrt((width)**2 * (1-eccentricity**2)),\n",
    "                                angle=(posang-90)*u.deg)\n",
    "        inside = aperture.contains(catalogue['SkyCoord'],wcs)\n",
    "        ratio = np.sum(inside)/np.sum(~inside)\n",
    "\n",
    "        if threshold in tried:\n",
    "            break\n",
    "        tried.add(threshold)\n",
    "\n",
    "        if np.abs(ratio-1)<0.02:\n",
    "            break\n",
    "        elif ratio>1:\n",
    "            threshold/=1.02\n",
    "        elif ratio<1:\n",
    "            threshold*=1.02\n",
    "\n",
    "    width = threshold*r25\n",
    "    aperture = EllipseSkyRegion(center,\n",
    "                            width=width,\n",
    "                            height=np.sqrt((width)**2 * (1-eccentricity**2)),\n",
    "                            angle=(posang-90)*u.deg)\n",
    "    catalogue['region'] = 'inner'\n",
    "    catalogue['region'][~aperture.contains(catalogue['SkyCoord'],wcs)] = 'outer'\n",
    "    print(f'width={threshold:.3f} r25')\n",
    "\n",
    "    return catalogue,threshold,aperture\n",
    "\n",
    "def split_quadrants(catalogue,wcs,posang):\n",
    "    \n",
    "    catalogue['region'] = 'south'\n",
    "    x0,y0 = center.to_pixel(wcs)\n",
    "    x,y = catalogue['x'],catalogue['y']\n",
    "\n",
    "    north = (y>y0-np.sin((posang)/180*np.pi)*(x-x0))\n",
    "    south = (y<y0-np.sin((posang)/180*np.pi)*(x-x0))\n",
    "    east = (x<x0+np.cos((posang-90)/180*np.pi)*(y-y0))\n",
    "    west = (x>x0+np.cos((posang-90)/180*np.pi)*(y-y0))\n",
    "\n",
    "    catalogue['region'][north & west] = 'nw'\n",
    "    catalogue['region'][north & east] = 'ne'\n",
    "    catalogue['region'][south & west] = 'sw'\n",
    "    catalogue['region'][south & east] = 'se'\n",
    "    \n",
    "    return catalogue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "split into inner/outer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "catalogue,threshold,aperture = split_radial(catalogue,r25,center,eccentricity,posang,wcs)\n",
    "\n",
    "logOH1 = abundance_gradients.loc[name]['R0']\n",
    "logOH2 = abundance_gradients.loc[name]['R0']+threshold*abundance_gradients.loc[name]['g_r25']\n",
    "\n",
    "print(f'inner dM*={deltaM(logOH1-logOH_sun):.3f}\\noutter dM*={deltaM(logOH2-logOH_sun):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "or split into quadrants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "catalogue['region'] = 'south'\n",
    "\n",
    "catalogue['region'][(center.ra<catalogue['SkyCoord'].ra) & (center.dec<catalogue['SkyCoord'].dec)] = 'north'\n",
    "catalogue['region'][(center.ra<catalogue['SkyCoord'].ra) & (center.dec>catalogue['SkyCoord'].dec)] = 'west'\n",
    "catalogue['region'][(center.ra>catalogue['SkyCoord'].ra) & (center.dec<catalogue['SkyCoord'].dec)] = 'east'\n",
    "catalogue['region'][(center.ra>catalogue['SkyCoord'].ra) & (center.dec>catalogue['SkyCoord'].dec)] = 'south'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "catalogue['region'] = 'west'\n",
    "\n",
    "catalogue['region'][(center.ra<catalogue['SkyCoord'].ra)] = 'west'\n",
    "catalogue['region'][(center.ra>catalogue['SkyCoord'].ra)] = 'east'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "catalogue['region'] = 'south'\n",
    "\n",
    "catalogue['region'][(center.dec<catalogue['SkyCoord'].dec)] = 'north'\n",
    "catalogue['region'][(center.dec>catalogue['SkyCoord'].dec)] = 'south'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# split into 4 quadrants based on position angel\n",
    "catalogue = split_quadrants(catalogue,wcs,posang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "compare central PNe to outer PNe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_quadrants(image,catalogue,wcs,aperture,posang,ax=None):\n",
    "\n",
    "    x0,y0 = center.to_pixel(wcs)\n",
    "    dx = 1000\n",
    "\n",
    "    majx1 = x0-np.cos(posang/180*np.pi)*dx\n",
    "    majx2 = x0+np.cos(posang/180*np.pi)*dx\n",
    "    majy1 = y0-np.sin(posang/180*np.pi)*dx\n",
    "    majy2 = y0+np.sin(posang/180*np.pi)*dx\n",
    "\n",
    "    minx1 = x0-np.cos((posang-90)/180*np.pi)*dx\n",
    "    minx2 = x0+np.cos((posang-90)/180*np.pi)*dx\n",
    "    miny1 = y0-np.sin((posang-90)/180*np.pi)*dx\n",
    "    miny2 = y0+np.sin((posang-90)/180*np.pi)*dx\n",
    "\n",
    "    if not ax:\n",
    "        fig = plt.figure(figsize=(single_column,single_column))\n",
    "        ax = fig.add_subplot(projection=wcs)\n",
    "\n",
    "    norm = simple_norm(image,clip=False,percent=97)\n",
    "    ax.imshow(image,norm=norm,cmap=plt.cm.Greys)\n",
    "\n",
    "    colors = iter(tab10)\n",
    "    for region in np.unique(catalogue['region']):\n",
    "        color = next(colors)\n",
    "        tmp1 = catalogue[catalogue['region']==region]\n",
    "\n",
    "        tmp = tmp1[aperture.contains(tmp1['SkyCoord'],wcs)]\n",
    "        sc = ax.errorbar(tmp['x'],tmp['y'],mec=color,mfc=color,fmt='o',ms=3,label=region)\n",
    "\n",
    "        tmp = tmp1[~aperture.contains(tmp1['SkyCoord'],wcs)]\n",
    "        ax.errorbar(tmp['x'],tmp['y'],fmt='o',mec=color,mfc='none',ms=3,mew=0.9)\n",
    "\n",
    "\n",
    "    pixel_aperture = aperture.to_pixel(wcs)\n",
    "    artist = pixel_aperture.as_artist(ec='black')\n",
    "    ax.add_artist(artist)\n",
    "\n",
    "    ax.plot([majx1,majx2],[majy1,majy2],color='black')\n",
    "    ax.plot([minx1,minx2],[miny1,miny2],color='black')\n",
    "\n",
    "    ax.set(xlim=(0,OIII.shape[1]),ylim=(0,OIII.shape[0]))\n",
    "    #ax.set_title(name)\n",
    "\n",
    "    ax.coords[0].set_ticks_visible(False)\n",
    "    ax.coords[0].set_ticklabel_visible(False)\n",
    "    ax.coords[1].set_ticks_visible(False)\n",
    "    ax.coords[1].set_ticklabel_visible(False)\n",
    "    \n",
    "    #ax.legend()\n",
    "    \n",
    "    return ax\n",
    "\n",
    "ax = plot_quadrants(OIII,catalogue,wcs,aperture,posang,ax=None)\n",
    "#plt.savefig(basedir/'reports'/name/f'{name}_regions.pdf',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### for a single galaxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "\n",
    "reg = np.unique(catalogue['region'])\n",
    "data1 = catalogue[catalogue['region']==reg[0]]['mOIII']\n",
    "data2 = catalogue[catalogue['region']==reg[1]]['mOIII']\n",
    "\n",
    "ks,pv = ks_2samp(data1,data2)\n",
    "print(f'{name}: statistic={ks:.3f}, pvalue={pv:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.analyse import MaximumLikelihood1D, pnlf, cdf\n",
    "from pnlf.plot.pnlf import plot_pnlf\n",
    "from scipy.stats import kstest\n",
    "\n",
    "regions = np.unique(catalogue['region'])\n",
    "if 'axes' in locals():\n",
    "    del axes\n",
    "pdfs = {}\n",
    "for i,region in enumerate(regions):\n",
    "    \n",
    "    data = catalogue[catalogue['region']==region]['mOIII']\n",
    "    err  = catalogue[catalogue['region']==region]['dmOIII']\n",
    "    \n",
    "    if len(data)<15:\n",
    "        print(f'not enough data points ({len(data)}) for region {region}')\n",
    "        continue\n",
    "        \n",
    "    fitter = MaximumLikelihood1D(pnlf,\n",
    "                                 data[data<completeness],\n",
    "                                 err=err[data<completeness],\n",
    "                                 mhigh=completeness,Mmax=-4.47)\n",
    "    mu,mu_p,mu_m = fitter([29])\n",
    "    pdfs[region] = (fitter.x_arr,fitter.likelihood_arr)\n",
    "    print('{}: {:.2f} + {:.2f} - {:.2f}'.format(region,mu,mu_p,mu_m))\n",
    "\n",
    "\n",
    "    #Plot PNLF\n",
    "    if 'axes' not in locals():\n",
    "        axes = plot_pnlf(data,mu,completeness,\n",
    "                 binsize=binsize,mhigh=28.5,Mmax=-4.47,color=tab10[i])\n",
    "    else:\n",
    "        axes = plot_pnlf(data,mu,completeness,\n",
    "                         binsize=binsize,mhigh=28.5,Mmax=-4.47,filename=None,color=tab10[i],axes=axes)\n",
    "    \n",
    "ax1,ax2 = axes \n",
    "h, l = ax2.get_legend_handles_labels()\n",
    "ax2.legend(h,regions)\n",
    "filename=basedir/'reports'/name/f'{name}_PNLF_radial'\n",
    "plt.savefig(filename.with_suffix('.pdf'),bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "calculate error of difference with Monte Carlo (the original errors are not gaussian and hence we can not use classical error propagation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.auxiliary import sample_numerical\n",
    "\n",
    "x,y=pdfs['inner']\n",
    "mu_inner = sample_numerical(x,y,100000)\n",
    "\n",
    "x,y=pdfs['outer']\n",
    "mu_outer = sample_numerical(x,y,100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.analyse import gaussian\n",
    "\n",
    "fig,(ax1,ax2) = plt.subplots(ncols=2,figsize=(8,3),gridspec_kw={'width_ratios': [1.5, 1]})\n",
    "\n",
    "ax1.hist(mu_inner,bins=np.arange(29,30.5,0.01),density=True,label='inner',alpha=0.5)\n",
    "ax1.hist(mu_outer,bins=np.arange(29,30.5,0.01),density=True,label='outer',alpha=0.5)\n",
    "ax1.set(xlabel='$(m-M)$',xlim=[29,30.5])\n",
    "ax1.legend(loc=2)\n",
    "\n",
    "diff = mu_outer-mu_inner\n",
    "mu = np.mean(diff)\n",
    "std = np.std(diff)\n",
    "print(f'{mu:.2f}+-{std:.2f}')\n",
    "x = np.linspace(0,1)\n",
    "ax2.hist(diff,bins=np.arange(0,1,0.01),density=True,color='#9E91A8',alpha=0.6)\n",
    "ax2.plot(x,gaussian(x,mu,std),color='black')\n",
    "ax2.set(xlabel=r'$\\Delta(m-M)$',xlim=[0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "NGC0628\n",
    "\n",
    "inner outer: statistic=0.272, pvalue=0.006\n",
    "inner: 29.78 + 0.08 - 0.15\n",
    "outer: 30.21 + 0.07 - 0.13\n",
    "\n",
    "\n",
    "statistic=0.244, pvalue=0.207\n",
    "ne: 29.81 + 0.10 - 0.21\n",
    "nw: 29.82 + 0.11 - 0.25\n",
    "se: 30.15 + 0.09 - 0.19\n",
    "sw: 29.94 + 0.10 - 0.23\n",
    "\n",
    "NGC3351\n",
    "\n",
    "inner outer: statistic=0.187, pvalue=0.141\n",
    "inner: 30.35 + 0.08 - 0.13\n",
    "outer: 30.32 + 0.08 - 0.13\n",
    "\n",
    "vergleicht nur 2 der 4\n",
    "ne: 30.22 + 0.10 - 0.19\n",
    "nw: 30.38 + 0.09 - 0.18\n",
    "se: 30.40 + 0.10 - 0.21\n",
    "sw: 30.45 + 0.10 - 0.21\n",
    "\n",
    "\n",
    "NGC1433\n",
    "\n",
    "NGC1433: statistic=0.170, pvalue=0.508\n",
    "inner: 31.37 + 0.07 - 0.10\n",
    "outer: 31.37 + 0.07 - 0.10\n",
    "\n",
    "\n",
    "NGC1433: statistic=0.222, pvalue=0.588\n",
    "ne: 31.29 + 0.09 - 0.19\n",
    "nw: 31.41 + 0.09 - 0.16\n",
    "se: 31.42 + 0.09 - 0.16\n",
    "w: 31.36 + 0.08 - 0.14\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### for all galaxies at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.auxiliary import project\n",
    "\n",
    "def calc_r25(name,x,y):\n",
    "    '''calculate deprojected r25\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # get the pixel position of the centre\n",
    "    with fits.open(data_ext/'MUSE_DR2.1'/'MUSEDAP'/f'{name}_MAPS.fits') as hdul:\n",
    "        wcs = WCS(hdul['FLUX'].header)\n",
    "    centre = sample_table.loc[name]['SkyCoord']\n",
    "    x_cen,y_cen = centre.to_pixel(wcs)\n",
    "    \n",
    "    pa  = sample_table.loc[name]['posang']\n",
    "    inc = sample_table.loc[name]['Inclination']\n",
    "    r25 = sample_table.loc[name]['r25']*u.arcmin\n",
    "    \n",
    "    # deproject\n",
    "    x_depr,y_depr = project(x-x_cen,y-y_cen,pa,inc)\n",
    "    skycoord_depr = SkyCoord.from_pixel(x_depr+x_cen,y_depr+y_cen,wcs)\n",
    "    \n",
    "    # separation to centre\n",
    "    sep = skycoord_depr.separation(centre)\n",
    "    \n",
    "    return (sep/r25).decompose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from regions import EllipseSkyRegion\n",
    "from scipy.stats import ks_2samp\n",
    "from pnlf.auxiliary import sample_numerical\n",
    "from pnlf.analyse import MaximumLikelihood1D,pnlf\n",
    "\n",
    "sample = results[results['N_PN']>50]['name']\n",
    "ncols = 4\n",
    "nrows = np.ceil(len(sample)/ncols)\n",
    "\n",
    "fig1 = plt.figure(figsize=(two_column,two_column*nrows/ncols))\n",
    "fig2 = plt.figure(figsize=(two_column,two_column*nrows/ncols))\n",
    "\n",
    "logOH_sun = 8.87\n",
    "deltaM = lambda OH: 0.928*OH**2+0.225*OH+0.014\n",
    "\n",
    "tbl=Table(dtype=['str']+12*[float],names=['name','(m-M)1','err+(m-M)1','err-(m-M)1',\n",
    "                                            '(m-M)2','err+(m-M)2','err-(m-M)2','d(m-M)','errd(m-M)',\n",
    "                                            'ks','pv','r1','r2'])\n",
    "for i,name in enumerate(sample):\n",
    "    \n",
    "    catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "    catalogue['overluminous'] = catalogue['overluminous'].astype(bool)\n",
    "    catalogue['SkyCoord'] = SkyCoord(catalogue['RaDec'])\n",
    "\n",
    "    # some parameters of the galaxy\n",
    "    completeness = parameters[name]['completeness_limit']\n",
    "    binsize = parameters[name]['binsize']\n",
    "    center = sample_table.loc[name]['SkyCoord']\n",
    "    posang = sample_table.loc[name]['posang']\n",
    "    inclination = sample_table.loc[name]['Inclination']\n",
    "    eccentricity = np.sin(inclination*u.deg).value\n",
    "    #r25 = sample_table.loc[name]['r25']*u.arcmin\n",
    "    #catalogue['r'] = catalogue['SkyCoord'].separation(center)\n",
    "    catalogue['r'] = calc_r25(name,catalogue['x'],catalogue['y'])\n",
    "    \n",
    "    catalogue = catalogue[(catalogue['type']=='PN') & (catalogue['mOIII']<completeness) & (~catalogue['overluminous']) & (~catalogue['exclude'])]\n",
    "    print(f'{name}: {len(catalogue)} objects')\n",
    "    \n",
    "    with fits.open(data_ext/'MUSE_DR2.1'/'MUSEDAP'/f'{name}_MAPS.fits') as hdul:\n",
    "        wcs = WCS(hdul['OIII5006_FLUX '].header)\n",
    "        OIII = hdul['OIII5006_FLUX'].data\n",
    "        Halpha = hdul['HA6562_FLUX'].data\n",
    "    \n",
    "    # split evenly between inner and outer\n",
    "    catalogue,threshold,aperture = split_radial(catalogue,r25,center,eccentricity,posang,wcs)\n",
    "    # split into quadrants\n",
    "    #catalogue = split_quadrants(catalogue,wcs,posang)\n",
    "    \n",
    "    # plot with the position of the PN and split into quadrants/radial\n",
    "    ax1 = fig1.add_subplot(nrows,ncols,i+1,projection=wcs)\n",
    "    ax1 = plot_quadrants(OIII,catalogue,wcs,aperture,posang,ax=ax1)\n",
    "    t = ax1.text(0.05,0.9,f'{name}', transform=ax1.transAxes,fontsize=6)\n",
    "    t.set_bbox(dict(facecolor='white', alpha=1, ec='white'))\n",
    "\n",
    "    # the cumulative luminosity function plot\n",
    "    ax2 = fig2.add_subplot(nrows,ncols,i+1)\n",
    "    regions = np.unique(catalogue['region'])\n",
    "    colors = iter(tab10)\n",
    "    for j,region in enumerate(regions):\n",
    "        data = catalogue[catalogue['region']==region]['mOIII']\n",
    "        N = len(data)        \n",
    "        color = next(colors)\n",
    "        data.sort()\n",
    "        ax2.plot(data,np.arange(1,N+1,1),ls='-',mfc=color,mec=color,ms=1,marker='o',label=region)\n",
    "\n",
    "    reg = np.unique(catalogue['region'])\n",
    "    data1 = catalogue[catalogue['region']==reg[0]]['mOIII']\n",
    "    data2 = catalogue[catalogue['region']==reg[1]]['mOIII']\n",
    "    ks,pv = ks_2samp(data1,data2)\n",
    "    print(f'{name}: statistic={ks:.3f}, pvalue={pv:.3f}')\n",
    "    \n",
    "    if True:\n",
    "        # this measures the distance for each subsample\n",
    "        fitter = MaximumLikelihood1D(pnlf,\n",
    "                                     data1,\n",
    "                                     err=catalogue[catalogue['region']==reg[0]]['dmOIII'],\n",
    "                                     mhigh=completeness,Mmax=-4.47)\n",
    "        mu1,mu_p1,mu_m1 = fitter([29])\n",
    "        x,y=fitter.x_arr,fitter.likelihood_arr\n",
    "        mu_inner = sample_numerical(x,y,100000)\n",
    "        \n",
    "        fitter = MaximumLikelihood1D(pnlf,\n",
    "                                     data2,\n",
    "                                     err=catalogue[catalogue['region']==reg[1]]['dmOIII'],\n",
    "                                     mhigh=completeness,Mmax=-4.47)\n",
    "        mu2,mu_p2,mu_m2 = fitter([29])\n",
    "        x,y=fitter.x_arr,fitter.likelihood_arr\n",
    "        mu_outer = sample_numerical(x,y,100000)    \n",
    "\n",
    "        diff = mu_outer-mu_inner\n",
    "        dmu = np.mean(diff)\n",
    "        std = np.std(diff)\n",
    "        \n",
    "        center = sample_table.loc[name]['SkyCoord']\n",
    "        r25 = sample_table.loc[name]['r25']*u.arcmin\n",
    "        r1 = np.mean(catalogue[catalogue['region']==reg[0]]['r'])\n",
    "        r2 = np.mean(catalogue[catalogue['region']==reg[1]]['r'])\n",
    "        tbl.add_row([name,mu1,mu_p1,mu_m1,mu2,mu_p2,mu_m2,dmu,std,ks,pv,r1,r2])\n",
    "    \n",
    "    ax2.text(0.57,0.08,f'{name}', transform=ax2.transAxes,fontsize=7)\n",
    "    ax2.text(0.05,0.78,f'$p$-value$={pv:.2f}$',transform=ax2.transAxes,fontsize=7)\n",
    "    ax2.text(0.07,0.88,f'$D_{{max}}={ks:.3f}$', transform=ax2.transAxes,fontsize=7)\n",
    "    ax.set(aspect='equal')\n",
    "    \n",
    "    if i%ncols==0:\n",
    "        ax2.set(ylabel='Cumulative N')\n",
    "    if i//ncols==nrows-1:\n",
    "        ax2.set(xlabel=r'$m_{[\\mathrm{OIII}]}$ / mag')\n",
    "\n",
    "    if i==5:\n",
    "        ax2.set(xlabel=r'$m_{[\\mathrm{OIII}]}$ / mag')\n",
    "\n",
    "# Create the legend\n",
    "\n",
    "h,l = ax2.get_legend_handles_labels()\n",
    "ax2 = fig2.add_subplot(nrows,ncols,i+2)\n",
    "ax2.legend(h,l,\n",
    "           loc=2\n",
    "           #ncol=2,\n",
    "           #loc=\"upper center\",   # Position of legend\n",
    "           #borderaxespad=0.1,    # Small spacing around legend box\n",
    "           )\n",
    "ax2.axis('off')\n",
    "\n",
    "fig1.tight_layout() \n",
    "fig2.tight_layout() \n",
    "\n",
    "fig1.savefig(basedir/'reports'/'subsamples_map.png',dpi=600,bbox_inches='tight')\n",
    "fig2.savefig(basedir/'reports'/'subsamples_PNLF_cum.png',dpi=600,bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tbl = join(tbl,abundance_gradients,keys='name')\n",
    "tbl['logOH1'] = tbl['R0'] +tbl['r1']*tbl['g_r25']\n",
    "tbl['logOH2'] = tbl['R0'] +tbl['r2']*tbl['g_r25']\n",
    "tbl['dlogOH'] = tbl['logOH2']-tbl['logOH1'] \n",
    "    \n",
    "tbl['dM1'] = deltaM(tbl['logOH1']-logOH_sun)\n",
    "tbl['dM2'] = deltaM(tbl['logOH2']-logOH_sun)\n",
    "tbl['d(m-M)'] = tbl['(m-M)2']-tbl['(m-M)1']\n",
    "for col in tbl.columns[1:]:\n",
    "    tbl[col].info.format='%.3f'\n",
    "    \n",
    "with open(basedir/'data'/'interim'/ 'pnlf_io.txt','w',newline='\\n') as f:\n",
    "    ascii.write(tbl,f,format='fixed_width_two_line',overwrite=True,delimiter_pad=' ',position_char='=')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Look at dM* as a function of g r25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from astropy.table import join \n",
    "\n",
    "tbl = ascii.read(basedir/'data'/'interim'/'pnlf_io.txt')\n",
    "tmp = join(tbl,results,keys='name')\n",
    "#tbl['err_d(m-M)'] = np.sqrt(tbl['err+(m-M)2']**2+tbl['err-(m-M)1']**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ascii.write(tbl[['name','dlogOH','d(m-M)']],sys.stdout, Writer = ascii.Latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ha = {'NGC4535':'left','NGC4321':'right','NGC3351':'right','NGC3627':'right','NGC1433':'right'}\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(single_column,single_column/1.618))\n",
    "\n",
    "for row in tbl:\n",
    "    ax.text(row['logOH2']-row['logOH1'],row['d(m-M)'],row['name'],\n",
    "           ha=ha.get(row['name'],'left'),va='top',fontsize=7)\n",
    "ax.errorbar(tbl['logOH2']-tbl['logOH1'],tbl['d(m-M)'],yerr=tbl['errd(m-M)'],fmt='o',ms=4)\n",
    "\n",
    "#ax.scatter(tmp['logOH2']-tmp['logOH1'],deltaM(tmp['logOH2']-logOH_sun)-deltaM(tmp['logOH1']-logOH_sun),color='tab:orange')\n",
    "\n",
    "ax.set(xlim=[-0.065,0.01],ylim=[-0.5,1],\n",
    "       xlabel=r'$\\Delta \\log (\\mathrm{O}/\\mathrm{H})$',ylabel='$\\Delta (m-M)$')\n",
    "#plt.savefig(basedir/'reports'/'inner_outer_difference.pdf',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "\n",
    "for row in tbl:\n",
    "    ax.text(row['dM1']-row['dM2'],row['d(m-M)'],row['name'])\n",
    "ax.scatter(tbl['dM1']-tbl['dM2'],tbl['d(m-M)'])\n",
    "ax.set(xlim=[-0.06,0.02],ylim=[-0.3,0.6],xlabel=r'$\\Delta$ M*',ylabel='$\\Delta$ (m-M)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "\n",
    "for row in tbl:\n",
    "    ax.text(row['logOH1'],row['(m-M)1'],row['name'])\n",
    "ax.scatter(tbl['logOH1'],tbl['(m-M)1'],label='inner')\n",
    "ax.scatter(tbl['logOH2'],tbl['(m-M)2'],label='outer')\n",
    "\n",
    "for row in tbl:\n",
    "    ax.arrow(row['logOH1'],row['(m-M)1'],\n",
    "             row['logOH2']-row['logOH1'],row['(m-M)2']-row['(m-M)1'],\n",
    "            )\n",
    "\n",
    "ax.set(xlim=[8.3,8.6],ylim=[28.2,31.7],xlabel=r'12+logO/H',ylabel='(m-M)')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## luminosity-specific planetary nebula number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import join \n",
    "\n",
    "from pnlf.analyse import F\n",
    "\n",
    "def NPN(mu,completeness,N_total,deltaM):\n",
    "    cutoff = mu - 4.47\n",
    "    p_deltaM = (F(cutoff+deltaM,mu) - F(cutoff,mu)) / (F(completeness,mu) - F(cutoff,mu))\n",
    "    \n",
    "    return N_total * p_deltaM\n",
    "\n",
    "\n",
    "results = ascii.read(basedir/'data'/'interim'/ 'results.txt',format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "abundance_gradients = ascii.read(basedir/'data'/'external'/'radial_abundance_gradients.txt',\n",
    "                                names=['name','R0','g_r25'])\n",
    "observed_mass = ascii.read(basedir/'data'/'interim'/ 'observed_mass.txt',format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "results = join(results,abundance_gradients)\n",
    "results = join(results,observed_mass)\n",
    "results.add_index('name')\n",
    "\n",
    "# from survey paper based on sample table distances\n",
    "results['spatial_res'] = [43.7,47.7,76.8,92.1,94.9,83.5,\n",
    "                               90.3,91.3,85.8,94.1,59.2,48.3,54.9,\n",
    "                               63.5,82.4,73.7,76.5, 25.2,90.8]\n",
    "# from survey paper\n",
    "results['PSF'] = [0.72,0.73,0.74,0.63,0.82,0.49,0.65,0.8,0.64,0.72,\n",
    "                  0.85,0.74,0.77,0.58,0.58,0.64,0.44,0.73,0.79]\n",
    "results['mass'] = sample_table['mass']\n",
    "results['SFR']  = sample_table['SFR']\n",
    "results['Inclination'] = sample_table['Inclination']\n",
    "results['AO'] = ~sample_table['AO'].mask\n",
    "\n",
    "# those two galaxies have a lower completeness limit\n",
    "row = results.loc['NGC3627']\n",
    "row ['N_PN'] = NPN(row['(m-M)'],27.5,row['N_PN'],28-row['(m-M)']+4.47)\n",
    "row = results.loc['NGC2835']\n",
    "row ['N_PN'] = NPN(row['(m-M)'],27.5,row['N_PN'],28-row['(m-M)']+4.47)\n",
    "\n",
    "# luminosity specific planetary nebula number (detected and not N25)\n",
    "results['alpha2'] = np.log10(results['N_PN']/results['Lbol'])\n",
    "results['alpha3'] = np.log10(results['N_PN']/10**results['obs_mass'])\n",
    "results['resolution'] = results['PSF']*(results['d/Mpc']*u.Mpc*(u.arcsec.to(u.rad))).to(u.pc).value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of PN within 1 mag of the bright end cutoff and extrapolate to completeness\n",
    "N_PN = []\n",
    "for name in results['name']:\n",
    "    with fits.open(basedir/'data'/'catalogues'/f'{name}_classifications.fits') as hdul:\n",
    "        catalogue = Table(hdul[1].data)    \n",
    "    threshold = results.loc[name]['(m-M)']-4.47+1\n",
    "    criteria = (catalogue['type']=='PN') & (catalogue['mOIII']<threshold) & ~catalogue['exclude'] & ~catalogue['overluminous']\n",
    "    N = NPN(row['(m-M)'],threshold,np.sum(criteria),28-threshold)\n",
    "    N_PN.append(N)\n",
    "results['alpha3'] = np.log10(np.array(N_PN)/results['Lbol'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first we look at the parameter space that our sample covers. We see that more massive galaxies are also more luminous, and that the massive galaxies in our sample are further away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double distance means increasing the ditsance modulus by\n",
    "d = Distance(distmod=27.9)\n",
    "d2 = Distance(2*d)\n",
    "\n",
    "print(f'd={d.distmod:.2f}, 2d={d2.distmod:.2f}, dd={d2.distmod-d.distmod:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "sc = ax.scatter(results['mass'],results['Lbol'])\n",
    "ax.set(xlabel=r'$\\log M/\\mathrm{M}_\\odot$',ylabel=r'$L_\\mathrm{bol}/\\mathrm{L}_\\odot$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "halign = {'NGC0628':'right','NGC1300':'right','NGC1512':'right'}\n",
    "valign = {'NGC1512':'top','NGC1300':'bottom'}\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "ax.scatter(results['mass'],results['(m-M)'])\n",
    "for name in sample_table['name']:\n",
    "    ax.text(sample_table.loc[name]['mass'],results.loc[name]['(m-M)'],name,\n",
    "            horizontalalignment=halign.get(name,'left'),\n",
    "            verticalalignment=valign.get(name,'center'))\n",
    "ax.set(xlabel=r'$\\log M/\\mathrm{M}_\\odot$',ylabel='distance',xlim=[9.2,11.5])      \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the number of PN decreases with distances because we sample a smaller part of the PNLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.analyse import F,cdf\n",
    "\n",
    "mu0 = 28.\n",
    "mhigh = 28   # also the completeness limit\n",
    "x = np.linspace(mu0-4.47,mhigh)\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(single_column,single_column/1.618))\n",
    "\n",
    "for dmu in [0,0.5,1,1.5]:\n",
    "    xp = x+dmu\n",
    "    yp = cdf(x,mu0,mhigh)\n",
    "    ax.plot(xp,yp,label=f'(m-M)={mu0+dmu}')\n",
    "    # how far above the cutoff until we detect 20%\n",
    "    p = yp[np.argmax(xp>=28)]\n",
    "    print(f'mu={mu0+dmu}, cutoff={mu0+dmu-4.47}, p={p:.2f}')\n",
    "\n",
    "ax.axvline(28,color='black')    \n",
    "ax.set(xlabel='mOIII',ylabel='cumulative PNLF')\n",
    "plt.legend()\n",
    "plt.savefig('cumPNLF.png',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu0 = 28.\n",
    "mhigh = 28\n",
    "x = np.linspace(mu0-4.47,mhigh)\n",
    "\n",
    "p = []\n",
    "distmod = np.arange(28.,33,0.25)\n",
    "distance = Distance(distmod=distmod).to(u.Mpc).value\n",
    "\n",
    "for mu in distmod:\n",
    "    dmu = mu-mu0\n",
    "    xp = x+dmu\n",
    "    yp = cdf(x,mu0,mhigh)\n",
    "    p.append(yp[np.argmax(xp>=28)])\n",
    "p = np.array(p)\n",
    "\n",
    "fig,(ax1,ax2)=plt.subplots(ncols=2,figsize=(two_column,two_column/2))\n",
    "ax1.plot(distmod,p)\n",
    "ax1.axvline(mhigh+4.47,color='black')\n",
    "ax1.set(xlabel='(m-M) / mag',ylabel=r'$N_\\mathrm{PN}$')\n",
    "\n",
    "ax2.plot(distance,p)\n",
    "ax2.axvline(Distance(distmod=mhigh+4.47).to(u.Mpc).value,color='black')\n",
    "ax2.set(xlabel='distance / Mpc',ylabel=r'$N_\\mathrm{PN}$')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our goal is to predict how many PNe we find a a given galaxy. We start by looking at the number of PN we find as a function of the distance to the galaxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "ref_gal = 'NGC0628'\n",
    "row = results.loc[ref_gal]\n",
    "\n",
    "# number of PN at reference point (1-res/250) for decrease due to resolution\n",
    "Nref = row['N_PN'] / np.interp(row['d/Mpc'],distance,p)\n",
    "alpha = np.log10(p*Nref/row['Lbol'])\n",
    "\n",
    "\n",
    "halign = {\n",
    " 'IC5332': 'left','NGC0628': 'left','NGC1087': 'right','NGC1300': 'right',\n",
    " 'NGC1365': 'left','NGC1385': 'right','NGC1433': 'left','NGC1512': 'right',\n",
    " 'NGC1566': 'left','NGC1672': 'right','NGC2835': 'left','NGC3351': 'left',\n",
    " 'NGC3627': 'left','NGC4254': 'right','NGC4303': 'right','NGC4321': 'right',\n",
    " 'NGC4535': 'left','NGC5068': 'left','NGC7496': 'right'}\n",
    "\n",
    "valign = {\n",
    " 'IC5332': 'bottom','NGC0628': 'bottom','NGC1087': 'bottom','NGC1300': 'center',\n",
    " 'NGC1365': 'top','NGC1385': 'bottom','NGC1433': 'center','NGC1512': 'top',\n",
    " 'NGC1566': 'bottom','NGC1672': 'bottom','NGC2835': 'top','NGC3351': 'center',\n",
    " 'NGC3627': 'bottom','NGC4254': 'bottom','NGC4303': 'top','NGC4321': 'center',\n",
    " 'NGC4535': 'bottom','NGC5068': 'bottom','NGC7496': 'bottom'}\n",
    "\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(single_column,single_column/1.618))\n",
    "\n",
    "ax.plot(distance,alpha,color='gray',lw=0.5,zorder=1)\n",
    "\n",
    "'''\n",
    "cmap = plt.cm.viridis_r\n",
    "cmap.set_bad('black')\n",
    "#tmp = results[np.isin(results['name'],masked)]\n",
    "tmp = results[results['AO']]\n",
    "sc = ax.scatter(tmp['d/Mpc'],tmp['alpha2'],s=2,marker='d',\n",
    "                c=tmp['age_mw'],cmap=cmap,zorder=2)\n",
    "#tmp = results[~np.isin(results['name'],masked)]\n",
    "tmp = results[~results['AO']]\n",
    "sc = ax.scatter(tmp['d/Mpc'],tmp['alpha2'],s=2,marker='o',\n",
    "                c=tmp['age_mw'],cmap=cmap,zorder=2)\n",
    "'''\n",
    "\n",
    "yerr = 1/(np.sqrt(results['N_PN'])*np.log(10))\n",
    "\n",
    "#ax.errorbar(results['d/Mpc'],results['alpha2'],yerr=yerr,\n",
    "#                 ms=2,fmt='o',color=tab10[0],zorder=2)\n",
    "sc = ax.scatter(results['d/Mpc'],results['alpha2'], c=sample_table['12+logOH'], s=4, zorder=3)\n",
    "\n",
    "for name in results['name']:\n",
    "    ax.text(results.loc[name]['d/Mpc'],results.loc[name]['alpha2'],name,\n",
    "            horizontalalignment=halign.get(name,'left'),\n",
    "            verticalalignment=valign.get(name,'center'),\n",
    "            fontsize=4)\n",
    "fig.colorbar(sc,label=r'$12+\\log_{10} \\mathrm{O/H}$')\n",
    "#fig.colorbar(sc,label=r'$N_\\mathrm{PN} / L_\\mathrm{bol}$')\n",
    "ax.set(xlim=[4,27],\n",
    "       xlabel='distance / Mpc',\n",
    "       ylabel=r'$\\log_{10} (N_\\mathrm{PN} / L_\\mathrm{bol})$')\n",
    "plt.savefig(basedir/'reports'/'specific_PN_number_vs_distance.pdf',dpi=600)\n",
    "plt.show()\n",
    "\n",
    "print(spearmanr(results['resolution'],results['alpha2']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the number of detection does not really depend on the distance but rather on the resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "ref_gal = 'NGC0628'\n",
    "row = results.loc[ref_gal]\n",
    "\n",
    "res = np.mean(results['PSF'])*(Distance(distmod=distmod)*(u.arcsec.to(u.rad))).to(u.pc).value\n",
    "# number of PN at reference point (1-res/250) for decrease due to resolution\n",
    "Nref = row['N_PN'] / np.interp(row['resolution'],res,p)\n",
    "alpha = np.log10(p*Nref/row['Lbol'])\n",
    "\n",
    "masked = [k for k,v in parameters.items() if 'mask' in v]\n",
    "\n",
    "halign = {\n",
    " 'IC5332': 'left','NGC0628': 'left','NGC1087': 'center','NGC1300': 'right',\n",
    " 'NGC1365': 'right','NGC1385': 'left','NGC1433': 'left','NGC1512': 'left',\n",
    " 'NGC1566': 'right','NGC1672': 'left','NGC2835': 'left','NGC3351': 'left',\n",
    " 'NGC3627': 'center','NGC4254': 'right','NGC4303': 'right','NGC4321': 'center',\n",
    " 'NGC4535': 'right','NGC5068': 'left','NGC7496': 'left'}\n",
    "\n",
    "valign = {\n",
    " 'IC5332': 'bottom','NGC0628': 'bottom','NGC1087': 'bottom','NGC1300': 'center',\n",
    " 'NGC1365': 'bottom','NGC1385': 'top','NGC1433': 'top','NGC1512': 'center',\n",
    " 'NGC1566': 'center','NGC1672': 'top','NGC2835': 'bottom','NGC3351': 'top',\n",
    " 'NGC3627': 'bottom','NGC4254': 'bottom','NGC4303': 'top','NGC4321': 'bottom',\n",
    " 'NGC4535': 'top','NGC5068': 'top','NGC7496': 'bottom'}\n",
    "\n",
    "print('correlation={:.2f}, pvalue={:.4f}'.format(*spearmanr(results['resolution'],results['alpha2'])))\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(single_column,single_column/1.618))\n",
    "\n",
    "ax.plot(res,alpha,color='gray',lw=0.5,zorder=1)\n",
    "\n",
    "#sc = ax.scatter(results['resolution'],results['alpha2'],s=2,\n",
    "#                c=results['mass'],cmap=plt.cm.viridis_r,zorder=2)\n",
    "\n",
    "#tmp = results[np.isin(results['name'],masked)]\n",
    "tmp = results[results['AO']]\n",
    "sc = ax.scatter(tmp['resolution'],tmp['alpha2'],s=2,marker='d',\n",
    "                c=tmp['R0'],cmap=plt.cm.viridis_r,zorder=2)\n",
    "#tmp = results[~np.isin(results['name'],masked)]\n",
    "tmp = results[~results['AO']]\n",
    "sc = ax.scatter(tmp['resolution'],tmp['alpha2'],s=2,marker='o',\n",
    "                c=tmp['R0'],cmap=plt.cm.viridis_r,zorder=2)\n",
    "\n",
    "\n",
    "for name in results['name']:\n",
    "    ax.text(results.loc[name]['resolution'],results.loc[name]['alpha2'],name,\n",
    "            horizontalalignment=halign.get(name,'left'),\n",
    "            verticalalignment=valign.get(name,'center'),\n",
    "            fontsize=4)\n",
    "#fig.colorbar(sc,label=r'$\\log_{10} M/\\mathrm{M}_\\odot$')\n",
    "fig.colorbar(sc,label=r'$12+\\log_{10} \\mathrm{O/H}$')\n",
    "\n",
    "ax.set(xlim=[11,91],\n",
    "       xlabel='resolution in pc',\n",
    "       ylabel=r'$\\log_{10} N_\\mathrm{PN} / L_\\mathrm{bol}$')\n",
    "plt.savefig(basedir/'reports'/'specific_PN_number_vs_resolution.pdf',dpi=600)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "can I simply use the number of detected PN? This means that galaxies further away will natuarlly have fewer detections as their cutoff is closer to the completeness limit and hence we expect fewer PNe anyways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "halign = {\n",
    " 'IC5332': 'right','NGC0628': 'left','NGC1087': 'left','NGC1300': 'right',\n",
    " 'NGC1365': 'left','NGC1385': 'left','NGC1433': 'left','NGC1512': 'left',\n",
    " 'NGC1566': 'right','NGC1672': 'left','NGC2835': 'left','NGC3351': 'left',\n",
    " 'NGC3627': 'right','NGC4254': 'left','NGC4303': 'right','NGC4321': 'right',\n",
    " 'NGC4535': 'left','NGC5068': 'left','NGC7496': 'left'}\n",
    "\n",
    "valign = {\n",
    " 'IC5332': 'top','NGC0628': 'bottom','NGC1087': 'bottom','NGC1300': 'center',\n",
    " 'NGC1365': 'top','NGC1385': 'top','NGC1433': 'center','NGC1512': 'top',\n",
    " 'NGC1566': 'center','NGC1672': 'top','NGC2835': 'bottom','NGC3351': 'top',\n",
    " 'NGC3627': 'top','NGC4254': 'top','NGC4303': 'top','NGC4321': 'center',\n",
    " 'NGC4535': 'top','NGC5068': 'top','NGC7496': 'bottom'}\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(2*single_column,2*single_column/1.618))\n",
    "sc = ax.scatter(results['resolution'],results['alpha'],s=8,\n",
    "                c=results['mass'],cmap=plt.cm.viridis_r)\n",
    "for name in results['name']:\n",
    "    ax.text(results.loc[name]['resolution'],results.loc[name]['alpha'],name,\n",
    "            horizontalalignment=halign.get(name,'left'),\n",
    "            verticalalignment=valign.get(name,'center'),\n",
    "            fontsize=8)\n",
    "\n",
    "fig.colorbar(sc,label=r'$\\log_{10} M/\\mathrm{M}_\\odot$')\n",
    "\n",
    "#fig.colorbar(sc,label=r'$N_\\mathrm{PN} / L_\\mathrm{bol}$')\n",
    "ax.set(xlim=[10,90],\n",
    "       xlabel='resolution / pc',\n",
    "       ylabel=r'$\\log N_\\mathrm{PN} / L_\\mathrm{bol}$')\n",
    "#plt.savefig(basedir/'reports'/'specific_PN_number_vs_resolution.pdf',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how many PN do we expect in a given galaxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate alpha from a reference galaxy\n",
    "ref_gal = 'IC5332'\n",
    "row = results.loc[ref_gal]\n",
    "Nref = row['N_PN'] / np.interp(row['(m-M)'],distmod,p)\n",
    "alpha = np.log10(p*Nref/row['Lbol'])\n",
    "\n",
    "# use alpha to predict the number of PN in another galaxy\n",
    "gal_name = 'NGC1365'\n",
    "row = results.loc[gal_name]\n",
    "a = np.interp(row['(m-M)'],distmod,alpha)\n",
    "print(f\"predicted: {10**a * row['Lbol']:.1f}, observed: {row['N_PN']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or based on resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate alpha from a reference galaxy\n",
    "ref_gal = 'NGC1512'\n",
    "row = results.loc[ref_gal]\n",
    "Nref = row['N_PN'] / np.interp(row['resolution'],res,p)\n",
    "alpha = np.log10(p*Nref/row['Lbol'])\n",
    "\n",
    "# use alpha to predict the number of PN in another galaxy\n",
    "gal_name = 'NGC0628'\n",
    "row = results.loc[gal_name]\n",
    "a = np.interp(row['resolution'],res,alpha)\n",
    "print(f\"predicted: {10**a * row['Lbol']:.1f}, observed: {row['N_PN']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "up to what distance can we observe a given galaxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = []\n",
    "for ref_gal in results['name']:\n",
    "    row = results.loc[ref_gal]\n",
    "    Nref = row['N_PN'] / np.interp(row['d/Mpc'],distance,p)\n",
    "    alpha = np.log10(p*Nref/row['Lbol'])\n",
    "    alphas.append(alpha[0])\n",
    "    alpha_min = np.log10(20/row['Lbol'])\n",
    "    max_dist = np.interp(-alpha_min,-alpha,distance)\n",
    "    \n",
    "    print(f'{ref_gal}: alpha={alpha[0]:.2f}, max_dist={max_dist:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10**min(alphas)/10**max(alphas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NGC5068 has the largest $\\alpha=-7.56$ and NGC1433 is the most luminous. Up to what distance could we observe a combination of both. NGC1365 has the smallest $\\alpha=-8.32$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = results.loc['NGC5068']\n",
    "Nref = row['N_PN'] / np.interp(row['d/Mpc'],distance,p)\n",
    "alpha = np.log10(p*Nref/row['Lbol'])\n",
    "\n",
    "row = results.loc['NGC1433']\n",
    "alpha_min = np.log10(20/row['Lbol'])\n",
    "max_dist = np.interp(-alpha_min,-alpha,distance)\n",
    "\n",
    "print(f'alpha={alpha[0]:.2f}, max_dist={max_dist:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = results.loc['NGC1365']\n",
    "Nref = row['N_PN'] / np.interp(row['d/Mpc'],distance,p)\n",
    "alpha = np.log10(p*Nref/row['Lbol'])\n",
    "\n",
    "row = results.loc['NGC1433']\n",
    "alpha_min = np.log10(20/row['Lbol'])\n",
    "max_dist = np.interp(-alpha_min,-alpha,distance)\n",
    "\n",
    "print(f'alpha={alpha[0]:.2f}, max_dist={max_dist:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alst = []\n",
    "for ref_gal in results['name']:\n",
    "    row = results.loc[ref_gal]\n",
    "    Nref = row['N_PN'] / np.interp(row['(m-M)'],distmod,p)\n",
    "    alpha = np.log10(p*Nref/row['Lbol'])\n",
    "    alst.append(alpha[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(single_column,single_column))\n",
    "\n",
    "ax.scatter(sample_table['12+logOH'],10**results['alpha'])\n",
    "ax.set(ylim=[1e-9,1.5e-8])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.scatter(results['mass'],results['obs_mass'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redo \n",
    "\n",
    "this section can be used to redo certain steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extinction correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyneb\n",
    "import re\n",
    "\n",
    "with fits.open(basedir/'data'/'catalogues'/f'nebulae_full.fits') as hdul:\n",
    "    catalogue = Table(hdul[1].data)\n",
    "catalogue['SkyCoord'] = SkyCoord(catalogue['RaDec'])\n",
    "\n",
    "rc = pyneb.RedCorr(R_V = 3.1, law = 'CCM89')\n",
    "rc.setCorr(obs_over_theo= catalogue['HA6562']/catalogue['HB4861'] / 2.86, wave1=6562.81, wave2=4861.33)\n",
    "rc.E_BV[(rc.E_BV<0) | (catalogue['HB4861']<3*catalogue['HB4861_err']) |  (catalogue['HA6562']<3*catalogue['HA6562_err'])] = 0\n",
    "catalogue['EBV_balmer'] = rc.E_BV\n",
    "catalogue['A5007'] =  -2.5*np.log10(rc.getCorr(5007))\n",
    "    \n",
    "catalogue['type_old'] = catalogue['type']\n",
    "catalogue['mOIII_old'] = catalogue['mOIII']\n",
    "\n",
    "for line in ['HB4861', 'OIII5006', 'HA6562', 'NII6583', 'SII6716', 'SII6730']:\n",
    "    wavelength = int(re.findall(r'\\d{4}', line)[0])\n",
    "    catalogue[f'{line}_old'] = catalogue[f'{line}']\n",
    "    catalogue[f'{line}_old_err'] = catalogue[f'{line}_err']\n",
    "    catalogue[line] = catalogue[line] * rc.getCorr(wavelength)\n",
    "    catalogue[f'{line}_err'] = catalogue[f'{line}_err'] * rc.getCorr(wavelength)\n",
    "catalogue['mOIII'] = -2.5*np.log10(catalogue['OIII5006']*1e-20) - 13.74\n",
    "\n",
    "print(f\"{np.sum((catalogue['type']=='PN') & (catalogue['A5007']<0))} objects have Av<0\")\n",
    "print(f\"mean A5007: {np.nanmean(catalogue[(catalogue['type']=='PN') & (catalogue['A5007']<0)]['A5007']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gal_name='NGC1433'\n",
    "print(f\"bright end: {results.loc[gal_name]['(m-M)']-4.47:.2f}\")\n",
    "sub = catalogue[(catalogue['gal_name']==gal_name) & (catalogue['type']=='PN') & (catalogue['A5007']<0)]\n",
    "sub.sort('mOIII_old')\n",
    "sub[['id','mOIII_old','mOIII','A5007']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gal_name in np.unique(catalogue['gal_name']):\n",
    "    a = catalogue['A5007'][(catalogue['gal_name']==gal_name) & (catalogue['type']=='PN') & (catalogue['A5007']<0)]\n",
    "    print(f'{gal_name}: {np.nanmean(a):.2f} ({len(a)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(A5007[(catalogue['type']=='PN') & (catalogue['mOIII']<28) & (A5007<0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "ax.hist(A5007[(catalogue['type']=='PN') & (catalogue['mOIII']<28)],bins=np.arange(-2,-0.01,0.2))\n",
    "ax.set(xlabel=r'$A_{5007}$',ylabel='N')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.analyse import emission_line_diagnostics\n",
    "catalogue['HA6562_SIGMA'] = 0\n",
    "lst = []\n",
    "for name in results['name']:\n",
    "    lst.append(emission_line_diagnostics(catalogue[catalogue['gal_name']==name],results.loc[name]['(m-M)'],28))\n",
    "tbl = vstack(lst)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl['HA6562_detection'] = tbl['HA6562_detection']=='True'\n",
    "tbl['SII_detection'] = tbl['SII_detection']=='True'\n",
    "tbl['overluminous'] = tbl['overluminous'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = tbl[((tbl['type']!='PN') & (tbl['type_old']=='PN')) | ((tbl['type']=='PN') & (tbl['type_old']!='PN'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.plot import plot_emission_line_ratio\n",
    "\n",
    "sample = sample[sample['mOIII']<28]\n",
    "\n",
    "plot_emission_line_ratio(sample,mu=30,completeness=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = tbl[(tbl['type']=='PN') & (tbl['type_old']!='PN')] #[['mOIII','mOIII_old']]\n",
    "problem[problem['mOIII']<28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(8,8))\n",
    "\n",
    "for t in ['HII','SNR','PN']:\n",
    "    tmp=catalogue[catalogue['type']==t]\n",
    "    ax.scatter(tmp['mOIII_old'],tmp['mOIII'],label=t)\n",
    "ax.plot([22,29],[22,29],color='black')\n",
    "ax.legend()\n",
    "ax.set(xlim=[22,29],ylim=[22,29])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(8,8))\n",
    "\n",
    "\n",
    "ax.scatter(catalogue['EBV_balmer'],catalogue['Ebv'])\n",
    "ax.plot([0,2],[0,2],color='black')\n",
    "ax.legend()\n",
    "ax.set(xlim=[0,2],ylim=[0,2],xlabel='E(B-V) Balmer',ylabel='E(B-V) Stars')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc.setCorr(obs_over_theo= catalogue['HA6562']/catalogue['HB4861'] / 2.86, wave1=6562.81, wave2=4861.33)\n",
    "EBV = rc.E_BV\n",
    "\n",
    "rc.setCorr(obs_over_theo= (catalogue['HA6562']-catalogue['HA6562_err']) / (catalogue['HB4861']+catalogue['HB4861_err']) / 2.86, wave1=6562.81, wave2=4861.33)\n",
    "EBV_minus = rc.E_BV\n",
    "\n",
    "rc.setCorr(obs_over_theo= (catalogue['HA6562']+catalogue['HA6562_err']) / (catalogue['HB4861']-catalogue['HB4861_err']) / 2.86, wave1=6562.81, wave2=4861.33)\n",
    "EBV_plus = rc.E_BV\n",
    "\n",
    "criteria  = (catalogue['type']=='PN')\n",
    "criteria &= (catalogue['HB4861']>3*catalogue['HB4861_err'])\n",
    "criteria &= (catalogue['HA6562']>3*catalogue['HA6562_err']) \n",
    "\n",
    "np.sum(criteria & (EBV_minus>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria  = (catalogue['type']=='PN')\n",
    "criteria &= (catalogue['HB4861']>3*catalogue['HB4861_err'])\n",
    "criteria &= (catalogue['HA6562']>3*catalogue['HA6562_err']) \n",
    "criteria &= (catalogue['EBV']>0) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(4,4))\n",
    "ax.hist(EBV[criteria],bins=np.arange(0,1,0.1),alpha=0.5)\n",
    "ax.hist(EBV_minus[criteria],bins=np.arange(0,1,0.1),alpha=0.5)\n",
    "\n",
    "\n",
    "ax.set(xlim=[0,1],xlabel='E(B-V) balmer')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(4,4))\n",
    "ax.hist(catalogue[criteria]['EBV'],bins=np.arange(0,1,0.1))\n",
    "ax.set(xlim=[0,1],xlabel='E(B-V) balmer')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(4,4))\n",
    "ax.scatter(catalogue[criteria]['mOIII'],catalogue[criteria]['mOIII_corr'])\n",
    "ax.plot([25,29],[25,29],color='black')\n",
    "ax.set(xlim=[25,29],ylim=[25,29])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(catalogue[criteria]['mOIII']-catalogue[criteria]['mOIII_corr'],bins=np.arange(0,5,0.5))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in np.unique(catalogue['gal_name']):\n",
    "    completeness = 28\n",
    "    \n",
    "    criteria  = (catalogue['gal_name']==name) \n",
    "    criteria &= (catalogue['type']=='PN') \n",
    "    criteria &= (catalogue['note']=='') \n",
    "    criteria &= (catalogue['HB4861']>3*catalogue['HB4861_err'])\n",
    "    sub = catalogue[criteria]\n",
    "    \n",
    "    print(f'{name}: min mOIII: {np.nanmin(sub[\"mOIII\"])}, {np.nanmin(sub[\"mOIII_corr\"])}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With CO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = pyneb.RedCorr(R_V = 3.1, law = 'CCM89')\n",
    "rc.setCorr(obs_over_theo= tmp['HA6562']/tmp['HB4861'] / 2.86, wave1=6562.81, wave2=4861.33)\n",
    "rc.E_BV[(rc.E_BV<0) | (tmp['HB4861']<3*tmp['HB4861_err']) |  (tmp['HA6562']<3*tmp['HA6562_err'])] = 0\n",
    "tmp['EBV_balmer'] = rc.E_BV\n",
    "tmp['A5007'] = -2.5*np.log10(rc.getCorr(5007))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from photutils import SkyCircularAperture, aperture_photometry\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "\n",
    "\n",
    "for name in np.unique(catalogue['gal_name']):\n",
    "    tmp = catalogue[(catalogue['gal_name']==name) & (catalogue['type']=='PN')]\n",
    "    if np.sum((tmp['A5007']<0) & (tmp['type']=='PN'))<2:\n",
    "        print(f'no PN for {name}')\n",
    "        continue\n",
    "    \n",
    "    with fits.open(data_ext/'ALMAv4p0'/f'{name.lower()}_12m+7m+tp_co21_broad_mom0.fits') as hdul:\n",
    "        CO = NDData(data=hdul[0].data,\n",
    "                    meta=hdul[0].header,\n",
    "                    wcs=WCS(hdul[0].header))\n",
    "\n",
    "    aperture = SkyCircularAperture(tmp['SkyCoord'],r=0.6*u.arcsec)\n",
    "    CO_flux = aperture_photometry(CO,aperture)\n",
    "    tmp['CO'] = CO_flux['aperture_sum']\n",
    "\n",
    "    ax.scatter(tmp['A5007'],tmp['CO'],label=name)\n",
    "\n",
    "ax.legend()\n",
    "ax.set(xlim=[-4,-0.1])\n",
    "ax.set(xlabel=r'$A_{5007}$',ylabel='CO')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PNLF fit\n",
    "\n",
    "this cell fits all galaxies and saves the resulting figures and distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.analyse import MaximumLikelihood1D, PNLF, pnlf, cdf\n",
    "from pnlf.plot.pnlf import plot_pnlf\n",
    "from scipy.stats import kstest\n",
    "\n",
    "name = 'NGC5068'\n",
    "\n",
    "tbl = Table(fits.getdata(basedir/'data'/'catalogues'/'PN_catalogue.fits'))\n",
    "tbl['overluminous'] = tbl['note']=='OL'\n",
    "\n",
    "completeness = parameters[name]['completeness_limit']\n",
    "binsize = parameters[name]['binsize']\n",
    "\n",
    "criteria = (tbl['type']=='PN') & ~tbl['overluminous'] & (tbl['gal_name']==name)\n",
    "data = tbl[criteria]\n",
    "print(f'{len(data)} PNe in sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from dust_extinction.parameter_averages import O94, CCM89\n",
    "from cluster.extinction import balmer_decrement\n",
    "\n",
    "extinction_model = CCM89(Rv=3.1)\n",
    "\n",
    "data['EBV'] = balmer_decrement(data['HA6562'],data['HB4861'],\n",
    "                               extinction_model=extinction_model)\n",
    "\n",
    "for line in ['HB4861','OIII5006','HA6562','NII6583','SII6716','SII6730']:\n",
    "    wavelength = int(re.findall(r'\\d{4}', line)[0])\n",
    "    print(f'working on {line}: {wavelength} A')\n",
    "    extinction_int = extinction_model.extinguish(wavelength*u.angstrom,Ebv=data['EBV'])\n",
    "    \n",
    "    data[f'{line}_corr'] = data[line] / extinction_int\n",
    "\n",
    "data['mOIII_corr'] = -2.5*np.log10(data['OIII5006_corr']*1e-20) - 13.74\n",
    "#data['dmOIII'] = np.abs( 2.5/np.log(10) * flux['OIII5006_err'] / flux['OIII5006'] )\n",
    "\n",
    "if True:\n",
    "    fig,ax=plt.subplots(figsize=(4,4))\n",
    "    ax.scatter(data['mOIII'],data['mOIII_corr'])\n",
    "    ax.plot([25,29],[25,29],color='black')\n",
    "    ax.set(xlim=[25,29],ylim=[25,29])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mmax = -4.53\n",
    "\n",
    "fitter = MaximumLikelihood1D(pnlf,data['mOIII'],err=data['dmOIII'],mhigh=completeness,Mmax=Mmax)\n",
    "mu,dp,dm = fitter([28])\n",
    "print('{:.2f} + {:.2f} - {:.2f}'.format(mu,dp,dm))\n",
    "\n",
    "ks,pv = kstest(data['mOIII'],cdf,args=(mu,completeness))\n",
    "print(f'statistic={ks:.3f}, pvalue={pv:.3f}')\n",
    "\n",
    "filename = None #basedir / 'reports' / galaxy.name / f'{galaxy.name}_PNLF_with_SNR'\n",
    "ax = plot_pnlf(data['mOIII'],mu,completeness,binsize=binsize,mhigh=30,color=tab10[0])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['EBV'] = balmer_decrement(data['HA6562'],data['HB4861'])\n",
    "\n",
    "plt.hist(data['EBV'],bins=np.arange(0,1,0.1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for all galaxies at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.analyse import MaximumLikelihood1D, PNLF, pnlf, cdf\n",
    "from pnlf.plot.pnlf import plot_pnlf\n",
    "from scipy.stats import kstest\n",
    "from pnlf.utils import get_bolometric_luminosity\n",
    "from pnlf.analyse import N25\n",
    "import datetime\n",
    "date = datetime.date.today().strftime('%Y.%m.%d')\n",
    "\n",
    "results = ascii.read(basedir/'data'/'interim'/ 'results.txt',format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "results.add_index('name')  \n",
    "    \n",
    "for name in results['name']:\n",
    "    \n",
    "    print(f'working on {name}')\n",
    "    \n",
    "    tbl = ascii.read(basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt')\n",
    "    tbl['SNRorPN'] = tbl['SNRorPN'] == 'True'\n",
    "    tbl['exclude'] = tbl['exclude'].astype(bool)\n",
    "    tbl['overluminous'] = tbl['overluminous'].astype(bool)\n",
    "\n",
    "    completeness = parameters[name]['completeness_limit']\n",
    "    binsize = parameters[name]['binsize']\n",
    "\n",
    "    criteria1 = (tbl['type']=='PN') & ~tbl['exclude'] & ~tbl['overluminous'] & (tbl['mOIII']<completeness)\n",
    "    data1 = tbl[criteria1]['mOIII']\n",
    "    err1  = tbl[criteria1]['dmOIII']\n",
    "\n",
    "    criteria2 = ((tbl['type']=='PN')|((tbl['type']=='SNR')&(tbl['SNRorPN']))) & ~tbl['exclude'] & ~tbl['overluminous'] & (tbl['mOIII']<completeness)\n",
    "    data2 = tbl[criteria2]['mOIII']\n",
    "    err2  = tbl[criteria2]['dmOIII']\n",
    "    \n",
    "    fitter = MaximumLikelihood1D(pnlf,data1,err=err1,mhigh=completeness)\n",
    "    mu1,dp1,dm1 = fitter([28])\n",
    "\n",
    "    ks1,pv1 = kstest(data1,cdf,args=(mu1,completeness))\n",
    "    print(f'without SNR: statistic={ks1:.3f}, pvalue={pv1:.3f}')\n",
    "\n",
    "    fitter = MaximumLikelihood1D(pnlf,data2,err=err2,mhigh=completeness)\n",
    "    mu2,dp2,dm2 = fitter([28])\n",
    "\n",
    "    ks2,pv2 = kstest(data1,cdf,args=(mu2,completeness))\n",
    "    print(f'with SNR: statistic={ks2:.3f}, pvalue={pv2:.3f}')\n",
    "\n",
    "    print(f'without SNR: {mu1:.2f}+{dp1:.2f}-{dm1:.2f}\\nwith SNR:    {mu2:.2f}+{dp2:.2f}-{dm2:.2f} ({mu1-mu2:.2f})')\n",
    "\n",
    "    #filename = basedir / 'reports' / galaxy.name / f'{galaxy.name}_PNLF_with_SNR'\n",
    "    #axes = plot_pnlf(tbl[criteria1]['mOIII'],mu1,completeness,binsize=binsize,mhigh=30,color=tab10[0])\n",
    "    #axes = plot_pnlf(tbl[criteria2]['mOIII'],mu2,completeness,binsize=binsize,mhigh=30,filename=filename,color='grey',alpha=0.7,axes=axes)\n",
    "    #plt.show()\n",
    "\n",
    "    results.loc[name]['(m-M)'] = mu1\n",
    "    results.loc[name]['err+(m-M)'] = dp1\n",
    "    results.loc[name]['err-(m-M)'] = dm1\n",
    "    results.loc[name]['mu_SNR'] = mu2\n",
    "    results.loc[name]['mu_SNR+'] = dp2\n",
    "    results.loc[name]['mu_SNR-'] = dm2\n",
    "    results.loc[name]['d/Mpc'] = Distance(distmod=mu1).to(u.Mpc).value\n",
    "    results.loc[name]['err+d/Mpc'] = 2*np.log(10)*10**(mu1/5) * dp1 / 1e6\n",
    "    results.loc[name]['err-d/Mpc'] = 2*np.log(10)*10**(mu1/5) * dm1 / 1e6\n",
    "    \n",
    "    # save results to output table\n",
    "    for col in results.colnames[2:]:\n",
    "        if col.startswith('N_'):\n",
    "            results[col].info.format = '%.0f'\n",
    "        else:\n",
    "            results[col].info.format = '%.3f'\n",
    "    results['Lbol'].info.format = '%.2e'    \n",
    "    \n",
    "with open(basedir/'data'/'interim'/ 'results_new.txt','w',newline='\\n') as f:\n",
    "    ascii.write(results,f,format='fixed_width_two_line',overwrite=True,delimiter_pad=' ',position_char='=')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### literature distance plot\n",
    "\n",
    "in case something has changed, this cell creates the plot with the comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.plot import compile_distances, plot_distances\n",
    "\n",
    "name = 'NGC4303'\n",
    "#for name in results['name']:\n",
    "\n",
    "plt.close('all')    \n",
    "mu,mu_m,mu_p = results.loc[name][['(m-M)','err-(m-M)','err+(m-M)']]\n",
    "print(name)\n",
    "filename = basedir / 'reports' / name / f'{name}_distances'\n",
    "distances = compile_distances(name)\n",
    "plot_distances(name,mu,mu_p,mu_m,distances,filename=filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emission line diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all objects defined here from the sample\n",
    "# define masks as slices\n",
    "exclude = {\n",
    " 'IC5332'  : [1338],\n",
    " 'NGC0628' : [886],\n",
    " 'NGC1300' : [2702,2578,2466,2523],\n",
    " 'NGC1365' : [730],\n",
    " 'NGC1385' : [88,44,585,606,677,106,29],\n",
    " 'NGC1512' : [272],\n",
    " 'NGC1566' : [25,168],\n",
    " 'NGC1672' : [275,199,],\n",
    " 'NGC2835' : [179,416,287,807],\n",
    " 'NGC4254' : [496,1948,1947,624,1941,473,206,285,573,482],\n",
    " 'NGC4303' : [411,380,327],\n",
    " 'NGC5068' : [554,557],\n",
    " 'NGC7496' : [353],\n",
    "}\n",
    "\n",
    "overluminous = {\n",
    " 'NGC1087' : [878],\n",
    " 'NGC1512' : [277],\n",
    " 'NGC1566' : [199,103],\n",
    " 'NGC1672' : [204,42],\n",
    " 'NGC2835' : [],\n",
    " 'NGC4254' : [447,345,1104],\n",
    " 'NGC4303' : [370],\n",
    " 'NGC4321' : [2571],\n",
    " 'NGC7496' : [408,350],\n",
    "}\n",
    "\n",
    "slow  = .2 #galaxy.sharplo  \n",
    "shigh = 1. #galaxy.sharphi \n",
    "r     = .8 #galaxy.roundness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'NGC1672'\n",
    "\n",
    "distance_modulus = parameters[name]['mu']\n",
    "completeness_limit = parameters[name]['completeness_limit']\n",
    "\n",
    "with fits.open(basedir/'data'/'interim'/'fluxes'/f'{name}_fluxes.fits') as hdul:\n",
    "    flux = Table(hdul[1].data)\n",
    "flux['SkyCoord'] = SkyCoord(flux['RaDec'])\n",
    "\n",
    "# create additional columns that are needed for the classification\n",
    "flux['exclude'] = False\n",
    "flux['overluminous'] = False\n",
    "\n",
    "# flag the objects from the dictionary\n",
    "indices = np.where(np.in1d(flux['id'], exclude.get(name,[])))[0]\n",
    "flux['exclude'][indices]=True\n",
    "indices = np.where(np.in1d(flux['id'], overluminous.get(name,[])))[0]\n",
    "flux['overluminous'][indices]=True\n",
    "\n",
    "# use mean for background\n",
    "for line in [x.split('_')[0] for x in flux.columns if x.endswith('_flux')]:\n",
    "    flux[f'{line}_flux'] = flux[f'{line}_flux_raw'] - flux[f'{line}_bkg_mean']\n",
    "    \n",
    "print(f'{name}: mu={distance_modulus}, cl={completeness_limit}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.analyse import emission_line_diagnostics\n",
    "from pnlf.analyse import MaximumLikelihood1D, pnlf, cdf\n",
    "from scipy.stats import kstest\n",
    "\n",
    "Mmax = -4.47\n",
    "\n",
    "print(f'emission line diagnostics for {name}')\n",
    "\n",
    "distance_modulus_old = distance_modulus\n",
    "N_PN_old = 0\n",
    "n_iter = 0\n",
    "while True:\n",
    "    n_iter += 1\n",
    "    print(f'\\nitteration {n_iter}')\n",
    "    \n",
    "    tbl = emission_line_diagnostics(flux,distance_modulus=distance_modulus,\n",
    "                                    completeness_limit=completeness_limit,\n",
    "                                    detection_limit=5) \n",
    "\n",
    "    # table contains all detected objects. here we mask all undesired objects.\n",
    "    c_shape = ((tbl['sharp']>slow) & (tbl['sharp']<shigh) & (np.abs(tbl['round'])<r)) \n",
    "    c_PN    = (tbl['type']=='PN')\n",
    "    c_SNR   = (tbl['SNRorPN'] & (tbl['type']=='SNR'))\n",
    "    c_detec = tbl['OIII5006_detection'] \n",
    "    c_limit = (tbl['mOIII']<completeness_limit) \n",
    "\n",
    "    criteria = c_shape & (c_PN) & ~tbl['exclude'] & ~tbl['overluminous'] & ~np.isnan(tbl['mOIII'])\n",
    "    data = tbl[np.where(criteria & c_limit)]['mOIII']\n",
    "    err = tbl[np.where(criteria & c_limit)]['dmOIII']\n",
    "\n",
    "    fitter = MaximumLikelihood1D(pnlf,data,err=err,mhigh=completeness_limit,Mmax=Mmax)\n",
    "    distance_modulus,mu_p,mu_m = fitter([29])\n",
    "    print('{}: {:.2f} + {:.2f} - {:.2f}'.format(name,distance_modulus,mu_p,mu_m))\n",
    "    ks,pv = kstest(data,cdf,args=(distance_modulus,completeness_limit))\n",
    "    print(f'{name}: statistic={ks:.3f}, pvalue={pv:.3f}')\n",
    "    \n",
    "    N_PN = len(data)\n",
    "    if (np.abs((distance_modulus-distance_modulus_old)/distance_modulus_old) > 0.01 or \\\n",
    "       N_PN_old != N_PN) and n_iter < 5:\n",
    "        N_PN_old = N_PN\n",
    "        distance_modulus_old = distance_modulus\n",
    "    else:\n",
    "        print('\\nN_PN and (m-M) did not change!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.plot.pnlf import plot_pnlf\n",
    "\n",
    "binsize = (completeness_limit-Mmax-distance_modulus) / 3\n",
    "filename = None #basedir / 'reports' / f'{name}' / f'{name}_PNLF'\n",
    "axes = plot_pnlf(tbl[criteria]['mOIII'],distance_modulus,completeness_limit,\n",
    "                 binsize=binsize,mhigh=28.5,Mmax=Mmax,filename=filename,color=tab10[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "\n",
    "lim = [1,1e4]\n",
    "ax.scatter(flux['OIII5006_flux'],flux['OIII5006_flux_mean'])\n",
    "ax.plot(lim,lim,color='black')\n",
    "ax.set(xlim=lim,ylim=lim,xscale='log',yscale='log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## PN Number vs Mass etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample=ascii.read(basedir/'reports'/'sample.txt')\n",
    "sample['SkyCoord'] = SkyCoord(sample['R.A.'],sample['Dec.'])\n",
    "sample.add_index('Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "galaxies = {}\n",
    "\n",
    "for n in result['name']:\n",
    "    print('are you sure that you want to run this?')\n",
    "    break\n",
    "    filename = data_raw / 'MUSEDAP' / f'{n}_MAPS.fits'\n",
    "\n",
    "    with fits.open(filename) as hdul:\n",
    "        d=hdul['STELLAR_MASS_DENSITY'].data\n",
    "        galaxies[n]= np.nansum(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "result['mass']=sample['mass']\n",
    "result['Survey Area'] = sample['Survey Area']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Calculate the survey area from number of pixels and distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for row in result:\n",
    "    N_pix = row['N_pixel']\n",
    "    d = Distance(distmod=parameters[row['name']]['mu'])\n",
    "    A_pix = ((d*(0.2/206265))**2).to(u.kpc**2)\n",
    "    \n",
    "    print(f'{row[\"name\"]}: {d:.2f}, {N_pix*A_pix:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,(ax1,ax2,ax3)=plt.subplots(ncols=3,nrows=1,figsize=(12,4))\n",
    "\n",
    "for row in result:\n",
    "    if row['N_PN']>1:\n",
    "        ax1.scatter(row['mass'],row['N_PN'])\n",
    "        ax1.text(row['mass'],row['N_PN']+2,row['name'],horizontalalignment='center')\n",
    "        \n",
    "        \n",
    "        ax2.scatter(row['Survey Area'],row['N_PN'])\n",
    "        ax2.text(row['Survey Area'],row['N_PN']+2,row['name'],horizontalalignment='center') \n",
    "\n",
    "        ax3.scatter(row['N_pixel'],row['N_PN'])\n",
    "        ax3.text(row['N_pixel'],row['N_PN']+2,row['name'],horizontalalignment='center') \n",
    "        \n",
    "\n",
    "ax1.set(xlabel='stellar mass density',ylabel='N PN')\n",
    "ax2.set(xlabel='Survey Area')\n",
    "ax3.set(xlabel='Npixel')\n",
    "#ax3.set(xlabel='Npixel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to literature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Offsets to different methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# combine the different \n",
    "rows = ['gal_name,(m-M),err(m-M),D(Mpc),Method,Refcode,Notes,SN Name,Redshift,H0,LMCModulus']\n",
    "for name in results['name']: \n",
    "    with open(basedir / 'data' / 'literature distances' / f'{name}.csv') as f:\n",
    "        raw = f.read()\n",
    "    for row in raw.split('\\n')[1:]:\n",
    "        if row:\n",
    "            rows.append(name+','+row.strip('#'))\n",
    "#with open(basedir / 'data' / 'literature distances' / f'literature_combined.csv','w+') as f:\n",
    "#    f.write('\\n'.join(rows))\n",
    "distances = ascii.read('\\n'.join(rows))\n",
    "distances['(m-M)_PHANGS'] = np.nan\n",
    "distances['(m-M)_PHANGS_err+'] = np.nan\n",
    "distances['(m-M)_PHANGS_err-'] = np.nan\n",
    "\n",
    "for name in results['name']: \n",
    "    distances['(m-M)_PHANGS'][distances['gal_name']==name] = results.loc[name]['(m-M)'] \n",
    "    distances['(m-M)_PHANGS_err+'][distances['gal_name']==name] = results.loc[name]['err+(m-M)'] \n",
    "    distances['(m-M)_PHANGS_err-'][distances['gal_name']==name] = results.loc[name]['err-(m-M)'] \n",
    "\n",
    "distances['d(m-M)'] =  distances['(m-M)']-distances['(m-M)_PHANGS']\n",
    "\n",
    "del distances[['Notes','SN Name','Redshift','H0','LMCModulus']]\n",
    "distances['year'] = [int(row['Refcode'][:4]) for row in distances]\n",
    "\n",
    "# to combine multiple values from once source\n",
    "'''\n",
    "gal_name = []\n",
    "dm = []\n",
    "err_dm = []\n",
    "methods = []\n",
    "dm_PHANGS = []\n",
    "dm_PHANGS_err_p = []\n",
    "dm_PHANGS_err_m = []\n",
    "marker = []\n",
    "for g in distances.group_by(['Refcode','Method','gal_name']).groups:\n",
    "    gal_name.append(g['gal_name'][0])\n",
    "    dm.append(g['(m-M)'].mean())\n",
    "    err_dm.append(np.sqrt(np.sum(g['err(m-M)']**2)))\n",
    "    methods.append(g['Method'][0])\n",
    "    dm_PHANGS.append(g['(m-M)_PHANGS'][0])\n",
    "    dm_PHANGS_err_p.append(g['(m-M)_PHANGS_err+'][0])\n",
    "    dm_PHANGS_err_m.append(g['(m-M)_PHANGS_err-'][0])\n",
    "\n",
    "    if len(g)==1:\n",
    "        marker.append('o')\n",
    "    else:\n",
    "        marker.append('D')\n",
    "\n",
    "distances = Table([gal_name,dm,err_dm,methods,dm_PHANGS,dm_PHANGS_err_p,dm_PHANGS_err_m,marker],\n",
    "                  names=['gal_name','(m-M)','err(m-M)','Method','(m-M)_PHANGS','(m-M)_PHANGS_err+','(m-M)_PHANGS_err-','marker'])\n",
    "distances['d(m-M)'] = distances['(m-M)_PHANGS'] - distances['(m-M)']\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.std(distances[(distances['Method']=='TRGB') & ~np.isin(distances['gal_name'],['NGC1433','NGC1512'])]['d(m-M)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(nrows=7,figsize=(two_column,1.25*two_column))\n",
    "\n",
    "colors = {\n",
    "'TRGB':'#f28e2b',\n",
    "'Cepheids':'#59a14e',\n",
    "'IRAS':'#ff9da7',\n",
    "'NAM' : '#edc949',\n",
    "'PNLF':'#e15759',\n",
    "'SNII optical':'#4e79a7',\n",
    "'SNIa':'#76b7b2',\n",
    "'Tully-Fisher':'#b07aa2'\n",
    "}\n",
    "\n",
    "m_labels = {'Tully-Fisher':'Tully--Fisher','SNIa':'Type Ia Supernova',\n",
    "            'SNII optical':'Type II Supernova optical',\n",
    "            'PNLF':'Planetary Nebula Luminosity Function',\n",
    "            'TRGB':'Tip of the Red Giant Branch',\n",
    "            'NAM':'Numerical Action Method'}\n",
    "\n",
    "distances.sort(['(m-M)_PHANGS','year'])\n",
    "\n",
    "for ax,Method in zip(axes,['PNLF','TRGB','Cepheids','Tully-Fisher','NAM','SNII optical','SNIa']):\n",
    "    sample = distances[distances['Method']==Method]\n",
    "    sample['x'] = np.arange(1,len(sample)+1)\n",
    "\n",
    "    #if Method=='TRGB':\n",
    "    #    sample=sample[~np.isin(sample['gal_name'],['NGC1433','NGC1512'])]\n",
    "    \n",
    "    label = f\"{m_labels.get(Method,Method)}: ${np.mean(sample['d(m-M)']):.2f}\\pm{np.std(sample['d(m-M)']):.2f}$\"\n",
    "    #ax.errorbar(np.arange(len(sample)),sample['d(m-M)'],yerr=sample['err(m-M)'],\n",
    "    #             fmt='o',color=colors[Method])\n",
    "    ax.axhline(0,color='black')\n",
    "    \n",
    "    galaxy_ticks = []\n",
    "    galaxy_labels = np.unique(sample['gal_name'])\n",
    "    for i,group in enumerate(sample.group_by('gal_name').groups):\n",
    "        m = group[0]['gal_name']\n",
    "        for row in group:\n",
    "            ax.errorbar(row['x'],row['d(m-M)'],yerr=row['err(m-M)'],color=colors[Method],ls='none',fmt='o',ms=2,zorder=2)\n",
    "        galaxy_ticks.append(np.mean(group['x']))\n",
    "        ax.axvline(np.max(group['x'])+0.5,color='gray',lw=0.5)\n",
    "        ax.fill_between([np.min(group['x'])-0.5,np.max(group['x'])+0.5],\n",
    "                        y1=2*[-row['(m-M)_PHANGS_err-']],\n",
    "                        y2=2*[row['(m-M)_PHANGS_err+']],facecolor='black', alpha=0.2,zorder=1)\n",
    "        ax.fill_between([np.min(group['x'])-0.5,np.max(group['x'])+0.5],\n",
    "                        y1=2*[-row['(m-M)_PHANGS_err-']],\n",
    "                        y2=2*[row['(m-M)_PHANGS_err+']],facecolor='black', alpha=0.2,zorder=1)\n",
    "    \n",
    "    if Method == 'Tully-Fisher':\n",
    "        ax.set(ylim=[-4,4],xlim=[0.5,len(sample)+0.5],ylabel=r'$\\Delta(m-M)$')        \n",
    "    elif Method == 'NAM':\n",
    "        ax.set(ylim=[-2,2],xlim=[0.5,len(sample)+0.5],ylabel=r'$\\Delta(m-M)$')        \n",
    "\n",
    "    else:\n",
    "        ax.set(ylim=[-1.5,1.5],xlim=[0.5,len(sample)+0.5],ylabel=r'$\\Delta(m-M)$')\n",
    "\n",
    "    ax.set_xticks(galaxy_ticks,minor=False)\n",
    "    ax.set_xticklabels(galaxy_labels,rotation=30,ha='right',fontsize=6)\n",
    "  \n",
    "    ax.set_title(label,fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(basedir/'reports'/'literature_distances.pdf',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### measured fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from astropy.coordinates import match_coordinates_sky # match sources against existing catalog\n",
    "from astropy.coordinates import Angle                 # work with angles (e.g. 1°2′3″)\n",
    "\n",
    "from pnlf.load_references import NGC628, \\\n",
    "                                 pn_NGC628_kreckel, \\\n",
    "                                 snr_NGC628_kreckel, \\\n",
    "                                 pn_NGC628_herrmann, \\\n",
    "                                 NGC628_kreckel, \\\n",
    "                                 pn_NGC5068_herrmann, \\\n",
    "                                 pn_NGC3351_ciardullo, \\\n",
    "                                 pn_NGC3627_ciardullo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,(ax1,ax2) = plt.subplots(nrows=2,ncols=1,figsize=(single_column,single_column*1.8))\n",
    "\n",
    "'''\n",
    "   NGC0628\n",
    "'''\n",
    "\n",
    "name = 'NGC0628'\n",
    "catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "if catalogue_file.is_file():\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "catalogue['SkyCoord'] = SkyCoord(catalogue['RaDec'])\n",
    "catalogue = catalogue[(catalogue['type']=='PN') | ((catalogue['type']=='SNR') & (catalogue['SNRorPN']==True)) ]\n",
    "#catalogue = catalogue[np.isin(catalogue['type'],['PN','SNR'])]\n",
    "catalogue['R2'] = catalogue['OIII5006'] / (catalogue['HA6562']+catalogue['NII6583'])\n",
    "catalogue['dR2'] = catalogue['R2']  * np.sqrt(catalogue['OIII5006_err']/catalogue['OIII5006_err']**2 + 1/(catalogue['HA6562']+catalogue['NII6583'])**2 * (catalogue['HA6562_err']**2+catalogue['NII6583_err']**2) )                                  \n",
    "\n",
    "matchcoord = NGC628.copy()\n",
    "\n",
    "ID, sep, _  = match_coordinates_sky(matchcoord['SkyCoord'],catalogue['SkyCoord'])\n",
    "matchcoord['mOIII_measured'] = catalogue[ID]['mOIII']\n",
    "matchcoord['dmOIII_measured'] = catalogue[ID]['dmOIII']\n",
    "matchcoord['R_measured'] = catalogue[ID]['R2']\n",
    "matchcoord['dR_measured'] = catalogue[ID]['dR2']\n",
    "crit = sep.__lt__(Angle(\"0.5s\"))\n",
    "\n",
    "for s,c in zip(['Kreckel PN','Kreckel SNR','Herrmann PN'],['tab:red','tab:orange','tab:blue']):\n",
    "    tmp = matchcoord[(matchcoord['source']==s) & crit]\n",
    "    ax1.errorbar(tmp['mOIII'],tmp['mOIII_measured'],\n",
    "                 yerr = tmp['dmOIII_measured'],\n",
    "                 marker='o',ms=2,ls='none',mec=c,mfc=c,ecolor=c,label=s)\n",
    "    tmp = matchcoord[(matchcoord['source']==s) & crit]\n",
    "    ax2.errorbar(tmp['R'],tmp['R_measured'],\n",
    "                 #xerr = tmp['dR'],\n",
    "                 #yerr = tmp['dR_measured'],\n",
    "                 marker='o',ms=2,ls='none',mec=c,mfc=c,ecolor=c,label=s)\n",
    "\n",
    "\n",
    "'''\n",
    "   NGC5068\n",
    "'''\n",
    "name = 'NGC5068'\n",
    "catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "if catalogue_file.is_file():\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "catalogue['SkyCoord'] = SkyCoord(catalogue['RaDec'])\n",
    "catalogue = catalogue[np.isin(catalogue['type'],['PN','SNR'])]\n",
    "catalogue['R2'] = catalogue['OIII5006'] / (catalogue['HA6562']+catalogue['NII6583'])\n",
    "catalogue['dR2'] = catalogue['R2']  * np.sqrt(catalogue['OIII5006_err']/catalogue['OIII5006_err']**2 + 1/(catalogue['HA6562']+catalogue['NII6583'])**2 * (catalogue['HA6562_err']**2+catalogue['NII6583_err']**2) )                                  \n",
    "\n",
    "matchcoord = pn_NGC5068_herrmann.copy()\n",
    "\n",
    "ID, sep, _  = match_coordinates_sky(matchcoord['SkyCoord'],catalogue['SkyCoord'])\n",
    "matchcoord['mOIII_measured'] = catalogue[ID]['mOIII']\n",
    "matchcoord['dmOIII_measured'] = catalogue[ID]['dmOIII']\n",
    "matchcoord['R_measured'] = catalogue[ID]['R2']\n",
    "matchcoord['dR_measured'] = catalogue[ID]['dR2']\n",
    "crit = sep.__lt__(Angle(\"0.5s\"))\n",
    "\n",
    "tmp = matchcoord[(crit)]\n",
    "c = 'tab:green'\n",
    "ax1.errorbar(tmp['mOIII'],tmp['mOIII_measured'],\n",
    "             yerr = tmp['dmOIII_measured'],\n",
    "             #xerr = tmp['dmOIII'],\n",
    "             marker='o',ms=2,ls='none',mec=c,mfc=c,ecolor=c,label=s)\n",
    "ax2.errorbar(tmp['R'],tmp['R_measured'],\n",
    "             #xerr = tmp['sigma_R'],\n",
    "             #yerr = tmp['dR_measured'],\n",
    "             marker='o',ms=2,ls='none',mec=c,mfc=c,ecolor=c,label=s)\n",
    "\n",
    "\n",
    "'''\n",
    "   NGC3627\n",
    "'''\n",
    "name = 'NGC3627'\n",
    "catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "if catalogue_file.is_file():\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "catalogue['SkyCoord'] = SkyCoord(catalogue['RaDec'])\n",
    "catalogue = catalogue[np.isin(catalogue['type'],['PN','SNR'])]\n",
    "\n",
    "matchcoord = pn_NGC3627_ciardullo.copy()\n",
    "\n",
    "ID, sep, _  = match_coordinates_sky(matchcoord['SkyCoord'],catalogue['SkyCoord'])\n",
    "matchcoord['mOIII_measured'] = catalogue[ID]['mOIII']\n",
    "matchcoord['dmOIII_measured'] = catalogue[ID]['dmOIII']\n",
    "crit = sep.__lt__(Angle(\"0.5s\"))\n",
    "\n",
    "tmp = matchcoord[crit]\n",
    "c = 'cyan'\n",
    "ax1.errorbar(tmp['mOIII'],tmp['mOIII_measured'],\n",
    "             yerr = tmp['dmOIII_measured'],\n",
    "             marker='o',ms=2,ls='none',mec=c,mfc=c,ecolor=c,label='NGC3627')\n",
    "\n",
    "\n",
    "'''\n",
    "   NGC3351\n",
    "'''\n",
    "name = 'NGC3351'\n",
    "catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "if catalogue_file.is_file():\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "catalogue['SkyCoord'] = SkyCoord(catalogue['RaDec'])\n",
    "catalogue = catalogue[np.isin(catalogue['type'],['PN','SNR'])]\n",
    "catalogue['R2'] = catalogue['OIII5006'] / (catalogue['HA6562']+catalogue['NII6583'])\n",
    "catalogue['dR2'] = catalogue['R2']  * np.sqrt(catalogue['OIII5006_err']/catalogue['OIII5006_err']**2 + 1/(catalogue['HA6562']+catalogue['NII6583'])**2 * (catalogue['HA6562_err']**2+catalogue['NII6583_err']**2) )                                  \n",
    "\n",
    "matchcoord = pn_NGC3351_ciardullo.copy()\n",
    "\n",
    "ID, sep, _  = match_coordinates_sky(matchcoord['SkyCoord'],catalogue['SkyCoord'])\n",
    "matchcoord['mOIII_measured'] = catalogue[ID]['mOIII']\n",
    "matchcoord['dmOIII_measured'] = catalogue[ID]['dmOIII']\n",
    "crit = sep.__lt__(Angle(\"0.5s\"))\n",
    "\n",
    "tmp = matchcoord[crit]\n",
    "c = 'purple'\n",
    "ax1.errorbar(tmp['mOIII'],tmp['mOIII_measured'],\n",
    "             yerr = tmp['dmOIII_measured'],\n",
    "             marker='o',ms=2,ls='none',mec=c,mfc=c,ecolor=c,label='NGC3351')\n",
    "\n",
    "\n",
    "ax1.plot([25,27.5],[25,27.5],color='black',lw=0.4)\n",
    "ax1.set(xlim=[25,27.5],ylim=[25,27.5])\n",
    "ax1.set_xlabel(r'$\\mathrm{m}_{[\\mathrm{O}\\,\\tiny{\\textsc{iii}}]}$ existing studies')\n",
    "ax1.set_ylabel(r'$\\mathrm{m}_{[\\mathrm{O}\\,\\tiny{\\textsc{iii}}]}$ this work')\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "xmin,xmax = 0,7\n",
    "ymin,ymax = 0,7\n",
    "ax2.plot([xmin,xmax],[xmin,xmax],color='black',lw=0.4)\n",
    "ax2.set_xlim([xmin,xmax])\n",
    "ax2.set_ylim([ymin,ymax])\n",
    "ax2.set_xlabel(r'$I_{[\\mathrm{O}\\,\\tiny{\\textsc{iii}}]}\\;/\\;(I_{\\mathrm{H}\\,\\alpha}+I_{[\\mathrm{N}\\,\\tiny{\\textsc{ii}}]})$ existing studies')\n",
    "ax2.set_ylabel(r'$I_{[\\mathrm{O}\\,\\tiny{\\textsc{iii}}]}\\;/\\;(I_{\\mathrm{H}\\,\\alpha}+I_{[\\mathrm{N}\\,\\tiny{\\textsc{ii}}]})$ this work')\n",
    "#ax2.legend(loc=2)\n",
    "\n",
    "plt.savefig(basedir / 'reports' / f'flux_comparison.pdf',dpi=600)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "name = 'NGC0628'\n",
    "catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "if catalogue_file.is_file():\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "catalogue['SkyCoord'] = SkyCoord(catalogue['RaDec'])\n",
    "catalogue = catalogue[np.isin(catalogue['type'],['PN','SNR'])]\n",
    "catalogue['R2'] = catalogue['OIII5006'] / (catalogue['HA6562']+catalogue['NII6583'])\n",
    "catalogue['dR2'] = catalogue['R2']  * np.sqrt(catalogue['OIII5006_err']/catalogue['OIII5006_err']**2 + 1/(catalogue['HA6562']+catalogue['NII6583'])**2 * (catalogue['HA6562_err']**2+catalogue['NII6583_err']**2) )                                  \n",
    "\n",
    "matchcoord = NGC628.copy()\n",
    "\n",
    "ID, sep, _  = match_coordinates_sky(matchcoord['SkyCoord'],catalogue['SkyCoord'])\n",
    "matchcoord['IDf'] = ID\n",
    "matchcoord['mOIII_measured'] = catalogue[ID]['mOIII']\n",
    "matchcoord['dmOIII_measured'] = catalogue[ID]['dmOIII']\n",
    "matchcoord['R_measured'] = catalogue[ID]['R2']\n",
    "matchcoord['dR_measured'] = catalogue[ID]['dR2']\n",
    "crit = sep.__lt__(Angle(\"0.5s\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other PNLF studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = ascii.read(basedir/'data'/'literature distances'/'latest.csv',delimiter=',',header_start=12,data_start=14)\n",
    "distances['year'] = distances['Date (Yr. - 1980)']+1980\n",
    "distances.rename_column('Galaxy ID','name')\n",
    "distances['name'] = [n.rstrip('a').rstrip('b') for n in distances['name']]\n",
    "\n",
    "results = ascii.read(basedir/'data'/'interim'/'results.txt')\n",
    "print(f\"intial cagalogue has {len(np.unique(distances[distances['Method']=='PNLF']['name']))} objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=distances[distances['Method']=='Cepheids']\n",
    "\n",
    "plt.hist(tmp['D (Mpc)'],bins=np.arange(0,50,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnlf_distances = distances[distances[\"Method\"]=='PNLF']\n",
    "print(f\"excluding {len(np.unique(pnlf_distances[(pnlf_distances['m-M']<22.5) | (pnlf_distances['m-M']>32)]['Galaxy ID']))} objects\")\n",
    "#pnlf_distances = pnlf_distances[(pnlf_distances['m-M']>22.5) & (pnlf_distances['m-M']<32)]  # exclude the many measurments of the LMC and SMC\n",
    "\n",
    "alias = {\n",
    "    'NGC 0628': 'MESSIER 074',\n",
    "    'NGC 3351': 'MESSIER 095',\n",
    "    'NGC 3627': 'MESSIER 066',\n",
    "    'NGC 4254': 'MESSIER 099',\n",
    "    'NGC 4303': 'MESSIER 061',\n",
    "    'NGC 4321': 'MESSIER 100'\n",
    "}\n",
    "\n",
    "alias_back = {v:k for k,v in alias.items()}\n",
    "\n",
    "phangs_sample = []\n",
    "for row in results:\n",
    "    name = row['name'].replace('NGC','NGC ').replace('IC','IC ')\n",
    "    name = alias.get(name,name)\n",
    "    phangs_sample.append(name)\n",
    "    new = ['',0,0,name,row['(m-M)'],row['err-(m-M)'],0,'PNLF','Schmnn+2020','',0,0,0,40,'',2020]\n",
    "    pnlf_distances.add_row(new)\n",
    "    \n",
    "galaxies = list(np.unique(pnlf_distances['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.auxiliary import mu_to_parsec\n",
    "\n",
    "d,d_err = mu_to_parsec(distances['m-M'],distances['err'])\n",
    "\n",
    "distances['d/Mpc'] = d\n",
    "distances['err d/Mpc'] = d_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances['ep'] = distances['err d/Mpc']/distances['d/Mpc']\n",
    "group = distances.group_by('Method')\n",
    "\n",
    "means = group.groups.aggregate(np.mean)\n",
    "for key, mean in zip(group.groups.keys, means):\n",
    "    print('mean for {0} = {1}'.format(key, mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "for method in ['Cepheids','PNLF','SBF','SNII optical','SNIa','TRGB','Tully-Fisher']:\n",
    "    tmp = distances[distances['Method']==method]\n",
    "    ax.scatter(tmp['year'],100*tmp['err d/Mpc']/tmp['d/Mpc'],label=method)\n",
    "ax.set(xlim=[1900,None],ylim=[0,100])\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(axes)=plt.subplots(nrows=2,ncols=2,figsize=(two_column,two_column))\n",
    "axes_iter = iter(axes.flatten())\n",
    "for method in ['PNLF','TRGB','Cepheids','SBF']:\n",
    "    ax=next(axes_iter)\n",
    "    tmp = distances[distances['Method']==method]\n",
    "    ax.scatter(tmp['year'],100*tmp['err d/Mpc']/tmp['d/Mpc'])\n",
    "    ax.set(xlim=[1980,None],ylim=[0,40],xlabel='year',ylabel='d/err in percent')\n",
    "    ax.set_title(method)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.auxiliary import mu_to_parsec\n",
    "\n",
    "d,d_err = mu_to_parsec(pnlf_distances['m-M'],pnlf_distances['err'])\n",
    "\n",
    "pnlf_distances['d/Mpc'] = d\n",
    "pnlf_distances['err d/Mpc'] = d_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "ax.scatter(pnlf_distances['year'],100*pnlf_distances['err d/Mpc']/pnlf_distances['d/Mpc'])\n",
    "ax.set(ylim=[1,40],xlabel='year',ylabel='err/distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(pnlf_distances[pnlf_distances['err d/Mpc']/pnlf_distances['d/Mpc']>0.15]['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "ax.hist(100*pnlf_distances['err d/Mpc']/pnlf_distances['d/Mpc'],bins=np.arange(0,40,5))\n",
    "ax.set(xlabel='err/distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trgb_sample = set(distances[distances['Method']=='TRGB']['name'])\n",
    "pnlf_sample = set(distances[distances['Method']=='PNLF']['name'])\n",
    "cepheid_sample = set(distances[distances['Method']=='Cepheids']['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = []\n",
    "for name in list(pnlf_sample & (cepheid_sample|trgb_sample)):\n",
    "    d_pnlf = distances[(distances['name']==name) & (distances['Method']=='PNLF')]['D (Mpc)'].mean()\n",
    "    d_ref = distances[(distances['name']==name) & ((distances['Method']=='TRGB')|(distances['Method']=='Cepheids'))]['D (Mpc)'].mean()\n",
    "    \n",
    "    dif = abs((d_ref-d_pnlf)/d_ref)\n",
    "    print(f'{name}: {dif}')\n",
    "    differences.append(dif)\n",
    "differences = np.array(differences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(differences[differences<0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = pnlf_distances.group_by('name')['m-M'].groups.aggregate(np.mean)\n",
    "dis = Distance(distmod=mu).value\n",
    "plt.hist(dis,bins=np.arange(10,100,2))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we sort by mean distance\n",
    "mean_dis = []\n",
    "for gal in galaxies:\n",
    "    mean_dis.append(pnlf_distances[pnlf_distances['name']==gal]['m-M'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnlf_distances.sort('year')\n",
    "important_papers = dict()\n",
    "is_measured = []\n",
    "for row in pnlf_distances:\n",
    "    #if row['name'] not in is_measured:\n",
    "    #    is_measured.append(row['name'])\n",
    "    if row['REFCODE'] in important_papers:\n",
    "        important_papers[row['REFCODE']] += 1\n",
    "    else:\n",
    "        important_papers[row['REFCODE']] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1,figsize=(10,6/1.618))\n",
    "\n",
    "x_pos  = []\n",
    "gal_names = [x for _,x in sorted(zip(mean_dis,galaxies))]\n",
    "\n",
    "print(f'{len(gal_names)} galaxies in sample')\n",
    "color_grid=[]\n",
    "for i,gal in enumerate(gal_names):\n",
    "    tmp = pnlf_distances[pnlf_distances['name']==gal]\n",
    "    ax.scatter(len(tmp)*[i+1],tmp['m-M'],marker=\"_\",color='gray')\n",
    "    # color the measured by me red\n",
    "    if len(tmp[tmp['REFCODE']=='Schmnn+2020'])>0:\n",
    "        ax.scatter([i+1],tmp[tmp['REFCODE']=='Schmnn+2020']['m-M'],marker=\"_\",color='tab:red')\n",
    "        color_grid.append(i)\n",
    "\n",
    "# create a legend with numbers only\n",
    "#legend_elements = [mpl.lines.Line2D([0], [0], color=tab10[i], lw=2, label=str(i+1)) for i in range(10)]\n",
    "#plt.legend(handles=legend_elements, loc='upper center',ncol=10)\n",
    "    \n",
    "ymin,ymax = 23,32\n",
    "# set the galaxy names as x-ticklabels\n",
    "ax.set(xticks=np.arange(1,len(galaxies)+1),\n",
    "       ylabel='($m-M$) / mag',\n",
    "       title='Galaxies with PNLF distances',\n",
    "       xlim=[0.5,len(galaxies)+0.5],\n",
    "       ylim=[ymin,ymax])\n",
    "ax.set_xticklabels(gal_names,rotation=90,color='gray')    \n",
    "\n",
    "# color the galaxies which are in the phangs sample \n",
    "for n in phangs_sample:\n",
    "    i = gal_names.index(n)\n",
    "    ax.get_xticklabels()[i].set_color(\"tab:red\")\n",
    "#for n in ['MESSIER 066','MESSIER 074','MESSIER 095','NGC 5068']:\n",
    "#    i = gal_names.index(n)\n",
    "#    ax.get_xticklabels()[i].set_color(\"tab:red\")    \n",
    "\n",
    "ax.grid(axis='x')\n",
    "#a = ax.get_xgridlines()\n",
    "#for i in color_grid:\n",
    "#    a[i].set_color('tab:red')\n",
    "\n",
    "yticks_mpc = np.logspace(np.log10(Distance(distmod=ymin).to(u.Mpc).value),np.log10(Distance(distmod=ymax).to(u.Mpc).value),10)\n",
    "yticks_mu  = Distance(yticks_mpc*u.Mpc).distmod\n",
    "    \n",
    "ax2 = ax.twinx()\n",
    "ax2.set_yticks(yticks_mu.value,minor=False)\n",
    "ax2.set_yticklabels([f'{x:.2f}' for x in yticks_mpc],ha=\"left\")\n",
    "ax2.set(ylim=[ymin,ymax],ylabel='$D$ / Mpc')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(basedir/'reports'/'PNstudies.png',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, (ax2,ax1) = plt.subplots(nrows=2,figsize=(two_column,two_column))\n",
    "\n",
    "gal_names = [x for _,x in sorted(zip(mean_dis,galaxies))]\n",
    "\n",
    "def literature_distances(labels,ax,ymin=23,ymax=32):\n",
    "    \n",
    "    # set the galaxy names as x-ticklabels\n",
    "    ax.set(xticks=np.arange(1,len(labels)+1),\n",
    "           ylabel='($m-M$) / mag',\n",
    "           xlim=[0.5,len(labels)+0.5],\n",
    "           ylim=[ymin,ymax])\n",
    "    labels_new = [alias_back.get(l,l) for l in labels]\n",
    "    ax.set_xticklabels(labels_new,rotation=90,color='gray')    \n",
    "    ax.grid(axis='x',ls='--',lw=0.4)\n",
    "    grid = ax.get_xgridlines()\n",
    "\n",
    "    for i,label in enumerate(labels):\n",
    "        tmp = pnlf_distances[pnlf_distances['name']==label]\n",
    "        ax.scatter(len(tmp)*[i+1],tmp['m-M'],marker=\"_\",color='gray')\n",
    "        # color the measured by me red\n",
    "        if len(tmp[tmp['REFCODE']=='Schmnn+2020'])>0:\n",
    "            ax.get_xticklabels()[i].set(color=\"tab:red\",fontweight='black')\n",
    "            ax.scatter([i+1],tmp[tmp['REFCODE']=='Schmnn+2020']['m-M'],marker=\"_\",color='tab:red')\n",
    "            grid[i].set(ls='-',lw=0.5)\n",
    "    \n",
    "    \n",
    "    yticks_mpc = np.logspace(np.log10(Distance(distmod=ymin).to(u.Mpc).value),np.log10(Distance(distmod=ymax).to(u.Mpc).value),10)\n",
    "    yticks_mu  = Distance(yticks_mpc*u.Mpc).distmod\n",
    "\n",
    "    axt = ax.twinx()\n",
    "    axt.set_yticks(yticks_mu.value,minor=False)\n",
    "    axt.set_yticklabels([f'{x:.2f}' for x in yticks_mpc],ha=\"left\")\n",
    "    axt.set(ylim=[ymin,ymax],ylabel='$D$ / Mpc')\n",
    "    \n",
    "    return ax\n",
    "    \n",
    "n = len(gal_names)\n",
    "ax1 = literature_distances(gal_names[:int(n/2)],ax1,ymin=23,ymax=30.5)\n",
    "ax2 = literature_distances(gal_names[int(n/2):],ax2,ymin=29.5,ymax=32.2)\n",
    "\n",
    "#ax2.set_title('Galaxies with PNLF distances')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.savefig(basedir/'reports'/'PNstudies.pdf',dpi=600)\n",
    "plt.savefig(basedir/'reports'/'PNstudies.png',dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.auxiliary import filter_table\n",
    "\n",
    "virgo = ['MESSIER 098','NGC 4216','MESSIER 099','MESSIER 061','MESSIER 100',\n",
    "         'NGC 4365','MESSIER 084','MESSIER 085','MESSIER 086','NGC 4429',\n",
    "         'NGC 4438','NGC 4442','NGC 4450','NGC 4459','MESSIER 049',\n",
    "         'NGC 4473','NGC 4477','MESSIER 087','MESSIER 088','NGC 4526',\n",
    "         'NGC 4535','MESSIER 091','MESSIER 089','MESSIER 090','MESSIER 058',\n",
    "         'NGC 4596','MESSIER 059','NGC 4654','MESSIER 060','NGC 4762']\n",
    "alias = {'MESSIER 099': 'NGC4254','MESSIER 061': 'NGC4303',\n",
    "         'MESSIER 100': 'NGC4321','NGC 4535': 'NGC4535'}\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(4,8))\n",
    "\n",
    "for i,name in enumerate(virgo):\n",
    "    sub = distances[distances['name']==name]\n",
    "    \n",
    "    ax.scatter(sub['m-M'],len(sub)*[i],color='gray')\n",
    "    \n",
    "    tmp = filter_table(sub,Method=['Cepheids','TRGB','PNLF'])\n",
    "    ax.scatter(tmp['m-M'],len(tmp)*[i],color='black')\n",
    "\n",
    "    if alias.get(name,None):\n",
    "        ax.scatter(results.loc[alias.get(name)]['(m-M)'],[i],color='red')\n",
    "        \n",
    "ax.set_yticks(np.arange(len(virgo)))\n",
    "ax.set_yticklabels(virgo)\n",
    "ax.set(ylim=[-0.5,len(virgo)-0.5],xlabel='(m-M) / mag')\n",
    "ax.set_title('Galaxies in the Virgo Cluster')\n",
    "plt.savefig(basedir/'reports'/'virgo_cluster.pdf',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many potential galaxies for PNLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = ascii.read(basedir/'data'/'literature distances'/'latest.csv',delimiter=',',header_start=12,data_start=14)\n",
    "distances['year'] = distances['Date (Yr. - 1980)']+1980\n",
    "distances.rename_column('Galaxy ID','name')\n",
    "distances['name'] = [n.rstrip('a').rstrip('b') for n in distances['name']]\n",
    "\n",
    "results = ascii.read(basedir/'data'/'interim'/'results.txt')\n",
    "print(f\"intial cagalogue has {len(np.unique(distances[distances['Method']=='PNLF']['name']))} objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = distances[(distances['D (Mpc)']<25) & np.isin(distances['Method'],['Tully-Fisher','Cepheids','SBF','TRGB','PNLF'])]\n",
    "subsample = np.unique(tmp[\"name\"])\n",
    "tmp2 = tmp[~np.isin(tmp['Method'],['Cepheids','TRGB','PNLF'])]\n",
    "subsample2 = np.unique(tmp2[\"name\"])\n",
    "\n",
    "print(f'{len(subsample)} objects in full sample (<10 Mpc)')\n",
    "print(f'{len(subsample2)} objects without good distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "for method in ['Tully-Fisher','TRGB','Cepheids','SBF','Faber-Jackson','PNLF']:\n",
    "    sub = distances[(distances['Method']==method) & (distances['D (Mpc)']<40)]\n",
    "    group = sub.group_by('name')\n",
    "    dis = group['D (Mpc)'].groups.aggregate(np.mean)\n",
    "    \n",
    "    un = np.unique(sub['name'])\n",
    "    print(f'{method}: {len(un)}')\n",
    "    \n",
    "    ax.hist(dis,bins=np.linspace(1,31,30),label=method)\n",
    "    \n",
    "ax.legend()\n",
    "ax.set(xlabel='Distance / Mpc',ylabel='number of galaxies')\n",
    "plt.savefig(basedir/'reports'/'distances_by_method.pdf',dpi=300)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with Deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep   = ascii.read(basedir/'data'/'literature distances'/'deep_distances.csv')\n",
    "result = ascii.read(basedir/'data'/'interim'/'results.txt')\n",
    "\n",
    "deep.add_index(\"galaxy\")\n",
    "deep['d'] = [float(x[:-4]) for x in deep['distance']]\n",
    "deep['e'] = [float(x[:-4]) for x in deep['error']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.auxiliary import mu_to_parsec\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(two_column,two_column/1.618))\n",
    "result.sort('d/Mpc')\n",
    "for i, row in enumerate(result):\n",
    "\n",
    "    tmp = deep.loc[row['name']]\n",
    "    if tmp['method'] == 'TRGB':\n",
    "        d,(dp,dm) = mu_to_parsec(row['(m-M)'],[row['err+(m-M)'],row['err-(m-M)']])\n",
    "\n",
    "        ax.errorbar(i-0.1,row['d/Mpc'],yerr=([dm.value],[dp.value]),fmt='o',color='tab:red')\n",
    "\n",
    "        ax.errorbar(i+0.1,tmp['d'],yerr=tmp['e'],fmt='o',color='black')\n",
    "        \n",
    "        diff = row['d/Mpc']-tmp['d']\n",
    "        if diff>0:\n",
    "            err = dm\n",
    "        else:\n",
    "            err = dp\n",
    "            \n",
    "        print(f\"{row['name']}: {diff/err:.2f}\")\n",
    "        \n",
    "        \n",
    "ax.set(xticks=np.arange(0,len(result)),\n",
    "       ylabel='$D$ / Mpc',\n",
    "       title='PHANGS distances',\n",
    "       xlim=[-0.5,len(result)-0.5])\n",
    "ax.set_xticklabels(result['name'],rotation=90)  \n",
    "ax.grid(axis='x')\n",
    "\n",
    "legend_elements = [mpl.lines.Line2D([0], [0], color=col, lw=2, label=l) for col,l in zip(['tab:red','black'],['PNLF','TRGB'])]\n",
    "plt.legend(handles=legend_elements, loc='lower center',ncol=10)\n",
    "#plt.savefig(basedir/'reports'/'PNLF_vs_TRGB.png',dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.auxiliary import parsec_to_mu\n",
    "\n",
    "\n",
    "distances = ascii.read(basedir/'data'/'literature distances'/'latest.csv',delimiter=',',header_start=12,data_start=14)\n",
    "trgb_distances = distances[distances[\"Method\"]=='TRGB']\n",
    "trgb_distances.rename_column('Galaxy ID','name')\n",
    "\n",
    "trgb_distances['year'] = trgb_distances['Date (Yr. - 1980)']+1980\n",
    "trgb_distances['name'] = [n.rstrip('a').rstrip('b') for n in trgb_distances['name']]\n",
    "\n",
    "alias = {\n",
    "'MESSIER074' : 'NGC0628',\n",
    "'MESSIER095' : 'NGC3351',\n",
    "'MESSIER066' : 'NGC3627',\n",
    "'MESSIER099' : 'NGC4254',\n",
    "'MESSIER061' : 'NGC4303',\n",
    "'MESSIER100' : 'NGC4321'\n",
    "}\n",
    "\n",
    "trgb_distances['name'] = [x.replace(' ','') for x in trgb_distances['name']]\n",
    "\n",
    "for k,v in alias.items():\n",
    "    trgb_distances['name'] = [x.replace(k,v) for x in trgb_distances['name']]\n",
    "trgb_distances = trgb_distances[np.isin(trgb_distances['name'],results['name'])]\n",
    "\n",
    "# add the new distances from deep\n",
    "for name in 'IC5332', 'NGC2835', 'NGC4321':\n",
    "    d = deep.loc[name]['d']\n",
    "    e = deep.loc[name]['e']\n",
    "    mu,err = parsec_to_mu(d*u.Mpc,e*u.Mpc)\n",
    "    \n",
    "    row = {'name':name,'m-M':mu,'err':err,'Method':'TRGB','D (Mpc)':d}\n",
    "    trgb_distances.add_row(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep.loc['NGC4321']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Distance(distmod=trgb['m-M']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.auxiliary import mu_to_parsec\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(two_column,two_column/1.618))\n",
    "\n",
    "sample  = np.unique(trgb_distances['name'])\n",
    "\n",
    "results = ascii.read(basedir/'data'/'interim'/ 'results.txt',format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "results = results[np.isin(results['name'],sample)]\n",
    "results.sort('d/Mpc')\n",
    "results.add_index('name')\n",
    "\n",
    "for i, name in enumerate(results['name']):\n",
    "    \n",
    "    trgb = trgb_distances[trgb_distances['name']==name]\n",
    "    for row in trgb:   \n",
    "        d,(dp,dm) = mu_to_parsec(row['m-M'],[row['err'],row['err']])\n",
    "        ax.errorbar(i-0.2,d.value,yerr=([dm.value],[dp.value]),fmt='o',color='black')\n",
    "    \n",
    "    pnlf = results.loc[name]\n",
    "    ax.errorbar(i+0.2,pnlf['d/Mpc'],yerr=([pnlf['err-d/Mpc']],[pnlf['err+d/Mpc']]),fmt='o',color='tab:red')\n",
    "\n",
    "    diff = pnlf['d/Mpc'] - np.mean(Distance(distmod=trgb['m-M'])).value\n",
    "    if diff>0:\n",
    "        err = pnlf['err-d/Mpc']\n",
    "    else:\n",
    "        err = pnlf['err+d/Mpc']\n",
    "\n",
    "    print(f\"{row['name']}: {diff/err:.2f}\") \n",
    "\n",
    "for x in np.arange(-0.5,len(results)+0.5):\n",
    "    ax.axvline(x,color='gray',zorder=0)\n",
    "ax.set(xticks=np.arange(0,len(results)),\n",
    "       ylabel='$D$ / Mpc',\n",
    "       title='PNLF vs TRGB',\n",
    "       xlim=[-0.5,len(results)-0.5])\n",
    "ax.set_xticklabels(results['name'],rotation=90)  \n",
    "#ax.grid(axis='x')\n",
    "\n",
    "legend_elements = [mpl.lines.Line2D([0], [0], color=col, lw=2, label=l) for col,l in zip(['tab:red','black'],['PNLF','TRGB'])]\n",
    "plt.legend(handles=legend_elements, loc='lower center',ncol=10)\n",
    "plt.savefig(basedir/'reports'/'PNLF_vs_TRGB.png',dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## PSF uncertainties\n",
    "\n",
    "the uncertainty of the PSF is ~0.1\"=0.5px. Here we explore how this impacts the measured fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.photometry import measure_flux \n",
    "\n",
    "class DisableLogger():\n",
    "    def __enter__(self):\n",
    "       logging.disable(logging.CRITICAL)\n",
    "    def __exit__(self, exit_type, exit_value, exit_traceback):\n",
    "       logging.disable(logging.NOTSET)\n",
    "        \n",
    "def est_err(tbl,galaxy,aperture_size=2):\n",
    "    '''estimate the flux error resulting from an uncertainy PSF\n",
    "    \n",
    "    The fwhm of the PSF is difficult to measure and the values we and for\n",
    "    the values we use we assume an uncertainty of dFWHM = 0.1\" = 0.5 px.\n",
    "    '''\n",
    "    tbl = tbl.copy()\n",
    "    delta = 0.5\n",
    "    print(f'aperture size = {aperture_size}')\n",
    "    \n",
    "    with DisableLogger():\n",
    "        \n",
    "        #print('using measured PSF')\n",
    "        flux1 = measure_flux(galaxy,tbl,lines=['OIII5006'],alpha=galaxy.power_index,Rv=3.1,Ebv=galaxy.Ebv,\n",
    "                            extinction='MW',background='local',aperture_size=aperture_size)\n",
    "        mOIII = -2.5*np.log10(flux1['OIII5006']*1e-20) - 13.74\n",
    "        dmOIII = 2.5/np.log(10) * flux1['OIII5006_err']/flux1['OIII5006']\n",
    "\n",
    "        #print(f'using PSF-{delta}')\n",
    "        tbl['fwhm'] -= delta\n",
    "        flux3 = measure_flux(galaxy,tbl,lines=['OIII5006'],alpha=galaxy.power_index,Rv=3.1,Ebv=galaxy.Ebv,\n",
    "                            extinction='MW',background='local',aperture_size=aperture_size)\n",
    "        mOIIIm = -2.5*np.log10(flux3['OIII5006']*1e-20) - 13.74\n",
    "        \n",
    "        #print(f'using PSF+{delta}')\n",
    "        tbl['fwhm'] += 2*delta\n",
    "        flux2 = measure_flux(galaxy,tbl,lines=['OIII5006'],alpha=galaxy.power_index,Rv=3.1,Ebv=galaxy.Ebv,\n",
    "                            extinction='MW',background='local',aperture_size=aperture_size)\n",
    "        mOIIIp = -2.5*np.log10(flux2['OIII5006']*1e-20) - 13.74\n",
    "\n",
    " \n",
    "    \n",
    "    #print(f'PSF-(PSF+delta): {np.nanmean(mOIII[mOIII<28]-mOIIIp[mOIII<28]):.3f}')\n",
    "    #print(f'PSF-(PSF-delta): {np.nanmean(mOIII[mOIII<28]-mOIIIm[mOIII<28]):.3f}')\n",
    "    print(f'(PSF-delta)+(PSF-delta): {np.nanmean(mOIIIm[mOIII<28]-mOIIIp[mOIII<28])/2:.3f}')\n",
    "\n",
    "    return mOIII,dmOIII,mOIIIp,mOIIIm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.io import ReadLineMaps\n",
    "\n",
    "# the catalogue with the PNe (and SNRs)\n",
    "with fits.open(basedir/'data'/'catalogues'/'nebulae.fits') as hdul:\n",
    "    catalogue = Table(hdul[1].data)\n",
    "catalogue['overluminous'] = catalogue['note']=='OL'\n",
    "catalogue['exclude'] = catalogue['note']=='EX'\n",
    "catalogue['SkyCoord'] = SkyCoord(catalogue['RA'],catalogue['DEC'])\n",
    "\n",
    "with open(basedir / 'data' / 'interim' / 'parameters.yml') as yml_file:\n",
    "    parameters = yaml.load(yml_file,Loader=yaml.FullLoader)\n",
    "    \n",
    "DR = 'DR2.1'\n",
    "lines = ['OIII5006']\n",
    "\n",
    "    \n",
    "aperture_size = [0.5,1,1.5,2,2.5,3,3.5]\n",
    "error_phot = {}\n",
    "error_psf = {}\n",
    "\n",
    "for gal_name in np.unique(catalogue['gal_name']):\n",
    "    print(gal_name)\n",
    "    \n",
    "    # read in the data we will be working with and print some information\n",
    "    galaxy = ReadLineMaps(data_ext/f'MUSE'/DR/'MUSEDAP',gal_name,extensions=lines,**parameters[gal_name])\n",
    "    #galaxy.center = sample_table.loc[name]['SkyCoord'].to_pixel(galaxy.wcs)\n",
    "    galaxy.Ebv = sample_table.loc[gal_name]['E(B-V)']\n",
    "    #galaxy.posang = sample_table.loc[name]['posang']\n",
    "    #galaxy.inclination = sample_table.loc[name]['Inclination']\n",
    "    #galaxy.r25 = sample_table.loc[name]['r25']*u.arcmin\n",
    "    \n",
    "    sources = catalogue[catalogue['gal_name']==gal_name]\n",
    "\n",
    "    error_phot_lst = []\n",
    "    error_psf_lst = []\n",
    "    \n",
    "    for a in aperture_size:\n",
    "        mOIII,dmOIII,mOIIIp,mOIIIm = est_err(sources,galaxy,aperture_size=a)\n",
    "\n",
    "        error_phot_lst.append(np.nanmean(dmOIII[mOIII<28]))\n",
    "        error_psf_lst.append(np.nanmean(mOIIIm[mOIII<28]-mOIIIp[mOIII<28])/2)\n",
    "    \n",
    "    error_phot[gal_name] = error_phot_lst\n",
    "    error_psf[gal_name] = error_psf_lst\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "error_phot_lst = error_phot[gal_name]\n",
    "error_psf_lst = error_psf[gal_name]\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(single_column,single_column))\n",
    "\n",
    "ax.plot(aperture_size,error_psf_lst,label='error from PSF',color='black',ls=':')\n",
    "ax.plot(aperture_size,error_phot_lst,label='error from photometry',color='black',ls='--')\n",
    "ax.plot(aperture_size,np.sqrt(np.power(error_phot_lst,2)+np.power(error_psf_lst,2)),label='total error',\n",
    "        color='tab:red')\n",
    "ax.legend()\n",
    "ax.set_title(f'error\\_PSF(fwhm=2.5)={error_psf_lst[aperture_size.index(2.5)]:.3f}')\n",
    "ax.set(xlabel='aperture size / fwhm',ylabel='dmOIII / mag')\n",
    "#plt.savefig(basedir/'reports'/galaxy.name/f'{galaxy.name}_aperture_size.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.plot.pnlf import _plot_pnlf\n",
    "\n",
    "names = results['name']\n",
    "nrows = 5\n",
    "ncols = 4\n",
    "filename = basedir / 'reports' / f'all_galaxies_psf_uncertainties_delte01'\n",
    "\n",
    "#----------------------------------------------\n",
    "# DO NOT MODIFY BELOW\n",
    "#----------------------------------------------\n",
    "width = two_column\n",
    "fig, axes = plt.subplots(nrows=nrows,ncols=ncols,figsize=(width,width/ncols*nrows))\n",
    "axes_iter = iter(axes.flatten())\n",
    "\n",
    "# loop over the galaxies we want to plot\n",
    "for gal_name in np.unique(catalogue['gal_name']):\n",
    "    \n",
    "    # get the next axis and find position on the grid\n",
    "    ax = next(axes_iter)\n",
    "    if nrows>1 and ncols>1:\n",
    "        i, j = np.where(axes == ax)\n",
    "        i,j=i[0],j[0]\n",
    "    elif ncols>1:\n",
    "        i,j = 0, np.where(axes==ax)[0]\n",
    "    elif nrows>1:\n",
    "        i,j = np.where(axes==ax)[0],0\n",
    "    else:\n",
    "        i,j=0,0\n",
    "        \n",
    "        \n",
    "    error_phot_lst = error_phot[gal_name]\n",
    "    error_psf_lst = error_psf[gal_name]\n",
    "\n",
    "    ax.plot(aperture_size,error_psf_lst,label='error from PSF',color='black',ls=':')\n",
    "    ax.plot(aperture_size,error_phot_lst,label='error from photometry',color='black',ls='--')\n",
    "    ax.plot(aperture_size,np.sqrt(np.power(error_phot_lst,2)+np.power(error_psf_lst,2)),label='total error',\n",
    "            color='tab:red')\n",
    "\n",
    "    \n",
    "    dPSF = error_psf_lst[aperture_size.index(2.5)]\n",
    "    ax.set_title(f'$\\Delta m_\\mathrm{{PSF}}={dPSF:.3f}$ mag',fontsize=7)     \n",
    "    ax.text(0.55,0.9,f'{gal_name}', transform=ax.transAxes,fontsize=7)\n",
    "    #ax.text(0.05,0.88,f'$\\Delta m_\\mathrm{{PSF}}={dPSF:.3f}$', transform=ax.transAxes,fontsize=6)     \n",
    "\n",
    "    xlim=ax.get_xlim()\n",
    "    ylim=ax.get_ylim()\n",
    "    ax.plot([xlim[0],2.5,2.5],[dPSF,dPSF,ylim[0]],color='black',ls=':',lw=0.5)\n",
    "    ax.set(xlim=xlim,ylim=ylim)\n",
    "    if i==nrows-1:\n",
    "        ax.set_xlabel('aperture size / fwhm')\n",
    "    if j==0:\n",
    "        ax.set_ylabel(ylabel='dmOIII / mag')\n",
    "    #ax.set_title(name)\n",
    "    #ax.set(xlim=[24,28.5])\n",
    " \n",
    "        \n",
    "axes[3,3].set_xlabel('aperture size / fwhm')\n",
    "ax = next(axes_iter)\n",
    "#ax.remove()\n",
    "h,l = fig.axes[0].get_legend_handles_labels()\n",
    "ax.axis('off')\n",
    "ax.legend(h,l,fontsize=7,loc='center left',frameon=False)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.15, hspace=0.15)\n",
    "plt.tight_layout()\n",
    "plt.savefig(filename.with_suffix('.pdf'),bbox_inches='tight')\n",
    "#plt.savefig(filename.with_suffix('.png'),bbox_inches='tight',dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dPSF = [v[aperture_size.index(2.5)] for k,v in error_psf.items()]\n",
    "\n",
    "plt.hist(dPSF,bins=np.linspace(0.05,0.35,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.median(dPSF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Extinction two LF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.analyse import sample_pnlf\n",
    "from pnlf.plot import plot_pnlf\n",
    "from pnlf.analyse import MaximumLikelihood1D, pnlf\n",
    "\n",
    "N_PN = 100\n",
    "mu = 30\n",
    "cl = 28\n",
    "Mmax= -4.47\n",
    "nbins = 6\n",
    "\n",
    "sample = sample_pnlf(N_PN,mu,cl)\n",
    "#extinction = np.random.randint(0,2,N_PN)\n",
    "extinction = np.isin(np.arange(N_PN),np.random.choice(np.arange(N_PN),size=int(N_PN/2),replace=False)).astype(float)\n",
    "print(f'extinction: {np.sum(extinction)} of {N_PN}')\n",
    "binsize = (cl-Mmax-mu) / nbins\n",
    "ax1,ax2 = plot_pnlf(sample,mu,cl,binsize=binsize)\n",
    "#ax1.set(yscale='linear')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = sample + 1 * extinction\n",
    "\n",
    "fitter = MaximumLikelihood1D(pnlf,sample,mhigh=cl,Mmax=Mmax)\n",
    "mu_fit,mu_p,mu_m = fitter([29])\n",
    "print('without extinction: {:.2f} + {:.2f} - {:.2f}'.format(mu_fit,mu_p,mu_m))\n",
    "\n",
    "fitter = MaximumLikelihood1D(pnlf,data[data<cl],mhigh=cl,Mmax=Mmax)\n",
    "mu_fit,mu_p,mu_m = fitter([29])\n",
    "print('with extinction: {:.2f} + {:.2f} - {:.2f}'.format(mu_fit,mu_p,mu_m))\n",
    "binsize = (cl-Mmax-mu) / 6\n",
    "\n",
    "fig,((ax1,ax2),(ax3,ax4)) = plt.subplots(nrows=2,ncols=2,figsize=(single_column,0.9*single_column))\n",
    "\n",
    "ax1,ax2=plot_pnlf(sample,mu,cl,binsize=binsize,axes=(ax1,ax2))\n",
    "#ax3,ax4=plot_pnlf(data[extinction>0],mu_fit,cl,binsize=binsize,axes=(ax3,ax4),color='grey')\n",
    "ax3,ax4=plot_pnlf(data,mu_fit,cl,binsize=binsize,axes=(ax3,ax4))\n",
    "\n",
    "#ax1.set_yticks([10,100])\n",
    "#ax2.set_ylim([0,1000])\n",
    "#ax1.set(yscale='linear')\n",
    "plt.savefig(basedir/'reports'/'extinction_pnlf.pdf',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.plot.pnlf import _plot_pnlf, _plot_cum_pnlf\n",
    "\n",
    "data1=data[extinction==0]\n",
    "data2=data[extinction>0]\n",
    "\n",
    "fig = plt.figure(figsize=(two_column,two_column/2))\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "\n",
    "ax1 = _plot_pnlf(data1,mu,cl,binsize=binsize,mhigh=28.5,Mmax=Mmax,color=tab10[0],ax=ax1)\n",
    "ax2 = _plot_cum_pnlf(data1,mu,cl,binsize=None,mhigh=28.5,Mmax=Mmax,color=tab10[0],ax=ax2)\n",
    "\n",
    "ax1 = _plot_pnlf(data2,mu,cl,binsize=binsize,mhigh=28.5,Mmax=Mmax,color='grey',ax=ax1)\n",
    "ax2 = _plot_cum_pnlf(data2,mu,cl,binsize=None,mhigh=28.5,Mmax=Mmax,color='grey',ax=ax2)\n",
    "\n",
    "#ax1.set(yscale='linear')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "now do it for a large sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mu   = 30\n",
    "cl   = 28\n",
    "N_PN = 100\n",
    "\n",
    "mu_dict = {0.1:[],0.5:[],1:[]}\n",
    "\n",
    "for i in range(1000):\n",
    "    sample = sample_pnlf(N_PN,mu,cl)\n",
    "    extinction = np.random.randint(0,2,N_PN)\n",
    "    fitter = MaximumLikelihood1D(pnlf,sample,mhigh=cl,Mmax=Mmax)\n",
    "    mu_ref,mu_p,mu_m = fitter([29])\n",
    "\n",
    "    for A5007 in [0.1,0.5,1]:\n",
    "        data = sample + A5007 * extinction\n",
    "        fitter = MaximumLikelihood1D(pnlf,data[data<cl],mhigh=cl,Mmax=Mmax)\n",
    "        mu_fit,mu_p,mu_m = fitter([29])\n",
    "        #print('{}: {:.2f} + {:.2f} - {:.2f}'.format(A5007,mu_fit,mu_p,mu_m))\n",
    "        mu_dict[A5007].append(mu_fit-mu_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,(ax1,ax2,ax3) = plt.subplots(ncols=3,figsize=(two_column,two_column/2.5))\n",
    "\n",
    "ax1.hist(mu_dict[0.1],np.arange(-0.1,0.5,0.02),density=True)\n",
    "ax2.hist(mu_dict[0.5],np.arange(-0.1,0.5,0.02),density=True)\n",
    "ax3.hist(mu_dict[1],np.arange(-0.1,0.5,0.02),density=True)\n",
    "\n",
    "for A5007, ax in zip((0.1,0.5,1.0),(ax1,ax2,ax3)):\n",
    "    ax.set(xlabel=r'$\\Delta (m-M)$',ylim=[0,15])\n",
    "    ax.set_title(f'${np.mean(mu_dict[A5007]):.3f}\\pm{np.std(mu_dict[A5007]):.3f}$',fontsize=7)\n",
    "    label = f'$A_{{5007}}={A5007}$'\n",
    "    ax.text(0.65,0.9,label, transform=ax.transAxes,fontsize=8)\n",
    "\n",
    "ax2.set_yticklabels([])\n",
    "ax3.set_yticklabels([])\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig(basedir/'reports'/'extinction_pnlf_diff.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "take a look at uncertainty as a function of sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# it's better to run this in the python script sample_pnlf.py\n",
    "\n",
    "from pnlf.analyse import sample_pnlf\n",
    "from pnlf.analyse import MaximumLikelihood1D, pnlf\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout,format='%(levelname)s: %(message)s',level=logging.WARNING)\n",
    "\n",
    "N_iter = 10\n",
    "mu   = 30\n",
    "Mmax = -4.47\n",
    "\n",
    "mu_dict = {}\n",
    "for cl in [26.5,27,27.5,28]:\n",
    "    for N_PN in [20,50,100,150]:\n",
    "        mu_dict[(N_PN,cl)] = []\n",
    "        for i in range(N_iter):\n",
    "            sample = sample_pnlf(N_PN,mu,cl)\n",
    "            fitter = MaximumLikelihood1D(pnlf,sample,mhigh=cl,Mmax=Mmax)\n",
    "            mu_fit,mu_p,mu_m = fitter([29])\n",
    "            mu_dict[(N_PN,cl)].append(mu_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(basedir/'scripts'/'sampled_pnlf.pkl','rb') as f:\n",
    "    mu_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=4,nrows=4,figsize=(two_column,1.1*two_column))\n",
    "\n",
    "for j, cl in enumerate([26.5,27,27.5,28]):\n",
    "    for i, N_PN in enumerate([20,50,100,150]):\n",
    "        ax = axes[i,j]\n",
    "        ax.hist(mu_dict[(N_PN,cl)],bins=np.arange(29.76,30.26,0.02),density=True)\n",
    "        ax.set(xlim=(29.75,30.25),ylim=[0,15])\n",
    "        ax.set_xticks([29.8,29.9,30,30.1,30.2])\n",
    "        ax.set_xticklabels([29.8,None,30.0,None,30.2])\n",
    "\n",
    "        #ax.set_title(f'cl={cl},NPN={N_PN}')\n",
    "        ax.set_title(f'${np.mean(mu_dict[(N_PN,cl)]):.3f}\\pm{np.std(mu_dict[(N_PN,cl)]):.3f}$',fontsize=7)\n",
    "        ax.set_yticklabels([])\n",
    "        \n",
    "        if j%4!=0:\n",
    "            ax.set_yticklabels([])\n",
    "        if i!=3:\n",
    "            ax.set_xticklabels([])\n",
    "        else:\n",
    "            ax.set(xlabel=r'$(m-M)$')\n",
    "\n",
    "axes[1,0].annotate(r'$N_{\\mathrm{PN}}$', xy=(-0.4, -0.2), xycoords='axes fraction',rotation=90,fontsize=8)\n",
    "axes[3,2].annotate(r'completeness limit / mag', xy=(-0.6,-0.55), xycoords='axes fraction',fontsize=8)\n",
    "\n",
    "\n",
    "axes[0,0].annotate(r'20', xy=(-0.2,0.5), xycoords='axes fraction',rotation=90,fontsize=8)\n",
    "axes[1,0].annotate(r'50', xy=(-0.2,0.5), xycoords='axes fraction',rotation=90,fontsize=8)\n",
    "axes[2,0].annotate(r'100', xy=(-0.2,0.5), xycoords='axes fraction',rotation=90,fontsize=8)\n",
    "axes[3,0].annotate(r'150', xy=(-0.2,0.5), xycoords='axes fraction',rotation=90,fontsize=8)\n",
    "\n",
    "\n",
    "axes[3,0].annotate(r'26.5', xy=(0.5,-0.4), xycoords='axes fraction',fontsize=8)\n",
    "axes[3,1].annotate(r'27.0', xy=(0.5,-0.4), xycoords='axes fraction',fontsize=8)\n",
    "axes[3,2].annotate(r'27.5', xy=(0.5,-0.4), xycoords='axes fraction',fontsize=8)\n",
    "axes[3,3].annotate(r'28.0', xy=(0.5,-0.4), xycoords='axes fraction',fontsize=8)\n",
    "\n",
    "\n",
    "# the horizontal one (completeness limit)\n",
    "con = mpl.patches.ConnectionPatch(xyA=(0.9,-0.45), xyB=(0.1,-0.45), \n",
    "                                  coordsA=\"axes fraction\", coordsB=\"axes fraction\",\n",
    "                                  axesA=axes[3,3], axesB=axes[3,0], color=\"black\",linewidth=0.6,\n",
    "                                  arrowstyle='<|-',)\n",
    "axes[3,3].add_artist(con)\n",
    "\n",
    "\n",
    "# the vertical one (N PN)\n",
    "con = mpl.patches.ConnectionPatch(xyA=(-0.26,0.9), xyB=(-0.26,0.1), \n",
    "                                  coordsA=\"axes fraction\", coordsB=\"axes fraction\",\n",
    "                                  axesA=axes[0,0], axesB=axes[3,0], color=\"black\",linewidth=0.6,\n",
    "                                  arrowstyle='-|>',)\n",
    "axes[0,0].add_artist(con)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.2,wspace=0.1)\n",
    "\n",
    "plt.savefig(basedir/'reports'/'sample_PNLF.pdf',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results['range'] = 28-(results['(m-M)']-4.47)\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "\n",
    "ax.scatter(results['range'],results['N_PN'])\n",
    "for name in results['name']:\n",
    "    ax.text(results.loc[name]['range'],results.loc[name]['N_PN'],name)\n",
    "       \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = sample[10:60]\n",
    "\n",
    "print(f'{len(data)} data points (min={np.min(data):.2f},max={np.max(data):.2f})')\n",
    "fitter = MaximumLikelihood1D(pnlf,data[data<cl],mhigh=cl,Mmax=Mmax)\n",
    "mu_fit,mu_p,mu_m = fitter([29])\n",
    "print('{:.2f} + {:.2f} - {:.2f}'.format(mu_fit,mu_p,mu_m))\n",
    "\n",
    "ax1,ax2=plot_pnlf(data,mu_fit,cl,binsize=binsize)\n",
    "#ax1.set(yscale='linear')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### PSF uncertainties\n",
    "\n",
    "for each galaxy we estimate the impact of the PSF uncertainties on the final magnitude uncertainty. This section is to showcase the impact that the individual errors have on the final uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tmp = catalogue[(catalogue['type']=='PN') & (catalogue['mOIII']<28)].copy()\n",
    "\n",
    "tmp['dPSF'] = np.nan\n",
    "for gal_name in np.unique(catalogue['gal_name']):\n",
    "    tmp['dPSF'][tmp['gal_name']==gal_name] = parameters[gal_name]['dPSF']\n",
    "tmp['dmOIII_old'] = np.sqrt(tmp['dmOIII']-tmp['dPSF'])\n",
    "for gal_name in np.unique(catalogue['gal_name']):\n",
    "    t = tmp[tmp['gal_name']==gal_name]\n",
    "    print(f\"{gal_name}: {np.mean(t['dmOIII_old']):.3f}, {parameters[gal_name]['dPSF']:.3f}, {np.mean(t['dmOIII']):.3f}\")\n",
    "print(f\"\\nmedian dPSF: {np.median(tmp['dPSF']):.2f}\\nmedian dmOIII: {np.median(tmp['dmOIII_old']):.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Change the classification criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.analyse import emission_line_diagnostics\n",
    "\n",
    "# the table with the measured distances\n",
    "results = ascii.read(basedir/'data'/'interim'/ 'results_median_bkg.txt',format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "results.add_index('name')\n",
    "\n",
    "name = 'IC5332'\n",
    "\n",
    "completeness_limit = parameters[name]['completeness_limit']\n",
    "distance_modulus = results.loc[name]['(m-M)']\n",
    "\n",
    "catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "if catalogue_file.is_file():\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "    catalogue['overluminous'] = catalogue['overluminous'].astype(bool)\n",
    "\n",
    "tbl = emission_line_diagnostics(catalogue,distance_modulus,completeness_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pn_original = catalogue[(catalogue['type']=='PN') & (catalogue['mOIII']<completeness_limit)]\n",
    "pn_new = tbl[(tbl['type']=='PN') & (tbl['mOIII']<completeness_limit)]\n",
    "\n",
    "print(f'original: {len(pn_original)}, new: {len(pn_new)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Median vs Mean Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results_mean = ascii.read(basedir/'data'/'interim'/ 'results_submitted.txt',format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "results_mean.add_index('name')\n",
    "results_median = ascii.read(basedir/'data'/'interim'/ 'results.txt',format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "results_median.add_index('name')\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(two_column,two_column))\n",
    "\n",
    "lim = [28,32.5]\n",
    "ax.errorbar(results_mean['(m-M)'],results_median['(m-M)'],\n",
    "            xerr=[results_mean['err+(m-M)'],results_mean['err-(m-M)']],\n",
    "            yerr=[results_median['err+(m-M)'],results_median['err-(m-M)']],fmt='o')\n",
    "ax.plot(lim,lim,color='black')\n",
    "ax.set(xlim=lim,ylim=lim,xlabel='(m-M) mean background',ylabel='(m-M) median background')\n",
    "\n",
    "for gal_name in ['NGC1566','NGC7496','NGC4254','NGC1087','NGC1385']:\n",
    "    ax.text(results_mean.loc[gal_name]['(m-M)'],results_median.loc[gal_name]['(m-M)'],gal_name,\n",
    "         ha='right',fontsize='7',zorder=4)\n",
    "    \n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Bootstrapping for stat error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results.add_column(0.0,index=9,name='err_stat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.analyse import MaximumLikelihood1D, pnlf\n",
    "\n",
    "sample = catalogue[(catalogue['type']=='PN') & (catalogue['note']=='')]\n",
    "\n",
    "for gal_name in np.unique(catalogue['gal_name']):\n",
    "    \n",
    "    cl = parameters[gal_name]['completeness_limit']\n",
    "    subsample = sample[(sample['gal_name']==gal_name) & (sample['mOIII']<cl)]['mOIII']\n",
    "    \n",
    "    print(gal_name)\n",
    "    fitter = MaximumLikelihood1D(pnlf,subsample,mhigh=28,Mmax=-4.47)\n",
    "    mu_fit,mu_p,mu_m = fitter([29])\n",
    "    print('           {:.2f} + {:.2f} - {:.2f}'.format(mu_fit,mu_p,mu_m))\n",
    "\n",
    "    mu_boot, std_boot = fitter.bootstrap([29],N_boot=1000)\n",
    "    results.loc[gal_name]['err_stat'] = std_boot\n",
    "    print('Bootstrap: {:.2f} +- {:.2f}'.format(mu_boot,std_boot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results['err+'] = np.sqrt(results['err+(m-M)']**2 + results['err_stat']**2)\n",
    "results['err-'] = np.sqrt(results['err-(m-M)']**2 + results['err_stat']**2)\n",
    "\n",
    "results['err_stat'].info.format='%.2f'\n",
    "results['err+'].info.format='%.3f'\n",
    "results['err-'].info.format='%.3f'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(results[['name','(m-M)','err_stat','err+(m-M)','err-(m-M)']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.plot import plot_pnlf\n",
    "\n",
    "gal_name = 'NGC1433'\n",
    "cl = parameters[gal_name]['completeness_limit']\n",
    "subsample = sample[(sample['gal_name']==gal_name) & (sample['mOIII']<cl)]['mOIII']\n",
    "mu = results.loc[gal_name]['(m-M)']\n",
    "binsize = (cl+4.47-mu)/3\n",
    "plot_pnlf(subsample,mu,cl,binsize=binsize)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot entire sky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = basedir / 'data' / 'interim' / 'sample.txt'\n",
    "sample = ascii.read(filename,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "sample['SkyCoord'] = SkyCoord(sample['R.A.'],sample['Dec.'])\n",
    "\n",
    "ra = sample['SkyCoord'].ra\n",
    "ra = ra.wrap_at(180*u.degree)\n",
    "dec = sample['SkyCoord'].dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mpl.use('pdf')\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fig.add_subplot(111, projection=\"mollweide\")\n",
    "ax.scatter(ra.radian,dec.radian,marker='.')\n",
    "#ax.set_xticklabels(['14h','16h','18h','20h','22h','0h','2h','4h','6h','8h','10h'])\n",
    "ax.grid(True)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "\n",
    "for x,y,s in zip(ra,dec,sample['Name']):\n",
    "    ax.annotate(s,(x.radian,y.radian),xycoords='data',size='x-small')\n",
    "\n",
    "fig.savefig(\"map.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/henrysky/milkyway_plot/blob/master/mw_plot/mw_plot_classes.py\n",
    "image_filename = basedir/'data'/'interim'/'MW_edgeon_unannotate.jpg'\n",
    "img = plt.imread(image_filename)\n",
    "img = img[1625:4875]  # so there are 3250px there\n",
    "\n",
    "center=(0, 0) * u.deg\n",
    "radius=(180, 90) * u.deg\n",
    "    \n",
    "y_img_center = 1625 - int((3250 / 180) * center[1].value)\n",
    "y_radious_px = int((3250 / 180) * radius[1].value)\n",
    "x_img_center = int((6500 / 360) * center[0].value) + 3250\n",
    "x_radious_px = int((6500 / 360) * radius[0].value)\n",
    "\n",
    "img = img[(y_img_center - y_radious_px):(y_img_center + y_radious_px),\n",
    "             (x_img_center - x_radious_px):(x_img_center + x_radious_px), :]\n",
    "\n",
    "'''\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='mollweide')\n",
    "\n",
    "lon = np.linspace(-np.pi, np.pi, 6500)\n",
    "lat = np.linspace(np.pi / 2., -np.pi / 2., 3250)\n",
    "Lon, Lat = np.meshgrid(lon, lat)\n",
    "\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = {'IC5332':(4,2),\n",
    "'NGC0628':(0,1),\n",
    "'NGC1087':(0,2),\n",
    "'NGC1300':(0,3),\n",
    "'NGC1365':(4,3),\n",
    "'NGC1385':(0,4),\n",
    "'NGC1433':(4,5),\n",
    "'NGC1512':(4,4),\n",
    "'NGC1566':(3,6),\n",
    "'NGC1672':(4,6),\n",
    "'NGC2835':(2,6),\n",
    "'NGC3351':(1,6),\n",
    "'NGC3627':(0,6),\n",
    "'NGC4254':(1,0),\n",
    "'NGC4303':(3,0),\n",
    "'NGC4321':(0, 0),\n",
    "'NGC4535':(2,0),\n",
    "'NGC5068':(4,0),\n",
    "'NGC7496':(4,1)}\n",
    "\n",
    "va = {\n",
    "'IC5332':'bottom',\n",
    "'NGC0628':'bottom',\n",
    "'NGC1087':'bottom',\n",
    "'NGC1300':'center',\n",
    "'NGC1365':'center',\n",
    "'NGC1385':'center',\n",
    "'NGC1433':'center',\n",
    "'NGC1512':'center',\n",
    "'NGC1566':'center',\n",
    "'NGC1672':'center',\n",
    "'NGC2835':'center',\n",
    "'NGC3351':'top',\n",
    "'NGC3627':'bottom',\n",
    "'NGC4254':'top',\n",
    "'NGC4303':'top',\n",
    "'NGC4321':'bottom',\n",
    "'NGC4535':'center',\n",
    "'NGC5068':'bottom',\n",
    "'NGC7496':'top'}\n",
    "ha = {\n",
    "'IC5332':'center',\n",
    "'NGC0628':'center',\n",
    "'NGC1087':'center',\n",
    "'NGC1300':'right',\n",
    "'NGC1365':'right',\n",
    "'NGC1385':'left',\n",
    "'NGC1433':'right',\n",
    "'NGC1512':'left',\n",
    "'NGC1566':'right',\n",
    "'NGC1672':'left',\n",
    "'NGC2835':'right',\n",
    "'NGC3351':'right',\n",
    "'NGC3627':'right',\n",
    "'NGC4254':'left',\n",
    "'NGC4303':'left',\n",
    "'NGC4321':'left',\n",
    "'NGC4535':'left',\n",
    "'NGC5068':'center',\n",
    "'NGC7496':'center'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.plot.plot import create_RGB\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(ncols=7, nrows=5,figsize=(1.5*two_column,two_column))\n",
    "gs = axs[1, 2].get_gridspec()\n",
    "\n",
    "path = data_raw / 'MUSE_DR2' / 'filterImages' \n",
    "\n",
    "# remove the underlying axes\n",
    "for ax in axs[1:-1,1:-1].flatten():\n",
    "    ax.remove()\n",
    "ax = fig.add_subplot(gs[1:-1,1:-1],projection=\"mollweide\")\n",
    "ax.pcolormesh(Lon, Lat,img[:, :, 0], cmap='gray', zorder=2, alpha=0.85, rasterized=True)\n",
    "ax.plot(ra.radian,dec.radian,'.r',ms=1)\n",
    "\n",
    "#ax.set_xticklabels(['14h','16h','18h','20h','22h','0h','2h','4h','6h','8h','10h'])\n",
    "ax.grid(True)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "\n",
    "for x,y,name in zip(ra,dec,sample['Name']):\n",
    "    #ax.annotate(s,(x.radian,y.radian),xycoords='data',size='x-small',position='top')\n",
    "    ax.text(x.radian,y.radian,name,\n",
    "            horizontalalignment=ha[name],\n",
    "            verticalalignment=va[name],\n",
    "            fontsize=6,\n",
    "            color='white')\n",
    "\n",
    "for name,idx in positions.items():\n",
    "\n",
    "    sdss_g, h = fits.getdata(path / f'{name}_IMAGE_FOV_SDSS_g_WCS_Pall_mad.fits',header=True)\n",
    "    sdss_r, h = fits.getdata(path / f'{name}_IMAGE_FOV_SDSS_r_WCS_Pall_mad.fits',header=True)\n",
    "    sdss_i, h = fits.getdata(path / f'{name}_IMAGE_FOV_SDSS_i_WCS_Pall_mad.fits',header=True)\n",
    "    \n",
    "    #ax=axs[idx]\n",
    "    axs[idx].remove()\n",
    "    ax = fig.add_subplot(gs[idx],projection=WCS(h))\n",
    "    \n",
    "    gri = create_RGB(sdss_i,sdss_r,sdss_g,weights=[1,1,1],percentile=[99,99,99])\n",
    "    gri[sdss_g==0] = (1,1,1)\n",
    "    ax.imshow(gri)\n",
    "    \n",
    "    #ax.annotate(f'{k}',(0.1, 0.5),xycoords='axes fraction', va='center')\n",
    "    ax.set_title(name,fontsize=6)\n",
    "    \n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "axs[(0,5)].remove()\n",
    "\n",
    "#fig.tight_layout()\n",
    "plt.subplots_adjust(wspace=0,hspace=0.3)\n",
    "\n",
    "plt.savefig(basedir/'reports'/'all_galaxies_sky.pdf',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Angular resolution of all galaxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "ang = []\n",
    "for name in results['name']:\n",
    "    with fits.open(data_raw/'MUSE_DR2.1'/'AUXILIARY'/'seeing_maps'/f'{name}_seeing.fits') as hdul:\n",
    "        PSF = hdul[0].data\n",
    "    \n",
    "    res_min = np.nanmin(PSF)/206265*results.loc[name]['d/Mpc']*1e6\n",
    "    res_max = np.nanmax(PSF)/206265*results.loc[name]['d/Mpc']*1e6\n",
    "        \n",
    "    ang_min = np.nanmin(PSF)\n",
    "    ang_max = np.nanmax(PSF)\n",
    "    \n",
    "    res.append(np.nanmean(PSF)/206265*results.loc[name]['d/Mpc']*1e6)\n",
    "    ang.append(np.nanmean(PSF))\n",
    "    \n",
    "    print(f'{name}: min={ang_min:.2f}\", max={ang_max:.2f}\"')\n",
    "    print(f'{name}: min={res_min:.2f} pc, max={res_max:.2f} pc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pointings = ascii.read(basedir/'data'/'external'/'PHANGS_pointings.csv',delimiter=';')\n",
    "pointings = pointings[~pointings['PSF'].mask]\n",
    "pointings['name'] = [x.split(' ')[0] for x in pointings['pointing']]\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "\n",
    "ax.hist(pointings['PSF'],bins=np.linspace(0.3,1.2,20))\n",
    "ax.set(xlabel='FWHM / arcsec',xlim=[0.3,1.2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for name in np.unique(pointings['name']):\n",
    "    print(name, np.mean(pointings['PSF'][pointings['name']==name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Match catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "name = 'NGC0628'\n",
    "catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "if catalogue_file.is_file():\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "catalogue['SkyCoord'] = SkyCoord(catalogue['RaDec'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "RA=24.1888\n",
    "DEC=15.7968\n",
    "\n",
    "coord = SkyCoord(RA*u.degree,DEC*u.degree)\n",
    "\n",
    "sep = coord.separation(catalogue['SkyCoord'])\n",
    "\n",
    "catalogue[np.argmin(sep)][['id','type']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "compare with Francesco's nebula catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pn = Table(fits.getdata(basedir/'data'/'catalogues'/'PN_catalogue.fits'))\n",
    "pn['SkyCoord'] = SkyCoord(pn['RA'],pn['DEC'])\n",
    "\n",
    "with fits.open(basedir /'..'/'cluster' / 'data' / 'interim' / 'Nebulae_Catalogue_v2p1.fits') as hdul:\n",
    "    nebulae = Table(hdul[1].data)\n",
    "nebulae['SkyCoord'] = SkyCoord(nebulae['cen_ra']*u.deg,nebulae['cen_dec']*u.deg,frame='icrs')\n",
    " \n",
    "\n",
    "region_ID = []\n",
    "for gal_name in np.unique(pn['gal_name']):\n",
    "    print(gal_name)\n",
    "    \n",
    "    sub = pn[pn['gal_name']==gal_name]\n",
    "    \n",
    "    filename = data_ext/'Products'/'Nebulae catalogue' /'spatial_masks'/f'{gal_name}_nebulae_mask.fits'\n",
    "    with fits.open(filename) as hdul:\n",
    "        nebulae_mask = NDData(hdul[0].data.astype(float),meta=hdul[0].header,wcs=WCS(hdul[0].header))\n",
    "        nebulae_mask.data[nebulae_mask.data==-1] = np.nan\n",
    "    \n",
    "    for row in sub:\n",
    "        x,y = row[['x','y']]\n",
    "        region_ID.append(nebulae_mask.data[int(y),int(x)])\n",
    "p = 100*np.sum(~np.isnan(region_ID))/len(region_ID)\n",
    "p = 100*np.sum(~np.isnan(region_ID) & (pn['type']=='PN'))/np.sum(pn['type']=='PN')\n",
    "print(f'nebulae catalogue contains {p:.2f}% of PNe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from astropy.coordinates import match_coordinates_sky\n",
    "\n",
    "pn = Table(fits.getdata(basedir/'data'/'catalogues'/'PN_catalogue.fits'))\n",
    "pn['SkyCoord'] = SkyCoord(pn['RA'],pn['DEC'])\n",
    "\n",
    "with fits.open(basedir /'..'/'cluster' / 'data' / 'interim' / 'Nebulae_Catalogue_v2p1.fits') as hdul:\n",
    "    nebulae = Table(hdul[1].data)\n",
    "nebulae['SkyCoord'] = SkyCoord(nebulae['cen_ra']*u.deg,nebulae['cen_dec']*u.deg,frame='icrs')\n",
    " \n",
    "match = 0\n",
    "for gal_name in np.unique(pn['gal_name']):\n",
    "    \n",
    "    sub_pn  = pn[(pn['gal_name']==gal_name) & (pn['type']=='PN')]\n",
    "    sub_hii = nebulae[nebulae['gal_name']==gal_name]\n",
    "    \n",
    "    idx,sep,_ = match_coordinates_sky(sub_pn['SkyCoord'],sub_hii['SkyCoord'])\n",
    "    \n",
    "    match+=len(sub_pn[sep<Angle('1\"')])\n",
    "    \n",
    "print(f'nebulae catalogue matches {100*match/np.sum(pn[\"type\"]==\"PN\"):.2f}% of PNe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pn['OIII5007'] = 10**(-(pn['mOIII']+13.74)/2.5)\n",
    "pn['HA6562'] = pn['OIII5007'] / 10**pn['logOIII/Ha']\n",
    "xlim = [np.min(pn['HA6562']),np.max(pn['HA6562'])]\n",
    "\n",
    "xlim =[2e-19,2e-16]\n",
    "bins = np.logspace(*np.log10(xlim),20)\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(single_column,single_column/1.618))\n",
    "\n",
    "#ax.hist(nebulae['HA6562_FLUX']*1e-20,bins=bins,label='HII regions',alpha=0.6)\n",
    "ax.hist(pn[np.isnan(region_ID) & (pn['type']=='PN')]['HA6562'],bins=bins,label='not in nebula catalogue',alpha=0.6)\n",
    "ax.hist(pn[~np.isnan(region_ID) & (pn['type']=='PN')]['HA6562'],bins=bins,label='in nebula catalogue',alpha=0.6)\n",
    "ax.legend()\n",
    "\n",
    "ax.set(xscale='log',xlim=xlim,xlabel='HA6562 / erg s-1 cm-2')\n",
    "plt.savefig(basedir/'reports'/'pn_Halpha_histogram.pdf',dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xlim =[1e-17,1e-15]\n",
    "bins = np.logspace(*np.log10(xlim),20)\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "\n",
    "ax.hist(pn[np.isnan(region_ID) & (pn['type']=='PN')]['OIII5007'],bins=bins,label='not in nebula catalogue',alpha=0.6)\n",
    "ax.hist(pn[~np.isnan(region_ID) & (pn['type']=='PN')]['OIII5007'],bins=bins,label='in nebula catalogue',alpha=0.6)\n",
    "ax.legend()\n",
    "\n",
    "ax.set(xscale='log',xlim=xlim,xlabel='OIII5007')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.mean(pn[np.isnan(region_ID) & (pn['type']=='PN')]['HA6562'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Measure mass in mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.io import ReadLineMaps\n",
    "from regions import PixCoord,EllipsePixelRegion\n",
    "\n",
    "observed_mass = {}\n",
    "age_mw = []\n",
    "\n",
    "\n",
    "with open(basedir / 'data' / 'interim' / 'parameters.yml') as yml_file:\n",
    "    parameters = yaml.load(yml_file,Loader=yaml.FullLoader)\n",
    "        \n",
    "for name in results['name']:\n",
    "\n",
    "    lines = ['OIII5006', 'HA6562']\n",
    "\n",
    "    # read in the data we will be working with and print some information\n",
    "    galaxy = ReadLineMaps(data_ext/'MUSE_DR2'/'MUSEDAP',name,extensions=lines,**parameters[name])\n",
    "    galaxy.center = sample_table.loc[name]['SkyCoord'].to_pixel(galaxy.wcs)\n",
    "    galaxy.Ebv = sample_table.loc[name]['E(B-V)']\n",
    "    galaxy.posang = sample_table.loc[name]['posang']\n",
    "    galaxy.inclination = sample_table.loc[name]['Inclination']\n",
    "    galaxy.r25 = sample_table.loc[name]['r25']*u.arcmin\n",
    "\n",
    "    eccentricity = np.sin(galaxy.inclination*u.deg).value\n",
    "    width = 0.2*(galaxy.r25/u.arcmin*300).value  # convert arcmin to pixel\n",
    "    # angle uses x-axis but posang is defined from north pole (y-axis)\n",
    "    aperture = EllipsePixelRegion(PixCoord(*galaxy.center),\n",
    "                                  width=width,\n",
    "                                  height=np.sqrt((width)**2 * (1-eccentricity**2)),\n",
    "                                  angle=(galaxy.posang-90)*u.deg)\n",
    "    center_mask = aperture.to_mask().to_image(galaxy.shape).astype(bool)\n",
    "\n",
    "    mask = np.zeros(galaxy.shape,dtype=bool)\n",
    "    mask |= galaxy.star_mask.astype(bool)\n",
    "    if hasattr(galaxy,'mask'):\n",
    "        print('masking parts of the image')\n",
    "        mask[galaxy.HA6562>getattr(galaxy,'HAmask',np.nanpercentile(galaxy.HA6562,95))]=True\n",
    "        mask |=center_mask\n",
    "    if name=='NGC1566':\n",
    "        # this galaxy has one extremely noise pointing\n",
    "        mask[galaxy.PSF==3.11]=True\n",
    "\n",
    "    with fits.open(galaxy.filename) as hdul:\n",
    "        data = hdul['AGE_MW'].data\n",
    "    age_mw.append(np.nanmedian(data[~mask]))\n",
    "        \n",
    "    area_per_pixel =  (0.2*Distance(distmod=sample_table.loc[name]['(m-M)'])*u.arcsec.to(u.rad)).to(u.pc)**2\n",
    "    m = np.log10(area_per_pixel.value * np.nansum(galaxy.stellar_mass[~mask]))\n",
    "    observed_mass[name] = m\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a,b = [],[]\n",
    "\n",
    "for k,v in observed_mass.items():\n",
    "    a.append(k)\n",
    "    b.append(v)\n",
    "t = Table([a,b],names=['name','obs_mass'])\n",
    "t['age_mw'] = age_mw\n",
    "t['age_mw'].info.format = '%.3f'\n",
    "t['obs_mass'].info.format = '%.3f'\n",
    "\n",
    "with open(basedir/'data'/'interim'/'observed_mass.txt','w',newline='\\n') as f:\n",
    "    ascii.write(t,f,format='fixed_width_two_line',overwrite=True,delimiter_pad=' ',position_char='=')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import astropy.units as u\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "from astropy.coordinates import match_coordinates_sky, Angle, SkyCoord\n",
    "\n",
    "# nebulae catalogue from Francesco (mostly HII-regions)\n",
    "filename = data_ext / 'MUSE_DR2.0' / 'Nebulae catalogue' / f'Nebulae_Catalogue_DR2_native.fits'\n",
    "with fits.open(filename) as hdul:\n",
    "    nebulae = Table(hdul[1].data)\n",
    "nebulae['SkyCoord'] = SkyCoord(nebulae['cen_ra']*u.deg,nebulae['cen_dec']*u.deg)\n",
    "nebulae.rename_columns(['cen_x','cen_y'],['x','y'])\n",
    "nebulae['mOIII'] = -2.5*np.log10(nebulae['OIII5006_FLUX']*1e-20) - 13.74\n",
    "nebulae.add_index('region_ID')\n",
    "\n",
    "# planetary nebulae catalogue\n",
    "filename = basedir / 'data' / 'catalogues' / f'nebulae.fits'\n",
    "with fits.open(filename) as hdul:\n",
    "    PN_candidates = Table(hdul[1].data)\n",
    "#PN_candidates['SkyCoord'] = SkyCoord(PN_candidates['RA'],PN_candidates['DEC'])\n",
    "PN_candidates = PN_candidates[(PN_candidates['mOIII']<28) & (PN_candidates['type']=='HII')]\n",
    "\n",
    "tolerance = Angle('1\"')\n",
    "\n",
    "# match the two catalogues\n",
    "idx, sep, _  = match_coordinates_sky(nebulae['SkyCoord'],PN_candidates['SkyCoord'])\n",
    "within_tolerance = len(sep[sep.__lt__(tolerance)])\n",
    "print(f'{within_tolerance} nebulae of {len(sep)} are also in PNe catalogue ({100*within_tolerance/len(sep):.2f}%)')\n",
    "\n",
    "idx, sep, _  = match_coordinates_sky(PN_candidates['SkyCoord'],nebulae['SkyCoord'])\n",
    "within_tolerance = len(sep[sep.__lt__(tolerance)])\n",
    "print(f'{within_tolerance} PN of {len(sep)} are also in nebulae catalogue ({100*within_tolerance/len(sep):.2f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "criteria = sep<tolerance\n",
    "fig,ax=plt.subplots()\n",
    "ax.scatter(PN_candidates[criteria]['mOIII'],nebulae[idx[criteria]]['mOIII'])\n",
    "ax.plot([20,28],[20,28],zorder=2,color='black')\n",
    "ax.set(xlabel='mOIII (Fabian)',ylabel='mOIII (Francesco)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from skimage.measure import find_contours\n",
    "\n",
    "name = 'NGC4254'\n",
    "subsample = PN_candidates[(sep>tolerance) & (PN_candidates['gal_name']==name)]\n",
    "\n",
    "# DAP linemaps (Halpha and OIII)\n",
    "filename = data_ext / 'MUSE_DR2.0' / 'MUSEDAP' / f'{name}_MAPS.fits'\n",
    "with fits.open(filename) as hdul:\n",
    "    Halpha = NDData(data=hdul['HA6562_FLUX'].data,\n",
    "                    uncertainty=StdDevUncertainty(hdul['HA6562_FLUX_ERR'].data),\n",
    "                    mask=np.isnan(hdul['HA6562_FLUX'].data),\n",
    "                    meta=hdul['HA6562_FLUX'].header,\n",
    "                    wcs=WCS(hdul['HA6562_FLUX'].header))\n",
    "    OIII = NDData(data=hdul['OIII5006_FLUX'].data,\n",
    "                    uncertainty=StdDevUncertainty(hdul['OIII5006_FLUX_ERR'].data),\n",
    "                    mask=np.isnan(hdul['OIII5006_FLUX'].data),\n",
    "                    meta=hdul['OIII5006_FLUX'].header,\n",
    "                    wcs=WCS(hdul['OIII5006_FLUX'].header))\n",
    "# nebulae spatial masks\n",
    "filename = data_ext / 'MUSE_DR2.0' / 'Nebulae catalogue' /'spatial_masks'/f'{name}_HIIreg_mask.fits'\n",
    "with fits.open(filename) as hdul:\n",
    "    nebulae_mask = NDData(hdul[0].data-1,meta=hdul[0].header,wcs=WCS(hdul[0].header))\n",
    "    nebulae_mask.data[nebulae_mask.data==-1] = np.nan\n",
    "    \n",
    "ncols = 6\n",
    "nrows = int(np.ceil(len(subsample)/ncols))\n",
    "\n",
    "width = two_column\n",
    "fig, axes = plt.subplots(nrows=nrows,ncols=ncols,figsize=(width,width/ncols*nrows))\n",
    "axes_iter = iter(axes.flatten())\n",
    "    \n",
    "for row in subsample:  \n",
    "\n",
    "    ax = next(axes_iter)\n",
    "    \n",
    "    data_cutout = Cutout2D(OIII.data,(row['x'],row['y']),size=16)\n",
    "    mask_cutout = Cutout2D(nebulae_mask.data,(row['x'],row['y']),size=16)\n",
    "    \n",
    "    norm = simple_norm(data_cutout.data,'linear',clip=False,percent=99)\n",
    "    ax.imshow(data_cutout.data,origin='lower',norm=norm,cmap=plt.cm.gray_r)\n",
    "    \n",
    "    region_ID = np.unique(mask_cutout.data[~np.isnan(mask_cutout.data)])\n",
    "\n",
    "    contours = []\n",
    "    for i in region_ID:\n",
    "        blank_mask = np.zeros_like(mask_cutout.data)\n",
    "        blank_mask[mask_cutout.data==i] = 1\n",
    "        contours += find_contours(blank_mask, 0.5)\n",
    "\n",
    "    for coords in contours:\n",
    "        ax.plot(coords[:,1],coords[:,0],color='tab:red',lw=0.5)\n",
    "    \n",
    "    x,y=data_cutout.input_position_cutout \n",
    "    aperture = CircularAperture((x,y), r=2.5)\n",
    "    aperture.plot(color='tab:blue',lw=.5, alpha=1,axes=ax)\n",
    "\n",
    "    ax.axis('off')\n",
    "    \n",
    "for i in range(nrows*ncols-len(subsample)):\n",
    "\n",
    "    # remove the empty axes at the bottom\n",
    "    ax = next(axes_iter)\n",
    "    ax.remove()\n",
    "fig.suptitle(name,y=0.9)\n",
    "plt.subplots_adjust(wspace=0.1, hspace=.0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "use spatial masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from astropy.wcs import WCS\n",
    "from astropy.table import join \n",
    "\n",
    "def get_value(data,x,y):\n",
    "    '''get the value of data at position x/y\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : ndarray\n",
    "    x : array \n",
    "    y : array\n",
    "    '''\n",
    "    \n",
    "    shape = data.shape\n",
    "    \n",
    "    out = []\n",
    "    for j,i in zip(x,y):\n",
    "        if 0<i<shape[0] and 0<j<shape[1]:\n",
    "            out.append(data[int(i),int(j)])\n",
    "        else:\n",
    "            out.append(np.nan)\n",
    "    return out\n",
    "\n",
    "\n",
    "PN_candidates['region_ID'] = np.nan\n",
    "\n",
    "for name in np.unique(PN_candidates['gal_name']):\n",
    "    #print(f'working on {name}')\n",
    "    \n",
    "    # read in the nebulae spatial mask\n",
    "    filename = data_ext / 'MUSE_DR2.0' / 'Nebulae catalogue' /'spatial_masks'/f'{name}_HIIreg_mask.fits'\n",
    "    with fits.open(filename) as hdul:\n",
    "        nebulae_mask = NDData(hdul[0].data-1,meta=hdul[0].header,wcs=WCS(hdul[0].header))\n",
    "        nebulae_mask.data[nebulae_mask.data==-1] = np.nan\n",
    "    \n",
    "    criteria = PN_candidates['gal_name']==name\n",
    "    PN_candidates['region_ID'][criteria] = get_value(nebulae_mask.data,x=PN_candidates['x'][criteria],y=PN_candidates['y'][criteria])\n",
    "    \n",
    "joined_catalogue = join(PN_candidates,nebulae,keys=['gal_name','region_ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### BPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(6,6))\n",
    "\n",
    "\n",
    "tmp = catalogue[catalogue['type']=='SNR']\n",
    "ax.scatter(np.log10((tmp['SII6716']+tmp['SII6730'])/tmp['HA6562']),np.log10(tmp['OIII5006']/tmp['HB4861']),\n",
    "           color='tab:orange',label='SNR',s=0.8)\n",
    "\n",
    "tmp = catalogue[catalogue['type']=='HII']\n",
    "ax.scatter(np.log10((tmp['SII6716']+tmp['SII6730'])/tmp['HA6562']),np.log10(tmp['OIII5006']/tmp['HB4861']),\n",
    "           color='tab:blue',label='HII',s=0.8)\n",
    "\n",
    "tmp = catalogue[catalogue['type']=='PN']\n",
    "ax.scatter(np.log10((tmp['SII6716']+tmp['SII6730'])/tmp['HA6562']),np.log10(tmp['OIII5006']/tmp['HB4861']),\n",
    "           color='tab:red',label='PN',s=0.8)\n",
    "\n",
    "ax.legend()\n",
    "ax.set(xlim=[-2.,1],ylim=[-1.5,2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with fits.open(data_ext/'MUSE_DR2.1'/'datacubes'/'IC5332_DATACUBE_FINAL_P01.fits') as hdul:\n",
    "    primary_header = hdul[0].header\n",
    "    data_header = hdul[1].header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "\n",
    "ax.hist(catalogue['v_SIGMA'],bins=np.arange(0,200,10))\n",
    "ax.set(xlim=[0,200])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tbl = catalogue[catalogue['mOIII']<28]\n",
    "print(f\"all:     {np.nanmean(tbl['v_SIGMA']):.2f},  {np.nanstd(tbl['v_SIGMA']):.2f}\")\n",
    "\n",
    "for name in results['name']:\n",
    "    tmp = tbl[tbl['gal_name']==name]\n",
    "    \n",
    "    print(f\"{name}: {np.nanmean(tmp['v_SIGMA']):.2f},  {np.nanmedian(tmp['v_SIGMA']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.nanmedian(catalogue['v_SIGMA'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Enricos catalgoue for the fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with fits.open(basedir/'data'/'external'/'PNe_enrico.fits') as hdul:\n",
    "    catalogue = Table(hdul[1].data)\n",
    "catalogue['gal_name'] = [x.strip() for x in catalogue['gal_name']]\n",
    "catalogue.rename_columns(['cen_x','cen_y'],['x','y'])\n",
    "\n",
    "catalogue['mOIII'] = -2.5*np.log10(catalogue['OIII5006_FLUX_DIG']*1e-20) - 13.74\n",
    "catalogue['dmOIII'] = np.abs( 2.5/np.log(10) * catalogue['OIII5006_FLUX_ERR_DIG'] / catalogue['OIII5006_FLUX_DIG'] )\n",
    "catalogue = catalogue[np.isfinite(catalogue['mOIII'])]\n",
    "\n",
    "for name in results['name']:\n",
    "    data = catalogue[catalogue['gal_name']==name]['mOIII']\n",
    "    print(name,len(data[data<28]))\n",
    "    \n",
    "print(f'N_PN={len(catalogue[catalogue[\"mOIII\"]<28])}')\n",
    "\n",
    "\n",
    "# to use with `pnlf.photometry.measure_flux`\n",
    "#sources['fwhm'] = [galaxy.PSF[int(y),int(x)] for x,y in sources[['x','y']]]\n",
    "#sources['sharpness'] = 0.5\n",
    "#sources['roundness2'] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.analyse import MaximumLikelihood1D, pnlf, cdf\n",
    "from pnlf.plot.pnlf import plot_pnlf\n",
    "from pnlf.auxiliary import mu_to_parsec\n",
    "from scipy.stats import kstest\n",
    "\n",
    "name = 'NGC4303'\n",
    "completeness_limit = 28\n",
    "\n",
    "Mmax = -4.47\n",
    "\n",
    "data = catalogue[catalogue['gal_name']==name]['mOIII']\n",
    "err = catalogue[catalogue['gal_name']==name]['dmOIII']\n",
    "\n",
    "if name in ['NGC2835','NGC4303']:\n",
    "    #data,err = data[data>26.8],err[data>26.8]\n",
    "    mask = data<26.\n",
    "else:\n",
    "    mask = np.zeros(len(data),dtype=bool)\n",
    "    \n",
    "print(f'analysing {name} (sample table: {parameters[name][\"mu\"]})')\n",
    "print(f'completeness limit = {completeness_limit}')\n",
    "fitter = MaximumLikelihood1D(pnlf,data[(data<completeness_limit) & ~mask],err=err[(data<completeness_limit) & ~mask],\n",
    "                             mhigh=completeness_limit,Mmax=Mmax)\n",
    "mu,mu_p,mu_m = fitter([29])\n",
    "\n",
    "d,(dp,dm)=mu_to_parsec(mu,[mu_p,mu_m])\n",
    "print('{:.2f} + {:.2f} - {:.2f}'.format(mu,mu_p,mu_m))\n",
    "print('{:.2f} + {:.2f} - {:.2f}'.format(d,dp,dm))\n",
    "\n",
    "ks,pv = kstest(data[(data<completeness_limit) & ~mask],cdf,args=(mu,completeness_limit))\n",
    "print(f'{name}: statistic={ks:.3f}, pvalue={pv:.3f}')\n",
    "\n",
    "binsize = (completeness_limit-Mmax-mu) / 2\n",
    "\n",
    "axes = plot_pnlf(data,mu,completeness_limit,mask=mask,\n",
    "                 binsize=binsize,mhigh=28.5,Mmax=Mmax,filename=None,color=tab10[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.plot.pnlf import _plot_pnlf\n",
    "\n",
    "nbins = {'IC5332':3,'NGC0628':3,'NGC1087':3,'NGC1300':2,'NGC1365':3,\n",
    "         'NGC1385':4,'NGC1433':3,'NGC1512':3,'NGC1566':3,'NGC1672':2,\n",
    "         'NGC2835':3,'NGC3351':3,'NGC3627':3,'NGC4254':4,'NGC4303':2,\n",
    "         'NGC4321':3,'NGC4535':3,'NGC5068':3,'NGC7496':3}\n",
    "\n",
    "completeness = { 'NGC1566':28,'NGC3351':28,'NGC4303':28,'NGC4535':28,'NGC5068':27}    \n",
    "\n",
    "sample = ['IC5332','NGC0628','NGC1433','NGC1566','NGC2835','NGC3351','NGC3627','NGC4303','NGC4535','NGC5068']\n",
    "\n",
    "cuts = {'NGC2835':26,'NGC3351':25.5,'NGC4303':26}\n",
    "\n",
    "\n",
    "Enrico_distances = {}\n",
    "\n",
    "names = results['name']\n",
    "nrows = 3\n",
    "ncols = 4\n",
    "filename = basedir / 'reports' / f'pnlf_enrico'\n",
    "\n",
    "#----------------------------------------------\n",
    "# DO NOT MODIFY BELOW\n",
    "#----------------------------------------------\n",
    "width = two_column\n",
    "fig, axes = plt.subplots(nrows=nrows,ncols=ncols,figsize=(width,width/ncols*nrows))\n",
    "axes_iter = iter(axes.flatten())\n",
    "Mmax = -4.47\n",
    "\n",
    "# loop over the galaxies we want to plot\n",
    "#for name in names:  \n",
    "for name in sample:\n",
    "    \n",
    "    # get the next axis and find position on the grid\n",
    "    ax = next(axes_iter)\n",
    "    if nrows>1 and ncols>1:\n",
    "        i, j = np.where(axes == ax)\n",
    "        i,j=i[0],j[0]\n",
    "    elif ncols>1:\n",
    "        i,j = 0, np.where(axes==ax)[0]\n",
    "    elif nrows>1:\n",
    "        i,j = np.where(axes==ax)[0],0\n",
    "    else:\n",
    "        i,j=0,0\n",
    "        \n",
    "    data = catalogue[catalogue['gal_name']==name]['mOIII']\n",
    "    err = catalogue[catalogue['gal_name']==name]['dmOIII']\n",
    "    completeness_limit = completeness.get(name,27.5)\n",
    "    \n",
    "    if name in cuts.keys():\n",
    "        #data,err = data[data>26.8],err[data>26.8]\n",
    "        mask = data<cuts.get(name,0)\n",
    "    else:\n",
    "        mask = np.zeros(len(data),dtype=bool)\n",
    "    \n",
    "    \n",
    "    print(f'analysing {name} (sample table: {parameters[name][\"mu\"]})')\n",
    "    fitter = MaximumLikelihood1D(pnlf,data[(data<completeness_limit) & ~mask],\n",
    "                                 err=err[(data<completeness_limit) & ~mask],\n",
    "                                 mhigh=completeness_limit,Mmax=Mmax)\n",
    "    mu,mu_p,mu_m = fitter([29])\n",
    "    d,(dp,dm)=mu_to_parsec(mu,[mu_p,mu_m])\n",
    "    print('{:.2f} + {:.2f} - {:.2f}'.format(mu,mu_p,mu_m))\n",
    "    print('{:.2f} + {:.2f} - {:.2f}'.format(d,dp,dm))\n",
    "\n",
    "    Enrico_distances[name] = (mu,mu_p,mu_m)\n",
    " \n",
    "        \n",
    "    ks,pv = kstest(data[data<completeness_limit],cdf,args=(mu,completeness_limit))\n",
    "    print(f'{name}: statistic={ks:.3f}, pvalue={pv:.3f}')\n",
    "\n",
    "    mlow = Mmax+mu\n",
    "    binsize = (completeness_limit-mlow) / nbins[name]\n",
    "    mhigh = completeness_limit+1.5*binsize\n",
    "    \n",
    "    ax=_plot_pnlf(data,mu,completeness_limit,mask=mask,binsize=binsize,mhigh=mhigh,ax=ax,ms=3)\n",
    "        \n",
    "    ylim=ax.get_ylim()\n",
    "    y2 = ylim[1]*1.7\n",
    "    if y2>100:y2=99\n",
    "    ax.set_ylim([0.7,y2])\n",
    "    if name in ['NGC1433','NGC1512']:\n",
    "        ax.set_ylim([None,99])\n",
    "    if name=='NGC1385':\n",
    "        ax.set_ylim([None,12])        \n",
    "    \n",
    "    if name in ['NGC5068','IC5332']:\n",
    "        ax.text(0.2,0.07,f'{name}', transform=ax.transAxes,fontsize=7)        \n",
    "    else:\n",
    "        ax.text(0.63,0.07,f'{name}', transform=ax.transAxes,fontsize=7)\n",
    "    \n",
    "    label = f'$(m-M)={mu:.2f}^{{+{mu_p:.2f}}}_{{-{mu_m:.2f}}}$'\n",
    "    ax.text(0.05,0.88,label, transform=ax.transAxes,fontsize=6)\n",
    "    \n",
    "    #ax.set_xlim([mu-5,completeness+0.5])\n",
    "    # add labels to the axis\n",
    "    if i==nrows-1:\n",
    "        ax.set_xlabel(r'$m_{[\\mathrm{O}\\,\\tiny{\\textsc{iii}}]}$ / mag')\n",
    "    if j==0:\n",
    "        ax.set_ylabel(r'$N_\\mathrm{PN}$')\n",
    "    #ax.set_title(name)\n",
    "    #ax.set(xlim=[24,28.5])\n",
    "axes[1,2].set_xlabel(r'$m_{[\\mathrm{O}\\,\\tiny{\\textsc{iii}}]}$ / mag')\n",
    "axes[1,3].set_xlabel(r'$m_{[\\mathrm{O}\\,\\tiny{\\textsc{iii}}]}$ / mag')\n",
    "\n",
    "ax = next(axes_iter)\n",
    "h,l = fig.axes[0].get_legend_handles_labels()\n",
    "ax.axis('off')\n",
    "ax.legend(h,l,fontsize=7,loc='center left',frameon=False)\n",
    "\n",
    "ax = next(axes_iter)\n",
    "ax.remove()\n",
    "\n",
    "plt.subplots_adjust(wspace=0.15, hspace=0.15)\n",
    "plt.savefig(filename.with_suffix('.pdf'),bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.plot.pnlf import _plot_pnlf\n",
    "\n",
    "nbins = {'IC5332':4,'NGC0628':4,'NGC1087':3,'NGC1300':2,'NGC1365':3,\n",
    "         'NGC1385':4,'NGC1433':3,'NGC1512':3,'NGC1566':3,'NGC1672':2,\n",
    "         'NGC2835':3,'NGC3351':4,'NGC3627':3,'NGC4254':4,'NGC4303':3,\n",
    "         'NGC4321':3,'NGC4535':3,'NGC5068':4,'NGC7496':3}\n",
    "\n",
    "cuts = {'NGC1433':26.8,'NGC1512':26,'NGC3351':25.5}\n",
    "\n",
    "Enrico_distances = {}\n",
    "\n",
    "names = results['name']\n",
    "nrows = 3\n",
    "ncols = 3\n",
    "filename = basedir / 'reports' / f'pnlf_enrico_dig'\n",
    "\n",
    "#----------------------------------------------\n",
    "# DO NOT MODIFY BELOW\n",
    "#----------------------------------------------\n",
    "width = two_column\n",
    "fig, axes = plt.subplots(nrows=nrows,ncols=ncols,figsize=(width,width/ncols*nrows))\n",
    "axes_iter = iter(axes.flatten())\n",
    "Mmax = -4.47\n",
    "\n",
    "# loop over the galaxies we want to plot\n",
    "for name in 'IC5332','NGC0628','NGC1365','NGC1433', 'NGC1512', 'NGC2835','NGC3351','NGC3627','NGC5068':  \n",
    "\n",
    "    # get the next axis and find position on the grid\n",
    "    ax = next(axes_iter)\n",
    "    if nrows>1 and ncols>1:\n",
    "        i, j = np.where(axes == ax)\n",
    "        i,j=i[0],j[0]\n",
    "    elif ncols>1:\n",
    "        i,j = 0, np.where(axes==ax)[0]\n",
    "    elif nrows>1:\n",
    "        i,j = np.where(axes==ax)[0],0\n",
    "    else:\n",
    "        i,j=0,0\n",
    "        \n",
    "    if name in ['IC5332','NGC2835','NGC3627']:\n",
    "        completeness_limit=27.5\n",
    "    else:\n",
    "        completeness_limit=28\n",
    "        \n",
    "    data = catalogue[catalogue['gal_name']==name]['mOIII']\n",
    "    err = catalogue[catalogue['gal_name']==name]['dmOIII']\n",
    "\n",
    "\n",
    "    cut = cuts.get(name,0)\n",
    "    data,err = data[data>cut],err[data>cut]\n",
    "\n",
    "    print(f'analysing {name} (sample table: {parameters[name][\"mu\"]})')\n",
    "    fitter = MaximumLikelihood1D(pnlf,data[data<completeness_limit],err=err[data<completeness_limit],\n",
    "                                 mhigh=completeness_limit,Mmax=Mmax)\n",
    "    mu,mu_p,mu_m = fitter([29])\n",
    "    d,(dp,dm)=mu_to_parsec(mu,[mu_p,mu_m])\n",
    "    print('{:.2f} + {:.2f} - {:.2f}'.format(mu,mu_p,mu_m))\n",
    "    print('{:.2f} + {:.2f} - {:.2f}'.format(d,dp,dm))\n",
    "\n",
    "    Enrico_distances[name] = (mu,mu_p,mu_m)\n",
    "    \n",
    "    ks,pv = kstest(data[data<completeness_limit],cdf,args=(mu,completeness_limit))\n",
    "    print(f'{name}: statistic={ks:.3f}, pvalue={pv:.3f}')\n",
    "\n",
    "    mlow = Mmax+mu\n",
    "    binsize = (completeness_limit-mlow) / nbins[name]\n",
    "    mhigh = completeness_limit+1.5*binsize\n",
    "    \n",
    "    ax=_plot_pnlf(data,mu,completeness_limit,binsize=binsize,mhigh=mhigh,ax=ax,ms=3)\n",
    "        \n",
    "    ylim=ax.get_ylim()\n",
    "    y2 = ylim[1]*1.7\n",
    "    if y2>100:y2=99\n",
    "    ax.set_ylim([0.7,y2])\n",
    "    if name in ['NGC1433','NGC1512']:\n",
    "        ax.set_ylim([None,99])\n",
    "    if name=='NGC1385':\n",
    "        ax.set_ylim([None,12])        \n",
    "    \n",
    "    if name=='NGC2835':\n",
    "        ax.text(0.2,0.07,f'{name}', transform=ax.transAxes,fontsize=7)        \n",
    "    else:\n",
    "        ax.text(0.63,0.07,f'{name}', transform=ax.transAxes,fontsize=7)\n",
    "    \n",
    "    label = f'$(m-M)={mu:.2f}^{{+{mu_p:.2f}}}_{{-{mu_m:.2f}}}$'\n",
    "    ax.text(0.05,0.88,label, transform=ax.transAxes,fontsize=6)\n",
    "    \n",
    "    #ax.set_xlim([mu-5,completeness+0.5])\n",
    "    # add labels to the axis\n",
    "    if i==nrows-1:\n",
    "        ax.set_xlabel(r'$m_{[\\mathrm{O}\\,\\tiny{\\textsc{iii}}]}$ / mag')\n",
    "    if j==0:\n",
    "        ax.set_ylabel(r'$N_\\mathrm{PN}$')\n",
    "    #ax.set_title(name)\n",
    "    #ax.set(xlim=[24,28.5])\n",
    "    \n",
    "#axes[3,3].set_xlabel(r'$m_{[\\mathrm{O}\\,\\tiny{\\textsc{iii}}]}$ / mag')\n",
    "#ax = next(axes_iter)\n",
    "#ax.remove()\n",
    "#h,l = fig.axes[0].get_legend_handles_labels()\n",
    "#ax.axis('off')\n",
    "#ax.legend(h,l,fontsize=7,loc='center left',frameon=False)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.15, hspace=0.15)\n",
    "plt.savefig(filename.with_suffix('.pdf'),bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "\n",
    "for i,(k,v) in enumerate(Enrico_distances.items()):\n",
    "    \n",
    "    ax.errorbar(i,v[0]-results.loc[k]['(m-M)'],yerr=v[2],color='tab:red',fmt='o')\n",
    "    \n",
    "ax.set_xticks(np.arange(len(Enrico_distances.keys())))\n",
    "ax.set_xticklabels(Enrico_distances.keys(),rotation=90)\n",
    "ax.axhline(0,color='black')\n",
    "ax.set(ylabel=r'$\\Delta(m-M)$ (Enrico$-$Fabian)')\n",
    "\n",
    "plt.savefig(basedir/'reports'/'pnlf_distances_enrico.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,1)\n",
    "\n",
    "R = 8.5\n",
    "g = -0.1\n",
    "\n",
    "y = R+g*x\n",
    "\n",
    "x_data = np.random.uniform(0,1,100)\n",
    "y_data = R+g*x_data + np.random.normal(scale=0.05,size=100)\n",
    "\n",
    "fig,(ax1,ax2)=plt.subplots(ncols=2,figsize=(8,4))\n",
    "\n",
    "ax1.plot(x,y,color='black')\n",
    "ax1.scatter(x_data,y_data)\n",
    "\n",
    "delta = y_data - (R+g*x_data)\n",
    "ax2.scatter(y_data,delta)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.auxiliary import mu_to_parsec, parsec_to_mu\n",
    "\n",
    "d,err = mu_to_parsec(29,0.109)\n",
    "\n",
    "err/d*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 10*u.Mpc\n",
    "parsec_to_mu(d,d*0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "708.667px",
    "left": "28px",
    "top": "110.283px",
    "width": "264.5px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
