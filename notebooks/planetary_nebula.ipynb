{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planetary Nebula <a class=\"tocSkip\">\n",
    "    \n",
    "This notebook is used to test and showcase the results of my first project. I use spectroscopic data from the [Multi Unit Spectroscopic Explorer](https://www.eso.org/sci/facilities/develop/instruments/muse.html) (MUSE) that has been observed as part of the [PHANGS](https://sites.google.com/view/phangs/home) collaboration.\n",
    "    \n",
    "I will use a set of line maps of emission lines to identify Planetary Nebula in the data an measure their brightness. This can then be used to fit an empiric relation and hence measure the distance to the galaxy.\n",
    "    \n",
    "This notebook is used for developement. Final code is moved to the `pymuse` packge in the `src` folder. Any production scripts reside in the `scripts` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    " \n",
    "### Load Basic Packages\n",
    "    \n",
    "First we load a bunch of common packages that are used across the project. More specific packages that are only used in one section are loaded later to make it clear where they belong to (this also applies to all custom moduls that were written for this project)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# reload modules after they have been modified\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# some basic packages\n",
    "import os                 # filesystem related stuff\n",
    "import json\n",
    "from pathlib import Path  # use instead of os.path and glob\n",
    "import sys                # mostly replaced by pathlib\n",
    "\n",
    "import errno      # more detailed error messages\n",
    "import warnings   # handles warnings\n",
    "import logging    # use logging instead of print\n",
    "\n",
    "from collections import OrderedDict  \n",
    "\n",
    "# packages for scientific computing\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "# packages for creating plots and figures\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# special functions for astronomy \n",
    "from astropy.table import Table  # useful datastructure\n",
    "from astropy.table import vstack # combine multiple tables\n",
    "\n",
    "from astropy.io import fits      # open fits files\n",
    "from astropy.io import ascii     # handle normal files\n",
    "\n",
    "from astropy.wcs import WCS               # handle coordinates\n",
    "from astropy.coordinates import SkyCoord  # convert pixel to sky coordinates\n",
    "\n",
    "from astropy.stats import sigma_clipped_stats  # calcualte statistics of images\n",
    "\n",
    "import astropy.units as u        # handle units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we use the `logging` module to handle informations and warnings (this does not always work as expected in jupyter notebooks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout,\n",
    "                    #format='(levelname)s %(name)s %(message)s',\n",
    "                    datefmt='%H:%M:%S',\n",
    "                    level=logging.INFO)\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data\n",
    "\n",
    "this uses the `ReadLineMaps` class from the `pymuse.io` module. To use it, we first need to specify the path to the data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymuse.io import ReadLineMaps\n",
    "\n",
    "# first we need to specify the path to the raw data\n",
    "data_raw = Path('d:\\downloads\\MUSEDAP')\n",
    "basedir = Path('..')\n",
    "\n",
    "with open(basedir / 'data' / 'interim' / 'parameters.json') as json_file:\n",
    "    parameters = json.load(json_file)\n",
    "\n",
    "# list all files in the specified directory\n",
    "galaxies = [x.name for x in data_raw.iterdir() if x.is_dir()]\n",
    "print(', '.join(map(str,galaxies)))\n",
    "\n",
    "# read in the data we will be working with and print some information\n",
    "galaxy = ReadLineMaps(data_raw / 'NGC628')\n",
    "setattr(galaxy,'mu',parameters[galaxy.name]['mu'])\n",
    "setattr(galaxy,'alpha',parameters[galaxy.name]['power_index'])\n",
    "\n",
    "#print('\\n' + str(NGC628))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = basedir / 'data' / 'raw' / 'phangs_sample_table_v1p4.fits'\n",
    "with fits.open(filename) as hdul:\n",
    "    sample_table = Table(hdul[1].data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference files\n",
    "\n",
    "To test the newly written routines we compare our results to those from Kreckel et al. (2017)\n",
    "\n",
    "**Requires** (both already loaded with standard packages)\n",
    " * `astropy.io.ascii`\n",
    " * `astropy.coordinates.SkyCoord`\n",
    " \n",
    "**Returns**\n",
    " * `pn_kreckel` table with all PNe detected by Kreckel et al. (2017)\n",
    " * `pn_bright` only PNe that are brighter than the completeness limit\n",
    " * `pn_hermann` only PNe that were also detected by Hermann et al. 2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn_kreckel = ascii.read(basedir / 'data' / 'external' / 'kreckel_pn_2017.txt')\n",
    "\n",
    "def string_to_ra(string):\n",
    "    '''convert coordinates from Kreckel et al. (2017) to astropy\n",
    "    \n",
    "    the right ascension in the paper is given as \n",
    "    \"01:36:42.212\" but astropy requires \"01h36m42.212s\".\n",
    "    This function replaces the \":\" with the appropriate character.\n",
    "    '''\n",
    "    return string.replace(':','h',1).replace(':','m') + 's'\n",
    "\n",
    "def string_to_dec(string):\n",
    "    '''convert coordinates from Kreckel et al. (2017) to astropy\n",
    "    \n",
    "    the declination in the paper is given as \"01:36:42.212\" \n",
    "    but astropy requires \"01d36m42.212s\".\n",
    "    This function replaces the \":\" with the appropriate character.\n",
    "    '''\n",
    "    return string.replace(':','d',1).replace(':','m') + 's'\n",
    "\n",
    "# convert string to astronomical coordinates\n",
    "pn_kreckel['RA'] = list(map(string_to_ra,pn_kreckel['RA']))\n",
    "pn_kreckel['DEC'] = list(map(string_to_dec,pn_kreckel['DEC']))\n",
    "pn_kreckel['SkyCoord'] = SkyCoord(pn_kreckel['RA'],pn_kreckel['DEC'])\n",
    "\n",
    "# select some subsets (PN from Hermann et al. 2008 or bright sources only)\n",
    "pn_herrmann = pn_kreckel[[True if i.endswith('a') else False for i in pn_kreckel['ID']]]\n",
    "pn_bright = pn_kreckel[pn_kreckel['mOIII']<27]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Detection\n",
    "\n",
    "There are two different approaches to identifying sources in an image. The first utilizes PSF fitting and uses implementations from astropy. The other uses the external `SExtractor` package which detects peaks and classifies them with a neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on IRAFStarFinder or DAPStarFinder\n",
    "\n",
    "The sources we are searching for are unresolved. However due to seeing, they will be smeared out. This PSF has the form of a Gaussian (or Moffat). The subsequent algorithms use this and try to fit a theoretical curve to the observed peaks in the image. If the fit aggrees within some threshold, it reports the peak as a source. The advantage is that for crowded fields, the algorithm will try to fit an individual function to each peak and thus enable us correctly identfiy objects that are closeby.\n",
    "\n",
    "The following function is based on this tutorial \n",
    "\n",
    "https://photutils.readthedocs.io/en/stable/detection.html\n",
    "\n",
    "https://photutils.readthedocs.io/en/stable/api/photutils.detection.DAOStarFinder.html#photutils.detection.DAOStarFinder\n",
    "\n",
    "**Requires**\n",
    " * A `photutils` starfinder. This can be either `DAOStarFinder` or `IRAFStarFinder`\n",
    " * `detect_unresolved_sources`\n",
    " \n",
    "**Returns**\n",
    " * `sources` a table with the position of all identified sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from photutils import DAOStarFinder            # DAOFIND routine to detect sources\n",
    "from photutils import IRAFStarFinder           # IRAF starfind routine to detect star\n",
    "\n",
    "from pymuse.detection import detect_unresolved_sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_roundness   = 0.8\n",
    "_sharpnesslo = 0.1\n",
    "_sharpnesshi = 0.9\n",
    "\n",
    "sources = detect_unresolved_sources(galaxy,\n",
    "                                    'OIII5006',\n",
    "                                    StarFinder=DAOStarFinder,\n",
    "                                    threshold=8,\n",
    "                                    roundlo=-_roundness,\n",
    "                                    roundhi=_roundness,\n",
    "                                    sharplo=_sharpnesslo,\n",
    "                                    sharphi=_sharpnesshi,\n",
    "                                    save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare to Kreckel et al. 2017\n",
    "\n",
    "As mentioned in the beginning, we compare the newly detected sources to those from Kreckel et al. (2017). \n",
    "\n",
    "**Requires**\n",
    " * `match_coordinates_sky` from `astropy.coordinates` to compare the two catalogues.\n",
    " * `Angle` from `astropy.coordinates` to set a maximum seperation in units of arcseconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.coordinates import match_coordinates_sky # match sources against existing catalog\n",
    "from astropy.coordinates import Angle                 # work with angles (e.g. 1°2′3″)\n",
    "\n",
    "tolerance = '0.5s'\n",
    "ID, angle, Quantity  = match_coordinates_sky(pn_bright['SkyCoord'],sources['SkyCoord'])\n",
    "within_tolerance = len(angle[angle.__lt__(Angle(tolerance))])\n",
    "\n",
    "print(f'{within_tolerance} of {len(angle)} match within {tolerance}\": {within_tolerance / len(angle)*100:.1f} %')\n",
    "print(f'mean seperation is {angle.mean().to_string(u.arcsec,decimal=True)}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot detected sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymuse.plot.plot import plot_sky_with_detected_stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = np.transpose((sources['x'], sources['y']))\n",
    "positions_kk = np.transpose(pn_bright['SkyCoord'].to_pixel(wcs=galaxy.wcs))\n",
    "positions = (position,positions_kk)\n",
    "\n",
    "save_file = Path.cwd() / '..' / 'reports' / 'figures' / f'{galaxy.name}_sky_sources_DAO.pdf'\n",
    "plot_sky_with_detected_stars(data=galaxy.OIII5006_DAP,\n",
    "                             wcs=galaxy.wcs,\n",
    "                             positions=positions,\n",
    "                             filename=save_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Cut out detected stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pymuse.plot.plot import sample_cutouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_file = Path.cwd() / '..' / 'reports' / 'figures' / f'{galaxy.name}_stars.pdf'\n",
    "\n",
    "stars = sample_cutouts(galaxy.OIII5006_DAP,sources,galaxy.wcs,nrows=4,ncols=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Using SExtractor\n",
    "\n",
    "there is no Python implementation of SExtractor. Instead we run it from the command line\n",
    "\n",
    "```\n",
    "sextractor file.fits -c default.sex\n",
    "```\n",
    "\n",
    "this will produce a file `test.cat` which contains the position of the sources. We read this table and calculate the sky position wiht astropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "file = Path.cwd() / '..' / 'data' / 'interim' / 'NGC628.cat'\n",
    "\n",
    "table = ascii.read(file)\n",
    "table['SkyCoord'] = SkyCoord.from_pixel(table['X_IMAGE'],table['Y_IMAGE'],NGC628.wcs)\n",
    "\n",
    "print(f'{len(table)} sources found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sources = Table()\n",
    "sources['x'] = table['X_IMAGE']\n",
    "sources['y'] = table['Y_IMAGE']\n",
    "sources['SkyCoord'] = table['SkyCoord']\n",
    "sources['fwhm'] = 0.8\n",
    "NGC628.peaks_tbl = sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Match with known sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ID, angle, Quantity  = match_coordinates_sky(pn_bright['SkyCoord'],table['SkyCoord'])\n",
    "within_1_arcsec = len(angle[angle.__lt__(Angle(\"0.5s\"))])\n",
    "\n",
    "print(f'{within_1_arcsec} of {len(angle)} match within 0.5\": {within_1_arcsec / len(angle)*100:.1f} %')\n",
    "print(f'mean seperation is {angle.mean().to_string(u.arcsec,decimal=True)}\"')\n",
    "#print(f'mean angle: {angle.mean():.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Plot detected sources\n",
    "\n",
    "this requires the previously loaded `plot_sources` from `pymuse.plot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "file = Path.cwd() / '..' / 'reports' / 'figures' / f'{NGC628.name}_sources_sextractor.pdf'\n",
    "\n",
    "position = np.transpose((sources['x'], sources['y']))\n",
    "references = np.transpose(pn_bright['SkyCoord'].to_pixel(wcs=NGC628.wcs))\n",
    "positions = (position,references)\n",
    "\n",
    "sky_with_detected_stars(data=NGC628.OIII5006_old,wcs=NGC628.wcs,positions=positions,filename=file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Completeness limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pymuse.detection import completeness_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mock_sources = completeness_limit(\n",
    "                   galaxy,\n",
    "                   'OIII5006',\n",
    "                   DAOStarFinder,\n",
    "                   threshold=8,\n",
    "                   iterations=1,\n",
    "                   roundlo=-_roundness,\n",
    "                   roundhi=_roundness,\n",
    "                   sharplo=_sharpnesslo,\n",
    "                   sharphi=_sharpnesshi\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flux measurement\n",
    "\n",
    "In the previous step we detected potential PN candidates by their [OIII] emission. This means we know their position but lack exact flux measurments. In this section we measure the flux of the identified objects in different emission lines that are used in later steps. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Growth curve analysis\n",
    "\n",
    "\n",
    "\n",
    "#### Gaussian\n",
    "\n",
    "A shape that is commonly used for the PSF is that of a 2D gaussian (we assume  variance of $\\sigma_x^2 = \\sigma_y^2 = \\sigma^2$). If we center the peak at the origin the PSF is described by\n",
    "$$\n",
    "f(x,y) = A \\exp\\left(-\\frac{x^2+y^2}{2\\sigma^2}\\right)\n",
    "$$\n",
    "with some amplitude $A$. We can rewrite this in polar coordinates as \n",
    "$$\n",
    "f(r,\\phi) = A \\exp\\left(-\\frac{r^2}{2\\sigma^2}\\right)\n",
    "$$\n",
    "The light inside an aperture of radius $P(R)$ is given by the integral\n",
    "$$\n",
    "P(R) = \\int_0^{2\\pi} \\int_0^R f(r,\\phi) \\mathrm{d} \\phi r \\mathrm{d} r = 2\\pi \\sigma^2 A \\left(1-\\exp \\left(-\\frac{R^2}{2\\sigma^2}\\right) \\right) \n",
    "$$\n",
    "We are interested in the ratio $p(R) = P(R) / P(\\infty)$. If we use the relation between the standard deviation and the $\\mathrm{FWHM}$ of a Gaussian $\\sigma = \\frac{\\mathrm{FWHM}}{2\\sqrt{2\\ln2}}$, we can write\n",
    "$$\n",
    "\\begin{align}p(R) = 1-\\exp\\left(- \\frac{4 \\ln 2 \\cdot R^2}{\\mathrm{fwhm}^2} \\right)\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "#### Moffat\n",
    "\n",
    "The measured FWHM are systematically larger than the reported values. A possible cause is that the shape of the PSF is not a perfect Gaussian, but rather described by a [Moffat](https://en.wikipedia.org/wiki/Moffat_distribution). This distribution is larger towards the wings and fitting a Gaussian to such a shape should result in a larger FWHM\n",
    "\n",
    "$$\n",
    "f(R;\\alpha,\\gamma) = A \\left[1 + \\left(\\frac{R}{\\gamma}\\right)^2 \\right]^{- \\alpha}\n",
    "$$\n",
    "\n",
    "**Note**: this nomenclature follows `astropy` and contradicts the commonly used scheme which uses $\\gamma=\\alpha$ and $\\alpha=\\beta$.\n",
    "\n",
    "The Full Width Half Maximum of this function is given by\n",
    "$$\n",
    "\\mathrm{FWHM} = 2\\gamma \\sqrt{2^{1/\\alpha}-1}\n",
    "$$\n",
    "\n",
    "like we did for the Gaussian we can calculate the amount of flux within a radius R as \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(R) = \\int_0^{2\\pi} \\int_0^R f(r,\\phi) \\mathrm{d} \\phi r \\mathrm{d} r = 2\\pi \\int_0^R A \\left[1 + \\left(\\frac{r}{\\gamma}\\right)^2 \\right]^{- \\alpha} r \\mathrm{d} r\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "to solve this we substitute $u=1+\\left(\\frac{r}{\\gamma} \\right)^2 $ with $\\frac{\\mathrm{d} u}{\\mathrm{d} r} = \\frac{2r}{\\gamma^2}$. \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(R) = A \\frac{\\gamma^2}{2(1-\\alpha)} \\left[1 + \\left( \\frac{R}{\\gamma} \\right)^2 \\right]^{1-\\alpha}- A\\frac{\\gamma^2}{2(1-\\alpha)}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "again we are interested in the ratio $p(R) = P(R) / P(\\infty)$. If we assume that $\\alpha>1$, the first term will be $0$ for $R\\rightarrow \\infty$ and so we end up with \n",
    "\n",
    "$$\n",
    "p(r) = \\left[ 1+\\left( \\frac{R}{\\gamma}\\right)^2\\right]^{1-\\alpha} - 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pymuse.photometry import light_in_gaussian, light_in_moffat, fwhm_moffat\n",
    "\n",
    "alpha = 4\n",
    "gamma = 10\n",
    "fwhm = fwhm_moffat(alpha,gamma)\n",
    "print(f'alpha={alpha:.2f}, gamma={gamma:.2f}, fwhm={fwhm:.2f}')\n",
    "\n",
    "d = np.arange(0,20,0.2)\n",
    "g = light_in_gaussian(d,fwhm)\n",
    "m = light_in_moffat(d,alpha,gamma)\n",
    "plt.plot(d/fwhm,100*g,label='Gaussian')\n",
    "plt.plot(d/fwhm,100*m,label='Moffat')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('diameter in fwhm')\n",
    "plt.ylabel('light in aperture in %')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Create an ideal Gaussian/Moffat source and measure growth curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from astropy.modeling import models, fitting \n",
    "from astropy.nddata import Cutout2D\n",
    "from astropy.stats import gaussian_sigma_to_fwhm, gaussian_fwhm_to_sigma\n",
    "\n",
    "from pymuse.photometry import growth_curve\n",
    "from pymuse.auxiliary import fwhm_moffat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "size=64\n",
    "fwhm = 10\n",
    "bkg = 0.5\n",
    "print(f'fwhm={fwhm}')\n",
    "\n",
    "std =  fwhm * gaussian_fwhm_to_sigma\n",
    "gaussian = models.Gaussian2D(x_mean=size/2,y_mean=size/2,x_stddev=std,y_stddev=std)\n",
    "img = gaussian(*np.indices((size,size))) + np.random.uniform(0,bkg,(size,size))\n",
    "plt.imshow(img, origin='lower')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fwhm_fit = growth_curve(img,size/2,size/2,model='gaussian',plot=True)[0]\n",
    "print(f'fwhm={fwhm}, measured={fwhm_fit:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "size=64\n",
    "alpha = 4.765\n",
    "gamma = 6/(2*np.sqrt(2**(1/4.76)-1))\n",
    "bkg = 0.01\n",
    "\n",
    "fwhm = 2*gamma * np.sqrt(2**(1/alpha)-1)\n",
    "print(f'alpha={alpha:.2f}, gamma={gamma:.2f}, fwhm={fwhm:.2f}')\n",
    "\n",
    "std = 4 * gaussian_fwhm_to_sigma\n",
    "moffat = models.Moffat2D(x_0=size/2,y_0=size/2,alpha=alpha,gamma=gamma)\n",
    "\n",
    "img = moffat(*np.indices((size,size))) + np.random.uniform(0,bkg,(size,size))\n",
    "plt.imshow(img, origin='lower')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fit = growth_curve(img,size/2,size/2,model='gaussian',plot=True,length=10)\n",
    "fwhm_fit = fit[0]\n",
    "#fwhm_fit = fwhm_moffat(*fit)\n",
    "\n",
    "print(f'fwhm={fwhm:.2f}, fit={fwhm_fit:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Apply to real data\n",
    "\n",
    "We saw that we can predict the aperture size dependence of the flux for mock sources. Now we pick real objects and try to do the same. \n",
    "\n",
    "Stars should have much larger stellar velocities. We use this to identify potential foreground stars in our source catalogue. We cannot use the peaks of the velocity maps as they seem to be displaced from the center of the star."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy.signal import convolve\n",
    "\n",
    "from astropy.nddata import Cutout2D\n",
    "from astropy.stats import gaussian_fwhm_to_sigma\n",
    "\n",
    "from pymuse.plot import single_cutout\n",
    "from pymuse.photometry import growth_curve, correct_PSF, fwhm_moffat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "we find stars due to their high velocity dispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# define kernel for smoothing\n",
    "smoothing_length = 10 \n",
    "kernel = np.ones((smoothing_length,smoothing_length))\n",
    "\n",
    "# find stars by their large velocity dispersion\n",
    "star_mask = np.zeros(NGC628.V_STARS.shape,dtype='f8')\n",
    "star_mask[np.abs(NGC628.V_STARS)>200] = 1\n",
    "\n",
    "# smooth ouput with convolution\n",
    "star_mask = convolve(star_mask,kernel,mode='same')\n",
    "star_mask[star_mask>0.1] = 1\n",
    "star_mask[star_mask<0.1] = 0\n",
    "star_mask[np.isnan(NGC628.V_STARS)] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stars = detect_unresolved_sources(NGC628,\n",
    "                                  'whitelight',\n",
    "                                   StarFinder=DAOStarFinder,\n",
    "                                   threshold=5,\n",
    "                                   oversize_PSF = 1.,\n",
    "                                   save=False)\n",
    "    \n",
    "stars = stars[star_mask[stars['y'].astype(int),stars['x'].astype(int)]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "size = 20\n",
    "x,y,fwhm = stars[i][['x','y','fwhm']]\n",
    "single_cutout(NGC628,'whitelight',x,y,size=size)\n",
    "print(fwhm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = NGC628.HA6562\n",
    "\n",
    "aperture = 25\n",
    "fit = growth_curve(data,x,y,model='moffat',rmax=15,plot=True,length=10)\n",
    "#fwhm_fit=fit[0]\n",
    "fwhm_fit = fwhm_moffat(*fit)\n",
    "\n",
    "radius = np.arange(0,10,0.5)\n",
    "plt.plot(radius,light_in_gaussian(radius,fwhm),label='gaussian',ls='--',color='tab:red')\n",
    "plt.legend()\n",
    "\n",
    "print(f'reported={fwhm:.2f}, measured={fwhm_fit:.2f}, ratio={fwhm_fit/fwhm:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "we have 6 objects classified as stars in our field of view. For each of them we do a growth curve analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "size = 20\n",
    "data = NGC628.whitelight\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(8,5))\n",
    "\n",
    "for i in range(len(stars)):\n",
    "    x,y,fwhm = stars[i][['x','y','fwhm']]\n",
    "\n",
    "    fit = growth_curve(data,x,y,model='moffat',rmax=30,plot=True,length=10)\n",
    "    fwhm_fit = fwhm_moffat(*fit)\n",
    "    print(f'alpha={fit[0]:.2f}, gamma={fit[1]:.2f}, reported={fwhm:.2f}, measured={fwhm_fit:.2f}, ratio={fwhm_fit/fwhm:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Fit 2D Function\n",
    "\n",
    "So far we didn't fit the PSF shape directly but took a slight detour with the light inside an aperture. Here we try to fit the 2D functions to the observed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "size = 16\n",
    "\n",
    "#sub = sources[sources['peak']>500]\n",
    "#x,y,fwhm = sub[8][['x','y','fwhm']]\n",
    "\n",
    "for line, cmap in zip(['whitelight','OIII5006','HA6562'],[plt.cm.viridis,plt.cm.Blues_r,plt.cm.Reds_r]):\n",
    "    # defien the size of the cutout region\n",
    "    star = Cutout2D(getattr(NGC628,line), (x,y), u.Quantity((size, size), u.pixel))\n",
    "\n",
    "    fitter = fitting.LevMarLSQFitter()\n",
    "    data = star.data\n",
    "    fig ,(ax1,ax2,ax3,ax4) = plt.subplots(1,4,figsize=(12,3))\n",
    "    #cmap = plt.cm.Blues\n",
    "\n",
    "    ax1.imshow(data,origin='lower',cmap=cmap)\n",
    "    ax1.set_title(f'image {line}')\n",
    "\n",
    "    std = fwhm * gaussian_fwhm_to_sigma\n",
    "    gaussian_theory = models.Gaussian2D(x_mean=size/2,y_mean=size/2,x_stddev=std,y_stddev=std)\n",
    "    ax2.imshow(gaussian_theory(*np.indices(data.shape)), origin='lower',cmap=cmap)\n",
    "    ax2.set_title('Gaussian reported')\n",
    "    \n",
    "    model = models.Gaussian2D()\n",
    "    gaussian = fitter(model,*np.indices(data.shape),data,maxiter=1000)\n",
    "    ax3.imshow(gaussian(*np.indices(data.shape)), origin='lower',cmap=cmap)\n",
    "    ax3.set_title('Gaussian fit')\n",
    "\n",
    "    model = models.Moffat2D(alpha=4.765,fixed={'alpha':True}) \n",
    "    moffat = fitter(model,*np.indices(data.shape),data,maxiter=2000)\n",
    "    fwhm_moffat = 2*moffat.gamma.value * np.sqrt(2**(1/moffat.alpha.value)-1)\n",
    "    ax4.imshow(moffat(*np.indices(data.shape)), origin='lower',cmap=cmap)\n",
    "    ax4.set_title('Moffat fit')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    xstd = gaussian.x_stddev * gaussian_sigma_to_fwhm\n",
    "    ystd = gaussian.y_stddev * gaussian_sigma_to_fwhm\n",
    "\n",
    "    print(f'{line}: reported: {fwhm:.3f}, gaussian={xstd:.3f} ,{ystd:.3f}, moffat={fwhm_moffat:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def fast_photometry(data,x,y,r,r_in,r_out):\n",
    "    '''\n",
    "    performe aperture photometry with backround subtraction for one source\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : ndarray\n",
    "        image data\n",
    "        \n",
    "    x : float\n",
    "        x cooridinate of the source\n",
    "    \n",
    "    y : float\n",
    "        y cooridinate of the source\n",
    "        \n",
    "    r : float\n",
    "        radius of the main aperture\n",
    "    \n",
    "    r_in : float\n",
    "        inner radius of the annulus that is used for the background        \n",
    "    \n",
    "    r_out : float\n",
    "        outer radius of the annulus that is used for the background\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    aperture = CircularAperture((x,y), r=r)\n",
    "    annulus_aperture = CircularAnnulus((x,y), r_in=r_in, r_out=r_out)\n",
    "    mask = annulus_aperture.to_mask(method='center')\n",
    "    annulus_data = mask.multiply(data)\n",
    "    annulus_data_1d = annulus_data[mask.data > 0]\n",
    "    _, bkg_median, _ = sigma_clipped_stats(annulus_data_1d[~np.isnan(annulus_data_1d)])\n",
    "    phot = aperture_photometry(data,aperture)\n",
    "    \n",
    "    return phot['aperture_sum'][0]-aperture.area*bkg_median\n",
    "\n",
    "def aperture_correction(data,positions,r_aperture):\n",
    "    \n",
    "    fluxes = [fast_photometry(data,x,y,r,r_in,r_out) for x,y in positions]\n",
    "    \n",
    "    apertures = CircularAperture(positions,r_aperture)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree\n",
    "from pymuse.plot import single_cutout\n",
    "\n",
    "positions = np.transpose([sources['x'],sources['y']])\n",
    "\n",
    "tree = cKDTree(positions)\n",
    "dists = tree.query(positions, 2)\n",
    "nn_dist = dists[0][:, 1]\n",
    "\n",
    "sub = sources[(nn_dist>16)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aperture Photometry\n",
    "\n",
    "we use the positions of the previously detected sources to measure the flux of different lines\n",
    "\n",
    "https://photutils.readthedocs.io/en/stable/aperture.html\n",
    "\n",
    "the values in the pixels are in units of $10^{-20} \\ \\mathrm{erg}  \\ \\mathrm{cm}^{-2} \\ \\mathrm{s}^{-1} / \\mathrm{spaxel}$. For the [OIII] line, this flux is then converted to an apparent magnitude\n",
    "$$\n",
    "m_{[\\mathrm{O\\ III}]} = -2.5 \\cdot \\log F_{[\\mathrm{O\\ III}]} - 13.74\n",
    "$$\n",
    "\n",
    "where $F_{[\\mathrm{O\\ III}]}$ is given in $\\mathrm{erg}  \\ \\mathrm{cm}^{-2} \\ \\mathrm{s}^{-1}$. Error propagation gives the error of the magnitude as\n",
    "\n",
    "$$\n",
    "\\Delta m_{[\\mathrm{O\\ III}]} = \\sqrt{\\left(\\frac{-2.5 \\cdot \\Delta F_{[\\mathrm{O\\ III}]}}{\\ln 10 \\cdot F_{[\\mathrm{O\\ III}]}}\\right)^2 }\n",
    "$$\n",
    "\n",
    "We only correct for extinction in the milky way. therefor we use the extinction function from Cardelli, Clayton & Mathis (1989) with $A_V = 0.2$ and $R_V=3.1$. The extinction is calculated with the following package\n",
    "\n",
    "https://extinction.readthedocs.io/en/latest/\n",
    "\n",
    "(Note: the DAP products are already extinction corrected).\n",
    "\n",
    "**Requires**\n",
    " * `extinction` a python package to account for the extinction in the Milky Way.\n",
    " * `measure_flux` from `pymuse.photometry`\n",
    " \n",
    "**Returns**\n",
    " * `flux` a Table with the measured line fluxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.coordinates import match_coordinates_sky # match sources against existing catalog\n",
    "from astropy.coordinates import Angle                 # work with angles (e.g. 1°2′3″)\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "from extinction import ccm89     # calculate extinction Cardelli et al. (1989)\n",
    "\n",
    "from pymuse.photometry import measure_flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = galaxy.alpha\n",
    "\n",
    "flux = measure_flux(galaxy,sources,alpha,aperture_size=2.,background='local')\n",
    "\n",
    "#calculate astronomical coordinates for comparison\n",
    "flux['SkyCoord'] = SkyCoord.from_pixel(flux['x'],flux['y'],galaxy.wcs)\n",
    "\n",
    "# calculate magnitudes from measured fluxes\n",
    "flux['mOIII'] = -2.5*np.log10(flux['OIII5006']*1e-20) - 13.74\n",
    "flux['dmOIII'] = np.abs( 2.5/np.log(10) * flux['OIII5006_err'] / flux['OIII5006'] )\n",
    "\n",
    "# correct for milky way extinction\n",
    "extinction = ccm89(wave=np.array([5007.]),a_v=0.2,r_v=3.1,unit='aa')[0]\n",
    "flux['mOIII'] -= extinction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Compare to Kreckel et al. 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from astropy.coordinates import match_coordinates_sky # match sources against existing catalog\n",
    "from astropy.coordinates import Angle                 # work with angles (e.g. 1°2′3″)\n",
    "from astropy.table import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ID, angle, Quantity  = match_coordinates_sky(pn_bright['SkyCoord'],flux['SkyCoord'])\n",
    "\n",
    "# for each object from Kreckel et al. 2017, we search for the nearest source\n",
    "# and copy our measured quantities to compare the two\n",
    "pn_bright['mOIII_measured']  = flux[ID]['mOIII']\n",
    "pn_bright['dmOIII_measured'] = flux[ID]['dmOIII']\n",
    "pn_bright['sep'] = angle\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(7,7))\n",
    "\n",
    "# we only use sources when their position agrees within this tolerance\n",
    "tolerance = '0.5\"'\n",
    "\n",
    "# calculate the difference in magnitude for those objects\n",
    "dif = np.mean(np.abs(pn_bright[angle<Angle(tolerance)]['mOIII'] - pn_bright[angle<Angle(tolerance)]['mOIII_measured']))\n",
    "\n",
    "print(f'{len(pn_bright[angle<Angle(tolerance)])} PN match within {tolerance}')\n",
    "print(f'the mean deviation is {dif:.3f} dex')\n",
    "\n",
    "ax.errorbar(pn_bright[angle<Angle(tolerance)]['mOIII'],\n",
    "            pn_bright[angle<Angle(tolerance)]['mOIII_measured'],\n",
    "            yerr=pn_bright[angle<Angle(tolerance)]['dmOIII_measured'],\n",
    "            fmt='o')\n",
    "\n",
    "ax.scatter(pn_bright[angle>Angle(tolerance)]['mOIII'],pn_bright[angle>Angle(tolerance)]['mOIII'],color='tab:orange')\n",
    "\n",
    "ax.plot([25.5,27.5],[25.5,27.5],color='black',lw=0.4)\n",
    "ax.plot([25.5,27.5],[25.,27.],color='black',lw=0.2,ls='--')\n",
    "ax.plot([25.5,27.5],[26.,28.],color='black',lw=0.2,ls='--')\n",
    "ax.set_xlabel(r'$\\mathrm{m}_{[\\mathrm{OIII}]}$ Kreckel et al. 2017',fontsize=16)\n",
    "ax.set_ylabel(r'$\\mathrm{m}_{[\\mathrm{OIII}]}$ this work',fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pymuse.plot.plot import single_cutout\n",
    "x,y=pn_kreckel[np.argmax(pn_kreckel['mOIII'])]['SkyCoord'].to_pixel(wcs=galaxy.wcs)\n",
    "\n",
    "single_cutout(galaxy,'OIII5006_DAP',x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "while the OIII magnitudes agree fairly well, we see a huge discrepancy in the H$\\alpha$ fluxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "table = hstack([pn_bright,flux[ID]])\n",
    "\n",
    "for col in ['OIII5006','HA6562','SII6716','NII6583']:\n",
    "    table[col][table[col]<0] = table[f'{col}_err'][table[col]<0] \n",
    "    \n",
    "table['OIII/Ha_measured'] = table['OIII5006'] / table['HA6562']\n",
    "table['Ha/SII_measured'] = table['HA6562'] / table['SII6716']\n",
    "table['Ha/NII_measured'] = table['HA6562'] / table['NII6583']\n",
    "\n",
    "    \n",
    "# print all relevant columns\n",
    "table[table['sep']<Angle('0.5s')][['mOIII_1','mOIII_2','OIII/Ha','OIII/Ha_measured','Ha/SII','Ha/SII_measured','Ha/NII','Ha/NII_measured']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(tbl['HA6562_apbkg'],tbl['HA6562']/tbl['HA6562_err'])\n",
    "plt.xlabel(r'$\\mathrm{H}\\alpha$ Background',fontsize=16)\n",
    "plt.ylabel(r'$\\mathrm{H}\\alpha / \\mathrm{H}\\alpha_\\mathrm{err}$',fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(tbl['HA6562_apbkg'],tbl['HA6562']/tbl['HA6562_apbkg'])\n",
    "plt.xlabel(r'$\\mathrm{H}\\alpha$ Background',fontsize=16)\n",
    "plt.ylabel(r'$\\mathrm{H}\\alpha / \\mathrm{H}\\alpha_\\mathrm{err}$',fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.sum(tbl['HA6562']/tbl['HA6562_err']<3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emission line diagnostics\n",
    "\n",
    "We built a catalgoue of possible planetary nebula and measuerd different emission lines. However this catalogue still contains objects that are similar to PN like HII regions or supernova remenants (SNR). In this next step we use emission line diagnostics to eliminate those contanimations. The distance modulus $\\mu$ is defined as the difference between the apparent and the absolute magnitude. By definition of the absolute magnitude, this relates to the distance $d$ in parsec as \n",
    "$$\n",
    "\\begin{align}\n",
    "\\mu = m - M \\\\\n",
    "d = 10^{1+\\frac{\\mu}{5}}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    " 1. filter out HII regions\n",
    "    $$\n",
    "     4 > \\log_{10} \\frac{[\\mathrm{OIII}]}{\\mathrm{H}\\alpha +[\\mathrm{NII}]} > -0.37 M_{[\\mathrm{OIII}]} - 1.16\n",
    "    $$\n",
    " 2. filter out SNR\n",
    "    $$\n",
    "     \\mathrm{H}\\alpha / [\\mathrm{SII}] < 2.5\n",
    "    $$\n",
    "    \n",
    " 3. estimate completness limit and remove fainter sources\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymuse.analyse import emission_line_diagnostics\n",
    "    \n",
    "tbl = emission_line_diagnostics(flux,29.91,27.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = basedir / 'reports' / 'catalogues' / f'pn_candidates_{NGC628.name}.txt'\n",
    "with open(filename,'w',newline='\\n') as f:\n",
    "    tbl['RaDec'] = tbl['SkyCoord'].to_string(style='hmsdms',precision=2)\n",
    "    for col in tbl.colnames:\n",
    "        if col not in ['id','RaDec','type']:\n",
    "            tbl[col].info.format = '%.3f' \n",
    "    ascii.write(tbl[['id','type','x','y','RaDec','OIII5006','OIII5006_err','mOIII','dmOIII','HA6562','HA6562_err',\n",
    "                          'NII6583','NII6583_err','SII6716','SII6716_err']][tbl['type']!='NaN'],\n",
    "                f,format='fixed_width',delimiter='\\t',overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Compare velocity dispersion of PN to HII-regions and SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "completeness = 27.5\n",
    "m = np.nanmean(tbl[tbl['mOIII']<completeness]['OIII5006_SIGMA'])\n",
    "print(f'all: v_sig = {m}')\n",
    "\n",
    "for t in ['PN','HII','SNR']:\n",
    "    m = np.nanmean(tbl[(tbl['type']==t) & (tbl['mOIII']<completeness)]['OIII5006_SIGMA'])\n",
    "    std = np.nanstd(tbl[(tbl['type']==t) & (tbl['mOIII']<completeness)]['OIII5006_SIGMA'])\n",
    "\n",
    "    print(f'{t}: v_sig = {m:.2f} +- {std:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the result of the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pymuse.plot.pnlf import plot_emission_line_ratio\n",
    "plot_emission_line_ratio(tbl,mu = 29.91)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from photutils import CircularAperture\n",
    "from astropy.visualization import simple_norm\n",
    "\n",
    "# ====== define input parameters =============================\n",
    "galaxy = NGC628\n",
    "labels=['SII6716','HA6562','OIII5006']\n",
    "wcs=NGC628.wcs\n",
    "# ============================================================\n",
    "\n",
    "table = tbl\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(ncols=2,figsize=(20,10),subplot_kw={'projection':wcs})\n",
    "\n",
    "norm = simple_norm(galaxy.HA6562,'linear',clip=False,max_percent=95)\n",
    "ax1.imshow(galaxy.HA6562,norm=norm,cmap=plt.cm.Greens_r)\n",
    "\n",
    "norm = simple_norm(galaxy.OIII5006_DAP,'linear',clip=False,max_percent=95)\n",
    "ax2.imshow(galaxy.OIII5006_DAP,norm=norm,cmap=plt.cm.Blues_r)\n",
    "\n",
    "for t,c in zip(['HII','SNR','PN'],['black','red','yellow']):\n",
    "    \n",
    "    sub = table[table['type']==t]\n",
    "    positions = np.transpose([sub['x'],sub['y']])\n",
    "    apertures = CircularAperture(positions, r=6)\n",
    "    apertures.plot(color=c,lw=.5, alpha=1,ax=ax1)\n",
    "    apertures.plot(color=c,lw=.5, alpha=1,ax=ax2)\n",
    "\n",
    "ax1.set_title('HA6562')\n",
    "ax2.set_title('OIII5006')\n",
    "\n",
    "plt.savefig(basedir / 'reports' / 'figures' / 'NGC628_detections_classification.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Compare classification to the results from Francesco Santoro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pymuse.detection import match_catalogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with fits.open(basedir / 'data' / 'external' / 'FS_cat_v01.fits') as hdul:\n",
    "    cat_FS = Table(hdul[1].data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Search for PNe that were classified by Francescos in my catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "del tbl['SkyCoord']\n",
    "PNe_candidates = cat_FS[(cat_FS['gal_name']=='NGC628') & (cat_FS['PNe_candidate']==1)]\n",
    "idx, sep = match_catalogues(PNe_candidates[['cen_x','cen_y']],tbl[['x','y']])\n",
    "\n",
    "max_sep = 2\n",
    "print(f'sep < {max_sep} px: {sum(sep<max_sep)/len(sep)*100:.2f} %')\n",
    "tbl[(idx)][sep<max_sep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Compare the measured fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tmp = hstack([PNe_candidates,tbl[(idx)][sep<max_sep]])\n",
    "\n",
    "tmp[['OIII5006_FLUX', 'OIII5006', 'HA6562_FLUX', 'HA6562', 'NII6583_FLUX','NII6583', 'SII6716_FLUX' ,'SII6716']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Search for HII regions that were classified by me in Francescos catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "HII_candidates = tbl[tbl['type'] == 'HII']\n",
    "catalogue = cat_FS[(~np.isnan(cat_FS['cen_x'])) & (~np.isnan(cat_FS['cen_y'])) & (cat_FS['gal_name']=='NGC628')]\n",
    "idx, sep = match_catalogues(HII_candidates[['x','y']],catalogue[['cen_x','cen_y']])\n",
    "\n",
    "max_sep = 2\n",
    "print(f'sep < 1 px: {sum(sep<1)/len(sep)*100:.2f} %')\n",
    "catalogue[idx][sep<max_sep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planetary nebula luminosity function\n",
    "\n",
    "The absolute magnitude of PN is described by (this is an empirical relation)\n",
    "$$ \n",
    "\\begin{align}\n",
    "N(M) &\\propto e^{0.307 M} \\left( 1- e^{3(M^*-M)} \\right) \\\\\n",
    "&\\propto e^{0.307 (m-\\mu)} \\left( 1- e^{3(M^*-m+\\mu)} \\right) \\\\\n",
    "&\\propto e^{0.307 (m-\\mu)} - e^{3M^*-2.693(m-\\mu)} \n",
    "\\end{align}\n",
    "$$\n",
    "To use this function in our Maximum Likelihood we need to normalize it. The indefinite integral is\n",
    "$$\n",
    "\\begin{align}\n",
    "\\int N(m)\\; \\mathrm{d} m \\propto \\frac{e^{0.307(m-\\mu)}}{0.307} + \\frac{e^{3M^* - 2.693(m-\\mu)}}{2.693}\n",
    "\\end{align}\n",
    "$$\n",
    "The luminosity function has a root when $M^* - m + \\mu =0$. We use this for the lower bound normalization. For the upper bound we use the luminosity for which we are confindent to detect all sources (=completeness limit).\n",
    "\n",
    "We can already use the normalized luminosity function for the maximum likelihood fitting. However we cannot really illustrate the result. To do this we need to introduce some binning. Then we can show the fit similar to a curve fit. Because we sum the PN in the bins, we don't plot the luminosity function but the integrated function. \n",
    "\n",
    "### With maximum likelihood\n",
    "\n",
    "**Note**: the function which is used for the likelihood must be normalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior(mu):\n",
    "    mu0 = 29.91\n",
    "    std = 0.5\n",
    "    \n",
    "    return 1 / (std*np.sqrt(2*np.pi)) * np.exp(-(mu-mu0)**2 / (2*std**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymuse.analyse import MaximumLikelihood, PNLF, pnlf\n",
    "\n",
    "completeness = 29.5\n",
    "\n",
    "criteria = ((tbl['type']=='PN'))\n",
    "data = tbl[np.where(criteria & (tbl['mOIII']<completeness))]['mOIII']\n",
    "err  = tbl[np.where(criteria & (tbl['mOIII']<completeness))]['dmOIII']\n",
    "#data = data[data>27]\n",
    "fitter = MaximumLikelihood(pnlf,\n",
    "                           data,\n",
    "                           prior=prior,\n",
    "                           mhigh=completeness)\n",
    "\n",
    "# a good guess would be mu_guess = min(data)-Mmax\n",
    "mu = fitter([28])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the fit\n",
    "\n",
    "to plot the fit we need to bin the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymuse.plot.pnlf import plot_pnlf\n",
    "filename = basedir / 'reports' / 'figures' / f'{galaxy.name}_PNLF'\n",
    "\n",
    "plot_pnlf(tbl[criteria]['mOIII'],mu,completeness,binsize=0.25,mhigh=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize as op\n",
    "from pymuse.analyse import F\n",
    "\n",
    "def f(mu,m,mhigh,Mmax):\n",
    "    mlow = Mmax + mu\n",
    "    normalization =  (np.exp(0.307*mu)*(np.exp(0.307*mlow)-np.exp(0.307*mhigh)) + np.exp(2.693*mu)*(np.exp(3*Mmax-2.693*mhigh)-np.exp(3*Mmax-2.693*mlow))) / (F(mhigh,mu)-F(mlow,mu))\n",
    "    like = 0.307*len(m)*mu+np.sum(3/(np.exp(-3*(Mmax-m+mu))-1))\n",
    "\n",
    "    return normalization + like\n",
    "\n",
    "op.newton(f,x0=29,args=(data,29,-4.47))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contaminate(tbl,percent):\n",
    "    \n",
    "    true  = np.where(tbl['type']=='PN')[0]\n",
    "    false = np.where(tbl['type']=='SNR')[0]\n",
    "    \n",
    "    false = np.random.choice(false,int(len(true)*percent),replace=False)\n",
    "    np.concatenate(true,false,out=true)\n",
    "\n",
    "    return tbl[true]\n",
    "\n",
    "contaminate(tbl,0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With data from Kreckel et al. 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter = MaximumLikelihood(pnlf,pn_bright['mOIII'],mhigh=27)\n",
    "mu = fitter([25])[0]\n",
    "plot_pnlf(pn_kreckel['mOIII'],mu=29.91,completeness=27,binsize=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### With least square  fitting\n",
    "\n",
    " - to use a least square approach we need to bin the data. \n",
    " + easier to implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def pnlf(m,mu,N0):\n",
    "    '''planetary nebula luminosity function for curve_fit\n",
    "    \n",
    "    N(m) ~ e^0.307(m-mu) * (1-e^3(Mmax-m+mu))\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    m : ndarray\n",
    "        apparent magnitudes of the PNs\n",
    "        \n",
    "    mu : float\n",
    "        distance modulus\n",
    "        \n",
    "    N0 : float\n",
    "    '''\n",
    "    \n",
    "    m = np.atleast_1d(m)\n",
    "    \n",
    "    Mmax = -4.47\n",
    "    completneness = 28\n",
    "    normalization = -3.62866*np.exp(0.307*Mmax) + 3.25733*np.exp(0.307*completneness-0.307*mu) + 0.371333 * np.exp(3*Mmax - 2.693 * completneness + 2.693 * mu)\n",
    "    \n",
    "    out = N0*np.exp(0.307*(m-mu)) * (1-np.exp(3*(Mmax-m+mu))) / normalization\n",
    "    out[m>completneness] = 0\n",
    "    out[m<Mmax+mu] = 0\n",
    "    \n",
    "    return out\n",
    "\n",
    "def fit_pnlf(table):\n",
    "    \n",
    "    #table = table[table['type']=='PN']\n",
    "    \n",
    "    binsize = 0.2\n",
    "\n",
    "    guess = np.array([25,10])\n",
    "    \n",
    "    mlow = np.floor(np.min(table))\n",
    "    mhigh = np.ceil(np.max(table))\n",
    "    hist,bins  = np.histogram(table,np.arange(mlow,mhigh,binsize))\n",
    "    \n",
    "    \n",
    "    fit,sig = curve_fit(pnlf, bins[1:]+binsize/2,hist , guess)\n",
    "    mu, N0 = fit\n",
    "    print(f'mu={mu:.3f}, N0={N0:.2f}')\n",
    "    \n",
    "    fig, (ax1,ax2) = plt.subplots(1,2,figsize=(8,4))\n",
    "    \n",
    "    ax1.scatter(bins[:-1]+binsize/2,hist)\n",
    "    ax1.plot(bins[:-1]+binsize/2,pnlf(bins[:-1]+0.1,mu=mu,N0=N0),c='tab:orange',ls='--')\n",
    "    ax1.set_yscale('log')\n",
    "    ax1.set_xlim([25,28])\n",
    "    ax1.set_ylim([0.8,1.1*np.max(hist)])\n",
    "    ax1.set_xlabel('$m_{[\\mathrm{OIII}]}$')\n",
    "    ax1.set_ylabel('$N$')\n",
    "    \n",
    "    ax2.plot(bins[1:]+binsize/2,np.cumsum(hist))\n",
    "    ax2.plot(bins[1:]+binsize/2,np.cumsum(pnlf(bins[:-1]+binsize/2,mu=mu,N0=N0)),ls='--')\n",
    "    ax2.set_xlim([mlow,mhigh])\n",
    "    ax2.set_ylim([0,len(table)])\n",
    "    ax2.set_xlabel('$m_{[\\mathrm{OIII}]}$')\n",
    "    ax2.set_ylabel('Cumulative N')\n",
    "    \n",
    "fit_pnlf(tbl[tbl['type']=='PN']['mOIII'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance in parsec\n",
    "\n",
    "the measured distances are in the form of the distance modulus $\\mu = m-M$ which is the difference between apparent and absolute magnitude. By defintion of the absolte magnitude, we can convert this number into a distance in pc\n",
    "$$\n",
    "d = 10^{\\frac{\\mu}{5}+1} = 10 \\cdot \\exp\\left( \\ln 10 \\frac{\\mu}{5} \\right) \\\\\n",
    "\\delta d = \\frac{\\ln 10}{5} 10 \\exp\\left( \\ln 10 \\frac{\\mu}{5} \\right) \\delta \\mu = 0.2 \\ln 10 \\; d \\; \\delta \\mu\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_modulus_to_parsec(mu,mu_err=np.array([])):\n",
    "    \n",
    "    d = 10 * np.exp(np.log(10)*mu/5)\n",
    "    if len(mu_err) > 0:\n",
    "        d_err = 0.2 * np.log(10) * d * mu_err\n",
    "    print(f'd = ({d/1e6:.2f} + {d_err[0]/1e6:.2f} - {d_err[1]/1e6:.2f}) Mpc')\n",
    "    \n",
    "    return d, d_err\n",
    "\n",
    "d,d_err = distance_modulus_to_parsec(30.033,np.array([0.014,0.015]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with fits.open(data_raw / 'NGC628' / 'NGC628_star_mask.fits') as hdul:\n",
    "    star_mask =hdul[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymuse.plot import create_RGB\n",
    "\n",
    "# ====== define input parameters =============================\n",
    "rgb = create_RGB(NGC628.SII6716,NGC628.HA6562,NGC628.OIII5006)\n",
    "labels=['SII6716','HA6562','OIII5006']\n",
    "wcs=NGC628.wcs\n",
    "# ============================================================\n",
    "\n",
    "# create an empty figure with correct projection\n",
    "fig, ax = plt.subplots(figsize=(20,20),subplot_kw={'projection':wcs})\n",
    "\n",
    "# plot the image\n",
    "plt.imshow(rgb,origin='lower')\n",
    "\n",
    "# create a legend\n",
    "if labels:\n",
    "    # first we create a legend with three invisible handles\n",
    "    handles = 3*[mpl.patches.Rectangle((0, 0), 0, 0, alpha=0.0)]\n",
    "    leg = ax.legend(handles,labels, frameon=False,handlelength=0,prop={'size': 16})\n",
    "\n",
    "    # next we set the color of the three labels\n",
    "    for color,text in zip(['red','green','blue'],leg.get_texts()):\n",
    "        text.set_color(color)\n",
    "\n",
    "plt.savefig(basedir / 'reports' / 'figures' / f'{NGC628.name}_rgb.pdf')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "360px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
