{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planetary Nebula <a class=\"tocSkip\">\n",
    "    \n",
    "This notebook is used to test and showcase the results of my first project. I use spectroscopic data from the [Multi Unit Spectroscopic Explorer](https://www.eso.org/sci/facilities/develop/instruments/muse.html) (MUSE) that has been observed as part of the [PHANGS](https://sites.google.com/view/phangs/home) collaboration.\n",
    "    \n",
    "I will use a set of line maps of emission lines to identify Planetary Nebula in the data an measure their brightness. This can then be used to fit an empiric relation and hence measure the distance to the galaxy.\n",
    "    \n",
    "This notebook is used for developement. Final code is moved to the `pymuse` packge in the `src` folder. Any production scripts reside in the `scripts` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    " \n",
    "### Load Basic Packages\n",
    "    \n",
    "First we load a bunch of common packages that are used across the project. More specific packages that are only used in one section are loaded later to make it clear where they belong to (this also applies to all custom moduls that were written for this project)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload modules after they have been modified\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# some basic packages\n",
    "import os                 # filesystem related stuff\n",
    "from pathlib import Path  # use instead of os.path and glob\n",
    "import sys                # mostly replaced by pathlib\n",
    "\n",
    "import errno      # more detailed error messages\n",
    "import warnings   # handles warnings\n",
    "import logging    # use logging instead of print\n",
    "\n",
    "from collections import OrderedDict  \n",
    "\n",
    "# packages for scientific computing\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "# packages for creating plots and figures\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# special functions for astronomy \n",
    "from astropy.table import Table  # useful datastructure\n",
    "from astropy.table import vstack # combine multiple tables\n",
    "\n",
    "from astropy.io import fits      # open fits files\n",
    "from astropy.io import ascii     # handle normal files\n",
    "\n",
    "from astropy.wcs import WCS               # handle coordinates\n",
    "from astropy.coordinates import SkyCoord  # convert pixel to sky coordinates\n",
    "\n",
    "from astropy.stats import sigma_clipped_stats  # calcualte statistics of images\n",
    "\n",
    "import astropy.units as u        # handle units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we use the `logging` module to handle informations and warnings (this does not always work as expected in jupyter notebooks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout,\n",
    "                    #format='(levelname)s %(name)s %(message)s',\n",
    "                    datefmt='%H:%M:%S',\n",
    "                    level=logging.INFO)\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference files\n",
    "\n",
    "To test the newly written routines we compare our results to those from Kreckel et al. (2017)\n",
    "\n",
    "**Requires** (both already loaded with standard packages)\n",
    " * `astropy.io.ascii`\n",
    " * `astropy.coordinates.SkyCoord`\n",
    " \n",
    "**Returns**\n",
    " * `pn_kreckel` table with all PNe detected by Kreckel et al. (2017)\n",
    " * `pn_bright` only PNe that are brighter than the completeness limit\n",
    " * `pn_hermann` only PNe that were also detected by Hermann et al. 2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn_kreckel = ascii.read(os.path.join('..','data','external','kreckel_pn_2017.txt'))\n",
    "\n",
    "def string_to_ra(string):\n",
    "    '''convert coordinates from Kreckel et al. (2017) to astropy\n",
    "    \n",
    "    the right ascension in the paper is given as \n",
    "    \"01:36:42.212\" but astropy requires \"01h36m42.212s\".\n",
    "    This function replaces the \":\" with the appropriate character.\n",
    "    '''\n",
    "    return string.replace(':','h',1).replace(':','m') + 's'\n",
    "\n",
    "def string_to_dec(string):\n",
    "    '''convert coordinates from Kreckel et al. (2017) to astropy\n",
    "    \n",
    "    the declination in the paper is given as \"01:36:42.212\" \n",
    "    but astropy requires \"01d36m42.212s\".\n",
    "    This function replaces the \":\" with the appropriate character.\n",
    "    '''\n",
    "    return string.replace(':','d',1).replace(':','m') + 's'\n",
    "\n",
    "# convert string to astronomical coordinates\n",
    "pn_kreckel['RA'] = list(map(string_to_ra,pn_kreckel['RA']))\n",
    "pn_kreckel['DEC'] = list(map(string_to_dec,pn_kreckel['DEC']))\n",
    "pn_kreckel['SkyCoord'] = SkyCoord(pn_kreckel['RA'],pn_kreckel['DEC'])\n",
    "\n",
    "# select some subsets (PN from Hermann et al. 2008 or bright sources only)\n",
    "pn_herrmann = pn_kreckel[[True if i.endswith('a') else False for i in pn_kreckel['ID']]]\n",
    "pn_bright = pn_kreckel[pn_kreckel['mOIII']<27]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data\n",
    "\n",
    "this uses the `ReadLineMaps` class from the `pymuse.io` module. To use it, we first need to specify the path to the data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymuse.io import ReadLineMaps\n",
    "\n",
    "# first we need to specify the path to the raw data\n",
    "data_raw = Path('d:\\downloads\\MUSEDAP')\n",
    "\n",
    "# list all files in the specified directory\n",
    "galaxies = [x.name for x in data_raw.iterdir() if x.is_dir()]\n",
    "#print(', '.join(map(str,galaxies)))\n",
    "\n",
    "# read in the data we will be working with and print some information\n",
    "NGC628 = ReadLineMaps(data_raw / 'NGC628')\n",
    "print(NGC628)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Detection\n",
    "\n",
    "There are two different approaches to identifying sources in an image. The first utilizes PSF fitting and uses implementations from astropy. The other uses the external `SExtractor` package which detects peaks and classifies them with a neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on IRAFStarFinder or DAPStarFinder\n",
    "\n",
    "The sources we are searching for are unresolved. However due to seeing, they will be smeared out. This PSF has the form of a Gaussian (or Moffat). The subsequent algorithms use this and try to fit a theoretical curve to the observed peaks in the image. If the fit aggrees within some threshold, it reports the peak as a source. The advantage is that for crowded fields, the algorithm will try to fit an individual function to each peak and thus enable us correctly identfiy objects that are closeby.\n",
    "\n",
    "The following function is based on this tutorial \n",
    "\n",
    "https://photutils.readthedocs.io/en/stable/detection.html\n",
    "\n",
    "https://photutils.readthedocs.io/en/stable/api/photutils.detection.DAOStarFinder.html#photutils.detection.DAOStarFinder\n",
    "\n",
    "**Requires**\n",
    " * A `photutils` starfinder. This can be either `DAOStarFinder` or `IRAFStarFinder`\n",
    " * `detect_unresolved_sources`\n",
    " \n",
    "**Returns**\n",
    " * `sources` a table with the position of all identified sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from photutils import DAOStarFinder            # DAOFIND routine to detect sources\n",
    "from photutils import IRAFStarFinder           # IRAF starfind routine to detect star\n",
    "\n",
    "from pymuse.detection import detect_unresolved_sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = detect_unresolved_sources(NGC628,\n",
    "                                    'OIII5006',\n",
    "                                    StarFinder=DAOStarFinder,\n",
    "                                    threshold=10,\n",
    "                                    PSF_size = 1.3,\n",
    "                                    save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare to Kreckel et al. 2017\n",
    "\n",
    "As mentioned in the beginning, we compare the newly detected sources to those from Kreckel et al. (2017). \n",
    "\n",
    "**Requires**\n",
    " * `match_coordinates_sky` from `astropy.coordinates` to compare the two catalogues.\n",
    " * `Angle` from `astropy.coordinates` to set a maximum seperation in units of arcseconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.coordinates import match_coordinates_sky # match sources against existing catalog\n",
    "from astropy.coordinates import Angle                 # work with angles (e.g. 1°2′3″)\n",
    "\n",
    "\n",
    "tolerance = '0.5s'\n",
    "ID, angle, Quantity  = match_coordinates_sky(pn_bright['SkyCoord'],sources['SkyCoord'])\n",
    "within_tolerance = len(angle[angle.__lt__(Angle(tolerance))])\n",
    "\n",
    "print(f'{within_tolerance} of {len(angle)} match within {tolerance}\": {within_tolerance / len(angle)*100:.1f} %')\n",
    "print(f'mean seperation is {angle.mean().to_string(u.arcsec,decimal=True)}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Plot detected sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pymuse.plot import plot_sky_with_detected_stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "position = np.transpose((sources['x'], sources['y']))\n",
    "positions_kk = np.transpose(pn_bright['SkyCoord'].to_pixel(wcs=NGC628.wcs))\n",
    "positions = (position,positions_kk)\n",
    "\n",
    "save_file = Path.cwd() / '..' / 'reports' / 'figures' / f'{NGC628.name}_sky_sources_DAO.pdf'\n",
    "plot_sky_with_detected_stars(data=NGC628.OIII5006_old,\n",
    "                             wcs=NGC628.wcs,\n",
    "                             positions=positions,\n",
    "                             filename=save_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Cut out detected stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pymuse.plot import sample_cutouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_file = Path.cwd() / '..' / 'reports' / 'figures' / f'{NGC628.name}_stars.pdf'\n",
    "\n",
    "stars = sample_cutouts(NGC628.OIII5006_old,sources,NGC628.wcs,nrows=4,ncols=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Using SExtractor\n",
    "\n",
    "there is no Python implementation of SExtractor. Instead we run it from the command line\n",
    "\n",
    "```\n",
    "sextractor file.fits -c default.sex\n",
    "```\n",
    "\n",
    "this will produce a file `test.cat` which contains the position of the sources. We read this table and calculate the sky position wiht astropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "file = Path.cwd() / '..' / 'data' / 'interim' / 'NGC628.cat'\n",
    "\n",
    "table = ascii.read(file)\n",
    "table['SkyCoord'] = SkyCoord.from_pixel(table['X_IMAGE'],table['Y_IMAGE'],NGC628.wcs)\n",
    "\n",
    "print(f'{len(table)} sources found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sources = Table()\n",
    "sources['x'] = table['X_IMAGE']\n",
    "sources['y'] = table['Y_IMAGE']\n",
    "sources['SkyCoord'] = table['SkyCoord']\n",
    "sources['fwhm'] = 0.8\n",
    "NGC628.sources = sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Match with known sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ID, angle, Quantity  = match_coordinates_sky(pn_bright['SkyCoord'],table['SkyCoord'])\n",
    "within_1_arcsec = len(angle[angle.__lt__(Angle(\"0.5s\"))])\n",
    "\n",
    "print(f'{within_1_arcsec} of {len(angle)} match within 0.5\": {within_1_arcsec / len(angle)*100:.1f} %')\n",
    "print(f'mean seperation is {angle.mean().to_string(u.arcsec,decimal=True)}\"')\n",
    "#print(f'mean angle: {angle.mean():.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Plot detected sources\n",
    "\n",
    "this requires the previously loaded `plot_sources` from `pymuse.plot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "file = Path.cwd() / '..' / 'reports' / 'figures' / f'{NGC628.name}_sources_sextractor.pdf'\n",
    "\n",
    "position = np.transpose((sources['x'], sources['y']))\n",
    "references = np.transpose(pn_bright['SkyCoord'].to_pixel(wcs=NGC628.wcs))\n",
    "positions = (position,references)\n",
    "\n",
    "sky_with_detected_stars(data=NGC628.OIII5006_old,wcs=NGC628.wcs,positions=positions,filename=file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completeness limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymuse.detection import completeness_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_sources = completeness_limit(\n",
    "                   NGC628,\n",
    "                   'OIII5006',\n",
    "                   DAOStarFinder,\n",
    "                   threshold=5,\n",
    "                   iterations=10,\n",
    "                   oversize_PSF=1.\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_sources = completeness_limit(\n",
    "                   NGC628,\n",
    "                   'OIII5006',\n",
    "                   DAOStarFinder,\n",
    "                   threshold=8,\n",
    "                   iterations=1,\n",
    "                   oversize_PSF=1.\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flux measurement\n",
    "\n",
    "In the previous step we detected potential PN candidates by their [OIII] emission. This means we know their position but lack exact flux measurments. In this section we measure the flux of the identified objects in different emission lines that are used in later steps. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Growth curve analysis\n",
    "\n",
    "for the PSF we assume a 2D gaussian that is centered around the origin and has a variance of $\\sigma_x^2 = \\sigma_y^2 = \\sigma^2$ and an amplitude of $A$\n",
    "$$\n",
    "f(x,y) = A \\exp\\left(-\\frac{x^2+y^2}{2\\sigma^2}\\right)\n",
    "$$\n",
    "we can rewrite this in polar coordinates as \n",
    "$$\n",
    "f(r,\\phi) = A \\exp\\left(-\\frac{r^2}{2\\sigma^2}\\right)\n",
    "$$\n",
    "The light inside an aperture of radius $P(R)$ is given by the integral\n",
    "$$\n",
    "P(R) = \\int_0^{2\\pi} \\int_0^R f(r,\\phi) \\mathrm{d} \\phi r \\mathrm{d} r = 2\\pi \\sigma^2 A \\left(1-\\exp \\left(-\\frac{R^2}{2\\sigma^2}\\right) \\right) \n",
    "$$\n",
    "We are interested in the ratio $p(R) = P(R) / P(\\infty)$. If we use the relation between the standard deviation and the $\\mathrm{FWHM}$ of a Gaussian $\\sigma = \\frac{\\mathrm{FWHM}}{2\\sqrt{2\\ln2}}=$, we can write\n",
    "$$\n",
    "\\begin{align}\n",
    "p(R) = 1-\\exp\\left(- \\frac{4 \\ln 2 \\cdot R^2}{\\mathrm{fwhm}^2} \\right)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def light_in_aperture(radius,fwhm):\n",
    "    '''\n",
    "    p(r) = 1 - e^(-4 ln2 r^2/fwhm^2)\n",
    "    \n",
    "    Given a circular aperture with the specified radius, this function\n",
    "    calculates the fraction of light inside the aperture if the \n",
    "    underlying distribution is a 2D gaussian with the specified fwhm.     \n",
    "    '''\n",
    "    \n",
    "    return 1-np.exp(- 4*np.log(2)*radius**2 / fwhm**2)\n",
    "\n",
    "d = np.linspace(0.5,4)\n",
    "p = light_in_aperture(d/2,1)\n",
    "plt.plot(d,100*p)\n",
    "plt.xlabel('diameter in fwhm')\n",
    "plt.ylabel('light in aperture in %')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "the previous calculation is based on two assumptions:\n",
    " 1. The PSF has the shape of a 2D Gaussian\n",
    " 2. We know the $\\mathrm{FWHM}$ of said PSF\n",
    " \n",
    "to validate those assumptions, we measure the flux as a function of aperture radius for different sources to check if if the shape is a Gaussian and to measure the real value of the $\\mathrm{FWHM}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pymuse.plot import single_cutout\n",
    "from pymuse.photometry import growth_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# we cannot sort a Table that has a SkyCoord object as a column\n",
    "del sources['SkyCoord']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# sort by brightness and select only sources from one pointing\n",
    "sources.sort('peak',reverse=True)\n",
    "PSF_fwhm = np.unique(sources['fwhm'])\n",
    "sub = sources[(sources['fwhm']==PSF_fwhm[2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# select one of the bright sources and take a look at it\n",
    "i = 3\n",
    "x,y = sub[i][['x','y']]\n",
    "guess=sub[i]['fwhm']\n",
    "single_cutout(NGC628,'whitelight',x,y)\n",
    "sub[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = NGC628.whitelight\n",
    "\n",
    "# this requires the next cell\n",
    "fit,sig = growth_curve(data,x,y,guess=0.8*guess,plot=True)\n",
    "print(f'reported={guess:.2f}, measured={fit[0]:.2f}, ratio={fit[0]/guess:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aperture Photometry\n",
    "\n",
    "we use the positions of the previously detected sources to measure the flux of different lines\n",
    "\n",
    "https://photutils.readthedocs.io/en/stable/aperture.html\n",
    "\n",
    "the values in the pixels are in units of $10^{-20} \\ \\mathrm{erg}  \\ \\mathrm{cm}^{-2} \\ \\mathrm{s}^{-1} / \\mathrm{spaxel}$. For the [OIII] line, this flux is then converted to an apparent magnitude\n",
    "$$\n",
    "m_{[\\mathrm{O\\ III}]} = -2.5 \\cdot \\log F_{[\\mathrm{O\\ III}]} - 13.74\n",
    "$$\n",
    "\n",
    "where $F_{[\\mathrm{O\\ III}]}$ is given in $\\mathrm{erg}  \\ \\mathrm{cm}^{-2} \\ \\mathrm{s}^{-1}$. Error propagation gives the error of the magnitude as\n",
    "\n",
    "$$\n",
    "\\Delta m_{[\\mathrm{O\\ III}]} = \\sqrt{\\left(\\frac{-2.5 \\cdot \\Delta F_{[\\mathrm{O\\ III}]}}{\\ln 10 \\cdot F_{[\\mathrm{O\\ III}]}}\\right)^2 }\n",
    "$$\n",
    "\n",
    "We only correct for extinction in the milky way. therefor we use the extinction function from Cardelli, Clayton & Mathis (1989) with $A_V = 0.2$ and $R_V=3.1$. The extinction is calculated with the following package\n",
    "\n",
    "https://extinction.readthedocs.io/en/latest/\n",
    "\n",
    "(Note: the DAP products are already extinction corrected).\n",
    "\n",
    "**Requires**\n",
    " * `extinction` a python package to account for the extinction in the Milky Way.\n",
    " * `measure_flux` from `pymuse.photometry`\n",
    " \n",
    "**Returns**\n",
    " * `flux` a Table with the measured line fluxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.coordinates import match_coordinates_sky # match sources against existing catalog\n",
    "from astropy.coordinates import Angle                 # work with angles (e.g. 1°2′3″)\n",
    "\n",
    "from extinction import ccm89     # calculate extinction Cardelli et al. (1989)\n",
    "\n",
    "from pymuse.photometry import measure_flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NGC628.lines.append('OIII5006_DAP')\n",
    "flux = measure_flux(NGC628,aperture_size=3)\n",
    "\n",
    "extinction = ccm89(wave=np.array([5007.]),a_v=0.2,r_v=3.1,unit='aa')[0]\n",
    "flux['mOIII'] -= extinction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare to Kreckel et al. 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.coordinates import match_coordinates_sky # match sources against existing catalog\n",
    "from astropy.coordinates import Angle                 # work with angles (e.g. 1°2′3″)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID, angle, Quantity  = match_coordinates_sky(pn_bright['SkyCoord'],flux['SkyCoord'])\n",
    "\n",
    "# for each object from Kreckel et al. 2017, we search for the nearest source\n",
    "# and copy our measured quantities to compare the two\n",
    "pn_bright['mOIII_measured']  = flux[ID]['mOIII']\n",
    "pn_bright['dmOIII_measured'] = flux[ID]['dmOIII']\n",
    "pn_bright['sep'] = angle\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(7,7))\n",
    "\n",
    "# we only use sources when their position agrees within this tolerance\n",
    "tolerance = '0.4\"'\n",
    "\n",
    "# calculate the difference in magnitude for those objects\n",
    "dif = np.mean(np.abs(pn_bright[angle<Angle(tolerance)]['mOIII'] - pn_bright[angle<Angle(tolerance)]['mOIII_measured']))\n",
    "\n",
    "print(f'{len(pn_bright[angle<Angle(tolerance)])} PN match within {tolerance}')\n",
    "print(f'the mean deviation is {dif:.3f} dex')\n",
    "\n",
    "ax.errorbar(pn_bright[angle<Angle(tolerance)]['mOIII'],\n",
    "            pn_bright[angle<Angle(tolerance)]['mOIII_measured'],\n",
    "            yerr=pn_bright[angle<Angle(tolerance)]['dmOIII_measured'],\n",
    "            fmt='o')\n",
    "\n",
    "ax.plot([25.5,27.5],[25.5,27.5],color='black',lw=0.4)\n",
    "ax.set_xlabel(r'$\\mathrm{m}_{[\\mathrm{OIII}]}$ Kreckel et al. 2017',fontsize=16)\n",
    "ax.set_ylabel(r'$\\mathrm{m}_{[\\mathrm{OIII}]}$ new',fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emission line diagnostics\n",
    "\n",
    "We built a catalgoue of possible planetary nebula and measuerd different emission lines. However this catalogue still contains objects that are similar to PN like HII regions or supernova remenants (SNR). In this next step we use emission line diagnostics to eliminate those contanimations. The distance modulus $\\mu$ is defined as the difference between the apparent and the absolute magnitude. By definition of the absolute magnitude, this relates to the distance $d$ in parsec as \n",
    "$$\n",
    "\\begin{align}\n",
    "\\mu = m - M \\\\\n",
    "d = 10^{1+\\frac{\\mu}{5}}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    " 1. filter out HII regions\n",
    "    $$\n",
    "     4 > \\log_{10} \\frac{[\\mathrm{OIII}]}{\\mathrm{H}\\alpha +[\\mathrm{NII}]} > -0.37 M_{[\\mathrm{OIII}]} - 1.16\n",
    "    $$\n",
    " 2. filter out SNR\n",
    "    $$\n",
    "     \\mathrm{H}\\alpha / [\\mathrm{SII}] > 2.5\n",
    "    $$\n",
    "    \n",
    " 3. estimate completness limit (for now I use 28) and remove fainter sources\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def emission_line_diagnostics(table,distance_modulus,completeness_limit):\n",
    "    '''Classify sources based on emission lines \n",
    "    \n",
    "    criteria1:\n",
    "    4 > log10 [OIII] / (Ha +[NII])\n",
    "    \n",
    "    criteria2:\n",
    "    log10 [OIII] / (Ha +[NII]) > -0.37 M[OIII] - 1.16\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    table : Astropy Table\n",
    "        Table with measured fluxes \n",
    "    \n",
    "    completeness_limit : float\n",
    "        Sources fainter than this magnitude are ignored\n",
    "        \n",
    "    distance_modulus : float \n",
    "       A first guess of the distance modulus (used for diagnostics)\n",
    "       distance_modulus = m - M\n",
    "    '''\n",
    "    \n",
    "        \n",
    "    # make sure the input is of the correct type\n",
    "    if not isinstance(table,Table):\n",
    "        raise TypeError('wrong input')\n",
    "    \n",
    "    # next we check if all columns exist\n",
    "    required = ['OIII5006','HA6562','NII6583','SII6716','mOIII']\n",
    "    missing = set(required) - set(flux.columns)\n",
    "    if missing:\n",
    "        raise KeyError(f'input table is missing {\", \".join(missing)}')\n",
    "    del missing\n",
    "       \n",
    "    #\n",
    "    # Preparation\n",
    "                       \n",
    "    # calculate the absolute magnitude based on a first estimate of the distance modulus \n",
    "    table['MOIII'] = table['mOIII'] - distance_modulus\n",
    "    # make sure that the new column can save strings with 3 characters\n",
    "    table['type'] = np.empty(len(table),dtype='U3')\n",
    "    table['type'][:] = 'PN'\n",
    "                       \n",
    "    # if the flux is smaller than the error we set it to the error\n",
    "    for line in ['OIII5006','HA6562','NII6583','SII6716']:\n",
    "        table[table[line]<table[f'{line}_err']][line] = table[table[line]<table[f'{line}_err']][f'{line}_err']\n",
    "                       \n",
    "    logger.info(f'{len(table)} entries in initial catalogue')\n",
    "             \n",
    "    # remove rows with NaN values in some columns\n",
    "    mask =  np.ones(len(table), dtype=bool)\n",
    "    for col in required:\n",
    "        mask &=  ~np.isnan(table[col])\n",
    "    table = table[mask]\n",
    "    logger.info(f'{len(mask[mask==False])} rows were removed because they contain NaN values')\n",
    "\n",
    "    mask = table['mOIII']< completeness_limit\n",
    "    table = table[mask]\n",
    "    logger.info(f'{len(mask[mask==False])} objects below the completness limit removed')    \n",
    "                       \n",
    "    table['type'][np.where(4 < np.log10(table['OIII5006'] / (table['HA6562']+table['NII6583'])))] = ''\n",
    "    table['type'][np.where(np.log10(table['OIII5006'] / (table['HA6562']+table['NII6583'])) < -0.37*table['MOIII'] - 1.16)] = 'HII'\n",
    "    table['type'][np.where(table['HA6562'] / table['SII6716'] < 2.5)] = 'SNR'\n",
    "\n",
    "    logger.info(f'{len(table[table[\"type\"]==\"HII\"])} objects classified as HII')\n",
    "    logger.info(f'{len(table[table[\"type\"]==\"\"])} objects classified as ...')\n",
    "    logger.info(f'{len(table[table[\"type\"]==\"SNR\"])} objects classified as SNR')\n",
    "    logger.info(f'{len(table[table[\"type\"]==\"PN\"])} possible planetary nebula found')\n",
    "    \n",
    "    return table\n",
    "    \n",
    "    \n",
    "tbl = emission_line_diagnostics(flux,29.91,27.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_emission_line_ratio(table):\n",
    "    \n",
    "    \n",
    "    fig, (ax1,ax2) = plt.subplots(nrows=1,ncols=2,figsize=(10,5))\n",
    "    \n",
    "    style = {'SNR':{\"marker\":'o',\"s\":30,\"edgecolors\":'tab:red',\"facecolors\":'white'},\n",
    "             'HII':{\"marker\":'+',\"s\":50,\"color\":'black'},\n",
    "             'PN':{\"marker\":'o',\"s\":30,\"color\":'black'}\n",
    "            }\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # left plot [OIII]/Ha over mOIII\n",
    "    # ------------------------------------------------\n",
    "    mOIII = np.linspace(24,29)\n",
    "    mu = 29.91\n",
    "    OIII_Ha = 10**(-0.37*(mOIII-mu)-1.16)\n",
    "    ax1.plot(mOIII,OIII_Ha,c='black',lw=0.6)\n",
    "    \n",
    "\n",
    "    for t in ['HII','SNR','PN']:\n",
    "        tbl = table[table['type']==t]\n",
    "        ax1.scatter(tbl['mOIII'],tbl['OIII5006']/(tbl['HA6562']+tbl['NII6583']),**style[t],label=t)\n",
    "    ax1.legend()\n",
    "    \n",
    "    ax1.set(xlim=[24,29],\n",
    "           ylim=[0.03,30],\n",
    "           yscale='log',\n",
    "           xlabel='m_OIII',\n",
    "           ylabel='OIII/Ha')\n",
    "    \n",
    "    ax1.yaxis.set_major_formatter(mpl.ticker.FuncFormatter(lambda y, _: '{:.16g}'.format(y)))\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # right plot Ha/[NII] over Ha/[SII]\n",
    "    # ------------------------------------------------\n",
    "    #mOIII = np.linspace(24,29)\n",
    "    #mu = 29.91\n",
    "    #OIII_Ha = 10**(-0.37*(mOIII-mu)-1.16)\n",
    "    #ax1.plot(mOIII,OIII_Ha)\n",
    "    \n",
    "    for t in ['HII','SNR','PN']:\n",
    "        tbl = table[table['type']==t]\n",
    "        ax2.scatter(np.log10(tbl['HA6562']/tbl['SII6716']),\n",
    "                    np.log10(tbl['HA6562']/tbl['NII6583']),**style[t],label=t)\n",
    "    ax2.legend()\n",
    "    \n",
    "    vert_SNR = np.array([[-0.1,-0.5],[-0.1,0.05],[0.3,0.25],[0.3,0.05],[0.1,-0.05],[0.1,-0.5]])\n",
    "    ax2.add_patch(mpl.patches.Polygon(vert_SNR,Fill=False,edgecolor='black'))\n",
    "    vert_SNR = np.array([[0.5,0.2],[0.5,0.7],[0.9,0.7],[0.9,0.2]])\n",
    "    ax2.add_patch(mpl.patches.Polygon(vert_SNR,Fill=False,edgecolor='black'))\n",
    "    ax2.plot([0.1,1.3],[-0.45,0.8],c='black',lw=0.6)\n",
    "    ax2.text(-0.1,-0.6,'SNR')\n",
    "    \n",
    "    ax2.set(xlim=[-1,1.5],\n",
    "           ylim=[-1,1],\n",
    "           #yscale='log',\n",
    "           xlabel=r'Log (H$\\alpha$ / [SII])',\n",
    "           ylabel=r'Log (H$\\alpha$ / [NII])')    \n",
    "    ax2.xaxis.set_major_locator(mpl.ticker.MultipleLocator(0.5))\n",
    "    ax2.yaxis.set_major_locator(mpl.ticker.MultipleLocator(0.5))\n",
    "    ax2.xaxis.set_minor_locator(mpl.ticker.MultipleLocator(0.1))\n",
    "    ax2.yaxis.set_minor_locator(mpl.ticker.MultipleLocator(0.1))    \n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "plot_emission_line_ratio(tbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planetary nebula luminosity function\n",
    "\n",
    "\n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "N(M) \\propto e^{0.307 M} \\left( 1- e^{3(M^*-M)} \\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "### With least square  fitting\n",
    "\n",
    " - to use a least square approach we need to bin the data. \n",
    " + easier to implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize, curve_fit\n",
    "from inspect import signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pnlf(m,mu,N0):\n",
    "    '''planetary nebula luminosity function\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        \n",
    "    m : ndarray\n",
    "        apparent magnitudes of the PNs\n",
    "        \n",
    "    mu : float\n",
    "        distance modulus\n",
    "    '''\n",
    "    \n",
    "    Mmax = -4.47\n",
    "    delta = 2.5\n",
    "    norm = np.exp(0.307*Mmax - 2.693*delta)*(0.371333 - 3.62866*np.exp(2.693*delta) + 3.25733 * np.exp(3*delta))\n",
    "    \n",
    "    return N0*np.exp(0.307*(m-mu)) * (1-np.exp(3*(Mmax-m+mu)))\n",
    "\n",
    "def fit_pnlf(table):\n",
    "    \n",
    "    #table = table[table['type']=='PN']\n",
    "    \n",
    "    binsize = 0.4\n",
    "    guess = np.array([25,10])\n",
    "    \n",
    "    mlow = np.floor(np.min(table))\n",
    "    mhigh = np.ceil(np.max(table))\n",
    "    hist,bins  = np.histogram(table,np.arange(mlow,mhigh,binsize))\n",
    "    \n",
    "    fit,sig = curve_fit(pnlf, bins[1:]+binsize/2,hist , guess)\n",
    "    mu, N0 = fit\n",
    "    print(f'mu={mu:.3f}, N0={N0:.2f}')\n",
    "    \n",
    "    fig, (ax1,ax2) = plt.subplots(1,2,figsize=(8,4))\n",
    "    \n",
    "    ax1.scatter(bins[:-1]+binsize/2,hist)\n",
    "    ax1.plot(bins[:-1]+binsize/2,pnlf(bins[:-1]+0.1,mu=mu,N0=N0),c='tab:orange',ls='--')\n",
    "    ax1.set_yscale('log')\n",
    "    ax1.set_xlim([25,28])\n",
    "    ax1.set_ylim([0.8,1.1*np.max(hist)])\n",
    "    ax1.set_xlabel('$m_{[\\mathrm{OIII}]}$')\n",
    "    ax1.set_ylabel('$N$')\n",
    "    \n",
    "    ax2.plot(bins[1:]+binsize/2,np.cumsum(hist))\n",
    "    ax2.plot(bins[1:]+binsize/2,np.cumsum(pnlf(bins[:-1]+binsize/2,mu=mu,N0=N0)),ls='--')\n",
    "    ax2.set_xlim([mlow,mhigh])\n",
    "    ax2.set_ylim([0,len(table)])\n",
    "    ax2.set_xlabel('$m_{[\\mathrm{OIII}]}$')\n",
    "    ax2.set_ylabel('Cumulative N')\n",
    "    \n",
    "fit_pnlf(tbl[tbl['type']=='PN']['mOIII'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With maximum liklihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximum liklihood estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaximumLikelihood:\n",
    "    '''\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    func : function\n",
    "        PDF of the form `func(data,params)`. `func` must accept a\n",
    "        ndarray for `data` and can have any number of additional\n",
    "        parameters.\n",
    "        \n",
    "    data : ndarray\n",
    "        Measured data that are feed into `func`.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,func,data):\n",
    "        \n",
    "        self.data = data\n",
    "        if len(signature(func).parameters)<2:\n",
    "            raise ValueError(f'`func` must accept at least two arguments')\n",
    "        self.func = func\n",
    "\n",
    "    def loglik(self,params):\n",
    "        '''calculate the log liklihood of the given parameters\n",
    "        \n",
    "        This function takes the previously specified PDF and calculates\n",
    "        the sum of the logarithmic probabilities.\n",
    "        '''\n",
    "        \n",
    "        return np.sum(np.log(self.func(self.data,*params)))\n",
    "    \n",
    "    def fit(self,guess):\n",
    "        '''use scipy minimize to find the best parameters'''\n",
    "        \n",
    "        self.result = minimize(self.loglik,guess,method ='Nelder-Mead')\n",
    "        #for name,var in zip(list(signature(self.func).parameters)[1:],self.result.x):\n",
    "        #    print(f'{name}={var:.3g}')\n",
    "        return self.result.x\n",
    "    \n",
    "    def __call__(self,guess):\n",
    "        return self.fit(guess)\n",
    "        \n",
    "fitter = MaximumLikelihood(pnlf,tbl[tbl['type']=='PN']['mOIII'])\n",
    "fitter([25,20])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance in parsec\n",
    "\n",
    "$$\n",
    "d = 10^{\\frac{\\mu}{5}+1} = 10 \\cdot \\exp\\left( \\ln 10 \\frac{\\mu}{5} \\right) \\\\\n",
    "\\delta d = \\frac{\\ln 10}{5} 10 \\exp\\left( \\ln 10 \\frac{\\mu}{5} \\right) \\delta \\mu = 0.2 \\ln 10 d \\delta \\mu\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "341.333px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
