{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project1 PNLF Postproduction <a class=\"tocSkip\">\n",
    "    \n",
    "After running the production notebook, this notebook can be used to create shared plots for the galaxies and LaTeX output tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "     \n",
    "First we load a bunch of common packages that are used across the project. More specific packages that are only used in one section are loaded later to make it clear where they belong to (this also applies to all custom moduls that were written for this project)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload modules after they have been modified\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pnlf.packages import *\n",
    "\n",
    "from pnlf.constants import tab10, single_column, two_column\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we use the `logging` module to handle informations and warnings (this does not always work as expected in jupyter notebooks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout,format='%(levelname)s: %(message)s',level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we need to specify the path to the raw data\n",
    "basedir = Path('..')\n",
    "data_raw = Path('a:')\n",
    "data_ext = Path('a:')\n",
    "\n",
    "with open(basedir / 'data' / 'interim' / 'parameters.yml') as yml_file:\n",
    "    parameters = yaml.load(yml_file,Loader=yaml.FullLoader)\n",
    "    \n",
    "results = ascii.read(basedir/'data'/'interim'/ 'results.txt',format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "results.add_index('name')\n",
    "#results.rename_columns(['(m-M)','err+(m-M)','err-(m-M)','mu_SNR','mu_SNR+','mu_SNR-'],['dis','dis_plus','dis_minus','dis_SNR','dis_SNR_plus','dis_SNR_minus'])\n",
    "\n",
    "with open(basedir / 'data' / 'interim' / 'parameters.yml') as yml_file:\n",
    "    parameters = yaml.load(yml_file,Loader=yaml.FullLoader)    \n",
    "    \n",
    "sample_table = ascii.read(basedir/'data'/'interim'/'sample.txt')\n",
    "sample_table.add_index('name')\n",
    "sample_table['SkyCoord'] = SkyCoord(sample_table['R.A.'],sample_table['Dec.'])\n",
    "\n",
    "catalogue_file = basedir / 'data' / 'catalogues' / f'nebulae.txt'\n",
    "if catalogue_file.is_file():\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['overluminous'] = catalogue['note']=='OL'\n",
    "    catalogue['exclude'] = catalogue['note']=='EX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in results[np.abs(results['(m-M)']-results['(m-M)_SNR'])>0.1]:\n",
    "    print(row['name'], '%.3f' % (row['(m-M)']-row['(m-M)_SNR']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## LaTeX sample table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from astropy.table import join \n",
    "\n",
    "abundance_gradients = ascii.read(basedir/'data'/'external'/'radial_abundance_gradients.txt',\n",
    "                                names=['name','R0','g_r25'])\n",
    "abundance_gradients.add_index('name')\n",
    "\n",
    "extinction = ascii.read(basedir/'data'/'external'/'extinction.txt')\n",
    "extinction.add_index('name')\n",
    "\n",
    "# 12+logOH at mean position of PNe\n",
    "logOH = []\n",
    "rmean = []\n",
    "for name in abundance_gradients['name']:\n",
    "    completeness = parameters[name]['completeness_limit']\n",
    "    catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "    catalogue['overluminous'] = catalogue['overluminous'].astype(bool)\n",
    "    catalogue['SkyCoord'] = SkyCoord(catalogue['RaDec'])\n",
    "    catalogue = catalogue[(catalogue['type']=='PN') & (~catalogue['exclude']) & (~catalogue['overluminous']) & (catalogue['mOIII']<completeness)]\n",
    "\n",
    "    center = sample_table.loc[name]['SkyCoord']\n",
    "    posang = sample_table.loc[name]['posang']\n",
    "    inclination = sample_table.loc[name]['Inclination']\n",
    "    eccentricity = np.sin(inclination*u.deg).value\n",
    "    r25 = sample_table.loc[name]['r25']*u.arcmin\n",
    "    catalogue['r'] = catalogue['SkyCoord'].separation(center)\n",
    "    rmean.append(np.mean(catalogue['r']/r25).decompose())\n",
    "        \n",
    "abundance_gradients['rmean'] = rmean\n",
    "abundance_gradients['12+logOH'] = abundance_gradients['R0'] + abundance_gradients['rmean']*abundance_gradients['g_r25']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "filename = basedir / 'data' / 'external' / 'phangs_sample_table_v1p6.fits'\n",
    "with fits.open(filename) as hdul:\n",
    "    sample = Table(hdul[1].data)\n",
    "\n",
    "#galaxies = sample_table[sample_table['HAS_MUSE']==1]['NAME']\n",
    "sample = sample[sample['survey_muse_status']!='not_in_survey']\n",
    "sample['name'] = [x.upper() for x in sample['name']]\n",
    "\n",
    "\n",
    "sample.rename_columns(['morph_string','orient_incl','orient_posang','size_r25'],\n",
    "                      ['Type','Inclination','posang','r25'])\n",
    "\n",
    "coord = SkyCoord(sample['orient_ra']*u.degree,sample['orient_dec']*u.degree)\n",
    "sample['R.A.'],sample['Dec.'] = zip(*[x.split(' ') for x in coord.to_string(style='hmsdms',precision=2)])\n",
    "sample['mass'] = np.log10(sample['props_mstar'])\n",
    "sample['SFR'] = np.log10(sample['props_sfr'])\n",
    "\n",
    "err_up = 10 ** (np.log10(sample['dist']) + sample['dist_unc']) - sample['dist']\n",
    "err_down = sample['dist'] - 10 ** (np.log10(sample['dist']) - sample['dist_unc'])\n",
    "sample['(m-M)'] = Distance(sample['dist']*u.Mpc).distmod.value\n",
    "sample['err(m-M)'] = 5/np.log(10)*err_up / sample['dist']\n",
    "sample['r25']/=60\n",
    "\n",
    "sample['(m-M)'].info.format = '%.2f' \n",
    "sample['err(m-M)'].info.format = '%.2f' \n",
    "sample['r25'].info.format = '%.2f' \n",
    "sample['mass'].info.format = '%.2f' \n",
    "sample['SFR'].info.format = '%.2f' \n",
    "\n",
    "columns = ['name','Type','R.A.','Dec.','(m-M)','err(m-M)','Inclination','posang','r25','mass','SFR']\n",
    "tbl = join(sample[columns],abundance_gradients,keys='name')\n",
    "tbl['E(B-V)'] = [extinction.loc[name]['E(B-V)'] for name in tbl['name']]\n",
    "tbl['AO'] = ['\\checkmark' if parameters[name]['power_index']==2.3 else '' for name in tbl['name'] ]\n",
    "tbl['12+logOH'].info.format = '%.2f' \n",
    "\n",
    "with open(basedir / 'data' / 'interim' / 'sample.txt','w',newline='\\n') as f:\n",
    "    ascii.write(tbl,f,format='fixed_width_two_line',overwrite=True,delimiter_pad=' ',position_char='=')\n",
    "    \n",
    "del tbl[['R0','rmean','g_r25','mass','SFR']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "latexdict = {'tabletype': 'table*',\n",
    "'header_start': '\\\\toprule\\\\toprule',\n",
    "'header_end': '\\\\midrule',\n",
    "'data_end': '\\\\bottomrule',\n",
    "'caption': f'Galaxy sample',\n",
    "'units': {'R.A.':'(J2000)','Dec.':'(J2000)','Inclination':'deg','Distance':'$\\si{\\mega\\parsec}$',\n",
    "          'r25':'arcmin'},\n",
    "'preamble': '\\\\centering',\n",
    "'tablefoot': f'\\\\label{{tbl:sample}}'\n",
    "            }\n",
    " \n",
    "tbl['name'] = [f'\\\\galaxyname{{{row[\"name\"][:-4]}}}{{{row[\"name\"][-4:]}}}' for row in tbl]\n",
    "#tbl['(m-M)'] = [f'{row[\"(m-M)\"]:.2f}\\pm{row[\"err(m-M)\"]:.2f}' for row in tbl]\n",
    "    \n",
    "with open(basedir / 'data' / 'interim' /'sample.tex','w',newline='\\n') as f:\n",
    "    ascii.write(tbl,f,Writer=ascii.Latex, latexdict=latexdict,overwrite=True,exclude_names=['Name'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LaTeX result table\n",
    "\n",
    "this uses the result table and prints out a LaTeX table (only the data part) that can be used in the final document. In another step, we merge the individual catalogues for PN and SNR identifications. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with SI units\n",
    "tbl_out = ''\n",
    "results.sort('name')\n",
    "for row in results:\n",
    "    name = f'\\\\galaxyname{{{row[\"name\"][:-4]}}}{{{row[\"name\"][-4:]}}}'\n",
    "    tbl_out += f'{name} & {row[\"N_PN\"]} & {row[\"N_SNRorPN\"]} '\n",
    "    tbl_out += f'& $\\\\uncertainty{{{row[\"(m-M)\"]:.2f}}}{{{row[\"err+(m-M)\"]:.2f}}}{{{row[\"err-(m-M)\"]:.2f}}}$ '\n",
    "    tbl_out += f'& $\\\\uncertainty{{{row[\"(m-M)_SNR\"]:.2f}}}{{{row[\"err+(m-M)_SNR\"]:.2f}}}{{{row[\"err-(m-M)_SNR\"]:.2f}}}$ '\n",
    "    tbl_out += f'& $\\\\uncertainty{{{row[\"d/Mpc\"]:.2f}}}{{{row[\"err+d/Mpc\"]:.2f}}}{{{row[\"err-d/Mpc\"]:.2f}}}$ \\\\\\\\\\n'\n",
    "    #tbl_out += f'& {row[\"alpha\"]:.2f}\\\\\\\\\\n'\n",
    "    #tbl_out += f'& $\\\\uncertainty{{{row[\"dis_SNR\"]:.2f}}}{{{row[\"dis_SNR_plus\"]:.2f}}}{{{row[\"dis_SNR_minus\"]:.2f}}}$ '\n",
    "    #tbl_out += f'& $\\\\uncertainty{{{row[\"dis_SNR_Mpc\"]:.2f}}}{{{row[\"dis_SNR_Mpc_plus\"]:.2f}}}{{{row[\"dis_SNR_Mpc_minus\"]:.2f}}}$\\\\\\\\\\n'\n",
    "    \n",
    "    \n",
    "print(tbl_out)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without SI units\n",
    "tbl_out = ''\n",
    "results.sort('name')\n",
    "for row in results:\n",
    "    print(f'\\\\setvalue{{mag/{row[\"name\"]} =\\\\SI[parse-numbers=false]{{\\\\uncertainty{{{row[\"(m-M)\"]:.2f}}}{{{row[\"err+(m-M)\"]:.2f}}}{{{row[\"err-(m-M)\"]:.2f}}}}}{{\\\\mag}}}}')\n",
    "print(' ')\n",
    "for row in results:\n",
    "    print(f'\\\\setvalue{{Mpc/{row[\"name\"]} =\\\\SI[parse-numbers=false]{{\\\\uncertainty{{{row[\"d/Mpc\"]:.2f}}}{{{row[\"err+d/Mpc\"]:.2f}}}{{{row[\"err-d/Mpc\"]:.2f}}}}}{{\\\\mega\\\\parsec}}}}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_out = ''\n",
    "results.sort('name')\n",
    "for row in results:\n",
    "    print(f'\\\\setvalue{{mag/{row[\"name\"]} = \\\\uncertainty{{{row[\"(m-M)\"]:.2f}}}{{{row[\"err+(m-M)\"]:.2f}}}{{{row[\"err-(m-M)\"]:.2f}}}}}')\n",
    "print(' ')\n",
    "for row in results:\n",
    "    print(f'\\\\setvalue{{Mpc/{row[\"name\"]} = \\\\uncertainty{{{row[\"d/Mpc\"]:.2f}}}{{{row[\"err+d/Mpc\"]:.2f}}}{{{row[\"err-d/Mpc\"]:.2f}}}}}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "for col in ['(m-M)','err+(m-M)','err-(m-M)','d/Mpc','err+d/Mpc','err-d/Mpc']:\n",
    "    results[col].info.format = '%.2f'\n",
    "\n",
    "distance_modulus = []\n",
    "distance_parsec = []\n",
    "for row in results:\n",
    "    distance_modulus.append(f'{row[\"(m-M)\"]:.2f} + {row[\"err-(m-M)\"]:.2f} - {row[\"err+(m-M)\"]:.2f}')\n",
    "    distance_parsec.append(f'{row[\"d/Mpc\"]:.2f} + {row[\"err+d/Mpc\"]:.2f} - {row[\"err-d/Mpc\"]:.2f}')\n",
    "results['mu'] = distance_modulus\n",
    "results['d/Mpc'] = distance_parsec\n",
    "                           \n",
    "filename = basedir / 'data' / 'interim' / f'distances.txt'\n",
    "with open(filename,'w',newline='\\n') as f:\n",
    "    ascii.write(results[['name','mu','d/Mpc']],\n",
    "                f,format='fixed_width',delimiter='\\t',overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Catalogues to single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_lst = []\n",
    "for name in results['name']:\n",
    "    tmp = ascii.read(basedir/'data'/'catalogues'/f'{name}_nebulae.txt',format='fixed_width_two_line')\n",
    "    tmp['gal_name'] = name\n",
    "    tbl_lst.append(tmp)\n",
    "catalogue = vstack(tbl_lst)\n",
    "\n",
    "catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "catalogue['overluminous'] = catalogue['overluminous'].astype(bool)\n",
    "catalogue['SNRorPN'] = catalogue['SNRorPN']=='True'\n",
    "catalogue['SkyCoord'] = SkyCoord(catalogue['RaDec'])\n",
    "catalogue['RA'],catalogue['DEC'] = zip(*[x.split(' ') for x in catalogue['SkyCoord'].to_string(style='hmsdms',precision=2)])\n",
    "\n",
    "notes = []\n",
    "for row in catalogue:\n",
    "    note = []\n",
    "    if row['SNRorPN']:\n",
    "        pass\n",
    "        #note.append('PN')\n",
    "    if row['overluminous']:\n",
    "        note.append('OL')\n",
    "    if row['exclude']:\n",
    "        note.append('EX')\n",
    "    notes.append(','.join(note))\n",
    "catalogue['note'] = notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['gal_name','id','type','x','y','RA','DEC','fwhm','mOIII','dmOIII','OIII/Ha','d(OIII/Ha)',\n",
    "           'NII/Ha','d(NII/Ha)','SII/Ha','d(SII/Ha)','note']\n",
    "# we only use PN or SNR that could be PN\n",
    "SNRorPN =  ((catalogue['type']=='PN')|((catalogue['type']=='SNR')&(catalogue['SNRorPN'])))\n",
    "criteria = SNRorPN & (catalogue['mOIII']<28) #& (~catalogue['exclude']) # | catalogue['overluminous'])\n",
    "\n",
    "catalogue['OIII/Ha']   = catalogue['OIII5006']/catalogue['HA6562']\n",
    "catalogue['d(OIII/Ha)']= catalogue['OIII5006'] / catalogue['HA6562'] * np.sqrt( (catalogue['HA6562_err'] / catalogue['HA6562'])**2 + (catalogue['OIII5006_err'] / catalogue['OIII5006'])**2)\n",
    "\n",
    "#catalogue['Ha/NII']    = catalogue['HA6562']/catalogue['NII6583']\n",
    "#catalogue['d(Ha/NII)'] = catalogue['HA6562'] / catalogue['NII6583'] * np.sqrt( (catalogue['NII6583_err'] / catalogue['NII6583'])**2 + (catalogue['HA6562_err'] / catalogue['HA6562'])**2)\n",
    "\n",
    "#catalogue['Ha/SII']    = catalogue['HA6562']/catalogue['SII']\n",
    "#catalogue['d(Ha/SII)'] = catalogue['HA6562'] / catalogue['SII'] * np.sqrt( (catalogue['SII_err'] / catalogue['SII'])**2 + (catalogue['HA6562_err'] / catalogue['HA6562'])**2)\n",
    "\n",
    "catalogue['NII/Ha']    = catalogue['NII6583']/catalogue['HA6562']\n",
    "catalogue['d(NII/Ha)'] = catalogue['NII/Ha']  * np.sqrt( (catalogue['NII6583_err'] / catalogue['NII6583'])**2 + (catalogue['HA6562_err'] / catalogue['HA6562'])**2)\n",
    "\n",
    "catalogue['SII/Ha']    = catalogue['SII']/catalogue['HA6562']\n",
    "catalogue['d(SII/Ha)'] = catalogue['SII/Ha']  * np.sqrt( (catalogue['SII_err'] / catalogue['SII'])**2 + (catalogue['HA6562_err'] / catalogue['HA6562'])**2)\n",
    "\n",
    "\n",
    "export = catalogue[columns][criteria].copy()\n",
    "\n",
    "\n",
    "for col in ['mOIII','dmOIII','OIII/Ha','d(OIII/Ha)','NII/Ha','d(NII/Ha)','SII/Ha','d(SII/Ha)']:\n",
    "    export[col].info.format = '%.2f' \n",
    "export.sort(['gal_name','mOIII']) \n",
    "with open(basedir/'data'/'catalogues'/'nebulae.txt','w',newline='\\n') as f:\n",
    "    ascii.write(export,f,format='fixed_width_two_line',overwrite=True,delimiter_pad=' ',position_char='=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overluminous = catalogue[catalogue['overluminous']]\n",
    "\n",
    "for row in overluminous[['gal_name','id','type','RA','DEC','mOIII','dmOIII']]:\n",
    "    print('{} & {} & {} & {} & {} & {} & {} \\\\\\\\'.format(*row))\n",
    "    \n",
    "overluminous[['gal_name','id','type','RA','DEC','mOIII','dmOIII']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create LaTeX table for a single galaxy (for paper)\n",
    "tmp = ascii.read(basedir/'data'/'catalogues'/'nebulae.txt')\n",
    "tmp = tmp[tmp['gal_name']=='NGC0628']\n",
    "\n",
    "with open(basedir / 'data' / 'catalogues' /'NGC0628_nebulae.tex','w',newline='\\n') as f:\n",
    "    ascii.write(tmp,f,Writer=ascii.Latex,overwrite=True,exclude_names=['x','y','fwhm'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Single PNLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.analyse import MaximumLikelihood1D, pnlf, cdf\n",
    "from pnlf.plot.pnlf import plot_pnlf\n",
    "from pnlf.auxiliary import mu_to_parsec\n",
    "from scipy.stats import kstest\n",
    "\n",
    "name = 'NGC1672'\n",
    "\n",
    "catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "if catalogue_file.is_file():\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "\n",
    "binsize = 0.4 #parameters[name]['binsize']\n",
    "completeness_limit = parameters[name]['completeness_limit']\n",
    "mu = parameters[name]['mu']\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# fit the data\n",
    "# ----------------------------------------------------------------------\n",
    "'''\n",
    "data = catalogue['mOIII'][(catalogue['type']=='PN') & (catalogue['mOIII']<completeness_limit)]\n",
    "err = catalogue['dmOIII'][(catalogue['type']=='PN') & (catalogue['mOIII']<completeness_limit)]\n",
    "\n",
    "fitter = MaximumLikelihood1D(pnlf,data,err=err,mhigh=completeness_limit,Mmax=-4.47)\n",
    "mu,mu_p,mu_m = fitter([29])\n",
    "\n",
    "d,(dp,dm)=mu_to_parsec(mu,[mu_p,mu_m])\n",
    "print('{:.2f} + {:.2f} - {:.2f}'.format(mu,mu_p,mu_m))\n",
    "print('{:.2f} + {:.2f} - {:.2f}'.format(d,dp,dm))\n",
    "\n",
    "ks,pv = kstest(data,cdf,args=(mu,completeness_limit))\n",
    "print(f'{name}: statistic={ks:.3f}, pvalue={pv:.3f}')\n",
    "'''\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "#plot PNLF\n",
    "# ----------------------------------------------------------------------\n",
    "filename = None #basedir / 'reports' / f'{galaxy.name}' / f'{galaxy.name}_PNLF'\n",
    "axes = plot_pnlf(catalogue['mOIII'][(catalogue['type']=='PN')],mu,completeness_limit,\n",
    "                 binsize=binsize,mhigh=29,filename=filename,color=tab10[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined PNLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.plot.pnlf import _plot_pnlf\n",
    "\n",
    "names = results['name']\n",
    "nrows = 5\n",
    "ncols = 4\n",
    "filename = basedir / 'reports' / f'all_galaxies_PNLF'\n",
    "\n",
    "#----------------------------------------------\n",
    "# DO NOT MODIFY BELOW\n",
    "#----------------------------------------------\n",
    "if nrows*ncols<len(names):\n",
    "    raise ValueError('not enough subplots for selected objects') \n",
    "width = two_column\n",
    "fig, axes = plt.subplots(nrows=nrows,ncols=ncols,figsize=(width,width/ncols*nrows))\n",
    "axes_iter = iter(axes.flatten())\n",
    "Mmax = -4.47\n",
    "\n",
    "# loop over the galaxies we want to plot\n",
    "for name in names:  \n",
    "\n",
    "    catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "    if catalogue_file.is_file():\n",
    "        catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "        catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "        catalogue['overluminous'] = catalogue['overluminous'].astype(bool)\n",
    "    sub = catalogue\n",
    "    \n",
    "    # get the next axis and find position on the grid\n",
    "    ax = next(axes_iter)\n",
    "    if nrows>1 and ncols>1:\n",
    "        i, j = np.where(axes == ax)\n",
    "        i,j=i[0],j[0]\n",
    "    elif ncols>1:\n",
    "        i,j = 0, np.where(axes==ax)[0]\n",
    "    elif nrows>1:\n",
    "        i,j = np.where(axes==ax)[0],0\n",
    "    else:\n",
    "        i,j=0,0\n",
    "        \n",
    "    # pre-process the data for the plot and read additional parameters\n",
    "    data = sub[(sub['type']=='PN') & (~sub['exclude'])]['mOIII']\n",
    "    mask = sub[(sub['type']=='PN') & (~sub['exclude'])]['overluminous']\n",
    "\n",
    "    mu = results.loc[name]['(m-M)']\n",
    "    completeness = parameters[name]['completeness_limit']\n",
    "\n",
    "    binsize = parameters[name]['binsize']\n",
    "    mlow = Mmax+mu\n",
    "    mhigh = 28.5\n",
    "\n",
    "    ax=_plot_pnlf(data,mu,completeness,mask,binsize=binsize,mhigh=mhigh,ax=ax,ms=3)\n",
    "    ax.text(0.63,0.07,f'{name}', transform=ax.transAxes,fontsize=7)\n",
    "\n",
    "    #ax.set_xlim([mu-5,completeness+0.5])\n",
    "    # add labels to the axis\n",
    "    if i==nrows-1:\n",
    "        ax.set_xlabel(r'$m_{[\\mathrm{OIII}]}$ / mag')\n",
    "    if j==0:\n",
    "        ax.set_ylabel(r'N')\n",
    "    #ax.set_title(name)\n",
    "    #ax.set(xlim=[24,28.5])\n",
    "    \n",
    "axes[3,3].set_xlabel(r'$m_{[\\mathrm{OIII}]}$ / mag')\n",
    "ax = next(axes_iter)\n",
    "#ax.remove()\n",
    "h,l = fig.axes[0].get_legend_handles_labels()\n",
    "ax.axis('off')\n",
    "ax.legend(h,l,fontsize=7,loc='center left',frameon=False)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.15, hspace=0.15)\n",
    "#plt.tight_layout()\n",
    "plt.savefig(filename.with_suffix('.pdf'),bbox_inches='tight')\n",
    "plt.savefig(filename.with_suffix('.png'),bbox_inches='tight',dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined cumulative PNLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.plot.pnlf import _plot_cum_pnlf\n",
    "from pnlf.analyse import cdf\n",
    "from scipy.stats import kstest\n",
    "\n",
    "names = results['name']\n",
    "nrows = 5\n",
    "ncols = 4\n",
    "filename = basedir / 'reports' / f'all_galaxies_PNLF_cum'\n",
    "\n",
    "#----------------------------------------------\n",
    "# DO NOT MODIFY BELOW\n",
    "#----------------------------------------------\n",
    "if nrows*ncols<len(names):\n",
    "    raise ValueError('not enough subplots for selected objects')\n",
    "width = two_column\n",
    "fig, axes = plt.subplots(nrows=nrows,ncols=ncols,figsize=(width,width/ncols*nrows))\n",
    "axes_iter = iter(axes.flatten())\n",
    "\n",
    "binsize=0.1\n",
    "Mmax = -4.47\n",
    "color = 'tab:red'\n",
    "\n",
    "for name in names:  \n",
    "        \n",
    "    catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "    if catalogue_file.is_file():\n",
    "        catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "        catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "        catalogue['overluminous'] = catalogue['overluminous'].astype(bool)\n",
    "    else:\n",
    "        print(f'no catalogue for {name}')\n",
    "        continue\n",
    "    \n",
    "    # get the next axis\n",
    "    ax = next(axes_iter)\n",
    "    # find current position on the grid\n",
    "    i, j = np.where(axes == ax)\n",
    "    i,j=i[0],j[0]\n",
    "    \n",
    "    data = catalogue[(catalogue['type']=='PN') & (~catalogue['exclude']) & (~catalogue['overluminous'])]['mOIII']\n",
    "    mu = results.loc[name]['(m-M)']\n",
    "    completeness = parameters[name]['completeness_limit']\n",
    "    cut = parameters[name].get('cut',0)\n",
    "    if cut>0:\n",
    "        print(f'warning: using cut={cut} for {name}')\n",
    "    data = data[data>cut]\n",
    "\n",
    "    ks,pv = kstest(data[data<completeness],cdf,args=(mu,completeness))\n",
    "\n",
    "    ax=_plot_cum_pnlf(data,mu,completeness,ax=ax,binsize=None)\n",
    "    ax.text(0.63,0.07,f'{name}', transform=ax.transAxes,fontsize=7)\n",
    "    ax.text(0.1,0.78,f'$p$-value$={pv:.2f}$',transform=ax.transAxes,fontsize=7)\n",
    "    ax.text(0.1,0.88,f'$D_{{max}}={ks:.3f}$', transform=ax.transAxes,fontsize=7)\n",
    "\n",
    "    # add labels to the axis\n",
    "    if i==nrows-1:\n",
    "        ax.set_xlabel(r'$m_{[\\mathrm{OIII}]}$ / mag')\n",
    "    if j==0:\n",
    "        ax.set_ylabel(r'Cumulative N')\n",
    "    \n",
    "    #ax.set_title(name)\n",
    "axes[3,3].set_xlabel(r'$m_{[\\mathrm{OIII}]}$ / mag')\n",
    "ax = next(axes_iter)\n",
    "#ax.remove()\n",
    "\n",
    "#h,l = fig.axes[0].get_legend_handles_labels()\n",
    "ax.axis('off')\n",
    "#ax.legend(h,l,fontsize=7,loc='center left',frameon=False)\n",
    "    \n",
    "plt.subplots_adjust(wspace=0.22, hspace=0.22)\n",
    "#plt.tight_layout()\n",
    "plt.savefig(filename.with_suffix('.pdf'),bbox_inches='tight')\n",
    "plt.savefig(filename.with_suffix('.png'),bbox_inches='tight',dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "together with SNR (and without loading each catalogue by itself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nebulae = ascii.read(basedir/'data'/'catalogues'/'nebulae.txt')\n",
    "nebulae['SkyCoord'] = SkyCoord(nebulae['RA'],nebulae['DEC'])\n",
    "nebulae['SNRorPN'] = [True if 'PN' in row else False for row in nebulae['note']]\n",
    "nebulae['OL'] = [True if 'OL' in row else False for row in nebulae['note']]\n",
    "nebulae = nebulae[~nebulae['OL']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "from pnlf.analyse import cdf\n",
    "\n",
    "names = results['name']\n",
    "names = ['NGC1087','NGC1365','NGC1385','NGC1512','NGC4321']\n",
    "nrows = 2\n",
    "ncols = 3\n",
    "filename = basedir / 'reports' / f'all_galaxies_PNLF_SNR_cum'\n",
    "\n",
    "#----------------------------------------------\n",
    "# DO NOT MODIFY BELOW\n",
    "#----------------------------------------------\n",
    "if nrows*ncols<len(names):\n",
    "    raise ValueError('not enough subplots for selected objects')\n",
    "width = two_column\n",
    "fig, axes = plt.subplots(nrows=nrows,ncols=ncols,figsize=(width,width/ncols*nrows))\n",
    "axes_iter = iter(axes.flatten())\n",
    "\n",
    "binsize=0.1\n",
    "Mmax = -4.47\n",
    "color = 'tab:red'\n",
    "\n",
    "for name in names:  \n",
    "    \n",
    "    # get the next axis\n",
    "    ax = next(axes_iter)\n",
    "    # find current position on the grid\n",
    "    i, j = np.where(axes == ax)\n",
    "    i,j=i[0],j[0]\n",
    "    \n",
    "    mu = results.loc[name]['(m-M)']\n",
    "    completeness = parameters[name]['completeness_limit']\n",
    "    \n",
    "    data1 = nebulae[(nebulae['gal_name']==name) & (nebulae['type']=='PN')]['mOIII']\n",
    "    data2 = nebulae[(nebulae['gal_name']==name) & ((nebulae['type']=='PN')|((nebulae['type']=='SNR')&nebulae['SNRorPN']))]['mOIII']\n",
    "\n",
    "    data1 = data1[data1<completeness]\n",
    "    data2 = data2[data2<completeness]\n",
    "    N1,N2 = len(data1),len(data2)      \n",
    "    #print(f'{name}: PN: {N1}, PN and SNR: {N2}')\n",
    "\n",
    "    ax.plot(data1,np.arange(1,N1+1,1),ls='-',mfc=tab10[0],mec=tab10[0],ms=1,marker='o',label='PN')\n",
    "    ax.plot(data2,np.arange(1,N2+1,1),ls='-',mfc=tab10[1],mec=tab10[1],ms=1,marker='o',label='PN+SNR')\n",
    "    \n",
    "    # plot the fit\n",
    "    ax.plot(data1,N1*cdf(data1,mu,completeness),ls=':',color='k',label='fit')\n",
    "    ax.plot(data2,N2*cdf(data2,results.loc[name]['mu_SNR'],completeness),ls=':',color='k')\n",
    "    \n",
    "    ks,pv = ks_2samp(data1,data2)\n",
    "    #ks,pv = kstest(data[data<completeness],cdf,args=(mu,completeness))\n",
    "    ax.text(0.55,0.08,f'{name}', transform=ax.transAxes,fontsize=7)\n",
    "    ax.text(0.1,0.78,f'$p$-value$={pv:.2f}$',transform=ax.transAxes,fontsize=7)\n",
    "    ax.text(0.1,0.88,f'$D_{{max}}={ks:.3f}$', transform=ax.transAxes,fontsize=7)\n",
    "\n",
    "    # add labels to the axis\n",
    "    if i==nrows-1:\n",
    "        ax.set_xlabel(r'$m_{[\\mathrm{OIII}]}$ / mag')\n",
    "    if j==0:\n",
    "        ax.set_ylabel(r'Cumulative N')\n",
    "    \n",
    "    #ax.set_title(name)\n",
    "axes[0,2].set_xlabel(r'$m_{[\\mathrm{OIII}]}$ / mag')\n",
    "ax = next(axes_iter)\n",
    "#ax.remove()\n",
    "\n",
    "h,l = fig.axes[0].get_legend_handles_labels()\n",
    "ax.axis('off')\n",
    "ax.legend(h,l,fontsize=7,loc='center left',frameon=False)\n",
    "    \n",
    "plt.subplots_adjust(wspace=0.22, hspace=0.22)\n",
    "#plt.tight_layout()\n",
    "plt.savefig(filename.with_suffix('.pdf'),bbox_inches='tight')\n",
    "#plt.savefig(filename.with_suffix('.png'),bbox_inches='tight',dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Combine line diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.analyse import PNLF\n",
    "\n",
    "names = result['name']\n",
    "style = {'SNR':{\"marker\":'o',\"ms\":3,\"mfc\":'None',\"mec\":tab10[0],'ls':'none','ecolor':tab10[0]},\n",
    "         'SNRorPN':{\"marker\":'o',\"ms\":4,\"mfc\":'white',\"mec\":'tab:green','ls':'none','ecolor':'tab:green'},\n",
    "         'HII':{\"marker\":'+',\"ms\":3,\"mec\":tab10[1],'ls':'none'},\n",
    "         'PN':{\"marker\":'o',\"ms\":2,\"mfc\":'black','mec':'black','ls':'none','ecolor':'black'}\n",
    "        }\n",
    "Mmax=-4.47\n",
    "color = 'tab:red'\n",
    "\n",
    "# define the figure with the number of subplots\n",
    "nrows = 2\n",
    "ncols = 3\n",
    "width = two_column\n",
    "fig, axes_arr = plt.subplots(nrows=nrows,ncols=ncols,figsize=(width,width/ncols*nrows))\n",
    "axes = iter(axes_arr.flatten())\n",
    "\n",
    "\n",
    "names = ['IC5332','NGC0628','NGC1566','NGC3351','NGC3627','NGC5068']\n",
    "\n",
    "# loop over the galaxies we want to plot\n",
    "for name in names:  \n",
    "       \n",
    "    # read in the data\n",
    "    catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "    if catalogue_file.is_file():\n",
    "        catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "        catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "        for col in catalogue.columns:\n",
    "            if col.endswith('detection'):\n",
    "                catalogue[col] = catalogue[col]=='True'\n",
    "    else:\n",
    "        print(f'no catalogue for {name}')\n",
    "        continue\n",
    "        \n",
    "    # get the next axis\n",
    "    ax = next(axes)\n",
    "    # find current position on the grid\n",
    "    i, j = np.where(axes_arr == ax)\n",
    "    i,j=i[0],j[0]\n",
    "    \n",
    "    # pre-process the data for the plot and read additional parameters\n",
    "    mu = result.loc[name]['dis']\n",
    "    completeness = parameters[name]['completeness_limit']\n",
    "    \n",
    "    # draw line that we use seperate PN from HII\n",
    "    MOIII = np.linspace(-5,1)\n",
    "    OIII_Ha = 10**(-0.37*(MOIII)-1.16)\n",
    "    ax.plot(MOIII,OIII_Ha,c='black',lw=0.6)\n",
    "    ax.axhline(10**4)\n",
    "\n",
    "    if completeness:\n",
    "        ax.axvline(completeness-mu,ls='--',c='grey',lw=0.5)\n",
    "    ax.axvline(Mmax,ls='--',c='grey',lw=0.5)\n",
    "\n",
    "    for t in ['HII','PN','SNR']:\n",
    "        tbl = catalogue[catalogue['type']==t]        \n",
    "        ax.errorbar(tbl['mOIII']-mu,tbl['OIII5006']/(tbl['HA6562']+tbl['NII6583']),**style[t],label=t) \n",
    "\n",
    "        if t=='PN':\n",
    "            # indicate for which PN we don't have a detection in HA6562\n",
    "            tbl = tbl[~tbl['HA6562_detection']]\n",
    "            ax.errorbar(tbl['mOIII']-mu,1.11*tbl['OIII5006']/(tbl['HA6562']+tbl['NII6583']),\n",
    "                         marker=r'$\\uparrow$',ms=4,mec='black',ls='none') \n",
    "        if t=='SNR':\n",
    "            #tbl = tbl[tbl['SNRorPN']] \n",
    "            ax.errorbar(tbl['mOIII']-mu,tbl['OIII5006']/(tbl['HA6562']+tbl['NII6583']), marker='x',ms=2,mec=tab10[0],ls='none') \n",
    "   \n",
    "    # objects that were rejeceted by eye\n",
    "    tbl = catalogue[catalogue['exclude']]\n",
    "    ax.errorbar(tbl['mOIII']-mu,tbl['OIII5006']/(tbl['HA6562']+tbl['NII6583']),marker='o',ms=3,ls='none',color='tab:green',label='rejected') \n",
    "    \n",
    "    \n",
    "    # configure axes \n",
    "    ax.set(xlim=[-5,np.ceil(completeness-mu)],\n",
    "           ylim=[0.03,200],\n",
    "           yscale='log')\n",
    "    \n",
    "    ax.yaxis.set_major_formatter(mpl.ticker.FuncFormatter(lambda y, _: '{:.16g}'.format(y)))\n",
    "\n",
    "    axt = ax.twiny()\n",
    "    xlim1,xlim2 = ax.get_xlim()\n",
    "    axt.set_xticks(np.arange(np.ceil(xlim1+mu),np.floor(xlim2+mu)+1),minor=False)\n",
    "    axt.set(xlim   = [xlim1+mu,xlim2+mu])\n",
    "    \n",
    "    if i==0:\n",
    "        axt.set(xlabel = r'$m_{\\mathrm{[OIII]}}$')\n",
    "    \n",
    "    if i==nrows-1:\n",
    "        ax.set(xlabel=r'$M_{\\mathrm{[OIII]}}$')\n",
    "    if j==0:\n",
    "        ax.set(ylabel=r'[OIII] / $(\\mathrm{H}\\alpha + \\mathrm{[NII]})$')\n",
    "    ax.set_title(name)\n",
    "    \n",
    "    ax.xaxis.set_major_locator(mpl.ticker.MaxNLocator(integer=True))\n",
    "    \n",
    "    \n",
    "h,l = fig.axes[0].get_legend_handles_labels()\n",
    "fig.legend(h, l, bbox_to_anchor=(0., 1.01, 1., .051),loc = 'upper center',ncol=4)\n",
    "\n",
    "plt.tight_layout()\n",
    "filename = basedir / 'reports' / f'all_objects_line_diagnostics'\n",
    "plt.savefig(filename.with_suffix('.pdf'),bbox_inches='tight')\n",
    "plt.savefig(filename.with_suffix('.png'),bbox_inches='tight',dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Combined Completeness limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = basedir/'data'/'interim'\n",
    "files = [x for x in path.iterdir() if x.stem.endswith('mock_sources')]\n",
    "\n",
    "limit   = 0.8\n",
    "max_sep = 0.3\n",
    "\n",
    "ncols = 5\n",
    "nrows = int(np.ceil(len(files)/ncols))\n",
    "\n",
    "width = 2*two_column\n",
    "fig, axes = plt.subplots(nrows=nrows,ncols=ncols,figsize=(width,width/ncols*nrows))\n",
    "axes_iter = iter(axes.flatten())\n",
    "\n",
    "for file in files:\n",
    "    \n",
    "    ax = next(axes_iter)\n",
    "    i, j = np.where(axes == ax)\n",
    "    i,j=i[0],j[0]\n",
    "    \n",
    "    name = file.stem.split('_')[0]\n",
    "    mock_sources = ascii.read(file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "  \n",
    "    hist = []\n",
    "    width = 0.5\n",
    "    bins = np.arange(26,30,width)\n",
    "\n",
    "    for center in bins:\n",
    "        tmp = mock_sources[(mock_sources['magnitude']>center-width/2) & (mock_sources['magnitude']<=center+width/2)]\n",
    "        if len(tmp)>0:\n",
    "            hist.append(np.sum(tmp['sep']<max_sep)/len(tmp))\n",
    "        else:\n",
    "            hist.append(0)\n",
    "    hist = np.array(hist)\n",
    "    \n",
    "    completeness_limit = np.max(bins[hist>=limit])\n",
    "    \n",
    "    ax.axhline(100*limit,color='black',lw=0.6)\n",
    "\n",
    "    ax.bar(bins[hist>=limit],hist[hist>=limit]*100,width=width*0.9,color=tab10[0])\n",
    "    ax.bar(bins[hist<limit],hist[hist<limit]*100,width=width*0.9,fc='white',ec=tab10[0])\n",
    "    \n",
    "    for b,h in zip(bins,hist):\n",
    "        if b>=26.5:\n",
    "            if h>=0.8:\n",
    "                ax.text(b,5,f'{h*100:.0f}\\%',horizontalalignment='center',color='white',fontsize=6)\n",
    "            else:\n",
    "                ax.text(b,5,f'{h*100:.0f}\\%',horizontalalignment='center',color=tab10[0],fontsize=6)\n",
    "    t = ax.text(0.75,0.92,f'{name}', transform=ax.transAxes,color='black',fontsize=7)\n",
    "    t = ax.text(0.75,0.82,f'cl={completeness_limit:.0f}', transform=ax.transAxes,color='black',fontsize=7)\n",
    "\n",
    "    ax.set(xlim=[26.2,29.8],\n",
    "           ylim=[0,100])\n",
    "    \n",
    "    if i==nrows-1:\n",
    "        ax.set(xlabel='m$_{[\\mathrm{OIII}]}$')\n",
    "    else:\n",
    "        ax.set_xticklabels([])\n",
    "    if j==0:\n",
    "        ax.set(ylabel='percentage of recovered objects')\n",
    "    else:\n",
    "        ax.set_yticklabels([])\n",
    "    \n",
    "    #ax.set_title(f'{name}: cl = {completeness_limit}')\n",
    "    \n",
    "for i in range(nrows*ncols-len(files)):\n",
    "\n",
    "    # remove the empty axes at the bottom\n",
    "    ax = next(axes_iter)\n",
    "    ax.remove()\n",
    "\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "\n",
    "filename = basedir / 'reports' / f'all_galaxies_completeness'\n",
    "plt.savefig(filename.with_suffix('.pdf'),bbox_inches='tight')\n",
    "plt.savefig(filename.with_suffix('.png'),bbox_inches='tight',dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.detection import plot_completeness_limit\n",
    "\n",
    "name = 'NGC0628'\n",
    "\n",
    "file = basedir/'data'/'interim'/f'{name}_mock_sources.txt'\n",
    "\n",
    "limit   = 0.8\n",
    "max_sep = 0.3\n",
    "\n",
    "mock_sources = ascii.read(file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "\n",
    "filename = basedir / 'reports' / name / f'{name}_completness.pdf'\n",
    "\n",
    "plot_completeness_limit(mock_sources,max_sep=max_sep,limit=limit,filename=filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Plot RGB image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.auxiliary import circular_mask\n",
    "from pnlf.plot.plot import create_RGB\n",
    "from pnlf.io import ReadLineMaps\n",
    "\n",
    "nrows = 5\n",
    "ncols = 4\n",
    "width = two_column\n",
    "fig, axes_arr = plt.subplots(nrows=nrows,ncols=ncols,figsize=(width,width/ncols*nrows))\n",
    "axes = iter(axes_arr.flatten())\n",
    "\n",
    "# loop over the galaxies we want to plot\n",
    "for name in results['name']:  \n",
    "        \n",
    "    # get the next axis\n",
    "    ax = next(axes)\n",
    "    # find current position on the grid\n",
    "    i, j = np.where(axes_arr == ax)\n",
    "    i,j=i[0],j[0]\n",
    "    \n",
    "    #galaxy = galaxies[name]\n",
    "    galaxy = ReadLineMaps(data_raw,name,**parameters[name])\n",
    "    \n",
    "    # define masks as slices\n",
    "    masks = {\n",
    "     'NGC1300' : circular_mask(*galaxy.shape,radius=50),\n",
    "     'NGC1365' : circular_mask(*galaxy.shape,(720,420),radius=200),\n",
    "     #'NGC1433' : circular_mask(*galaxy.shape,radius=100),\n",
    "     'NGC1512' : circular_mask(*galaxy.shape,radius=70),\n",
    "     'NGC1566' : circular_mask(*galaxy.shape,(450,450),radius=100)|circular_mask(*galaxy.shape,(350,150),radius=180),\n",
    "     'NGC1672' : circular_mask(*galaxy.shape,(600,310),radius=60),\n",
    "     #'NGC3627' : circular_mask(*galaxy.shape,(330,740),radius=100),\n",
    "     'NGC3351' : circular_mask(*galaxy.shape,radius=200),\n",
    "     'NGC4321' : circular_mask(*galaxy.shape,(550,450),radius=60),\n",
    "     'NGC4535' : circular_mask(*galaxy.shape,(300,520),radius=100)\n",
    "    }\n",
    "    \n",
    "    mask = np.zeros(galaxy.shape,dtype=bool)\n",
    "    mask |= galaxy.star_mask.astype(bool)\n",
    "    mask[masks.get(galaxy.name,(slice(-1,0),slice(-1,0)))] = True\n",
    "\n",
    "    #img = galaxy.OIII5006_DAP.copy()\n",
    "    img = create_RGB(galaxy.HA6562,galaxy.OIII5006_DAP,galaxy.SII6716,weights=[0.6,1,0.6],percentile=[95,99.,95])\n",
    "    img[mask,...] = (1,1,1) #(1, 165/255, 1/255) \n",
    "\n",
    "    ax.imshow(img,origin='lower')\n",
    "    ax.set_title(name)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "filename = basedir / 'reports' / f'all_objects_rgb'\n",
    "plt.savefig(filename.with_suffix('.pdf'),bbox_inches='tight')\n",
    "#plt.savefig(filename.with_suffix('.png'),bbox_inches='tight',dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overluminous sources\n",
    "\n",
    "the following objects are marked as overluminous. \n",
    "\n",
    "```\n",
    " 'NGC1300' : [3069],\n",
    " 'NGC1512' : [277], \n",
    " 'NGC1566' : [137],\n",
    " 'NGC1672' : [203,211],\n",
    " 'NGC2835' : [673],\n",
    " 'NGC4303' : [421],\n",
    " 'NGC4321' : [2111],\n",
    " 'NGC7496' : [408,352],\n",
    " ```\n",
    " \n",
    " NGC1300: is classified as an HII-region, never appears again\n",
    " NGC1512: is a SNR and does not appear in PNLF\n",
    " NGC1566: one PN appears as overluminous\n",
    " NGC1672: one SNR and one PN\n",
    " NGC2835: one PN that appears as such\n",
    " NGC4303: one PN appears and one SNR that could be a PN\n",
    " NGC4321: one PN that appears as such\n",
    " NGC7496: one PN that appears. 352 is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='NGC7496'\n",
    "catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "if catalogue_file.is_file():\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "    catalogue['overluminous'] = catalogue['overluminous'].astype(bool)\n",
    "catalogue[catalogue['overluminous']][['id','mOIII','type','SNRorPN','overluminous']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RGB image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue_file = basedir / 'data' / 'catalogues' / f'nebulae.txt'\n",
    "if catalogue_file.is_file():\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['overluminous'] = catalogue['note']=='OL'\n",
    "    catalogue['exclude'] = catalogue['note']=='EX'\n",
    "sample = catalogue[catalogue['overluminous']]\n",
    "\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.io import ReadLineMaps\n",
    "from pnlf.auxiliary import filter_table\n",
    "from pnlf.plot.utils import radial_profile, create_RGB\n",
    "\n",
    "\n",
    "filename = basedir / 'reports' / f'all_galaxies_exclude'\n",
    "\n",
    "size = 40\n",
    "\n",
    "catalogue_file = basedir / 'data' / 'catalogues' / f'nebulae.txt'\n",
    "if catalogue_file.is_file():\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['overluminous'] = catalogue['note']=='OL'\n",
    "    catalogue['exclude'] = catalogue['note']=='EX'\n",
    "sample = catalogue[catalogue['exclude']]\n",
    "\n",
    "n_objects = len(sample)\n",
    "print(f'plotting cutouts for {n_objects} objects')\n",
    "ncols = 5\n",
    "nrows = int(np.ceil(n_objects/ncols))\n",
    "\n",
    "width = two_column\n",
    "fig, axes = plt.subplots(nrows=nrows,ncols=ncols,figsize=(width,width/ncols*nrows))\n",
    "axes_iter = iter(axes.flatten())\n",
    "\n",
    "failed = 0\n",
    "for row in sample:\n",
    "    \n",
    "    name = row['gal_name']\n",
    "    galaxy = ReadLineMaps(data_raw/'MUSE_DR2'/'MUSEDAP',name,**parameters[name])\n",
    "    \n",
    "    print(row['type'])\n",
    "\n",
    "    ax = next(axes_iter)\n",
    "\n",
    "    x,y = row[['x','y']]\n",
    "    aperture_size=2.5*row['fwhm']/2\n",
    "\n",
    "    star = Cutout2D(galaxy.OIII5006, (x,y), u.Quantity((size, size), u.pixel),wcs=galaxy.wcs)\n",
    "\n",
    "\n",
    "    rgb = create_RGB(galaxy.HA6562,galaxy.OIII5006,galaxy.SII6716,percentile=99)\n",
    "    yslice = slice(int(x-size/2),int(x+size/2))\n",
    "    xslice = slice(int(y-size/2),int(y+size/2))\n",
    "\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks([])\n",
    "\n",
    "    try:\n",
    "        im = ax.imshow(rgb[xslice,yslice,:],origin='lower')\n",
    "    except:\n",
    "        text = f'{name}: {row[\"id\"]}'\n",
    "        t = ax.text(0.06,0.87,text, transform=ax.transAxes,color='black',fontsize=7)\n",
    "        continue\n",
    "\n",
    "    '''\n",
    "    norm = simple_norm(star.data,clip=False,percent=99)\n",
    "    im = ax.imshow(star.data,norm=norm,origin='lower',cmap=plt.cm.Reds)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks([])\n",
    "    '''\n",
    "\n",
    "    aperture = CircularAperture((size/2+(x-int(x)),size/2+(y-int(y))),aperture_size)\n",
    "    aperture.plot(color='tab:red',lw=0.8,axes=ax)\n",
    "\n",
    "    profile = radial_profile(star.data,star.input_position_cutout)\n",
    "\n",
    "    ax2 = ax.inset_axes([0.02, 0.02, 0.32, 0.25])\n",
    "    ax2.set_yticks([])\n",
    "    ax2.set_xticks([])  \n",
    "\n",
    "    ax2.plot(profile,color='black')\n",
    "    ax2.axvline(aperture_size,color='tab:red',lw=0.5)\n",
    "\n",
    "    text = f'{name}, {row[\"id\"]} ({row[\"type\"]})'\n",
    "    t = ax.text(0.07,0.87,text, transform=ax.transAxes,color='black',fontsize=5)\n",
    "    t.set_bbox(dict(facecolor='white', alpha=1, ec='white'))\n",
    "\n",
    "\n",
    "    if (row['mOIII']<results.loc[name]['(m-M)']-3.97) and False:\n",
    "        for loc in ['bottom','top','right','left']:\n",
    "            ax.spines[loc].set_color('tab:orange')\n",
    "            ax.spines[loc].set_linewidth(1)\n",
    "    #t = ax.text(0.05,0.8,f'mOIII={row[\"mOIII\"]:.1f}', transform=ax.transAxes,color='black',fontsize=8)\n",
    "    #t.set_bbox(dict(facecolor='white', alpha=1, ec='white'))\n",
    "\n",
    "for i in range(nrows*ncols-n_objects+failed):\n",
    "    # remove the empty axes at the bottom\n",
    "    ax = next(axes_iter)\n",
    "    ax.remove()\n",
    "    \n",
    "plt.subplots_adjust(wspace=-0.01,hspace=0.05)\n",
    "if filename:\n",
    "    #plt.savefig(filename.with_suffix('.png'),dpi=600)\n",
    "    plt.savefig(filename.with_suffix('.pdf'),dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make a plot with growth curve, RGB, OIII and Halpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.plot.plot import create_RGB\n",
    "from pnlf.io import ReadLineMaps\n",
    "from pnlf.auxiliary import filter_table\n",
    "from pnlf.plot.plot import radial_profile\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import datetime\n",
    "\n",
    "filename = basedir / 'reports' / f'all_galaxies_overluminous_full'\n",
    "\n",
    "catalogue_file = basedir / 'data' / 'catalogues' / f'nebulae.txt'\n",
    "if catalogue_file.is_file():\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['overluminous'] = catalogue['note']=='OL'\n",
    "    catalogue['exclude'] = catalogue['note']=='EX'\n",
    "\n",
    "size = 40\n",
    "sample = catalogue[catalogue['overluminous']]\n",
    "\n",
    "ncols = 4\n",
    "nrows = 4\n",
    "\n",
    "width = 8.27\n",
    "N = len(sample)\n",
    "Npage = nrows # number we get on each page\n",
    "\n",
    "with PdfPages(filename.with_suffix('.pdf')) as pdf:\n",
    "\n",
    "    for i in range(int(np.ceil(N/Npage))):\n",
    "        print(f'working on page {i+1}')\n",
    "\n",
    "        sub_sample = sample[i*Npage:(i+1)*Npage]\n",
    "\n",
    "        fig, axes = plt.subplots(nrows=nrows,ncols=ncols,figsize=(width,width/ncols*nrows))\n",
    "\n",
    "        for row, (ax1,ax2,ax3,ax4) in zip(sub_sample,axes):  \n",
    "            \n",
    "            name = row['gal_name']\n",
    "            galaxy = ReadLineMaps(data_raw/'MUSE_DR2'/'MUSEDAP',name,**parameters[name])\n",
    "\n",
    "            x,y = row[['x','y']]\n",
    "            aperture_size=2.5*row['fwhm']/2\n",
    "            aperture = CircularAperture((size/2+(x-int(x)),size/2+(y-int(y))),aperture_size)\n",
    "\n",
    "            star = Cutout2D(galaxy.OIII5006, (x,y), u.Quantity((size, size), u.pixel),wcs=galaxy.wcs)\n",
    "            profile = radial_profile(star.data,star.input_position_cutout)\n",
    "\n",
    "            ax1.plot(profile,color='black')\n",
    "            ax1.axvline(aperture_size,color='tab:red',lw=0.5)\n",
    "            text = f'{name}: ID={row[\"id\"]}'\n",
    "            t = ax1.text(0.07,0.87,text, transform=ax1.transAxes,color='black',fontsize=7)\n",
    "            t.set_bbox(dict(facecolor='white', alpha=1, ec='white'))\n",
    "            ax1.axis('off')\n",
    "            \n",
    "            norm = simple_norm(star.data,clip=False,percent=99)\n",
    "            im = ax2.imshow(star.data,norm=norm,origin='lower',cmap=plt.cm.Greens)\n",
    "            aperture.plot(color='black',lw=0.8,axes=ax2)\n",
    "            ax2.axis('off')\n",
    "\n",
    "            star = Cutout2D(galaxy.HA6562, (x,y), u.Quantity((size, size), u.pixel),wcs=galaxy.wcs)\n",
    "            norm = simple_norm(star.data,clip=False,percent=99)\n",
    "            im = ax3.imshow(star.data,norm=norm,origin='lower',cmap=plt.cm.Reds)\n",
    "            aperture.plot(color='black',lw=0.8,axes=ax3)\n",
    "            ax3.axis('off')\n",
    "\n",
    "            rgb = create_RGB(galaxy.HA6562,galaxy.OIII5006,galaxy.SII6716,percentile=99)\n",
    "            yslice = slice(int(x-size/2),int(x+size/2))\n",
    "            xslice = slice(int(y-size/2),int(y+size/2))\n",
    "\n",
    "            im = ax4.imshow(rgb[xslice,yslice,:],origin='lower')\n",
    "            aperture.plot(color='tab:red',lw=0.8,axes=ax4)\n",
    "\n",
    "            ax4.axis('off')\n",
    "        \n",
    "        for (ax1,ax2,ax3,ax4) in axes[Npage-len(sub_sample):]:\n",
    "            print('removing axis')\n",
    "            ax1.axis('off')    \n",
    "            ax2.axis('off')    \n",
    "            ax3.axis('off')    \n",
    "            ax4.axis('off')    \n",
    "        \n",
    "        plt.subplots_adjust(wspace=-0.1, hspace=0)\n",
    "\n",
    "        \n",
    "\n",
    "        pdf.savefig()  # saves the current figure into a pdf page\n",
    "        plt.close()\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot all PNe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue_file = basedir / 'data' / 'catalogues' / f'nebulae.txt'\n",
    "catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "catalogue['overluminous'] = catalogue['note']=='OL'\n",
    "catalogue['exclude'] = catalogue['note']=='EX'\n",
    "catalogue['SkyCoord'] = SkyCoord(catalogue['RA'],catalogue['DEC'])\n",
    "group_distances = ascii.read(basedir/'data'/'literature distances'/'group_distances.txt')\n",
    "group_distances.add_index('Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'NGC7496'\n",
    "\n",
    "tmp = catalogue[catalogue['gal_name']==name]\n",
    "\n",
    "print(f\"N_PN = {np.sum(tmp['type']=='PN')}\")\n",
    "print(f\"overluminous N_PN = {np.sum((tmp['type']=='PN') & (tmp['overluminous']))}\")\n",
    "print(f\"excluded N_PN = {np.sum((tmp['type']=='PN') & (tmp['exclude']))}\")\n",
    "\n",
    "print(f\"N_SNR = {np.sum(tmp['type']=='SNR')}\")\n",
    "print(f\"overluminous N_SNR = {np.sum((tmp['type']=='SNR') & (tmp['overluminous']))}\")\n",
    "print(f\"excluded N_SNR = {np.sum((tmp['type']=='SNR') & (tmp['exclude']))}\")\n",
    "print(f\"SNR or PN = {np.sum((tmp['type']=='SNR') & (tmp['exclude']))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.io import ReadLineMaps\n",
    "from pnlf.auxiliary import filter_table\n",
    "from pnlf.plot.cutouts import multipage_cutout_with_profile\n",
    "\n",
    "name = 'NGC1512'\n",
    "\n",
    "filename = basedir / 'reports' / name / f'{name}_PN_cutouts'\n",
    "\n",
    "galaxy = ReadLineMaps(data_raw/'MUSE_DR2'/'MUSEDAP',name,**parameters[name])\n",
    "\n",
    "catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "if catalogue_file.is_file():\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "    catalogue['overluminous'] = catalogue['overluminous'].astype(bool)\n",
    "sample = catalogue[(catalogue['mOIII']<28) & (catalogue['type']=='PN')]\n",
    "sample.sort('mOIII')\n",
    "sample = sample[:24]\n",
    "\n",
    "multipage_cutout_with_profile(galaxy,sample,filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectrum of those objects\n",
    "I only downloaded datacubes for the DR1 galaxies (IC5332,NGC0628,NGC1087,NGC1365,NGC1512,NGC1566,NGC1672,NGC2835,NGC3351,NGC3627,NGC4254,NGC4535,NGC5068)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.auxiliary import annulus_mask, circular_mask\n",
    "from pnlf.io import ReadLineMaps\n",
    "from pnlf.auxiliary import filter_table\n",
    "\n",
    "name = 'NGC0628'\n",
    "\n",
    "filename = basedir / 'reports' / name / f'{name}_exclude'\n",
    "region_IDs = exclude[name]\n",
    "xlim=[4750,7000]\n",
    "size = 40\n",
    "\n",
    "print(f'plot spectra for {len(region_IDs)} regions')\n",
    "\n",
    "cube_path = Path('g:\\Archive')/'MUSE'/'DR1'/'datacubes'\n",
    "if name not in [x.stem.split('_')[0] for x in cube_path.iterdir()]:\n",
    "    raise FileNotFoundError(f'no datacube for {name}')\n",
    "with fits.open(cube_path / f'{name}_DATACUBE_FINAL.fits' , memmap=True, mode='denywrite') as hdul:\n",
    "    data_cube   = hdul[1].data\n",
    "    cube_header = hdul[1].header\n",
    "    \n",
    "galaxy = ReadLineMaps(data_raw/'MUSE_DR2'/'MUSEDAP',name,**parameters[name])\n",
    "\n",
    "catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "if catalogue_file.is_file():\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "\n",
    "fig = plt.figure(figsize=(two_column,len(region_IDs)*two_column/4)) \n",
    "gs = mpl.gridspec.GridSpec(len(region_IDs), 2, width_ratios=[1,3]) \n",
    "\n",
    "spectra = {}\n",
    "for i,region_ID in enumerate(region_IDs):\n",
    "    \n",
    "    x,y = filter_table(catalogue,id=region_ID)[['x','y']][0]\n",
    "\n",
    "    ax1 = fig.add_subplot(gs[2*i])\n",
    "    ax2 = fig.add_subplot(gs[2*i+1])\n",
    "    \n",
    "    r = Cutout2D(galaxy.OIII5006, (x,y), u.Quantity((size, size), u.pixel),wcs=galaxy.wcs)\n",
    "    norm = simple_norm(r.data,'linear',clip=False,percent=95)\n",
    "    ax1.imshow(r.data, origin='lower',norm=norm,cmap='Greys')\n",
    "\n",
    "    aperture = CircularAperture(r.position_cutout,8)\n",
    "    aperture.plot(color='tab:red',lw=1,axes=ax1)\n",
    "\n",
    "    t = ax1.text(0.07,0.87,f'{region_ID}', transform=ax1.transAxes,color='black',fontsize=7)\n",
    "    t.set_bbox(dict(facecolor='white', alpha=1, ec='white'))\n",
    "    ax1.set_xticks([])\n",
    "    ax1.set_yticks([])\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        # there will be NaNs in the subcube that is used for the sigma clipping\n",
    "        # astropy will issue a warning which we ignore in this enviornment\n",
    "        circle  = circular_mask(*data_cube.shape[1:],(x,y),4)\n",
    "        annulus = annulus_mask(*data_cube.shape[1:],(x,y),8,12) \n",
    "        _, bkg, _ = sigma_clipped_stats(data_cube[...,annulus],axis=1)\n",
    "    \n",
    "    spectrum = np.sum(data_cube[...,circle],axis=1)    \n",
    "    # the background is the median * the number of non zero pixel\n",
    "    spectrum_without_bkg = spectrum - bkg * np.sum(circle)\n",
    "    \n",
    "    #spectra = np.sum(data_cube[...,int(x)-1:int(x)+1,int(y)-1:int(y)+1],axis=(1,2))    \n",
    "    # the wavelenght coverage of MUSE\n",
    "    wavelength = np.linspace(4749.88,9349.88,data_cube.shape[0]) \n",
    "    \n",
    "    ax2.plot(wavelength,spectrum,color=tab10[1],label='with background')\n",
    "    ax2.plot(wavelength,spectrum_without_bkg,color=tab10[0],label='background subtracted')\n",
    "    #ax2.legend() \n",
    "\n",
    "    ax2.set(xlim=xlim,\n",
    "            ylabel=r'erg\\,/\\,s\\,/\\,\\AA')\n",
    "    if i ==0 :\n",
    "        ax2.set_title(name)\n",
    "    if i == len(region_IDs)-1:\n",
    "        ax2.set(xlabel=r'$\\lambda$\\,/\\,\\AA')\n",
    "    else:\n",
    "        ax2.set_xticklabels([])\n",
    "        \n",
    "    ax2.yaxis.tick_right()\n",
    "    ax2.yaxis.set_ticks_position('both')\n",
    "    ax2.yaxis.set_label_position(\"right\")\n",
    "    \n",
    "    # save spectra\n",
    "    spectra[f'{region_ID}_wavelength'] = wavelength\n",
    "    spectra[f'{region_ID}_spectra'] = spectrum\n",
    "    spectra[f'{region_ID}_bkg'] = bkg * np.sum(circle)\n",
    "    \n",
    "plt.subplots_adjust(wspace=0,hspace=0.05)\n",
    "    \n",
    "if filename:\n",
    "    plt.savefig(filename.with_suffix('.pdf'),dpi=600)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.auxiliary import annulus_mask, circular_mask\n",
    "\n",
    "name = 'NGC0628'\n",
    "\n",
    "cube_path = Path('g:\\Archive')/'MUSE'/'DR1'/'datacubes'\n",
    "if name not in [x.stem.split('_')[0] for x in cube_path.iterdir()]:\n",
    "    raise FileNotFoundError(f'no datacube for {name}')\n",
    "with fits.open(cube_path / f'{name}_DATACUBE_FINAL.fits' , memmap=True, mode='denywrite') as hdul:\n",
    "    data_cube   = hdul[1].data\n",
    "    cube_header = hdul[1].header\n",
    "    \n",
    "catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "if catalogue_file.is_file():\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "    \n",
    "\n",
    "def extract_spectra(cube,header,positions,region_ID,filename):\n",
    "    '''extract spectra from a spectral cube at given positions'''\n",
    "    \n",
    "    logger.info(f'extracting spectrum for {len(positions)} objects')\n",
    "    \n",
    "    wavelength = []\n",
    "    spectrum   = []\n",
    "    background = []\n",
    "    \n",
    "    radii = [22.48, 21.42, 22.12]\n",
    "    \n",
    "    for i,pos in enumerate(positions):\n",
    "        print(f'{i+1} of {len(positions)}')\n",
    "        print(radii[i])\n",
    "        x,y=pos\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            # there will be NaNs in the subcube that is used for the sigma clipping\n",
    "            # astropy will issue a warning which we ignore in this enviornment\n",
    "            circle  = circular_mask(*cube.shape[1:],(x,y),radii[i])\n",
    "            annulus = annulus_mask(*cube.shape[1:],(x,y),23,24) \n",
    "            _, bkg, _ = sigma_clipped_stats(cube[...,annulus],axis=1)\n",
    "\n",
    "        spectrum.append(np.sum(data_cube[...,circle],axis=1))  \n",
    "        background.append(bkg * np.sum(circle))\n",
    "        wavelength.append(np.linspace(header['CRVAL3'],header['CRVAL3']+header['NAXIS3']*header['CD3_3'],header['NAXIS3']))\n",
    "    \n",
    "    spectra = Table(data=[region_ID,wavelength,spectrum,background],\n",
    "                    names=['region_ID','wavelenght','spectrum','bkg'])\n",
    "\n",
    "    hdu = fits.BinTableHDU(spectra,name='spectra')\n",
    "    hdu.writeto(filename,overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#positions = catalogue[catalogue['type']=='PN'][['x','y']]\n",
    "#filename = basedir/'data'/'suspicious'/f'{name}_spectra_liz.fits'\n",
    "#extract_spectra(data_cube,cube_header,positions[:50],catalogue[catalogue['type']=='PN']['id'][:50],filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with fits.open(basedir/'data'/'suspicious'/'{}_spectra.fits'.format(name)) as hdul:\n",
    "    spec = Table(hdul[1].data)\n",
    "spec.add_index('region_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dap_path = Path('g:\\Archive')/'MUSE'/'DR1'/'MUSEDAP'/'NGC0628_MAPS.fits'\n",
    "with fits.open(dap_path) as hdul:\n",
    "    wcs = WCS(hdul['FLUX'].header)\n",
    "    \n",
    "\n",
    "ra  = np.array([24.1623,24.1645,24.1888])\n",
    "dec = np.array([15.7701,15.7958,15.7968])\n",
    "\n",
    "p_sk = SkyCoord(ra*u.degree,dec*u.degree)\n",
    "\n",
    "for sk in p_sk:\n",
    "    p_xy.append(sk.to_pixel(wcs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = basedir/'data'/'suspicious'/f'{name}_spectra_liz.fits'\n",
    "extract_spectra(data_cube,cube_header,positions,[1,2,3],filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_xy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = p_xy[0]\n",
    "width = 30\n",
    "sub_cube = data_cube[:,int(x)-width:int(x)+width,int(y)-width:int(y)+width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with fits.open(basedir/'data'/'suspicious'/f'{name}_spectra_liz.fits') as hdul:\n",
    "    spec = Table(hdul[1].data)\n",
    "spec.add_index('region_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = positions[0]\n",
    "\n",
    "plt.plot(data_cube[:,int(p[0]),int(p[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = catalogue[(np.isin(catalogue['type'],['PN','SNR'])) & (catalogue['mOIII']<28)][['id','x','y','RaDec','mOIII','type']]\n",
    "\n",
    "with open(basedir / 'data' / f'{name}_PN_and_SNR.txt','w',newline='\\n') as f:\n",
    "    ascii.write(sub,f,format='fixed_width_two_line',overwrite=True,delimiter_pad=' ',position_char='=')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spectral_cube import SpectralCube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sk in p_sk:\n",
    "    sep=sk.separation(catalogue['SkyCoord'])\n",
    "    row = catalogue[np.argmin(sep)]\n",
    "    print(catalogue[sep.__lt__(Angle('10\"'))]['type'])\n",
    "    print(f'{np.min(sep.to(u.arcsec)):.2f}, {row[\"id\"]}, {row[\"type\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Compare measured magnitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from astropy.coordinates import match_coordinates_sky # match sources against existing catalog\n",
    "from astropy.coordinates import Angle                 # work with angles (e.g. 123)\n",
    "\n",
    "from pnlf.load_references import NGC628, \\\n",
    "                                 pn_NGC628_kreckel, \\\n",
    "                                 snr_NGC628_kreckel, \\\n",
    "                                 pn_NGC628_herrmann, \\\n",
    "                                 NGC628_kreckel, \\\n",
    "                                 pn_NGC5068_herrmann, \\\n",
    "                                 pn_NGC3351_ciardullo, \\\n",
    "                                 pn_NGC3627_ciardullo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,(ax1,ax2) = plt.subplots(nrows=2,ncols=1,figsize=(single_column,single_column*1.8))\n",
    "\n",
    "'''\n",
    "   NGC0628\n",
    "'''\n",
    "\n",
    "name = 'NGC0628'\n",
    "catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "if catalogue_file.is_file():\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "catalogue['SkyCoord'] = SkyCoord(catalogue['RaDec'])\n",
    "catalogue = catalogue[(catalogue['type']=='PN') | ((catalogue['type']=='SNR') & (catalogue['SNRorPN']==True)) ]\n",
    "#catalogue = catalogue[np.isin(catalogue['type'],['PN','SNR'])]\n",
    "catalogue['R2'] = catalogue['OIII5006'] / (catalogue['HA6562']+catalogue['NII6583'])\n",
    "catalogue['dR2'] = catalogue['R2']  * np.sqrt(catalogue['OIII5006_err']/catalogue['OIII5006_err']**2 + 1/(catalogue['HA6562']+catalogue['NII6583'])**2 * (catalogue['HA6562_err']**2+catalogue['NII6583_err']**2) )                                  \n",
    "\n",
    "matchcoord = NGC628.copy()\n",
    "\n",
    "ID, sep, _  = match_coordinates_sky(matchcoord['SkyCoord'],catalogue['SkyCoord'])\n",
    "matchcoord['mOIII_measured'] = catalogue[ID]['mOIII']\n",
    "matchcoord['dmOIII_measured'] = catalogue[ID]['dmOIII']\n",
    "matchcoord['R_measured'] = catalogue[ID]['R2']\n",
    "matchcoord['dR_measured'] = catalogue[ID]['dR2']\n",
    "crit = sep.__lt__(Angle(\"0.5s\"))\n",
    "\n",
    "for s,c in zip(['Kreckel PN','Kreckel SNR','Herrmann PN'],['tab:red','tab:orange','tab:blue']):\n",
    "    tmp = matchcoord[(matchcoord['source']==s) & crit]\n",
    "    ax1.errorbar(tmp['mOIII'],tmp['mOIII_measured'],\n",
    "                 yerr = tmp['dmOIII_measured'],\n",
    "                 marker='o',ms=2,ls='none',mec=c,mfc=c,ecolor=c,label=s)\n",
    "    tmp = matchcoord[(matchcoord['source']==s) & crit]\n",
    "    ax2.errorbar(tmp['R'],tmp['R_measured'],\n",
    "                 #xerr = tmp['dR'],\n",
    "                 #yerr = tmp['dR_measured'],\n",
    "                 marker='o',ms=2,ls='none',mec=c,mfc=c,ecolor=c,label=s)\n",
    "\n",
    "\n",
    "'''\n",
    "   NGC5068\n",
    "'''\n",
    "name = 'NGC5068'\n",
    "catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "if catalogue_file.is_file():\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "catalogue['SkyCoord'] = SkyCoord(catalogue['RaDec'])\n",
    "catalogue = catalogue[np.isin(catalogue['type'],['PN','SNR'])]\n",
    "catalogue['R2'] = catalogue['OIII5006'] / (catalogue['HA6562']+catalogue['NII6583'])\n",
    "catalogue['dR2'] = catalogue['R2']  * np.sqrt(catalogue['OIII5006_err']/catalogue['OIII5006_err']**2 + 1/(catalogue['HA6562']+catalogue['NII6583'])**2 * (catalogue['HA6562_err']**2+catalogue['NII6583_err']**2) )                                  \n",
    "\n",
    "matchcoord = pn_NGC5068_herrmann.copy()\n",
    "\n",
    "ID, sep, _  = match_coordinates_sky(matchcoord['SkyCoord'],catalogue['SkyCoord'])\n",
    "matchcoord['mOIII_measured'] = catalogue[ID]['mOIII']\n",
    "matchcoord['dmOIII_measured'] = catalogue[ID]['dmOIII']\n",
    "matchcoord['R_measured'] = catalogue[ID]['R2']\n",
    "matchcoord['dR_measured'] = catalogue[ID]['dR2']\n",
    "crit = sep.__lt__(Angle(\"0.5s\"))\n",
    "\n",
    "tmp = matchcoord[(crit)]\n",
    "c = 'tab:green'\n",
    "ax1.errorbar(tmp['mOIII'],tmp['mOIII_measured'],\n",
    "             yerr = tmp['dmOIII_measured'],\n",
    "             #xerr = tmp['dmOIII'],\n",
    "             marker='o',ms=2,ls='none',mec=c,mfc=c,ecolor=c,label=s)\n",
    "ax2.errorbar(tmp['R'],tmp['R_measured'],\n",
    "             #xerr = tmp['sigma_R'],\n",
    "             #yerr = tmp['dR_measured'],\n",
    "             marker='o',ms=2,ls='none',mec=c,mfc=c,ecolor=c,label=s)\n",
    "\n",
    "\n",
    "'''\n",
    "   NGC3627\n",
    "'''\n",
    "name = 'NGC3627'\n",
    "catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "if catalogue_file.is_file():\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "catalogue['SkyCoord'] = SkyCoord(catalogue['RaDec'])\n",
    "catalogue = catalogue[np.isin(catalogue['type'],['PN','SNR'])]\n",
    "\n",
    "matchcoord = pn_NGC3627_ciardullo.copy()\n",
    "\n",
    "ID, sep, _  = match_coordinates_sky(matchcoord['SkyCoord'],catalogue['SkyCoord'])\n",
    "matchcoord['mOIII_measured'] = catalogue[ID]['mOIII']\n",
    "matchcoord['dmOIII_measured'] = catalogue[ID]['dmOIII']\n",
    "crit = sep.__lt__(Angle(\"0.5s\"))\n",
    "\n",
    "tmp = matchcoord[crit]\n",
    "c = 'cyan'\n",
    "ax1.errorbar(tmp['mOIII'],tmp['mOIII_measured'],\n",
    "             yerr = tmp['dmOIII_measured'],\n",
    "             marker='o',ms=2,ls='none',mec=c,mfc=c,ecolor=c,label='NGC3627')\n",
    "\n",
    "\n",
    "'''\n",
    "   NGC3351\n",
    "'''\n",
    "name = 'NGC3351'\n",
    "catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "if catalogue_file.is_file():\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "catalogue['SkyCoord'] = SkyCoord(catalogue['RaDec'])\n",
    "catalogue = catalogue[np.isin(catalogue['type'],['PN','SNR'])]\n",
    "catalogue['R2'] = catalogue['OIII5006'] / (catalogue['HA6562']+catalogue['NII6583'])\n",
    "catalogue['dR2'] = catalogue['R2']  * np.sqrt(catalogue['OIII5006_err']/catalogue['OIII5006_err']**2 + 1/(catalogue['HA6562']+catalogue['NII6583'])**2 * (catalogue['HA6562_err']**2+catalogue['NII6583_err']**2) )                                  \n",
    "\n",
    "matchcoord = pn_NGC3351_ciardullo.copy()\n",
    "\n",
    "ID, sep, _  = match_coordinates_sky(matchcoord['SkyCoord'],catalogue['SkyCoord'])\n",
    "matchcoord['mOIII_measured'] = catalogue[ID]['mOIII']\n",
    "matchcoord['dmOIII_measured'] = catalogue[ID]['dmOIII']\n",
    "crit = sep.__lt__(Angle(\"0.5s\"))\n",
    "\n",
    "tmp = matchcoord[crit]\n",
    "c = 'purple'\n",
    "ax1.errorbar(tmp['mOIII'],tmp['mOIII_measured'],\n",
    "             yerr = tmp['dmOIII_measured'],\n",
    "             marker='o',ms=2,ls='none',mec=c,mfc=c,ecolor=c,label='NGC3351')\n",
    "\n",
    "\n",
    "ax1.plot([25,27.5],[25,27.5],color='black',lw=0.4)\n",
    "ax1.set(xlim=[25,27.5],ylim=[25,27.5])\n",
    "ax1.set_xlabel(r'$\\mathrm{m}_{[\\mathrm{O}\\,\\tiny{\\textsc{iii}}]}$ existing studies')\n",
    "ax1.set_ylabel(r'$\\mathrm{m}_{[\\mathrm{O}\\,\\tiny{\\textsc{iii}}]}$ this work')\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "xmin,xmax = 0,7\n",
    "ymin,ymax = 0,7\n",
    "ax2.plot([xmin,xmax],[xmin,xmax],color='black',lw=0.4)\n",
    "ax2.set_xlim([xmin,xmax])\n",
    "ax2.set_ylim([ymin,ymax])\n",
    "ax2.set_xlabel(r'$I_{[\\mathrm{O}\\,\\tiny{\\textsc{iii}}]}\\;/\\;(I_{\\mathrm{H}\\,\\alpha}+I_{[\\mathrm{N}\\,\\tiny{\\textsc{ii}}]})$ existing studies')\n",
    "ax2.set_ylabel(r'$I_{[\\mathrm{O}\\,\\tiny{\\textsc{iii}}]}\\;/\\;(I_{\\mathrm{H}\\,\\alpha}+I_{[\\mathrm{N}\\,\\tiny{\\textsc{ii}}]})$ this work')\n",
    "#ax2.legend(loc=2)\n",
    "\n",
    "plt.savefig(basedir / 'reports' / f'flux_comparison.pdf',dpi=600)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "name = 'NGC0628'\n",
    "catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "if catalogue_file.is_file():\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "catalogue['SkyCoord'] = SkyCoord(catalogue['RaDec'])\n",
    "catalogue = catalogue[np.isin(catalogue['type'],['PN','SNR'])]\n",
    "catalogue['R2'] = catalogue['OIII5006'] / (catalogue['HA6562']+catalogue['NII6583'])\n",
    "catalogue['dR2'] = catalogue['R2']  * np.sqrt(catalogue['OIII5006_err']/catalogue['OIII5006_err']**2 + 1/(catalogue['HA6562']+catalogue['NII6583'])**2 * (catalogue['HA6562_err']**2+catalogue['NII6583_err']**2) )                                  \n",
    "\n",
    "matchcoord = NGC628.copy()\n",
    "\n",
    "ID, sep, _  = match_coordinates_sky(matchcoord['SkyCoord'],catalogue['SkyCoord'])\n",
    "matchcoord['IDf'] = ID\n",
    "matchcoord['mOIII_measured'] = catalogue[ID]['mOIII']\n",
    "matchcoord['dmOIII_measured'] = catalogue[ID]['dmOIII']\n",
    "matchcoord['R_measured'] = catalogue[ID]['R2']\n",
    "matchcoord['dR_measured'] = catalogue[ID]['dR2']\n",
    "crit = sep.__lt__(Angle(\"0.5s\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## measure (m-M) from inner and outer PNe\n",
    "\n",
    "the metallicity and with it $M*$ decreases in the outer regions of the galaxies. A smaller $M*$ should lead to a larger distance. Therefore the PNe in the outer parts should yield a larger distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "abundance_gradients = ascii.read(basedir/'data'/'external'/'radial_abundance_gradients.txt',\n",
    "                                names=['name','R0','g_r25'])\n",
    "abundance_gradients.add_index('name')\n",
    "\n",
    "pnlf_io = ascii.read(basedir/'data'/'interim'/ 'pnlf_io.txt')\n",
    "pnlf_io.add_index('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from regions import EllipseSkyRegion\n",
    "\n",
    "name = 'NGC1433'\n",
    "\n",
    "logOH_sun = 8.87\n",
    "deltaM = lambda OH: 0.928*OH**2+0.225*OH+0.014\n",
    "\n",
    "try:\n",
    "    mu_trgb = trgb.loc[name]['trgb_(m-M)']\n",
    "except:\n",
    "    print(f'no TRGB for {name}')\n",
    "    mu_trgb=0\n",
    "completeness = parameters[name]['completeness_limit']\n",
    "binsize = parameters[name]['binsize']\n",
    "\n",
    "catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "if catalogue_file.is_file():\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "    catalogue['overluminous'] = catalogue['overluminous'].astype(bool)\n",
    "\n",
    "catalogue['SkyCoord'] = SkyCoord(catalogue['RaDec'])\n",
    "catalogue = catalogue[(catalogue['type']=='PN') & (~catalogue['exclude']) & (~catalogue['overluminous']) & (catalogue['mOIII']<completeness)]\n",
    "\n",
    "center = sample_table.loc[name]['SkyCoord']\n",
    "posang = sample_table.loc[name]['posang']\n",
    "inclination = sample_table.loc[name]['Inclination']\n",
    "eccentricity = np.sin(inclination*u.deg).value\n",
    "\n",
    "r25 = sample_table.loc[name]['r25']*u.arcmin\n",
    "\n",
    "catalogue['r'] = catalogue['SkyCoord'].separation(center)\n",
    "rmean = np.mean(catalogue['r']/r25).decompose()\n",
    "logOH_rmean = abundance_gradients.loc[name]['R0']+rmean*abundance_gradients.loc[name]['g_r25']\n",
    "\n",
    "print(f'rmean = {rmean:.2f} r25')\n",
    "print(f'dM*={deltaM(logOH_rmean-logOH_sun):.3f}')\n",
    "\n",
    "with fits.open(data_ext/'MUSE_DR2'/'MUSEDAP'/f'{name}_MAPS.fits') as hdul:\n",
    "    wcs = WCS(hdul['OIII5006_FLUX '].header)\n",
    "    OIII = hdul['OIII5006_FLUX'].data\n",
    "    Halpha = hdul['HA6562_FLUX'].data\n",
    "    \n",
    "catalogue['region'] = '     '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def split_radial(catalogue,r25,center,eccentricity,posang,wcs):\n",
    "    threshold = 0.5\n",
    "    tried = set()\n",
    "    while True: \n",
    "        width = threshold*r25\n",
    "        aperture = EllipseSkyRegion(center,\n",
    "                                width=width,\n",
    "                                height=np.sqrt((width)**2 * (1-eccentricity**2)),\n",
    "                                angle=(posang-90)*u.deg)\n",
    "        inside = aperture.contains(catalogue['SkyCoord'],wcs)\n",
    "        ratio = np.sum(inside)/np.sum(~inside)\n",
    "\n",
    "        if threshold in tried:\n",
    "            break\n",
    "        tried.add(threshold)\n",
    "\n",
    "        if np.abs(ratio-1)<0.02:\n",
    "            break\n",
    "        elif ratio>1:\n",
    "            threshold/=1.02\n",
    "        elif ratio<1:\n",
    "            threshold*=1.02\n",
    "\n",
    "    width = threshold*r25\n",
    "    aperture = EllipseSkyRegion(center,\n",
    "                            width=width,\n",
    "                            height=np.sqrt((width)**2 * (1-eccentricity**2)),\n",
    "                            angle=(posang-90)*u.deg)\n",
    "    catalogue['region'] = 'inner'\n",
    "    catalogue['region'][~aperture.contains(catalogue['SkyCoord'],wcs)] = 'outer'\n",
    "    print(f'width={threshold:.3f} r25')\n",
    "\n",
    "    return catalogue,threshold,aperture\n",
    "\n",
    "def split_quadrants(catalogue,wcs,posang):\n",
    "    \n",
    "    catalogue['region'] = 'south'\n",
    "    x0,y0 = center.to_pixel(wcs)\n",
    "    x,y = catalogue['x'],catalogue['y']\n",
    "\n",
    "    north = (y>y0-np.sin((posang)/180*np.pi)*(x-x0))\n",
    "    south = (y<y0-np.sin((posang)/180*np.pi)*(x-x0))\n",
    "    east = (x<x0+np.cos((posang-90)/180*np.pi)*(y-y0))\n",
    "    west = (x>x0+np.cos((posang-90)/180*np.pi)*(y-y0))\n",
    "\n",
    "    catalogue['region'][north & west] = 'nw'\n",
    "    catalogue['region'][north & east] = 'ne'\n",
    "    catalogue['region'][south & west] = 'sw'\n",
    "    catalogue['region'][south & east] = 'se'\n",
    "    \n",
    "    return catalogue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "split into inner/outer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "catalogue,threshold,aperture = split_radial(catalogue,r25,center,eccentricity,posang,wcs)\n",
    "\n",
    "r = width/r25\n",
    "\n",
    "logOH1 = abundance_gradients.loc[name]['R0']\n",
    "logOH2 = abundance_gradients.loc[name]['R0']+r*abundance_gradients.loc[name]['g_r25']\n",
    "\n",
    "print(f'inner dM*={deltaM(logOH1-logOH_sun):.3f}\\noutter dM*={deltaM(logOH2-logOH_sun):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "or split into quadrants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "catalogue['region'] = 'south'\n",
    "\n",
    "catalogue['region'][(center.ra<catalogue['SkyCoord'].ra) & (center.dec<catalogue['SkyCoord'].dec)] = 'north'\n",
    "catalogue['region'][(center.ra<catalogue['SkyCoord'].ra) & (center.dec>catalogue['SkyCoord'].dec)] = 'west'\n",
    "catalogue['region'][(center.ra>catalogue['SkyCoord'].ra) & (center.dec<catalogue['SkyCoord'].dec)] = 'east'\n",
    "catalogue['region'][(center.ra>catalogue['SkyCoord'].ra) & (center.dec>catalogue['SkyCoord'].dec)] = 'south'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "catalogue['region'] = 'west'\n",
    "\n",
    "catalogue['region'][(center.ra<catalogue['SkyCoord'].ra)] = 'west'\n",
    "catalogue['region'][(center.ra>catalogue['SkyCoord'].ra)] = 'east'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "catalogue['region'] = 'south'\n",
    "\n",
    "catalogue['region'][(center.dec<catalogue['SkyCoord'].dec)] = 'north'\n",
    "catalogue['region'][(center.dec>catalogue['SkyCoord'].dec)] = 'south'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# split into 4 quadrants based on position angel\n",
    "catalogue = split_quadrants(catalogue,wcs,posang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "compare central PNe to outer PNe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_quadrants(image,catalogue,wcs,aperture,posang,ax=None):\n",
    "\n",
    "    x0,y0 = center.to_pixel(wcs)\n",
    "    dx = 1000\n",
    "\n",
    "    majx1 = x0-np.cos(posang/180*np.pi)*dx\n",
    "    majx2 = x0+np.cos(posang/180*np.pi)*dx\n",
    "    majy1 = y0-np.sin(posang/180*np.pi)*dx\n",
    "    majy2 = y0+np.sin(posang/180*np.pi)*dx\n",
    "\n",
    "    minx1 = x0-np.cos((posang-90)/180*np.pi)*dx\n",
    "    minx2 = x0+np.cos((posang-90)/180*np.pi)*dx\n",
    "    miny1 = y0-np.sin((posang-90)/180*np.pi)*dx\n",
    "    miny2 = y0+np.sin((posang-90)/180*np.pi)*dx\n",
    "\n",
    "    if not ax:\n",
    "        fig = plt.figure(figsize=(single_column,single_column))\n",
    "        ax = fig.add_subplot(projection=wcs)\n",
    "\n",
    "    norm = simple_norm(image,clip=False,percent=97)\n",
    "    ax.imshow(image,norm=norm,cmap=plt.cm.Greys)\n",
    "\n",
    "    colors = iter(tab10)\n",
    "    for region in np.unique(catalogue['region']):\n",
    "        color = next(colors)\n",
    "        tmp1 = catalogue[catalogue['region']==region]\n",
    "\n",
    "        tmp = tmp1[aperture.contains(tmp1['SkyCoord'],wcs)]\n",
    "        sc = ax.errorbar(tmp['x'],tmp['y'],mec=color,mfc=color,fmt='o',ms=3,label=region)\n",
    "\n",
    "        tmp = tmp1[~aperture.contains(tmp1['SkyCoord'],wcs)]\n",
    "        ax.errorbar(tmp['x'],tmp['y'],fmt='o',mec=color,mfc='none',ms=3,mew=0.9)\n",
    "\n",
    "\n",
    "    pixel_aperture = aperture.to_pixel(wcs)\n",
    "    artist = pixel_aperture.as_artist(ec='black')\n",
    "    ax.add_artist(artist)\n",
    "\n",
    "    ax.plot([majx1,majx2],[majy1,majy2],color='black')\n",
    "    ax.plot([minx1,minx2],[miny1,miny2],color='black')\n",
    "\n",
    "    ax.set(xlim=(0,OIII.shape[1]),ylim=(0,OIII.shape[0]))\n",
    "    #ax.set_title(name)\n",
    "\n",
    "    ax.coords[0].set_ticks_visible(False)\n",
    "    ax.coords[0].set_ticklabel_visible(False)\n",
    "    ax.coords[1].set_ticks_visible(False)\n",
    "    ax.coords[1].set_ticklabel_visible(False)\n",
    "    \n",
    "    #ax.legend()\n",
    "    \n",
    "    return ax\n",
    "\n",
    "ax = plot_quadrants(OIII,catalogue,wcs,aperture,posang,ax=None)\n",
    "#plt.savefig(basedir/'reports'/name/f'{name}_regions.pdf',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "\n",
    "reg = np.unique(catalogue['region'])\n",
    "data1 = catalogue[catalogue['region']==reg[0]]['mOIII']\n",
    "data2 = catalogue[catalogue['region']==reg[1]]['mOIII']\n",
    "\n",
    "ks,pv = ks_2samp(data1,data2)\n",
    "print(f'{name}: statistic={ks:.3f}, pvalue={pv:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.analyse import MaximumLikelihood1D, pnlf, cdf\n",
    "from pnlf.plot.pnlf import plot_pnlf\n",
    "from scipy.stats import kstest\n",
    "\n",
    "regions = np.unique(catalogue['region'])\n",
    "if 'axes' in locals():\n",
    "    del axes\n",
    "for i,region in enumerate(regions):\n",
    "    \n",
    "    data = catalogue[catalogue['region']==region]['mOIII']\n",
    "    err  = catalogue[catalogue['region']==region]['dmOIII']\n",
    "    \n",
    "    if len(data)<15:\n",
    "        print(f'not enough data points ({len(data)}) for region {region}')\n",
    "        continue\n",
    "        \n",
    "    fitter = MaximumLikelihood1D(pnlf,\n",
    "                                 data[data<completeness],\n",
    "                                 err=err[data<completeness],\n",
    "                                 mhigh=completeness,Mmax=-4.47)\n",
    "    mu,mu_p,mu_m = fitter([29])\n",
    "    print('{}: {:.2f} + {:.2f} - {:.2f}'.format(region,mu,mu_p,mu_m))\n",
    "\n",
    "\n",
    "    #Plot PNLF\n",
    "    if 'axes' not in locals():\n",
    "        axes = plot_pnlf(data,mu,completeness,\n",
    "                 binsize=binsize,mhigh=28.5,Mmax=-4.47,color=tab10[i])\n",
    "    else:\n",
    "        axes = plot_pnlf(data,mu,completeness,\n",
    "                         binsize=binsize,mhigh=28.5,Mmax=-4.47,filename=None,color=tab10[i],axes=axes)\n",
    "    \n",
    "ax1,ax2 = axes \n",
    "h, l = ax2.get_legend_handles_labels()\n",
    "ax2.legend(h,regions)\n",
    "filename=basedir/'reports'/name/f'{name}_PNLF_radial'\n",
    "plt.savefig(filename.with_suffix('.pdf'),bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "NGC0628\n",
    "\n",
    "inner outer: statistic=0.272, pvalue=0.006\n",
    "inner: 29.78 + 0.08 - 0.15\n",
    "outer: 30.21 + 0.07 - 0.13\n",
    "\n",
    "\n",
    "statistic=0.244, pvalue=0.207\n",
    "ne: 29.81 + 0.10 - 0.21\n",
    "nw: 29.82 + 0.11 - 0.25\n",
    "se: 30.15 + 0.09 - 0.19\n",
    "sw: 29.94 + 0.10 - 0.23\n",
    "\n",
    "NGC3351\n",
    "\n",
    "inner outer: statistic=0.187, pvalue=0.141\n",
    "inner: 30.35 + 0.08 - 0.13\n",
    "outer: 30.32 + 0.08 - 0.13\n",
    "\n",
    "vergleicht nur 2 der 4\n",
    "ne: 30.22 + 0.10 - 0.19\n",
    "nw: 30.38 + 0.09 - 0.18\n",
    "se: 30.40 + 0.10 - 0.21\n",
    "sw: 30.45 + 0.10 - 0.21\n",
    "\n",
    "\n",
    "NGC1433\n",
    "\n",
    "NGC1433: statistic=0.170, pvalue=0.508\n",
    "inner: 31.37 + 0.07 - 0.10\n",
    "outer: 31.37 + 0.07 - 0.10\n",
    "\n",
    "\n",
    "NGC1433: statistic=0.222, pvalue=0.588\n",
    "ne: 31.29 + 0.09 - 0.19\n",
    "nw: 31.41 + 0.09 - 0.16\n",
    "se: 31.42 + 0.09 - 0.16\n",
    "w: 31.36 + 0.08 - 0.14\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Multiple galaxies at once "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nebulae = ascii.read(basedir/'data'/'catalogues'/'nebulae.txt')\n",
    "nebulae['SkyCoord'] = SkyCoord(nebulae['RA'],nebulae['DEC'])\n",
    "nebulae = nebulae[(nebulae['type']=='PN')&(nebulae['note']!='OL')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from regions import EllipseSkyRegion\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "sample = ['NGC0628','NGC1433','NGC3351','NGC3627','NGC4321','NGC5068']\n",
    "ncols = 3\n",
    "nrows = np.ceil(len(sample)/ncols)\n",
    "\n",
    "fig1 = plt.figure(figsize=(two_column,two_column/1.5))\n",
    "fig2 = plt.figure(figsize=(two_column,two_column/1.5))\n",
    "\n",
    "for i,name in enumerate(sample):\n",
    "    \n",
    "    catalogue = nebulae[nebulae['gal_name']==name].copy()\n",
    "    \n",
    "    # some parameters of the galaxy\n",
    "    completeness = parameters[name]['completeness_limit']\n",
    "    binsize = parameters[name]['binsize']\n",
    "    center = sample_table.loc[name]['SkyCoord']\n",
    "    posang = sample_table.loc[name]['posang']\n",
    "    inclination = sample_table.loc[name]['Inclination']\n",
    "    eccentricity = np.sin(inclination*u.deg).value\n",
    "    r25 = sample_table.loc[name]['r25']*u.arcmin\n",
    "    catalogue['r'] = catalogue['SkyCoord'].separation(center)\n",
    "    \n",
    "    with fits.open(data_ext/'MUSE_DR2'/'MUSEDAP'/f'{name}_MAPS.fits') as hdul:\n",
    "        wcs = WCS(hdul['OIII5006_FLUX '].header)\n",
    "        OIII = hdul['OIII5006_FLUX'].data\n",
    "        Halpha = hdul['HA6562_FLUX'].data\n",
    "    \n",
    "    # split evenly between inner and outer\n",
    "    catalogue,threshold,aperture = split_radial(catalogue,r25,center,eccentricity,posang,wcs)\n",
    "    # split into quadrants\n",
    "    #catalogue = split_quadrants(catalogue,wcs,posang)\n",
    "    \n",
    "    # plot with the position of the PN and split into quadrants/radial\n",
    "    ax1 = fig1.add_subplot(nrows,ncols,i+1,projection=wcs)\n",
    "    ax1 = plot_quadrants(OIII,catalogue,wcs,aperture,posang,ax=ax1)\n",
    "    t = ax1.text(0.05,0.9,f'{name}', transform=ax1.transAxes,fontsize=6)\n",
    "    t.set_bbox(dict(facecolor='white', alpha=1, ec='white'))\n",
    "\n",
    "    # the cumulative luminosity function plot\n",
    "    ax2 = fig2.add_subplot(nrows,ncols,i+1)\n",
    "    regions = np.unique(catalogue['region'])\n",
    "    colors = iter(tab10)\n",
    "    for j,region in enumerate(regions):\n",
    "        data = catalogue[catalogue['region']==region]['mOIII']\n",
    "        N = len(data)        \n",
    "        color = next(colors)\n",
    "        ax2.plot(data,np.arange(1,N+1,1),ls='-',mfc=color,mec=color,ms=1,marker='o',label=region)\n",
    "\n",
    "    reg = np.unique(catalogue['region'])\n",
    "    data1 = catalogue[catalogue['region']==reg[0]]['mOIII']\n",
    "    data2 = catalogue[catalogue['region']==reg[1]]['mOIII']\n",
    "    ks,pv = ks_2samp(data1,data2)\n",
    "    print(f'{name}: statistic={ks:.3f}, pvalue={pv:.3f}')\n",
    "    \n",
    "    ax2.text(0.68,0.08,f'{name}', transform=ax2.transAxes,fontsize=7)\n",
    "    ax2.text(0.05,0.78,f'$p$-value$={pv:.2f}$',transform=ax2.transAxes,fontsize=7)\n",
    "    ax2.text(0.05,0.88,f'$D_{{max}}={ks:.3f}$', transform=ax2.transAxes,fontsize=7)\n",
    "\n",
    "    if i%ncols==0:\n",
    "        ax2.set(ylabel='Cumulative N')\n",
    "    if i//ncols==nrows-1:\n",
    "        ax2.set(xlabel=r'$m_{[\\mathrm{OIII}]}$ / mag')\n",
    "fig1.tight_layout() \n",
    "fig2.tight_layout() \n",
    "\n",
    "fig1.savefig(basedir/'reports'/'subsamples_map.pdf',dpi=600,bbox_inches='tight')\n",
    "fig2.savefig(basedir/'reports'/'subsamples_cum_PNLF.pdf',dpi=600,bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Something else ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "row = [name,threshold,mui,muo,deltaM(logOH1-logOH_sun),deltaM(logOH2-logOH_sun)]\n",
    "if name in pnlf_io['name']:\n",
    "    pnlf_io.loc[name] = row \n",
    "else:\n",
    "    pnlf_io.add_row(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for col in pnlf_io.columns[1:]:\n",
    "    pnlf_io[col].info.format='%.3f'\n",
    "    \n",
    "with open(basedir/'data'/'interim'/ 'pnlf_io.txt','w',newline='\\n') as f:\n",
    "    ascii.write(pnlf_io,f,format='fixed_width_two_line',overwrite=True,delimiter_pad=' ',position_char='=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pnlf_io['err(m-M)'] = 0.0\n",
    "\n",
    "for row in pnlf_io:\n",
    "    row['err(m-M)'] = np.sqrt(2)*results.loc[row['name']]['err+(m-M)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = np.arange(len(pnlf_io))\n",
    "\n",
    "pnlf_io.sort('r')\n",
    "fig,ax=plt.subplots()\n",
    "\n",
    "ax.axhline(0,color='black',lw=1)\n",
    "ax.errorbar(x,pnlf_io['(m-M)outer']-pnlf_io['(m-M)inner'],\n",
    "            yerr=pnlf_io['err(m-M)'],fmt='o',color='tab:red',label='(m-M)')\n",
    "ax.scatter(x,pnlf_io['dM*inner']-pnlf_io['dM*outer'],color='tab:blue',label='$\\Delta M*$')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(pnlf_io['name'],rotation=90)\n",
    "ax.set(ylabel=r'outer - inner')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pnlf_io['d(m-M)'] = pnlf_io['(m-M)outer']-pnlf_io['(m-M)inner']\n",
    "pnlf_io['dM*'] = pnlf_io['dM*outer']-pnlf_io['dM*inner']\n",
    "\n",
    "for col in pnlf_io.columns[1:]:\n",
    "    pnlf_io[col].info.format='%.3f'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pnlf_io.sort('name')\n",
    "ascii.write(pnlf_io[['name','r','d(m-M)','dM*']], sys.stdout, Writer = ascii.Latex,\n",
    "            latexdict = {'tabletype': 'table*'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metallicity dependance of the zero point\n",
    "\n",
    "the zeropoint $M*$ of the PNLF must be measured from galaxies with known distances. Ciardullo+2002 suggested a quadratic dependence on metallicity. Here we try to validate this assumption by comparing our measured distances to TRGB distances and infer $M*$. \n",
    "\n",
    "From **Ferrares+2000**\n",
    "\n",
    "The OIII5007 magnitude of the PNLF, m*, uncorrected for foreground extinction, is listed in column (9) of Table 3. Because PNLF distance moduli are calculated by tting the luminosity function with a standard template (e.g., Ciardullo et al. 1989b), only the nal distance moduli are published. From these we derived m* a posteriori by subtracting the zero point (and the extinction correction, if applied) adopted by the authors. The PNLF distances to the SMC, NGC 3109, and NGC 5253, listed in Table 3, are not well constrained. The planetary nebula (PN) sample in NGC 3109 (Richer & McCall 1992) includes only seven objects, and an upper limit to the distance is derived from the brightest of the PNs observed. Jacoby, Walker, & Ciardullo (1990) advise against the use of the PNLF distance to the SMC because of the small number of PNs dening the luminosity function. Finally, the small number of PNs detected in NGC 5253, the presence of strong internal dust extinction, and the galaxys very low metal abundance all conjoin to produce a very ill constrained PNLF magnitude cuto, unsuitable for distance determinations (Phillips et al. 1992). Uncertainties in the values of m* are summarized, for example, in Jacoby, Ciardullo, & Ford (1990). They include a contribution associated with the tting procedure (of the order of 0.10 mag), photometric zero points (D0.05 mag), the lter response calibration (D0.04 mag), and the uncertain denition of the empirical PNLF (D0.05 mag). Errors in the reddening estimate, which are sometimes included, have been removed (in quadrature) from the present analysis, since we only deal with uncorrected magnitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import join\n",
    "\n",
    "logOH_sun = 8.87\n",
    "\n",
    "abundance_gradients = ascii.read(basedir/'data'/'external'/'radial_abundance_gradients.txt',\n",
    "                                names=['name','R0','g_r25'])\n",
    "abundance_gradients.add_index('name')\n",
    "\n",
    "# create table with literature TRGB distances\n",
    "trgb_distances = {'name':[],'trgb_(m-M)':[],'trgb_err(m-M)':[],'refcode':[]}\n",
    "for name in results['name']:\n",
    "    litdist = ascii.read(basedir / 'data' / 'literature distances' / f'{name}.csv',delimiter=',',comment='#')\n",
    "    \n",
    "    if 'TRGB' in litdist['Method']:\n",
    "        sub = litdist[litdist['Method']=='TRGB']\n",
    "        sub.sort('Refcode',reverse=True)\n",
    "        \n",
    "        trgb_distances['name'].append(name)\n",
    "        trgb_distances['trgb_(m-M)'].append(sub['(m-M)'][0])\n",
    "        trgb_distances['trgb_err(m-M)'].append(sub['err(m-M)'][0])\n",
    "        trgb_distances['refcode'].append(sub['Refcode'][0])\n",
    "\n",
    "trgb = Table(trgb_distances)      \n",
    "trgb = join(results[['name','(m-M)','err+(m-M)','err-(m-M)']],trgb,'name')\n",
    "trgb = join(trgb,abundance_gradients,'name')\n",
    "trgb.add_index('name')\n",
    "\n",
    "# to calculate average position of PN\n",
    "catalogue = ascii.read(basedir/'data'/'catalogues'/'PN_candidates.txt')\n",
    "catalogue['SkyCoord'] = SkyCoord(catalogue['RA'],catalogue['DEC'])\n",
    "\n",
    "\n",
    "trgb['rmean'] = 0.0\n",
    "for name in trgb['name']:\n",
    "    tmp = catalogue[(catalogue['gal_name']==name) & (catalogue['overluminous']!='True')]\n",
    "    center = sample_table.loc[name]['SkyCoord']\n",
    "    r25 = sample_table.loc[name]['r25']*u.arcmin\n",
    "    trgb.loc[name]['rmean'] = np.mean(tmp['SkyCoord'].separation(center)/r25).decompose()\n",
    "trgb['logOH'] = trgb['R0'] +trgb['rmean']*trgb['g_r25']\n",
    "trgb['dM*'] = trgb['(m-M)']-trgb['trgb_(m-M)']\n",
    "trgb['[O/H]'] = trgb['logOH']-logOH_sun\n",
    "trgb['errM*'] = np.sqrt(trgb['err+(m-M)']**2 + trgb['trgb_err(m-M)'])\n",
    "trgb['errM*'].info.format = '%.2f'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### fix $(m-M)$ and fit $M*$\n",
    "\n",
    "we fix $(m-M)$ to the TRGB value and leave $M*$ as a free parameter \n",
    "\n",
    "IC5332,NGC0628,NGC1365,NGC1433,NGC1512,NGC1566,NGC2835,NGC3351,NGC3627,NGC4321,NGC5068"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "name = 'NGC5068'\n",
    "\n",
    "catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "if catalogue_file.is_file():\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "    catalogue['overluminous'] = catalogue['overluminous'].astype(bool)\n",
    "\n",
    "catalogue['SkyCoord'] = SkyCoord(catalogue['RaDec'])\n",
    "catalogue = catalogue[(catalogue['type']=='PN') & (~catalogue['exclude']) & (~catalogue['overluminous']) & (catalogue['mOIII']<completeness)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.plot.pnlf import plot_pnlf\n",
    "from pnlf.analyse import F\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def pnlf_Mmax(m,Mmax,mu,mhigh):\n",
    "\n",
    "    m = np.atleast_1d(m)\n",
    "    mlow = Mmax+mu\n",
    "    \n",
    "    normalization = 1/(F(mhigh,mu) - F(mlow,mu))    \n",
    "    out = normalization * np.exp(0.307*(m-mu)) * (1-np.exp(3*(Mmax-m+mu)))\n",
    "    out[(m>mhigh) | (m<mlow)] = 0\n",
    "    \n",
    "    return out\n",
    "\n",
    "def gaussian(x,mu,sig):\n",
    "    return 1/np.sqrt(2*np.pi*sig**2) * np.exp(-(x-mu)**2/(2*sig**2))\n",
    "\n",
    "def prior(param):\n",
    "    return gaussian(param,-4.47,0.08)\n",
    "\n",
    "# pre-process the data for the plot and read additional parameters\n",
    "data = catalogue[(catalogue['type']=='PN') & (~catalogue['exclude'])]['mOIII']\n",
    "err = catalogue[(catalogue['type']=='PN') & (~catalogue['exclude'])]['dmOIII']\n",
    "\n",
    "mu_trgb = trgb.loc[name]['trgb_(m-M)']\n",
    "completeness = parameters[name]['completeness_limit']\n",
    "binsize = parameters[name]['binsize']\n",
    "\n",
    "fitter = MaximumLikelihood1D(pnlf_Mmax,data[data<completeness],err=err[data<completeness],mu=mu_trgb,mhigh=completeness)\n",
    "Mmax = minimize(fitter.likelihood,[-4.47],method=fitter.method).x[0]\n",
    "\n",
    "mlow = Mmax+mu_trgb\n",
    "mhigh = 28.5\n",
    "\n",
    "print(f'{name}: Mmax={Mmax:.2f}, dMmax={Mmax+4.47:.2f}')\n",
    "\n",
    "axes = plot_pnlf(data,mu_trgb,completeness,binsize=binsize,mhigh=28.5,Mmax=Mmax,filename=None,color=tab10[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.analyse import MaximumLikelihood1D, F\n",
    "from pnlf.plot.pnlf import _plot_pnlf\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "names = list(trgb['name'])\n",
    "\n",
    "names.remove('NGC1433')\n",
    "names.remove('NGC1512')\n",
    "\n",
    "nrows = 3\n",
    "ncols = 3\n",
    "filename = None #basedir / 'reports' / f'all_galaxies_PNLF'\n",
    "\n",
    "#----------------------------------------------\n",
    "# DO NOT MODIFY BELOW\n",
    "#----------------------------------------------\n",
    "\n",
    "width = two_column\n",
    "fig, axes = plt.subplots(nrows=nrows,ncols=ncols,figsize=(width,width/ncols*nrows))\n",
    "axes_iter = iter(axes.flatten())\n",
    "\n",
    "trgb['dM*new'] = 0.0\n",
    "for name in names:\n",
    "    \n",
    "    catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "    if catalogue_file.is_file():\n",
    "        catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "        catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "    else:\n",
    "        print(f'no catalogue for {name}')\n",
    "        continue\n",
    "        \n",
    "    # get the next axis and find position on the grid\n",
    "    ax = next(axes_iter)\n",
    "    if nrows>1 and ncols>1:\n",
    "        i, j = np.where(axes == ax)\n",
    "        i,j=i[0],j[0]\n",
    "    elif ncols>1:\n",
    "        i,j = 0, np.where(axes==ax)[0]\n",
    "    elif nrows>1:\n",
    "        i,j = np.where(axes==ax)[0],0\n",
    "    else:\n",
    "        i,j=0,0\n",
    "        \n",
    "    # pre-process the data for the plot and read additional parameters\n",
    "    data = catalogue[(catalogue['type']=='PN') & (~catalogue['exclude'])]['mOIII']\n",
    "    err = catalogue[(catalogue['type']=='PN') & (~catalogue['exclude'])]['dmOIII']\n",
    "\n",
    "    mu_trgb = trgb.loc[name]['trgb_(m-M)']\n",
    "    completeness = parameters[name]['completeness_limit']\n",
    "\n",
    "    binsize = parameters[name]['binsize']\n",
    "\n",
    "    fitter = MaximumLikelihood1D(pnlf_Mmax,data[data<completeness],err=err[data<completeness],prior=prior,mu=mu_trgb,mhigh=completeness)\n",
    "    Mmax = minimize(fitter.likelihood,[-4.47],method=fitter.method).x[0]\n",
    "    \n",
    "    trgb.loc[name]['dM*new'] = Mmax+4.47\n",
    "    \n",
    "    mlow = Mmax+mu_trgb\n",
    "    mhigh = 28.5\n",
    "    \n",
    "    print(f'{name}: Mmax={Mmax:.2f}, dMmax={Mmax+4.47:.2f}')\n",
    "    \n",
    "    ax=_plot_pnlf(data,mu_trgb,completeness,binsize=binsize,mlow=mlow,mhigh=mhigh,ax=ax,ms=3)\n",
    "    ax.text(0.4,0.08,f'{name}', transform=ax.transAxes,fontsize=7)\n",
    "\n",
    "    #ax.set_xlim([mu-5,completeness+0.5])\n",
    "    # add labels to the axis\n",
    "    if i==nrows-1:\n",
    "        ax.set_xlabel(r'$m_{[\\mathrm{OIII}]}$ / mag')\n",
    "    if j==0:\n",
    "        ax.set_ylabel(r'N')\n",
    "    #ax.set_title(name)\n",
    "    #ax.set(xlim=[24,28.5])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### measure M* from our data\n",
    "\n",
    "Fit dM* (from TRGB distances) to log (O/H) to determine the zeropoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.modeling import models, fitting\n",
    "\n",
    "# OH = logOH-logOH_sun\n",
    "deltaM = lambda OH: 0.928*OH**2+0.225*OH+0.014\n",
    "\n",
    "logOH = np.linspace(8,9)\n",
    "\n",
    "model  = models.Polynomial1D(degree=2,c0=0.014, c1=0.225, c2= 0.928)\n",
    "fitter = fitting.LinearLSQFitter()\n",
    "\n",
    "mask = np.isin(trgb['name'],['NGC1433','NGC1512'])\n",
    "\n",
    "fit = fitter(model,trgb[~mask]['[O/H]'],trgb[~mask]['dM*'],weights=trgb[~mask]['errM*'])\n",
    "\n",
    "print('Ciardullo: c0=0.014, c1=0.225, c2= 0.928')\n",
    "print('Fit:       c0={:.3f}, c1={:.3f}, c2={:.3f}'.format(*fit.parameters))\n",
    "\n",
    "fig,ax = plt.subplots(nrows=1,ncols=1,figsize=(two_column,two_column/1.6))\n",
    "\n",
    "ax.errorbar(trgb[~mask]['logOH'],-4.47+trgb[~mask]['dM*'],yerr=trgb[~mask]['errM*'], fmt='ko',label='data')\n",
    "ax.errorbar(trgb[mask]['logOH'],-4.47+trgb[mask]['dM*'],yerr=trgb[mask]['errM*'], fmt='ro',label='excluded')\n",
    "ax.plot(logOH, -4.47+fit(logOH-logOH_sun), 'b-', lw=2,label='fit')\n",
    "ax.plot(logOH,-4.47+deltaM(logOH-logOH_sun),'k:',label='Ciarduollo+2002')\n",
    "\n",
    "ax.axhline(-4.47,ls='--',color='k')\n",
    "#ax.set(xlabel='12+log O/H',ylabel='M* (mag)')\n",
    "ax.set(xlim=[8,9],ylim=[-6.5,-2.5],xlabel=f'12+log O/H',ylabel='M* (mag)')\n",
    "ax.invert_yaxis()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cepheids = Table({\n",
    " 'name':['LMC','SMC','NGC224','NGC300','NGC598','NGC2403','NGC3031','NGC3351','NGC3368','NGC3627','NGC4258','NGC5253','NGC5457'],\n",
    " 'EBV' : [0.075,0.037,0.062,0.013,0.041,0.040,0.080,0.028,0.025,0.032,0.016,0.056,0.009],\n",
    " '(m-M)' : [18.50,19.01 ,24.38 ,26.53 ,24.56 ,27.48 ,27.75 ,29.85 ,29.97 ,29.86 ,29.44 ,27.56 ,29.13],\n",
    " 'err(m-M)' : [0.0,0.03,0.05,0.07,0.10,0.10,0.08,0.09,0.06,0.08,0.07,0.14,0.11],\n",
    " 'M*': [-4.56,-4.67,-4.66,-4.21,-4.08,-4.41,-4.52,-4.39,-4.65,-4.44,-4.51,-4.05,-4.28],\n",
    " '+M*': [0.13,0.40,0.14,0.67,0.16,0.16,0.12,0.19,0.12,0.12,0.13,0.63,0.15],\n",
    " '-M*' : [0.09,0.17,0.11,0.16,0.14,0.13,0.11,0.13,0.11,0.12,0.11,0.16,0.14],\n",
    " 'logOH': [8.50,8.03,8.98,8.35,8.82,8.80,8.75,9.24,9.20,9.25,8.85,8.15,8.50],\n",
    " 'dM*' : [0.06,0.48,0,0.15,0,0,0,0,0,0,0,0.33,0.06]\n",
    "})\n",
    "\n",
    "zeropoint = cepheids.copy()\n",
    "# dM* has a different meaning in the Cepheid table (some correction form Dopita+92)\n",
    "trgb['M*'] = -4.47+trgb['dM*']\n",
    "# add our own data\n",
    "for row in trgb:\n",
    "    if row['name'] not in ['NGC1433','NGC1512']:\n",
    "        new = [row['name'],0,row['(m-M)'],row['err+(m-M)'],row['M*'],row['errM*'],row['errM*'],row['logOH'],0]\n",
    "        zeropoint.add_row(new)\n",
    "    \n",
    "err_p,err_m = zeropoint['+M*'], zeropoint['-M*']\n",
    "\n",
    "zeropoint.sort('logOH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.modeling import models, fitting\n",
    "\n",
    "model  = models.Polynomial1D(degree=2,c0=0.014, c1=0.225, c2= 0.928)\n",
    "fitter = fitting.LinearLSQFitter()\n",
    "\n",
    "logOH = np.linspace(7.8,9.5)\n",
    "logOH_sun = 8.87\n",
    "\n",
    "fig,ax = plt.subplots(nrows=1,ncols=1,figsize=(single_column,single_column/1.5))\n",
    "\n",
    "fit = fitter(model,cepheids['logOH']-logOH_sun,cepheids['M*']+cepheids['dM*']+4.47,weights=1/cepheids['+M*'])\n",
    "#ax.plot(logOH, -4.47+fit(logOH-logOH_sun), 'r-', lw=1.2,label='fit cepheids',zorder=2)\n",
    "print('Ciardullo: c0=0.014, c1=0.225, c2= 0.928')\n",
    "print('Fit Cepheids: c0={:.3f}, c1={:.3f}, c2={:.3f}'.format(*fit.parameters))\n",
    "#ax.plot(logOH, -4.47+fit(logOH), 'b-', lw=2,label='fit Cepheids')\n",
    "\n",
    "fit = fitter(model,zeropoint['logOH']-logOH_sun,zeropoint['M*']+zeropoint['dM*']+4.47,weights=1/zeropoint['+M*'])\n",
    "print('Fit Cepheids+TRGB: c0={:.3f}, c1={:.3f}, c2={:.3f}'.format(*fit.parameters))\n",
    "\n",
    "ax.errorbar(cepheids['logOH'],cepheids['M*']+cepheids['dM*'],\n",
    "            yerr=[cepheids['+M*'],cepheids['-M*']], \n",
    "            fmt='o',color=tab10[4],ms=3,label='Cepheids',zorder=3)\n",
    "ax.errorbar(trgb[~mask]['logOH'],trgb[~mask]['M*'],\n",
    "            yerr=trgb[~mask]['errM*'], \n",
    "            fmt='o',color=tab10[2],ms=3,label='TRGB',zorder=3)\n",
    "\n",
    "ax.plot(logOH, -4.47+fit(logOH-logOH_sun), 'k-', lw=1.2,label='fit',zorder=2)\n",
    "ax.plot(logOH,-4.47+deltaM(logOH-logOH_sun),'k:',lw=1.2,label='Ciardullo+2002',color='gray',zorder=1)\n",
    "plt.locator_params(axis='y',nbins=5)\n",
    "\n",
    "# and now with a constant line\n",
    "model  = models.Polynomial1D(degree=1,c0=-4.5, c1=0)\n",
    "model.c1.fixed=True\n",
    "fit = fitter(model,trgb[~mask]['logOH'],trgb[~mask]['M*'],weights=1/trgb[~mask]['errM*'])\n",
    "print(f'TRGB: M*={fit.c0.value:.2f}')\n",
    "\n",
    "fit = fitter(model,cepheids['logOH'],cepheids['M*'],weights=1/cepheids['+M*'])\n",
    "print(f'Cepheids: M*={fit.c0.value:.2f}')\n",
    "\n",
    "fit = fitter(model,zeropoint['logOH'],zeropoint['M*'],weights=1/zeropoint['+M*'])\n",
    "print(f'together: M*={fit.c0.value:.2f}')\n",
    "\n",
    "#for row in zeropoint:\n",
    "#    ax.text(row['logOH'],row['M*'],row['name'],fontsize=3)\n",
    "\n",
    "#for row in cepheids:\n",
    "#    ax.text(row['logOH'],row['M*']+row['dM*'],row['name'])\n",
    "ax.axhline(fit.c0.value,ls='-',lw=1.2,color='k',zorder=2)\n",
    "\n",
    "#ax.set(xlabel='12+log O/H',ylabel='M* (mag)')\n",
    "ax.set(xlim=[8,9.3],ylim=[-5.5,-3.5],xlabel=f'12+log O/H',ylabel=r'$M^*$ / mag')\n",
    "ax.invert_yaxis()\n",
    "plt.legend(ncol=2)\n",
    "plt.savefig(basedir/'reports'/'zeropoint.pdf',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue = ascii.read(basedir/'data'/'catalogues'/'PN_candidates.txt')\n",
    "catalogue['SkyCoord'] = SkyCoord(catalogue['R.A.'],catalogue['Dec.'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redo fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.analyse import MaximumLikelihood1D, PNLF, pnlf, cdf\n",
    "from pnlf.plot.pnlf import plot_pnlf\n",
    "from scipy.stats import kstest\n",
    "from pnlf.utils import get_bolometric_luminosity\n",
    "from pnlf.analyse import N25\n",
    "import datetime\n",
    "date = datetime.date.today().strftime('%Y.%m.%d')\n",
    "\n",
    "results = ascii.read(basedir/'data'/'interim'/ 'results.txt',format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "results.add_index('name')  \n",
    "    \n",
    "for name in results['name']:\n",
    "    \n",
    "    print(f'working on {name}')\n",
    "    \n",
    "    tbl = ascii.read(basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt')\n",
    "    tbl['SNRorPN'] = tbl['SNRorPN'] == 'True'\n",
    "    tbl['exclude'] = tbl['exclude'].astype(bool)\n",
    "    tbl['overluminous'] = tbl['overluminous'].astype(bool)\n",
    "\n",
    "    completeness = parameters[name]['completeness_limit']\n",
    "    binsize = parameters[name]['binsize']\n",
    "\n",
    "    criteria1 = (tbl['type']=='PN') & ~tbl['exclude'] & ~tbl['overluminous'] & (tbl['mOIII']<completeness)\n",
    "    data1 = tbl[criteria1]['mOIII']\n",
    "    err1  = tbl[criteria1]['dmOIII']\n",
    "\n",
    "    criteria2 = ((tbl['type']=='PN')|((tbl['type']=='SNR')&(tbl['SNRorPN']))) & ~tbl['exclude'] & ~tbl['overluminous'] & (tbl['mOIII']<completeness)\n",
    "    data2 = tbl[criteria2]['mOIII']\n",
    "    err2  = tbl[criteria2]['dmOIII']\n",
    "    \n",
    "    fitter = MaximumLikelihood1D(pnlf,data1,err=err1,mhigh=completeness)\n",
    "    mu1,dp1,dm1 = fitter([28])\n",
    "\n",
    "    ks1,pv1 = kstest(data1,cdf,args=(mu1,completeness))\n",
    "    print(f'without SNR: statistic={ks1:.3f}, pvalue={pv1:.3f}')\n",
    "\n",
    "    fitter = MaximumLikelihood1D(pnlf,data2,err=err2,mhigh=completeness)\n",
    "    mu2,dp2,dm2 = fitter([28])\n",
    "\n",
    "    ks2,pv2 = kstest(data1,cdf,args=(mu2,completeness))\n",
    "    print(f'with SNR: statistic={ks2:.3f}, pvalue={pv2:.3f}')\n",
    "\n",
    "    print(f'without SNR: {mu1:.2f}+{dp1:.2f}-{dm1:.2f}\\nwith SNR:    {mu2:.2f}+{dp2:.2f}-{dm2:.2f} ({mu1-mu2:.2f})')\n",
    "\n",
    "    #filename = basedir / 'reports' / galaxy.name / f'{galaxy.name}_PNLF_with_SNR'\n",
    "    #axes = plot_pnlf(tbl[criteria1]['mOIII'],mu1,completeness,binsize=binsize,mhigh=30,color=tab10[0])\n",
    "    #axes = plot_pnlf(tbl[criteria2]['mOIII'],mu2,completeness,binsize=binsize,mhigh=30,filename=filename,color='grey',alpha=0.7,axes=axes)\n",
    "    #plt.show()\n",
    "\n",
    "    results.loc[name]['(m-M)'] = mu1\n",
    "    results.loc[name]['err+(m-M)'] = dp1\n",
    "    results.loc[name]['err-(m-M)'] = dm1\n",
    "    results.loc[name]['mu_SNR'] = mu2\n",
    "    results.loc[name]['mu_SNR+'] = dp2\n",
    "    results.loc[name]['mu_SNR-'] = dm2\n",
    "    results.loc[name]['d/Mpc'] = Distance(distmod=mu1).to(u.Mpc).value\n",
    "    results.loc[name]['err+d/Mpc'] = 2*np.log(10)*10**(mu1/5) * dp1 / 1e6\n",
    "    results.loc[name]['err-d/Mpc'] = 2*np.log(10)*10**(mu1/5) * dm1 / 1e6\n",
    "    \n",
    "    # save results to output table\n",
    "    for col in results.colnames[2:]:\n",
    "        if col.startswith('N_'):\n",
    "            results[col].info.format = '%.0f'\n",
    "        else:\n",
    "            results[col].info.format = '%.3f'\n",
    "    results['Lbol'].info.format = '%.2e'    \n",
    "    \n",
    "with open(basedir/'data'/'interim'/ 'results_new.txt','w',newline='\\n') as f:\n",
    "    ascii.write(results,f,format='fixed_width_two_line',overwrite=True,delimiter_pad=' ',position_char='=')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redo all distance plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.plot.pnlf import compare_distances\n",
    "\n",
    "name = 'NGC5068'\n",
    "mu,mu_m,mu_p = results.loc[name][['(m-M)','err-(m-M)','err+(m-M)']]\n",
    "\n",
    "print(name)\n",
    "filename = basedir / 'reports' / name / f'{name}_distances'\n",
    "distances = compare_distances(name,mu,mu_p,mu_m,filename=filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PN Number vs Mass etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=ascii.read(basedir/'reports'/'sample.txt')\n",
    "sample['SkyCoord'] = SkyCoord(sample['R.A.'],sample['Dec.'])\n",
    "sample.add_index('Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxies = {}\n",
    "\n",
    "for n in result['name']:\n",
    "    print('are you sure that you want to run this?')\n",
    "    break\n",
    "    filename = data_raw / 'MUSEDAP' / f'{n}_MAPS.fits'\n",
    "\n",
    "    with fits.open(filename) as hdul:\n",
    "        d=hdul['STELLAR_MASS_DENSITY'].data\n",
    "        galaxies[n]= np.nansum(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['mass']=sample['mass']\n",
    "result['Survey Area'] = sample['Survey Area']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the survey area from number of pixels and distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in result:\n",
    "    N_pix = row['N_pixel']\n",
    "    d = Distance(distmod=parameters[row['name']]['mu'])\n",
    "    A_pix = ((d*(0.2/206265))**2).to(u.kpc**2)\n",
    "    \n",
    "    print(f'{row[\"name\"]}: {d:.2f}, {N_pix*A_pix:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax1,ax2,ax3)=plt.subplots(ncols=3,nrows=1,figsize=(12,4))\n",
    "\n",
    "for row in result:\n",
    "    if row['N_PN']>1:\n",
    "        ax1.scatter(row['mass'],row['N_PN'])\n",
    "        ax1.text(row['mass'],row['N_PN']+2,row['name'],horizontalalignment='center')\n",
    "        \n",
    "        \n",
    "        ax2.scatter(row['Survey Area'],row['N_PN'])\n",
    "        ax2.text(row['Survey Area'],row['N_PN']+2,row['name'],horizontalalignment='center') \n",
    "\n",
    "        ax3.scatter(row['N_pixel'],row['N_PN'])\n",
    "        ax3.text(row['N_pixel'],row['N_PN']+2,row['name'],horizontalalignment='center') \n",
    "        \n",
    "\n",
    "ax1.set(xlabel='stellar mass density',ylabel='N PN')\n",
    "ax2.set(xlabel='Survey Area')\n",
    "ax3.set(xlabel='Npixel')\n",
    "#ax3.set(xlabel='Npixel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other PNLF studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = ascii.read(basedir/'data'/'literature distances'/'latest.csv',delimiter=',',header_start=12,data_start=14)\n",
    "results = ascii.read(basedir/'data'/'interim'/'results.txt')\n",
    "print(f\"intial cagalogue has {len(np.unique(distances[distances['Method']=='PNLF']['Galaxy ID']))} objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnlf_distances = distances[distances[\"Method\"]=='PNLF']\n",
    "print(f\"excluding {len(np.unique(pnlf_distances[(pnlf_distances['m-M']<22.5) | (pnlf_distances['m-M']>32)]['Galaxy ID']))} objects\")\n",
    "#pnlf_distances = pnlf_distances[(pnlf_distances['m-M']>22.5) & (pnlf_distances['m-M']<32)]  # exclude the many measurments of the LMC and SMC\n",
    "\n",
    "pnlf_distances['year'] = pnlf_distances['Date (Yr. - 1980)']+1980\n",
    "pnlf_distances.rename_column('Galaxy ID','name')\n",
    "pnlf_distances['name'] = [n.rstrip('a').rstrip('b') for n in pnlf_distances['name']]\n",
    "\n",
    "alias = {\n",
    "    'NGC 0628': 'MESSIER 074',\n",
    "    'NGC 3351': 'MESSIER 095',\n",
    "    'NGC 3627': 'MESSIER 066',\n",
    "    'NGC 4254': 'MESSIER 099',\n",
    "    'NGC 4303': 'MESSIER 061',\n",
    "    'NGC 4321': 'MESSIER 100'\n",
    "}\n",
    "\n",
    "alias_back = {v:k for k,v in alias.items()}\n",
    "\n",
    "phangs_sample = []\n",
    "for row in results:\n",
    "    name = row['name'].replace('NGC','NGC ').replace('IC','IC ')\n",
    "    name = alias.get(name,name)\n",
    "    phangs_sample.append(name)\n",
    "    new = ['',0,0,name,row['(m-M)'],row['err-(m-M)'],0,'PNLF','Schmnn+2020','',0,0,0,40,'',2020]\n",
    "    pnlf_distances.add_row(new)\n",
    "    \n",
    "galaxies = list(np.unique(pnlf_distances['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = pnlf_distances.group_by('name')['m-M'].groups.aggregate(np.mean)\n",
    "dis = Distance(distmod=mu).value\n",
    "plt.hist(dis,bins=np.arange(10,100,2))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we sort by mean distance\n",
    "mean_dis = []\n",
    "for gal in galaxies:\n",
    "    mean_dis.append(pnlf_distances[pnlf_distances['name']==gal]['m-M'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnlf_distances.sort('year')\n",
    "important_papers = dict()\n",
    "is_measured = []\n",
    "for row in pnlf_distances:\n",
    "    #if row['name'] not in is_measured:\n",
    "    #    is_measured.append(row['name'])\n",
    "    if row['REFCODE'] in important_papers:\n",
    "        important_papers[row['REFCODE']] += 1\n",
    "    else:\n",
    "        important_papers[row['REFCODE']] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1,figsize=(10,6/1.618))\n",
    "\n",
    "x_pos  = []\n",
    "gal_names = [x for _,x in sorted(zip(mean_dis,galaxies))]\n",
    "\n",
    "print(f'{len(gal_names)} galaxies in sample')\n",
    "color_grid=[]\n",
    "for i,gal in enumerate(gal_names):\n",
    "    tmp = pnlf_distances[pnlf_distances['name']==gal]\n",
    "    ax.scatter(len(tmp)*[i+1],tmp['m-M'],marker=\"_\",color='gray')\n",
    "    # color the measured by me red\n",
    "    if len(tmp[tmp['REFCODE']=='Schmnn+2020'])>0:\n",
    "        ax.scatter([i+1],tmp[tmp['REFCODE']=='Schmnn+2020']['m-M'],marker=\"_\",color='tab:red')\n",
    "        color_grid.append(i)\n",
    "\n",
    "# create a legend with numbers only\n",
    "#legend_elements = [mpl.lines.Line2D([0], [0], color=tab10[i], lw=2, label=str(i+1)) for i in range(10)]\n",
    "#plt.legend(handles=legend_elements, loc='upper center',ncol=10)\n",
    "    \n",
    "ymin,ymax = 23,32\n",
    "# set the galaxy names as x-ticklabels\n",
    "ax.set(xticks=np.arange(1,len(galaxies)+1),\n",
    "       ylabel='($m-M$) / mag',\n",
    "       title='Galaxies with PNLF distances',\n",
    "       xlim=[0.5,len(galaxies)+0.5],\n",
    "       ylim=[ymin,ymax])\n",
    "ax.set_xticklabels(gal_names,rotation=90,color='gray')    \n",
    "\n",
    "# color the galaxies which are in the phangs sample \n",
    "for n in phangs_sample:\n",
    "    i = gal_names.index(n)\n",
    "    ax.get_xticklabels()[i].set_color(\"tab:red\")\n",
    "#for n in ['MESSIER 066','MESSIER 074','MESSIER 095','NGC 5068']:\n",
    "#    i = gal_names.index(n)\n",
    "#    ax.get_xticklabels()[i].set_color(\"tab:red\")    \n",
    "\n",
    "ax.grid(axis='x')\n",
    "#a = ax.get_xgridlines()\n",
    "#for i in color_grid:\n",
    "#    a[i].set_color('tab:red')\n",
    "\n",
    "yticks_mpc = np.logspace(np.log10(Distance(distmod=ymin).to(u.Mpc).value),np.log10(Distance(distmod=ymax).to(u.Mpc).value),10)\n",
    "yticks_mu  = Distance(yticks_mpc*u.Mpc).distmod\n",
    "    \n",
    "ax2 = ax.twinx()\n",
    "ax2.set_yticks(yticks_mu.value,minor=False)\n",
    "ax2.set_yticklabels([f'{x:.2f}' for x in yticks_mpc],ha=\"left\")\n",
    "ax2.set(ylim=[ymin,ymax],ylabel='$D$ / Mpc')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(basedir/'reports'/'PNstudies.png',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, (ax2,ax1) = plt.subplots(nrows=2,figsize=(two_column,two_column))\n",
    "\n",
    "gal_names = [x for _,x in sorted(zip(mean_dis,galaxies))]\n",
    "\n",
    "def literature_distances(labels,ax,ymin=23,ymax=32):\n",
    "    \n",
    "    # set the galaxy names as x-ticklabels\n",
    "    ax.set(xticks=np.arange(1,len(labels)+1),\n",
    "           ylabel='($m-M$) / mag',\n",
    "           xlim=[0.5,len(labels)+0.5],\n",
    "           ylim=[ymin,ymax])\n",
    "    labels_new = [alias_back.get(l,l) for l in labels]\n",
    "    ax.set_xticklabels(labels_new,rotation=90,color='gray')    \n",
    "    ax.grid(axis='x',ls='--',lw=0.4)\n",
    "    grid = ax.get_xgridlines()\n",
    "\n",
    "    for i,label in enumerate(labels):\n",
    "        tmp = pnlf_distances[pnlf_distances['name']==label]\n",
    "        ax.scatter(len(tmp)*[i+1],tmp['m-M'],marker=\"_\",color='gray')\n",
    "        # color the measured by me red\n",
    "        if len(tmp[tmp['REFCODE']=='Schmnn+2020'])>0:\n",
    "            ax.get_xticklabels()[i].set(color=\"tab:red\",fontweight='black')\n",
    "            ax.scatter([i+1],tmp[tmp['REFCODE']=='Schmnn+2020']['m-M'],marker=\"_\",color='tab:red')\n",
    "            grid[i].set(ls='-',lw=0.5)\n",
    "    \n",
    "    \n",
    "    yticks_mpc = np.logspace(np.log10(Distance(distmod=ymin).to(u.Mpc).value),np.log10(Distance(distmod=ymax).to(u.Mpc).value),10)\n",
    "    yticks_mu  = Distance(yticks_mpc*u.Mpc).distmod\n",
    "\n",
    "    axt = ax.twinx()\n",
    "    axt.set_yticks(yticks_mu.value,minor=False)\n",
    "    axt.set_yticklabels([f'{x:.2f}' for x in yticks_mpc],ha=\"left\")\n",
    "    axt.set(ylim=[ymin,ymax],ylabel='$D$ / Mpc')\n",
    "    \n",
    "    return ax\n",
    "    \n",
    "n = len(gal_names)\n",
    "ax1 = literature_distances(gal_names[:int(n/2)],ax1,ymin=23,ymax=30.5)\n",
    "ax2 = literature_distances(gal_names[int(n/2):],ax2,ymin=29.5,ymax=32.2)\n",
    "\n",
    "#ax2.set_title('Galaxies with PNLF distances')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.savefig(basedir/'reports'/'PNstudies.pdf',dpi=600)\n",
    "plt.savefig(basedir/'reports'/'PNstudies.png',dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode_only(array):\n",
    "    m,c = mode(array)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with Deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep   = ascii.read(basedir/'data'/'literature distances'/'deep_distances.csv')\n",
    "result = ascii.read(basedir/'data'/'interim'/'results.txt')\n",
    "\n",
    "deep.add_index(\"galaxy\")\n",
    "deep['d'] = [float(x[:-4]) for x in deep['distance']]\n",
    "deep['e'] = [float(x[:-4]) for x in deep['error']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.auxiliary import mu_to_parsec\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(two_column,two_column/1.618))\n",
    "result.sort('d/Mpc')\n",
    "for i, row in enumerate(result):\n",
    "\n",
    "    tmp = deep.loc[row['name']]\n",
    "    if tmp['method'] == 'TRGB':\n",
    "        d,(dp,dm) = mu_to_parsec(row['(m-M)'],[row['err+(m-M)'],row['err-(m-M)']])\n",
    "\n",
    "        ax.errorbar(i-0.1,row['d/Mpc'],yerr=([dm.value],[dp.value]),fmt='o',color='tab:red')\n",
    "\n",
    "        ax.errorbar(i+0.1,tmp['d'],yerr=tmp['e'],fmt='o',color='black')\n",
    "        \n",
    "        diff = row['d/Mpc']-tmp['d']\n",
    "        if diff>0:\n",
    "            err = dm\n",
    "        else:\n",
    "            err = dp\n",
    "            \n",
    "        print(f\"{row['name']}: {diff/err:.2f}\")\n",
    "        \n",
    "        \n",
    "ax.set(xticks=np.arange(0,len(result)),\n",
    "       ylabel='$D$ / Mpc',\n",
    "       title='PHANGS distances',\n",
    "       xlim=[-0.5,len(result)-0.5])\n",
    "ax.set_xticklabels(result['name'],rotation=90)  \n",
    "ax.grid(axis='x')\n",
    "\n",
    "legend_elements = [mpl.lines.Line2D([0], [0], color=col, lw=2, label=l) for col,l in zip(['tab:red','black'],['PNLF','TRGB'])]\n",
    "plt.legend(handles=legend_elements, loc='lower center',ncol=10)\n",
    "#plt.savefig(basedir/'reports'/'PNLF_vs_TRGB.png',dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.auxiliary import parsec_to_mu\n",
    "\n",
    "\n",
    "distances = ascii.read(basedir/'data'/'literature distances'/'latest.csv',delimiter=',',header_start=12,data_start=14)\n",
    "trgb_distances = distances[distances[\"Method\"]=='TRGB']\n",
    "trgb_distances.rename_column('Galaxy ID','name')\n",
    "\n",
    "trgb_distances['year'] = trgb_distances['Date (Yr. - 1980)']+1980\n",
    "trgb_distances['name'] = [n.rstrip('a').rstrip('b') for n in trgb_distances['name']]\n",
    "\n",
    "alias = {\n",
    "'MESSIER074' : 'NGC0628',\n",
    "'MESSIER095' : 'NGC3351',\n",
    "'MESSIER066' : 'NGC3627',\n",
    "'MESSIER099' : 'NGC4254',\n",
    "'MESSIER061' : 'NGC4303',\n",
    "'MESSIER100' : 'NGC4321'\n",
    "}\n",
    "\n",
    "trgb_distances['name'] = [x.replace(' ','') for x in trgb_distances['name']]\n",
    "\n",
    "for k,v in alias.items():\n",
    "    trgb_distances['name'] = [x.replace(k,v) for x in trgb_distances['name']]\n",
    "trgb_distances = trgb_distances[np.isin(trgb_distances['name'],results['name'])]\n",
    "\n",
    "# add the new distances from deep\n",
    "for name in 'IC5332', 'NGC2835', 'NGC4321':\n",
    "    d = deep.loc[name]['d']\n",
    "    e = deep.loc[name]['e']\n",
    "    mu,err = parsec_to_mu(d*u.Mpc,e*u.Mpc)\n",
    "    \n",
    "    row = {'name':name,'m-M':mu,'err':err,'Method':'TRGB','D (Mpc)':d}\n",
    "    trgb_distances.add_row(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep.loc['NGC4321']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Distance(distmod=trgb['m-M']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.auxiliary import mu_to_parsec\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(two_column,two_column/1.618))\n",
    "\n",
    "sample  = np.unique(trgb_distances['name'])\n",
    "\n",
    "results = ascii.read(basedir/'data'/'interim'/ 'results.txt',format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "results = results[np.isin(results['name'],sample)]\n",
    "results.sort('d/Mpc')\n",
    "results.add_index('name')\n",
    "\n",
    "for i, name in enumerate(results['name']):\n",
    "    \n",
    "    trgb = trgb_distances[trgb_distances['name']==name]\n",
    "    for row in trgb:   \n",
    "        d,(dp,dm) = mu_to_parsec(row['m-M'],[row['err'],row['err']])\n",
    "        ax.errorbar(i-0.2,d.value,yerr=([dm.value],[dp.value]),fmt='o',color='black')\n",
    "    \n",
    "    pnlf = results.loc[name]\n",
    "    ax.errorbar(i+0.2,pnlf['d/Mpc'],yerr=([pnlf['err-d/Mpc']],[pnlf['err+d/Mpc']]),fmt='o',color='tab:red')\n",
    "\n",
    "    diff = pnlf['d/Mpc'] - np.mean(Distance(distmod=trgb['m-M'])).value\n",
    "    if diff>0:\n",
    "        err = pnlf['err-d/Mpc']\n",
    "    else:\n",
    "        err = pnlf['err+d/Mpc']\n",
    "\n",
    "    print(f\"{row['name']}: {diff/err:.2f}\") \n",
    "\n",
    "for x in np.arange(-0.5,len(results)+0.5):\n",
    "    ax.axvline(x,color='gray',zorder=0)\n",
    "ax.set(xticks=np.arange(0,len(results)),\n",
    "       ylabel='$D$ / Mpc',\n",
    "       title='PNLF vs TRGB',\n",
    "       xlim=[-0.5,len(results)-0.5])\n",
    "ax.set_xticklabels(results['name'],rotation=90)  \n",
    "#ax.grid(axis='x')\n",
    "\n",
    "legend_elements = [mpl.lines.Line2D([0], [0], color=col, lw=2, label=l) for col,l in zip(['tab:red','black'],['PNLF','TRGB'])]\n",
    "plt.legend(handles=legend_elements, loc='lower center',ncol=10)\n",
    "plt.savefig(basedir/'reports'/'PNLF_vs_TRGB.png',dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot entire sky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = basedir / 'data' / 'interim' / 'sample.txt'\n",
    "sample = ascii.read(filename,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "sample['SkyCoord'] = SkyCoord(sample['R.A.'],sample['Dec.'])\n",
    "\n",
    "ra = sample['SkyCoord'].ra\n",
    "ra = ra.wrap_at(180*u.degree)\n",
    "dec = sample['SkyCoord'].dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mpl.use('pdf')\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fig.add_subplot(111, projection=\"mollweide\")\n",
    "ax.scatter(ra.radian,dec.radian,marker='.')\n",
    "#ax.set_xticklabels(['14h','16h','18h','20h','22h','0h','2h','4h','6h','8h','10h'])\n",
    "ax.grid(True)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "\n",
    "for x,y,s in zip(ra,dec,sample['Name']):\n",
    "    ax.annotate(s,(x.radian,y.radian),xycoords='data',size='x-small')\n",
    "\n",
    "fig.savefig(\"map.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/henrysky/milkyway_plot/blob/master/mw_plot/mw_plot_classes.py\n",
    "image_filename = basedir/'data'/'interim'/'MW_edgeon_unannotate.jpg'\n",
    "img = plt.imread(image_filename)\n",
    "img = img[1625:4875]  # so there are 3250px there\n",
    "\n",
    "center=(0, 0) * u.deg\n",
    "radius=(180, 90) * u.deg\n",
    "    \n",
    "y_img_center = 1625 - int((3250 / 180) * center[1].value)\n",
    "y_radious_px = int((3250 / 180) * radius[1].value)\n",
    "x_img_center = int((6500 / 360) * center[0].value) + 3250\n",
    "x_radious_px = int((6500 / 360) * radius[0].value)\n",
    "\n",
    "img = img[(y_img_center - y_radious_px):(y_img_center + y_radious_px),\n",
    "             (x_img_center - x_radious_px):(x_img_center + x_radious_px), :]\n",
    "\n",
    "'''\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='mollweide')\n",
    "\n",
    "lon = np.linspace(-np.pi, np.pi, 6500)\n",
    "lat = np.linspace(np.pi / 2., -np.pi / 2., 3250)\n",
    "Lon, Lat = np.meshgrid(lon, lat)\n",
    "\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = {'IC5332':(4,2),\n",
    "'NGC0628':(0,1),\n",
    "'NGC1087':(0,2),\n",
    "'NGC1300':(0,3),\n",
    "'NGC1365':(4,3),\n",
    "'NGC1385':(0,4),\n",
    "'NGC1433':(4,5),\n",
    "'NGC1512':(4,4),\n",
    "'NGC1566':(3,6),\n",
    "'NGC1672':(4,6),\n",
    "'NGC2835':(2,6),\n",
    "'NGC3351':(1,6),\n",
    "'NGC3627':(0,6),\n",
    "'NGC4254':(1,0),\n",
    "'NGC4303':(3,0),\n",
    "'NGC4321':(0, 0),\n",
    "'NGC4535':(2,0),\n",
    "'NGC5068':(4,0),\n",
    "'NGC7496':(4,1)}\n",
    "\n",
    "va = {\n",
    "'IC5332':'bottom',\n",
    "'NGC0628':'bottom',\n",
    "'NGC1087':'bottom',\n",
    "'NGC1300':'center',\n",
    "'NGC1365':'center',\n",
    "'NGC1385':'center',\n",
    "'NGC1433':'center',\n",
    "'NGC1512':'center',\n",
    "'NGC1566':'center',\n",
    "'NGC1672':'center',\n",
    "'NGC2835':'center',\n",
    "'NGC3351':'top',\n",
    "'NGC3627':'bottom',\n",
    "'NGC4254':'top',\n",
    "'NGC4303':'top',\n",
    "'NGC4321':'bottom',\n",
    "'NGC4535':'center',\n",
    "'NGC5068':'bottom',\n",
    "'NGC7496':'top'}\n",
    "ha = {\n",
    "'IC5332':'center',\n",
    "'NGC0628':'center',\n",
    "'NGC1087':'center',\n",
    "'NGC1300':'right',\n",
    "'NGC1365':'right',\n",
    "'NGC1385':'left',\n",
    "'NGC1433':'right',\n",
    "'NGC1512':'left',\n",
    "'NGC1566':'right',\n",
    "'NGC1672':'left',\n",
    "'NGC2835':'right',\n",
    "'NGC3351':'right',\n",
    "'NGC3627':'right',\n",
    "'NGC4254':'left',\n",
    "'NGC4303':'left',\n",
    "'NGC4321':'left',\n",
    "'NGC4535':'left',\n",
    "'NGC5068':'center',\n",
    "'NGC7496':'center'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.plot.plot import create_RGB\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(ncols=7, nrows=5,figsize=(1.5*two_column,two_column))\n",
    "gs = axs[1, 2].get_gridspec()\n",
    "\n",
    "path = data_raw / 'MUSE_DR2' / 'filterImages' \n",
    "\n",
    "# remove the underlying axes\n",
    "for ax in axs[1:-1,1:-1].flatten():\n",
    "    ax.remove()\n",
    "ax = fig.add_subplot(gs[1:-1,1:-1],projection=\"mollweide\")\n",
    "ax.pcolormesh(Lon, Lat,img[:, :, 0], cmap='gray', zorder=2, alpha=0.85, rasterized=True)\n",
    "ax.plot(ra.radian,dec.radian,'.r',ms=1)\n",
    "\n",
    "#ax.set_xticklabels(['14h','16h','18h','20h','22h','0h','2h','4h','6h','8h','10h'])\n",
    "ax.grid(True)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "\n",
    "for x,y,name in zip(ra,dec,sample['Name']):\n",
    "    #ax.annotate(s,(x.radian,y.radian),xycoords='data',size='x-small',position='top')\n",
    "    ax.text(x.radian,y.radian,name,\n",
    "            horizontalalignment=ha[name],\n",
    "            verticalalignment=va[name],\n",
    "            fontsize=6,\n",
    "            color='white')\n",
    "\n",
    "for name,idx in positions.items():\n",
    "\n",
    "    sdss_g, h = fits.getdata(path / f'{name}_IMAGE_FOV_SDSS_g_WCS_Pall_mad.fits',header=True)\n",
    "    sdss_r, h = fits.getdata(path / f'{name}_IMAGE_FOV_SDSS_r_WCS_Pall_mad.fits',header=True)\n",
    "    sdss_i, h = fits.getdata(path / f'{name}_IMAGE_FOV_SDSS_i_WCS_Pall_mad.fits',header=True)\n",
    "    \n",
    "    #ax=axs[idx]\n",
    "    axs[idx].remove()\n",
    "    ax = fig.add_subplot(gs[idx],projection=WCS(h))\n",
    "    \n",
    "    gri = create_RGB(sdss_i,sdss_r,sdss_g,weights=[1,1,1],percentile=[99,99,99])\n",
    "    gri[sdss_g==0] = (1,1,1)\n",
    "    ax.imshow(gri)\n",
    "    \n",
    "    #ax.annotate(f'{k}',(0.1, 0.5),xycoords='axes fraction', va='center')\n",
    "    ax.set_title(name,fontsize=6)\n",
    "    \n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "axs[(0,5)].remove()\n",
    "\n",
    "#fig.tight_layout()\n",
    "plt.subplots_adjust(wspace=0,hspace=0.3)\n",
    "\n",
    "plt.savefig(basedir/'reports'/'all_galaxies_sky.pdf',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Angular resolution of all galaxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in results['name']:\n",
    "    with fits.open(data_raw/'AUXILIARY'/'seeing_maps'/f'{name}_seeing.fits') as hdul:\n",
    "        PSF = hdul[0].data\n",
    "    \n",
    "    res_min = np.nanmin(PSF)/206265*results.loc[name]['d/Mpc']*1e6\n",
    "    res_max = np.nanmax(PSF)/206265*results.loc[name]['d/Mpc']*1e6\n",
    "    \n",
    "    ang_min = np.nanmin(PSF)\n",
    "    ang_max = np.nanmax(PSF)\n",
    "    \n",
    "    print(f'{name}: min={ang_min:.2f} pc, max={ang_max:.2f} pc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.auxiliary import mu_to_parsec, parsec_to_mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 18.72\n",
    "mu,mu_err = parsec_to_mu(d*u.Mpc,0.15*d*u.Mpc)\n",
    "print(f'{mu.value:.2f},{mu_err[0]:.2f},{d:.2f},NAM,2020AJ....159...67K,,,,,')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d,derr= 17.22, 2.58 \n",
    "mu,mu_err = parsec_to_mu( d*u.Mpc,derr*u.Mpc)\n",
    "print(f'{mu.value:.2f},{mu_err[0]:.2f},{d:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trgb['(m-M)'], trgb['err(m-M)'] = parsec_to_mu(trgb['Distance']*u.Mpc,trgb['Error']*u.Mpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trgb = ascii.read(basedir/'data'/'literature distances'/'PHANGSDistancesJuly23.txt',format='csv',delimiter='&')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogues = {}\n",
    "for name in results['name']:\n",
    "    filename = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "    catalogues[name] = ascii.read(filename,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.analyse import MaximumLikelihood1D, PNLF, pnlf\n",
    "from pnlf.plot.pnlf import plot_pnlf\n",
    "from pnlf.auxiliary import mu_to_parsec\n",
    "\n",
    "name = 'NGC1385'\n",
    "\n",
    "param = parameters[name]\n",
    "cl = param['completeness_limit']\n",
    "tbl = catalogues[name]\n",
    "if False:\n",
    "    data = tbl[((tbl['type']=='PN') | (tbl['SNRorPN']=='True')) & (tbl['exclude']==0)]['mOIII']\n",
    "    err = tbl[((tbl['type']=='PN') | (tbl['SNRorPN']=='True')) & (tbl['exclude']==0)]['dmOIII']\n",
    "else:\n",
    "    data = tbl[(tbl['type']=='PN') & (tbl['exclude']==0) & (tbl['v_SIGMA']<1000) ]['mOIII']\n",
    "    err  = tbl[(tbl['type']=='PN') & (tbl['exclude']==0)]['dmOIII']\n",
    "\n",
    "fitter = MaximumLikelihood1D(pnlf,data[data<cl],mhigh=cl,Mmax=-4.47)\n",
    "mu,mu_p,mu_m = fitter([28])\n",
    "mu_p = np.sqrt(mu_p**2+np.nanmean(err)**2+dPSF**2)\n",
    "mu_m = np.sqrt(mu_m**2+np.nanmean(err)**2+dPSF**2)\n",
    "d,(dp,dm)=mu_to_parsec(mu,[mu_p,mu_m])\n",
    "print('{:.2f} + {:.2f} - {:.2f}'.format(d,dp,dm))\n",
    "print('{:.2f} + {:.2f} - {:.2f}'.format(mu,mu_p,mu_m))\n",
    "\n",
    "#Plot PNLF\n",
    "axes = plot_pnlf(data,\n",
    "                 mu,\n",
    "                 cl,\n",
    "                 binsize=param['binsize'],\n",
    "                 #mhigh=29,\n",
    "                 filename=None,\n",
    "                 color=tab10[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tbl[(tbl['type']=='PN') & (tbl['mOIII']<29) & (tbl['exclude']==0)]\n",
    "tmp.sort('mOIII')\n",
    "\n",
    "plt.scatter(tmp['mOIII'],tmp['v_SIGMA'])\n",
    "plt.axvline(np.min(tmp['mOIII'])+1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.io import ReadLineMaps\n",
    "galaxy = ReadLineMaps(data_raw,name,**parameters[name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.plot.plot import plot_sky_with_detected_stars\n",
    "tmp = tbl[tbl['exclude']==1]\n",
    "positions = np.transpose((tmp['x'], tmp['y']))\n",
    "\n",
    "plot_sky_with_detected_stars(data=galaxy.OIII5006_DAP,\n",
    "                             wcs=galaxy.wcs,\n",
    "                             positions=positions\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'NGC0628'\n",
    "catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "if catalogue_file.is_file():\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "catalogue['SkyCoord'] = SkyCoord(catalogue['RaDec'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RA=24.1888\n",
    "DEC=15.7968\n",
    "\n",
    "coord = SkyCoord(RA*u.degree,DEC*u.degree)\n",
    "\n",
    "sep = coord.separation(catalogue['SkyCoord'])\n",
    "\n",
    "catalogue[np.argmin(sep)][['id','type']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure mass in mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.io import ReadLineMaps\n",
    "from regions import PixCoord,EllipsePixelRegion\n",
    "\n",
    "observed_mass = {}\n",
    "age_mw = []\n",
    "\n",
    "\n",
    "with open(basedir / 'data' / 'interim' / 'parameters.yml') as yml_file:\n",
    "    parameters = yaml.load(yml_file,Loader=yaml.FullLoader)\n",
    "        \n",
    "for name in results['name']:\n",
    "\n",
    "    lines = ['OIII5006', 'HA6562']\n",
    "\n",
    "    # read in the data we will be working with and print some information\n",
    "    galaxy = ReadLineMaps(data_ext/'MUSE_DR2'/'MUSEDAP',name,extensions=lines,**parameters[name])\n",
    "    galaxy.center = sample_table.loc[name]['SkyCoord'].to_pixel(galaxy.wcs)\n",
    "    galaxy.Ebv = sample_table.loc[name]['E(B-V)']\n",
    "    galaxy.posang = sample_table.loc[name]['posang']\n",
    "    galaxy.inclination = sample_table.loc[name]['Inclination']\n",
    "    galaxy.r25 = sample_table.loc[name]['r25']*u.arcmin\n",
    "\n",
    "    eccentricity = np.sin(galaxy.inclination*u.deg).value\n",
    "    width = 0.2*(galaxy.r25/u.arcmin*300).value  # convert arcmin to pixel\n",
    "    # angle uses x-axis but posang is defined from north pole (y-axis)\n",
    "    aperture = EllipsePixelRegion(PixCoord(*galaxy.center),\n",
    "                                  width=width,\n",
    "                                  height=np.sqrt((width)**2 * (1-eccentricity**2)),\n",
    "                                  angle=(galaxy.posang-90)*u.deg)\n",
    "    center_mask = aperture.to_mask().to_image(galaxy.shape).astype(bool)\n",
    "\n",
    "    mask = np.zeros(galaxy.shape,dtype=bool)\n",
    "    mask |= galaxy.star_mask.astype(bool)\n",
    "    if hasattr(galaxy,'mask'):\n",
    "        print('masking parts of the image')\n",
    "        mask[galaxy.HA6562>getattr(galaxy,'HAmask',np.nanpercentile(galaxy.HA6562,95))]=True\n",
    "        mask |=center_mask\n",
    "    if name=='NGC1566':\n",
    "        # this galaxy has one extremely noise pointing\n",
    "        mask[galaxy.PSF==3.11]=True\n",
    "\n",
    "    with fits.open(galaxy.filename) as hdul:\n",
    "        data = hdul['AGE_MW'].data\n",
    "    age_mw.append(np.nanmedian(data[~mask]))\n",
    "        \n",
    "    area_per_pixel =  (0.2*Distance(distmod=sample_table.loc[name]['(m-M)'])*u.arcsec.to(u.rad)).to(u.pc)**2\n",
    "    m = np.log10(area_per_pixel.value * np.nansum(galaxy.stellar_mass[~mask]))\n",
    "    observed_mass[name] = m\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = [],[]\n",
    "\n",
    "for k,v in observed_mass.items():\n",
    "    a.append(k)\n",
    "    b.append(v)\n",
    "t = Table([a,b],names=['name','obs_mass'])\n",
    "t['age_mw'] = age_mw\n",
    "t['age_mw'].info.format = '%.3f'\n",
    "t['obs_mass'].info.format = '%.3f'\n",
    "\n",
    "with open(basedir/'data'/'interim'/'observed_mass.txt','w',newline='\\n') as f:\n",
    "    ascii.write(t,f,format='fixed_width_two_line',overwrite=True,delimiter_pad=' ',position_char='=')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## luminosity-specific planetary nebula number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import join \n",
    "\n",
    "from pnlf.analyse import F\n",
    "\n",
    "def NPN(mu,completeness,N_total,deltaM):\n",
    "    cutoff = mu - 4.47\n",
    "    p_deltaM = (F(cutoff+deltaM,mu) - F(cutoff,mu)) / (F(completeness,mu) - F(cutoff,mu))\n",
    "    \n",
    "    return N_total * p_deltaM\n",
    "\n",
    "\n",
    "results = ascii.read(basedir/'data'/'interim'/ 'results.txt',format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "abundance_gradients = ascii.read(basedir/'data'/'external'/'radial_abundance_gradients.txt',\n",
    "                                names=['name','R0','g_r25'])\n",
    "observed_mass = ascii.read(basedir/'data'/'interim'/ 'observed_mass.txt',format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "results = join(results,abundance_gradients)\n",
    "results = join(results,observed_mass)\n",
    "results.add_index('name')\n",
    "\n",
    "# from survey paper based on sample table distances\n",
    "results['spatial_res'] = [43.7,47.7,76.8,92.1,94.9,83.5,\n",
    "                               90.3,91.3,85.8,94.1,59.2,48.3,54.9,\n",
    "                               63.5,82.4,73.7,76.5, 25.2,90.8]\n",
    "# from survey paper\n",
    "results['PSF'] = [0.72,0.73,0.74,0.63,0.82,0.49,0.65,0.8,0.64,0.72,\n",
    "                  0.85,0.74,0.77,0.58,0.58,0.64,0.44,0.73,0.79]\n",
    "results['mass'] = sample_table['mass']\n",
    "results['SFR']  = sample_table['SFR']\n",
    "results['Inclination'] = sample_table['Inclination']\n",
    "results['AO'] = ~sample_table['AO'].mask\n",
    "\n",
    "# those two galaxies have a lower completeness limit\n",
    "row = results.loc['NGC3627']\n",
    "row ['N_PN'] = NPN(row['(m-M)'],27.5,row['N_PN'],28-row['(m-M)']+4.47)\n",
    "row = results.loc['NGC2835']\n",
    "row ['N_PN'] = NPN(row['(m-M)'],27.5,row['N_PN'],28-row['(m-M)']+4.47)\n",
    "\n",
    "# luminosity specific planetary nebula number (detected and not N25)\n",
    "results['alpha2'] = np.log10(results['N_PN']/results['Lbol'])\n",
    "results['alpha3'] = np.log10(results['N_PN']/10**results['obs_mass'])\n",
    "results['resolution'] = results['PSF']*(results['d/Mpc']*u.Mpc*(u.arcsec.to(u.rad))).to(u.pc).value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(results['PSF'][results['AO']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(results['PSF'][~results['AO']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(100*u.pc/0.76/u.arcsec.to(u.rad)).to(u.Mpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of PN within 1 mag of the bright end cutoff and extrapolate to completeness\n",
    "N_PN = []\n",
    "for name in results['name']:\n",
    "    catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "    catalogue['overluminous'] = catalogue['overluminous'].astype(bool)\n",
    "    threshold = results.loc[name]['(m-M)']-4.47+1\n",
    "    criteria = (catalogue['type']=='PN') & (catalogue['mOIII']<threshold) & ~catalogue['exclude'] & ~catalogue['overluminous']\n",
    "    N = NPN(row['(m-M)'],threshold,np.sum(criteria),28-threshold)\n",
    "    N_PN.append(N)\n",
    "results['alpha3'] = np.log10(np.array(N_PN)/results['Lbol'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first we look at the parameter space that our sample covers. We see that more massive galaxies are also more luminous, and that the massive galaxies in our sample are further away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double distance means increasing the ditsance modulus by\n",
    "d = Distance(distmod=28.9)\n",
    "d2 = Distance(2*d)\n",
    "\n",
    "print(f'd={d.distmod:.2f}, 2d={d2.distmod:.2f}, dd={d2.distmod-d.distmod:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "sc = ax.scatter(results['mass'],results['Lbol'])\n",
    "ax.set(xlabel=r'$\\log M/\\mathrm{M}_\\odot$',ylabel=r'$L_\\mathrm{bol}/\\mathrm{L}_\\odot$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "halign = {'NGC0628':'right','NGC1300':'right','NGC1512':'right'}\n",
    "valign = {'NGC1512':'top','NGC1300':'bottom'}\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "ax.scatter(results['mass'],results['(m-M)'])\n",
    "for name in sample_table['name']:\n",
    "    ax.text(sample_table.loc[name]['mass'],results.loc[name]['(m-M)'],name,\n",
    "            horizontalalignment=halign.get(name,'left'),\n",
    "            verticalalignment=valign.get(name,'center'))\n",
    "ax.set(xlabel=r'$\\log M/\\mathrm{M}_\\odot$',ylabel='distance',xlim=[9.2,11.5])      \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the number of PN decreases with distances because we sample a smaller part of the PNLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.analyse import F,cdf\n",
    "\n",
    "mu0 = 28.\n",
    "mhigh = 28   # also the completeness limit\n",
    "x = np.linspace(mu0-4.47,mhigh)\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(two_column,two_column/1.618))\n",
    "\n",
    "for dmu in [0,0.5,1,1.5,2,2.5]:\n",
    "    xp = x+dmu\n",
    "    yp = cdf(x,mu0,mhigh)\n",
    "    ax.plot(xp,yp,label=f'(m-M)={mu0+dmu}')\n",
    "    # how far above the cutoff until we detect 20%\n",
    "    p = yp[np.argmax(xp>=28)]\n",
    "    print(f'mu={mu0+dmu}, cutoff={mu0+dmu-4.47}, p={p:.2f}')\n",
    "\n",
    "ax.axvline(28,color='black')    \n",
    "ax.set(xlabel='mOIII',ylabel='cumulative PNLF')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu0 = 28.\n",
    "mhigh = 28\n",
    "x = np.linspace(mu0-4.47,mhigh)\n",
    "\n",
    "p = []\n",
    "distmod = np.arange(28.,33,0.25)\n",
    "distance = Distance(distmod=distmod).to(u.Mpc).value\n",
    "\n",
    "for mu in distmod:\n",
    "    dmu = mu-mu0\n",
    "    xp = x+dmu\n",
    "    yp = cdf(x,mu0,mhigh)\n",
    "    p.append(yp[np.argmax(xp>=28)])\n",
    "p = np.array(p)\n",
    "\n",
    "fig,(ax1,ax2)=plt.subplots(ncols=2,figsize=(two_column,two_column/2))\n",
    "ax1.plot(distmod,p)\n",
    "ax1.axvline(mhigh+4.47,color='black')\n",
    "ax1.set(xlabel='(m-M) / mag',ylabel=r'$N_\\mathrm{PN}$')\n",
    "\n",
    "ax2.plot(distance,p)\n",
    "ax2.axvline(Distance(distmod=mhigh+4.47).to(u.Mpc).value,color='black')\n",
    "ax2.set(xlabel='distance / Mpc',ylabel=r'$N_\\mathrm{PN}$')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our goal is to predict how many PNe we find a a given galaxy. We start by looking at the number of PN we find as a function of the distance to the galaxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "ref_gal = 'NGC0628'\n",
    "row = results.loc[ref_gal]\n",
    "\n",
    "# number of PN at reference point (1-res/250) for decrease due to resolution\n",
    "Nref = row['N_PN'] / np.interp(row['d/Mpc'],distance,p)\n",
    "alpha = np.log10(p*Nref/row['Lbol'])\n",
    "\n",
    "\n",
    "halign = {\n",
    " 'IC5332': 'left','NGC0628': 'left','NGC1087': 'right','NGC1300': 'right',\n",
    " 'NGC1365': 'right','NGC1385': 'right','NGC1433': 'left','NGC1512': 'center',\n",
    " 'NGC1566': 'left','NGC1672': 'left','NGC2835': 'left','NGC3351': 'left',\n",
    " 'NGC3627': 'center','NGC4254': 'right','NGC4303': 'right','NGC4321': 'right',\n",
    " 'NGC4535': 'left','NGC5068': 'left','NGC7496': 'right'}\n",
    "\n",
    "valign = {\n",
    " 'IC5332': 'bottom','NGC0628': 'bottom','NGC1087': 'top','NGC1300': 'center',\n",
    " 'NGC1365': 'bottom','NGC1385': 'bottom','NGC1433': 'center','NGC1512': 'top',\n",
    " 'NGC1566': 'center','NGC1672': 'top','NGC2835': 'top','NGC3351': 'center',\n",
    " 'NGC3627': 'bottom','NGC4254': 'bottom','NGC4303': 'center','NGC4321': 'center',\n",
    " 'NGC4535': 'bottom','NGC5068': 'bottom','NGC7496': 'bottom'}\n",
    "\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(single_column,single_column/1.618))\n",
    "\n",
    "ax.plot(distance,alpha,color='gray',lw=0.5,zorder=1)\n",
    "\n",
    "'''\n",
    "cmap = plt.cm.viridis_r\n",
    "cmap.set_bad('black')\n",
    "#tmp = results[np.isin(results['name'],masked)]\n",
    "tmp = results[results['AO']]\n",
    "sc = ax.scatter(tmp['d/Mpc'],tmp['alpha2'],s=2,marker='d',\n",
    "                c=tmp['age_mw'],cmap=cmap,zorder=2)\n",
    "#tmp = results[~np.isin(results['name'],masked)]\n",
    "tmp = results[~results['AO']]\n",
    "sc = ax.scatter(tmp['d/Mpc'],tmp['alpha2'],s=2,marker='o',\n",
    "                c=tmp['age_mw'],cmap=cmap,zorder=2)\n",
    "'''\n",
    "sc = ax.scatter(results['d/Mpc'],results['alpha2'],s=2,marker='o',c=tab10[0],zorder=2)\n",
    "\n",
    "for name in results['name']:\n",
    "    ax.text(results.loc[name]['d/Mpc'],results.loc[name]['alpha2'],name,\n",
    "            horizontalalignment=halign.get(name,'left'),\n",
    "            verticalalignment=valign.get(name,'center'),\n",
    "            fontsize=4)\n",
    "#fig.colorbar(sc,label=r'$12+\\log_{10} \\mathrm{O/H}$')\n",
    "#fig.colorbar(sc,label=r'$N_\\mathrm{PN} / L_\\mathrm{bol}$')\n",
    "ax.set(xlim=[4,27],\n",
    "       xlabel='distance / Mpc',\n",
    "       ylabel=r'$\\log_{10} (N_\\mathrm{PN} / L_\\mathrm{bol})$')\n",
    "plt.savefig(basedir/'reports'/'specific_PN_number_vs_distance.pdf',dpi=600)\n",
    "plt.show()\n",
    "\n",
    "print(spearmanr(results['resolution'],results['alpha2']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the number of detection does not really depend on the distance but rather on the resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "ref_gal = 'NGC0628'\n",
    "row = results.loc[ref_gal]\n",
    "\n",
    "res = np.mean(results['PSF'])*(Distance(distmod=distmod)*(u.arcsec.to(u.rad))).to(u.pc).value\n",
    "# number of PN at reference point (1-res/250) for decrease due to resolution\n",
    "Nref = row['N_PN'] / np.interp(row['resolution'],res,p)\n",
    "alpha = np.log10(p*Nref/row['Lbol'])\n",
    "\n",
    "masked = [k for k,v in parameters.items() if 'mask' in v]\n",
    "\n",
    "halign = {\n",
    " 'IC5332': 'left','NGC0628': 'left','NGC1087': 'center','NGC1300': 'right',\n",
    " 'NGC1365': 'right','NGC1385': 'left','NGC1433': 'left','NGC1512': 'left',\n",
    " 'NGC1566': 'right','NGC1672': 'left','NGC2835': 'left','NGC3351': 'left',\n",
    " 'NGC3627': 'center','NGC4254': 'right','NGC4303': 'right','NGC4321': 'center',\n",
    " 'NGC4535': 'right','NGC5068': 'left','NGC7496': 'left'}\n",
    "\n",
    "valign = {\n",
    " 'IC5332': 'bottom','NGC0628': 'bottom','NGC1087': 'bottom','NGC1300': 'center',\n",
    " 'NGC1365': 'bottom','NGC1385': 'top','NGC1433': 'top','NGC1512': 'bottom',\n",
    " 'NGC1566': 'center','NGC1672': 'top','NGC2835': 'bottom','NGC3351': 'top',\n",
    " 'NGC3627': 'bottom','NGC4254': 'bottom','NGC4303': 'top','NGC4321': 'bottom',\n",
    " 'NGC4535': 'top','NGC5068': 'top','NGC7496': 'bottom'}\n",
    "\n",
    "print('correlation={:.2f}, pvalue={:.4f}'.format(*spearmanr(results['resolution'],results['alpha2'])))\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(single_column,single_column/1.618))\n",
    "\n",
    "ax.plot(res,alpha,color='gray',lw=0.5,zorder=1)\n",
    "\n",
    "#sc = ax.scatter(results['resolution'],results['alpha2'],s=2,\n",
    "#                c=results['mass'],cmap=plt.cm.viridis_r,zorder=2)\n",
    "\n",
    "#tmp = results[np.isin(results['name'],masked)]\n",
    "tmp = results[results['AO']]\n",
    "sc = ax.scatter(tmp['resolution'],tmp['alpha2'],s=2,marker='d',\n",
    "                c=tmp['R0'],cmap=plt.cm.viridis_r,zorder=2)\n",
    "#tmp = results[~np.isin(results['name'],masked)]\n",
    "tmp = results[~results['AO']]\n",
    "sc = ax.scatter(tmp['resolution'],tmp['alpha2'],s=2,marker='o',\n",
    "                c=tmp['R0'],cmap=plt.cm.viridis_r,zorder=2)\n",
    "\n",
    "\n",
    "for name in results['name']:\n",
    "    ax.text(results.loc[name]['resolution'],results.loc[name]['alpha2'],name,\n",
    "            horizontalalignment=halign.get(name,'left'),\n",
    "            verticalalignment=valign.get(name,'center'),\n",
    "            fontsize=4)\n",
    "#fig.colorbar(sc,label=r'$\\log_{10} M/\\mathrm{M}_\\odot$')\n",
    "fig.colorbar(sc,label=r'$12+\\log_{10} \\mathrm{O/H}$')\n",
    "\n",
    "ax.set(xlim=[11,91],\n",
    "       xlabel='resolution in pc',\n",
    "       ylabel=r'$\\log_{10} N_\\mathrm{PN} / L_\\mathrm{bol}$')\n",
    "plt.savefig(basedir/'reports'/'specific_PN_number_vs_resolution.pdf',dpi=600)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "can I simply use the number of detected PN? This means that galaxies further away will natuarlly have fewer detections as their cutoff is closer to the completeness limit and hence we expect fewer PNe anyways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "halign = {\n",
    " 'IC5332': 'right','NGC0628': 'left','NGC1087': 'left','NGC1300': 'right',\n",
    " 'NGC1365': 'left','NGC1385': 'left','NGC1433': 'left','NGC1512': 'left',\n",
    " 'NGC1566': 'right','NGC1672': 'left','NGC2835': 'left','NGC3351': 'left',\n",
    " 'NGC3627': 'right','NGC4254': 'left','NGC4303': 'right','NGC4321': 'right',\n",
    " 'NGC4535': 'left','NGC5068': 'left','NGC7496': 'left'}\n",
    "\n",
    "valign = {\n",
    " 'IC5332': 'top','NGC0628': 'bottom','NGC1087': 'bottom','NGC1300': 'center',\n",
    " 'NGC1365': 'top','NGC1385': 'top','NGC1433': 'center','NGC1512': 'top',\n",
    " 'NGC1566': 'center','NGC1672': 'top','NGC2835': 'bottom','NGC3351': 'top',\n",
    " 'NGC3627': 'top','NGC4254': 'top','NGC4303': 'top','NGC4321': 'center',\n",
    " 'NGC4535': 'top','NGC5068': 'top','NGC7496': 'bottom'}\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(2*single_column,2*single_column/1.618))\n",
    "sc = ax.scatter(results['resolution'],results['alpha'],s=8,\n",
    "                c=results['mass'],cmap=plt.cm.viridis_r)\n",
    "for name in results['name']:\n",
    "    ax.text(results.loc[name]['resolution'],results.loc[name]['alpha'],name,\n",
    "            horizontalalignment=halign.get(name,'left'),\n",
    "            verticalalignment=valign.get(name,'center'),\n",
    "            fontsize=8)\n",
    "\n",
    "fig.colorbar(sc,label=r'$\\log_{10} M/\\mathrm{M}_\\odot$')\n",
    "\n",
    "#fig.colorbar(sc,label=r'$N_\\mathrm{PN} / L_\\mathrm{bol}$')\n",
    "ax.set(xlim=[10,90],\n",
    "       xlabel='resolution / pc',\n",
    "       ylabel=r'$\\log N_\\mathrm{PN} / L_\\mathrm{bol}$')\n",
    "#plt.savefig(basedir/'reports'/'specific_PN_number_vs_resolution.pdf',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how many PN do we expect in a given galaxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate alpha from a reference galaxy\n",
    "ref_gal = 'NGC5068'\n",
    "row = results.loc[ref_gal]\n",
    "Nref = row['N_PN'] / np.interp(row['(m-M)'],distmod,p)\n",
    "alpha = np.log10(p*Nref/row['Lbol'])\n",
    "\n",
    "# use alpha to predict the number of PN in another galaxy\n",
    "gal_name = 'NGC0628'\n",
    "row = results.loc[gal_name]\n",
    "a = np.interp(row['(m-M)'],distmod,alpha)\n",
    "print(f\"predicted: {10**a * row['Lbol']:.1f}, observed: {row['N_PN']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or based on resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate alpha from a reference galaxy\n",
    "ref_gal = 'NGC1512'\n",
    "row = results.loc[ref_gal]\n",
    "Nref = row['N_PN'] / np.interp(row['resolution'],res,p)\n",
    "alpha = np.log10(p*Nref/row['Lbol'])\n",
    "\n",
    "# use alpha to predict the number of PN in another galaxy\n",
    "gal_name = 'NGC0628'\n",
    "row = results.loc[gal_name]\n",
    "a = np.interp(row['resolution'],res,alpha)\n",
    "print(f\"predicted: {10**a * row['Lbol']:.1f}, observed: {row['N_PN']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "up to what distance can we observe a given galaxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ref_gal in results['name']:\n",
    "    row = results.loc[ref_gal]\n",
    "    Nref = row['N_PN'] / np.interp(row['d/Mpc'],distance,p)\n",
    "    alpha = np.log10(p*Nref/row['Lbol'])\n",
    "\n",
    "    alpha_min = np.log10(20/row['Lbol'])\n",
    "    max_dist = np.interp(-alpha_min,-alpha,distance)\n",
    "    \n",
    "    print(f'{ref_gal}: alpha={alpha[0]:.2f}, max_dist={max_dist:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NGC5068 has the largest $\\alpha=-7.56$ and NGC1433 is the most luminous. Up to what distance could we observe a combination of both. NGC1365 has the smallest $\\alpha=-8.32$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = results.loc['NGC5068']\n",
    "Nref = row['N_PN'] / np.interp(row['d/Mpc'],distance,p)\n",
    "alpha = np.log10(p*Nref/row['Lbol'])\n",
    "\n",
    "row = results.loc['NGC1433']\n",
    "alpha_min = np.log10(20/row['Lbol'])\n",
    "max_dist = np.interp(-alpha_min,-alpha,distance)\n",
    "\n",
    "print(f'alpha={alpha[0]:.2f}, max_dist={max_dist:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = results.loc['NGC1365']\n",
    "Nref = row['N_PN'] / np.interp(row['d/Mpc'],distance,p)\n",
    "alpha = np.log10(p*Nref/row['Lbol'])\n",
    "\n",
    "row = results.loc['NGC1433']\n",
    "alpha_min = np.log10(20/row['Lbol'])\n",
    "max_dist = np.interp(-alpha_min,-alpha,distance)\n",
    "\n",
    "print(f'alpha={alpha[0]:.2f}, max_dist={max_dist:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alst = []\n",
    "for ref_gal in results['name']:\n",
    "    row = results.loc[ref_gal]\n",
    "    Nref = row['N_PN'] / np.interp(row['(m-M)'],distmod,p)\n",
    "    alpha = np.log10(p*Nref/row['Lbol'])\n",
    "    alst.append(alpha[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(alst,results['alpha'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.scatter(results['mass'],results['obs_mass'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "708.667px",
    "left": "28px",
    "top": "110.283px",
    "width": "237.533px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
