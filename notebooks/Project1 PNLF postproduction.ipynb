{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project1 PNLF Postproduction <a class=\"tocSkip\">\n",
    "    \n",
    "After running the production notebook, this notebook can be used to create shared plots for the galaxies and LaTeX output tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "     \n",
    "First we load a bunch of common packages that are used across the project. More specific packages that are only used in one section are loaded later to make it clear where they belong to (this also applies to all custom moduls that were written for this project)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload modules after they have been modified\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pnlf.packages import *\n",
    "\n",
    "from pnlf.constants import tab10, single_column, two_column\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we use the `logging` module to handle informations and warnings (this does not always work as expected in jupyter notebooks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout,format='%(levelname)s: %(message)s',level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we need to specify the path to the raw data\n",
    "basedir = Path('..')\n",
    "data_raw = basedir / 'data' / 'raw' / 'MUSE' / 'DR2'\n",
    "\n",
    "with open(basedir / 'data' / 'interim' / 'parameters.yml') as yml_file:\n",
    "    parameters = yaml.load(yml_file,Loader=yaml.FullLoader)\n",
    "    \n",
    "results = ascii.read(basedir/'data'/'interim'/ 'results.txt',format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "results.add_index('name')\n",
    "#results.rename_columns(['(m-M)','err+(m-M)','err-(m-M)','mu_SNR','mu_SNR+','mu_SNR-'],['dis','dis_plus','dis_minus','dis_SNR','dis_SNR_plus','dis_SNR_minus'])\n",
    "\n",
    "with open(basedir / 'data' / 'interim' / 'parameters.yml') as yml_file:\n",
    "    parameters = yaml.load(yml_file,Loader=yaml.FullLoader)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## LaTeX sample table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.auxiliary import search_table\n",
    "\n",
    "def area(dic):\n",
    "    '''Calculate the area in an image\n",
    "    \n",
    "    from the number of pixels and the distance,\n",
    "    corrected for inclination\n",
    "    '''\n",
    "    \n",
    "    size_of_pixel = 0.2*u.arcsec\n",
    "\n",
    "    distance = Distance(distmod=dic['mu'])\n",
    "    pixel_area = (size_of_pixel/u.arcsec * distance/206265)**2\n",
    "        \n",
    "    return pixel_area.to(u.kpc**2) *dic['Npixel'] / np.cos(dic['inclination']*u.deg)\n",
    "\n",
    "\n",
    "filename = basedir / 'data' / 'external' / 'phangs_sample_table_v1p5.fits'\n",
    "with fits.open(filename) as hdul:\n",
    "    sample_table = Table(hdul[1].data)\n",
    "\n",
    "#galaxies = sample_table[sample_table['HAS_MUSE']==1]['NAME']\n",
    "galaxies = sample_table[sample_table['survey_muse_status']!='not_in_survey']['name']\n",
    "\n",
    "latexdict = {'tabletype': 'table*',\n",
    "'header_start': '\\\\toprule\\\\toprule',\n",
    "'header_end': '\\\\midrule',\n",
    "'data_end': '\\\\bottomrule',\n",
    "'caption': f'Galaxy sample',\n",
    "'units': {'R.A.':'(J2000)','Dec.':'(J2000)','Inclination':'deg','Distance':'$\\si{\\mega\\parsec}$',\n",
    "          'Survey Area':'$\\si{\\square\\kilo\\parsec}$'},\n",
    "'preamble': '\\\\centering',\n",
    "'tablefoot': f'\\\\label{{tbl:sample}}'\n",
    "            }\n",
    " \n",
    "sample_dict = {\n",
    "'Name': [],\n",
    "'Type':[],\n",
    "'R.A.': [],\n",
    "'Dec.': [],\n",
    "'Distance': [],\n",
    "'Inclination': [],\n",
    "'posang': [],\n",
    "'r25': [],\n",
    "'mass': [],\n",
    "'SFR': [],\n",
    "'Survey Area': [],\n",
    "'E(B-V)': [],\n",
    "'AO' : []\n",
    "}\n",
    "\n",
    "    \n",
    "for name in galaxies:\n",
    "    stbl = search_table(sample_table,name)\n",
    "    d = stbl[\"dist\"][0]\n",
    "    d_unc = stbl[\"dist_unc\"][0]\n",
    "\n",
    "    sample_dict['Type'].append(stbl['morph_string'])    \n",
    "    sample_dict['Name'].append(name.upper())\n",
    "    sample_dict['R.A.'].append(stbl['orient_ra'])\n",
    "    sample_dict['Dec.'].append(stbl['orient_dec'])\n",
    "    sample_dict['Distance'].append(d)\n",
    "    sample_dict['Inclination'].append(stbl['orient_incl'])\n",
    "    sample_dict['posang'].append(stbl['orient_posang'])\n",
    "    sample_dict['r25'].append(stbl['size_r25'])\n",
    "    sample_dict['mass'].append(stbl['props_mstar'])\n",
    "    sample_dict['SFR'].append(stbl['props_sfr'])\n",
    "    sample_dict['E(B-V)'].append(parameters[name.upper()]['Ebv'])\n",
    "    if parameters[name.upper()]['power_index'] == 2.3:\n",
    "        sample_dict['AO'].append('\\checkmark')\n",
    "    else:\n",
    "        sample_dict['AO'].append('')\n",
    "\n",
    "    try:\n",
    "        sample_dict['Survey Area'].append(f'{area(parameters[name.upper()]).value:.1f}')\n",
    "    except:\n",
    "        sample_dict['Survey Area'].append('NaN')\n",
    "    '''\n",
    "    sample_dict['Name'].append(name)\n",
    "    sample_dict['R.A.'].append(stbl['ORIENT_RA'])\n",
    "    sample_dict['Dec.'].append(stbl['ORIENT_DEC'])\n",
    "    sample_dict['Distance'].append(stbl['DIST'])\n",
    "    sample_dict['Inclination'].append(stbl['ORIENT_INCL'])\n",
    "    sample_dict['$\\log_{10}(M_*)$'].append(stbl['MSTAR_LOGMSTAR'])\n",
    "    sample_dict['$\\log_{10}($SFR$)$'].append(stbl['SFR_LOGSFR'])\n",
    "    '''\n",
    "\n",
    "sample = Table(sample_dict)\n",
    "sample['mass'] = np.log10(sample['mass'])\n",
    "sample['SFR'] = np.log10(sample['SFR'])\n",
    "sample['mass'].info.format = '%.2f' \n",
    "sample['SFR'].info.format = '%.2f' \n",
    "coord = SkyCoord(sample['R.A.']*u.degree,sample['Dec.']*u.degree)\n",
    "sample['R.A.'], sample['Dec.'] = zip(*[x[0].split(' ') for x in coord.to_string(style='hmsdms',precision=2)])\n",
    "#sample.add_column('',index=1,name='Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(basedir / 'data' / 'interim' / 'sample.txt','w',newline='\\n') as f:\n",
    "    ascii.write(sample,f,format='fixed_width_two_line',overwrite=True,delimiter_pad=' ',position_char='=')\n",
    "    \n",
    "sample.rename_columns(['mass','SFR'],['$\\log_{10}(M_*/\\si{\\Msun})$','$\\log_{10}($SFR$/\\si{\\Msun \\per \\year})$'])\n",
    "sample.remove_columns(['r25','Survey Area'])\n",
    "with open(basedir / 'data' / 'interim' /'sample.tex','w',newline='\\n') as f:\n",
    "    ascii.write(sample,f,Writer=ascii.Latex, latexdict=latexdict,overwrite=True)\n",
    "    \n",
    "#sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LaTeX result table\n",
    "\n",
    "this uses the result table and prints out a LaTeX table (only the data part) that can be used in the final document. In another step, we merge the individual catalogues for PN and SNR identifications. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['dis_Mpc'] = Distance(distmod=results['(m-M)']).to(u.Mpc)\n",
    "results['dis_Mpc_plus'] = (Distance(distmod=results['(m-M)']+results['err+(m-M)']) - results['dis_Mpc']).to(u.Mpc)\n",
    "results['dis_Mpc_minus'] = (results['dis_Mpc']-Distance(distmod=results['(m-M)']-results['err-(m-M)'])).to(u.Mpc)\n",
    "\n",
    "#results['dis_SNR_Mpc'] = (Distance(distmod=results['dis_SNR'])).to(u.Mpc)\n",
    "#results['dis_SNR_Mpc_plus'] = (Distance(distmod=results['dis_SNR']+results['dis_SNR_plus']) - results['dis_SNR_Mpc']).to(u.Mpc)\n",
    "#results['dis_SNR_Mpc_minus'] = (results['dis_SNR_Mpc']-Distance(distmod=results['dis_SNR']-results['dis_SNR_minus'])).to(u.Mpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "for col in ['(m-M)','err+(m-M)','err-(m-M)','dis_Mpc','dis_Mpc_plus','dis_Mpc_minus']:\n",
    "    results[col].info.format = '%.2f'\n",
    "\n",
    "distance_modulus = []\n",
    "distance_parsec = []\n",
    "for row in results:\n",
    "    distance_modulus.append(f'{row[\"(m-M)\"]:.2f} + {row[\"err-(m-M)\"]:.2f} - {row[\"err+(m-M)\"]:.2f}')\n",
    "    distance_parsec.append(f'{row[\"dis_Mpc\"]:.2f} + {row[\"dis_Mpc_plus\"]:.2f} - {row[\"dis_Mpc_plus\"]:.2f}')\n",
    "results['mu'] = distance_modulus\n",
    "results['d/Mpc'] = distance_parsec\n",
    "                           \n",
    "filename = basedir / 'data' / 'interim' / f'distances.txt'\n",
    "with open(filename,'w',newline='\\n') as f:\n",
    "    ascii.write(results[['name','mu','d/Mpc']],\n",
    "                f,format='fixed_width',delimiter='\\t',overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_out = ''\n",
    "results.sort('name')\n",
    "for row in results:\n",
    "    tbl_out += f'{row[\"name\"]} & {row[\"N_PN\"]} & {row[\"N_SNR\"]} ({row[\"N_SNRorPN\"]}) '\n",
    "    tbl_out += f'& $\\\\uncertainty{{{row[\"(m-M)\"]:.2f}}}{{{row[\"err+(m-M)\"]:.2f}}}{{{row[\"err-(m-M)\"]:.2f}}}$ '\n",
    "    tbl_out += f'& $\\\\uncertainty{{{row[\"dis_Mpc\"]:.2f}}}{{{row[\"dis_Mpc_plus\"]:.2f}}}{{{row[\"dis_Mpc_minus\"]:.2f}}}$ '\n",
    "    tbl_out += f'& {row[\"alpha\"]:.2f}\\\\\\\\\\n'\n",
    "    #tbl_out += f'& $\\\\uncertainty{{{row[\"dis_SNR\"]:.2f}}}{{{row[\"dis_SNR_plus\"]:.2f}}}{{{row[\"dis_SNR_minus\"]:.2f}}}$ '\n",
    "    #tbl_out += f'& $\\\\uncertainty{{{row[\"dis_SNR_Mpc\"]:.2f}}}{{{row[\"dis_SNR_Mpc_plus\"]:.2f}}}{{{row[\"dis_SNR_Mpc_minus\"]:.2f}}}$\\\\\\\\\\n'\n",
    "    \n",
    "    \n",
    "print(tbl_out)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_out = ''\n",
    "results.sort('name')\n",
    "for row in results:\n",
    "    print(f'\\\\setvalue{{mag/{row[\"name\"]} =\\\\SI{{\\\\uncertainty{{{row[\"(m-M)\"]:.2f}}}{{{row[\"err+(m-M)\"]:.2f}}}{{{row[\"err-(m-M)\"]:.2f}}}}}{{\\\\mag}}}}')\n",
    "print(' ')\n",
    "for row in results:\n",
    "    print(f'\\\\setvalue{{Mpc/{row[\"name\"]} =\\\\SI{{\\\\uncertainty{{{row[\"dis_Mpc\"]:.2f}}}{{{row[\"dis_Mpc_plus\"]:.2f}}}{{{row[\"dis_Mpc_minus\"]:.2f}}}}}{{\\\\mega\\\\parsec}}}}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_lst = []\n",
    "ID_lst = []\n",
    "for name in results['name']:\n",
    "    tmp = ascii.read(basedir/'data'/'catalogues'/f'{name}_SNR_candidates.txt',format='fixed_width_two_line')\n",
    "    ID_lst += list(tmp['ID'])\n",
    "    del tmp['ID']\n",
    "    tbl_lst.append(tmp)\n",
    "    \n",
    "tbl = vstack(tbl_lst)\n",
    "tbl.add_column(ID_lst,index=1,name='ID')\n",
    "\n",
    "\n",
    "with open(basedir/'data'/'catalogues'/'SNR_candidates.txt','w',newline='\\n') as f:\n",
    "    ascii.write(tbl,f,format='fixed_width_two_line',overwrite=True,delimiter_pad=' ',position_char='=')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined PNLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we define possible lists of objects to plot\n",
    "DR2  = ['NGC1300','NGC1385','NGC1433','NGC4303','NGC4321','NGC7496']\n",
    "good = ['IC5332','NGC0628','NGC1566','NGC3351','NGC3627','NGC5068']\n",
    "#good = ['NGC0628','NGC3627','NGC5068']\n",
    "PHANGS_sample = ['IC5332','NGC1087','NGC1300','NGC1365','NGC1385','NGC1433', 'NGC1512','NGC1566','NGC1672',\n",
    "                 'NGC2835','NGC3351','NGC3627','NGC4254','NGC4303','NGC4321','NGC4535','NGC5068','NGC7496']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.plot.pnlf import _plot_pnlf\n",
    "\n",
    "names = results['name']\n",
    "nrows = 5\n",
    "ncols = 4\n",
    "filename = basedir / 'reports' / f'all_objects_PNLF'\n",
    "\n",
    "#----------------------------------------------\n",
    "# DO NOT MODIFY BELOW\n",
    "#----------------------------------------------\n",
    "if nrows*ncols<len(names):\n",
    "    raise ValueError('not enough subplots for selected objects') \n",
    "width = two_column\n",
    "fig, axes = plt.subplots(nrows=nrows,ncols=ncols,figsize=(width,width/ncols*nrows))\n",
    "axes_iter = iter(axes.flatten())\n",
    "Mmax = -4.47\n",
    "    \n",
    "# loop over the galaxies we want to plot\n",
    "for name in names:  \n",
    "    # read in the data\n",
    "    catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "    if catalogue_file.is_file():\n",
    "        catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "        catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "    else:\n",
    "        print(f'no catalogue for {name}')\n",
    "        continue\n",
    "        \n",
    "    # get the next axis and find position on the grid\n",
    "    ax = next(axes_iter)\n",
    "    if nrows>1 and ncols>1:\n",
    "        i, j = np.where(axes == ax)\n",
    "        i,j=i[0],j[0]\n",
    "    elif ncols>1:\n",
    "        i,j = 0, np.where(axes==ax)[0]\n",
    "    elif nrows>1:\n",
    "        i,j = np.where(axes==ax)[0],0\n",
    "    else:\n",
    "        i,j=0,0\n",
    "        \n",
    "    # pre-process the data for the plot and read additional parameters\n",
    "    data = catalogue[(catalogue['type']=='PN') & (~catalogue['exclude'])]['mOIII']\n",
    "    mu = results.loc[name]['(m-M)']\n",
    "    completeness = parameters[name]['completeness_limit']\n",
    "    cut = parameters[name].get('cut',0)\n",
    "    if cut>0:\n",
    "        print(f'warning: using cut={cut} for {name}')\n",
    "    data = data[data>cut]\n",
    "    binsize = parameters[name]['binsize']\n",
    "    mlow = Mmax+mu\n",
    "    mhigh = 30\n",
    "\n",
    "    ax=_plot_pnlf(data,mu,completeness,binsize=binsize,ax=ax)\n",
    "    ax.text(0.4,0.08,f'{name}', transform=ax.transAxes,fontsize=7)\n",
    "\n",
    "    #ax.set_xlim([mu-5,completeness+0.5])\n",
    "    # add labels to the axis\n",
    "    if i==nrows-1:\n",
    "        ax.set_xlabel(r'$m_{[\\mathrm{OIII}]}$ / mag')\n",
    "    if j==0:\n",
    "        ax.set_ylabel(r'N')\n",
    "    #ax.set_title(name)\n",
    "    \n",
    "h,l = fig.axes[0].get_legend_handles_labels()\n",
    "#fig.legend(h, l, bbox_to_anchor=(0., 1.01, 1., .051),loc = 'upper center',ncol=2)\n",
    "\n",
    "axes[3,3].set_xlabel(r'$m_{[\\mathrm{OIII}]}$ / mag')\n",
    "ax = next(axes_iter)\n",
    "ax.remove()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(filename.with_suffix('.pdf'),bbox_inches='tight')\n",
    "plt.savefig(filename.with_suffix('.png'),bbox_inches='tight',dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined cumulative PNLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.plot.pnlf import _plot_cum_pnlf\n",
    "from pnlf.analyse import cdf\n",
    "from scipy.stats import kstest\n",
    "\n",
    "names = results['name']\n",
    "nrows = 5\n",
    "ncols = 4\n",
    "filename = basedir / 'reports' / f'all_objects_PNLF_cum'\n",
    "\n",
    "#----------------------------------------------\n",
    "# DO NOT MODIFY BELOW\n",
    "#----------------------------------------------\n",
    "if nrows*ncols<len(names):\n",
    "    raise ValueError('not enough subplots for selected objects')\n",
    "width = two_column\n",
    "fig, axes = plt.subplots(nrows=nrows,ncols=ncols,figsize=(width,width/ncols*nrows))\n",
    "axes_iter = iter(axes.flatten())\n",
    "\n",
    "binsize=0.1\n",
    "Mmax = -4.47\n",
    "color = 'tab:red'\n",
    "\n",
    "for name in names:  \n",
    "        \n",
    "    catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "    if catalogue_file.is_file():\n",
    "        catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "        catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "    else:\n",
    "        print(f'no catalogue for {name}')\n",
    "        continue\n",
    "    \n",
    "    # get the next axis\n",
    "    ax = next(axes_iter)\n",
    "    # find current position on the grid\n",
    "    i, j = np.where(axes == ax)\n",
    "    i,j=i[0],j[0]\n",
    "    \n",
    "    data = catalogue[(catalogue['type']=='PN') & (~catalogue['exclude'])]['mOIII']\n",
    "    mu = results.loc[name]['(m-M)']\n",
    "    completeness = parameters[name]['completeness_limit']\n",
    "    cut = parameters[name].get('cut',0)\n",
    "    if cut>0:\n",
    "        print(f'warning: using cut={cut} for {name}')\n",
    "    data = data[data>cut]\n",
    "\n",
    "    ks,pv = kstest(data[data<completeness],cdf,args=(mu,completeness))\n",
    "\n",
    "    ax=_plot_cum_pnlf(data,mu,completeness,ax=ax,binsize=None)\n",
    "    ax.text(0.55,0.08,f'{name}', transform=ax.transAxes,fontsize=7)\n",
    "    ax.text(0.1,0.78,f'$p$-value$={pv:.2f}$',transform=ax.transAxes,fontsize=7)\n",
    "    ax.text(0.1,0.88,f'$D_{{max}}={ks:.3f}$', transform=ax.transAxes,fontsize=7)\n",
    "\n",
    "    # add labels to the axis\n",
    "    if i==nrows-1:\n",
    "        ax.set_xlabel(r'$m_{[\\mathrm{OIII}]}$ / mag')\n",
    "    if j==0:\n",
    "        ax.set_ylabel(r'Cumulative N')\n",
    "    \n",
    "    #ax.set_title(name)\n",
    "axes[3,3].set_xlabel(r'$m_{[\\mathrm{OIII}]}$ / mag')\n",
    "ax = next(axes_iter)\n",
    "ax.remove()\n",
    "\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig(filename.with_suffix('.pdf'),bbox_inches='tight')\n",
    "plt.savefig(filename.with_suffix('.png'),bbox_inches='tight',dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine line diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.analyse import PNLF\n",
    "\n",
    "names = result['name']\n",
    "style = {'SNR':{\"marker\":'o',\"ms\":3,\"mfc\":'None',\"mec\":tab10[0],'ls':'none','ecolor':tab10[0]},\n",
    "         'SNRorPN':{\"marker\":'o',\"ms\":4,\"mfc\":'white',\"mec\":'tab:green','ls':'none','ecolor':'tab:green'},\n",
    "         'HII':{\"marker\":'+',\"ms\":3,\"mec\":tab10[1],'ls':'none'},\n",
    "         'PN':{\"marker\":'o',\"ms\":2,\"mfc\":'black','mec':'black','ls':'none','ecolor':'black'}\n",
    "        }\n",
    "Mmax=-4.47\n",
    "color = 'tab:red'\n",
    "\n",
    "# define the figure with the number of subplots\n",
    "nrows = 2\n",
    "ncols = 3\n",
    "width = two_column\n",
    "fig, axes_arr = plt.subplots(nrows=nrows,ncols=ncols,figsize=(width,width/ncols*nrows))\n",
    "axes = iter(axes_arr.flatten())\n",
    "\n",
    "\n",
    "names = ['IC5332','NGC0628','NGC1566','NGC3351','NGC3627','NGC5068']\n",
    "\n",
    "# loop over the galaxies we want to plot\n",
    "for name in names:  \n",
    "       \n",
    "    # read in the data\n",
    "    catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "    if catalogue_file.is_file():\n",
    "        catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "        catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "        for col in catalogue.columns:\n",
    "            if col.endswith('detection'):\n",
    "                catalogue[col] = catalogue[col]=='True'\n",
    "    else:\n",
    "        print(f'no catalogue for {name}')\n",
    "        continue\n",
    "        \n",
    "    # get the next axis\n",
    "    ax = next(axes)\n",
    "    # find current position on the grid\n",
    "    i, j = np.where(axes_arr == ax)\n",
    "    i,j=i[0],j[0]\n",
    "    \n",
    "    # pre-process the data for the plot and read additional parameters\n",
    "    mu = result.loc[name]['dis']\n",
    "    completeness = parameters[name]['completeness_limit']\n",
    "    \n",
    "    # draw line that we use seperate PN from HII\n",
    "    MOIII = np.linspace(-5,1)\n",
    "    OIII_Ha = 10**(-0.37*(MOIII)-1.16)\n",
    "    ax.plot(MOIII,OIII_Ha,c='black',lw=0.6)\n",
    "    ax.axhline(10**4)\n",
    "\n",
    "    if completeness:\n",
    "        ax.axvline(completeness-mu,ls='--',c='grey',lw=0.5)\n",
    "    ax.axvline(Mmax,ls='--',c='grey',lw=0.5)\n",
    "\n",
    "    for t in ['HII','PN','SNR']:\n",
    "        tbl = catalogue[catalogue['type']==t]        \n",
    "        ax.errorbar(tbl['mOIII']-mu,tbl['OIII5006']/(tbl['HA6562']+tbl['NII6583']),**style[t],label=t) \n",
    "\n",
    "        if t=='PN':\n",
    "            # indicate for which PN we don't have a detection in HA6562\n",
    "            tbl = tbl[~tbl['HA6562_detection']]\n",
    "            ax.errorbar(tbl['mOIII']-mu,1.11*tbl['OIII5006']/(tbl['HA6562']+tbl['NII6583']),\n",
    "                         marker=r'$\\uparrow$',ms=4,mec='black',ls='none') \n",
    "        if t=='SNR':\n",
    "            #tbl = tbl[tbl['SNRorPN']] \n",
    "            ax.errorbar(tbl['mOIII']-mu,tbl['OIII5006']/(tbl['HA6562']+tbl['NII6583']), marker='x',ms=2,mec=tab10[0],ls='none') \n",
    "   \n",
    "    # objects that were rejeceted by eye\n",
    "    tbl = catalogue[catalogue['exclude']]\n",
    "    ax.errorbar(tbl['mOIII']-mu,tbl['OIII5006']/(tbl['HA6562']+tbl['NII6583']),marker='o',ms=3,ls='none',color='tab:green',label='rejected') \n",
    "    \n",
    "    \n",
    "    # configure axes \n",
    "    ax.set(xlim=[-5,np.ceil(completeness-mu)],\n",
    "           ylim=[0.03,200],\n",
    "           yscale='log')\n",
    "    \n",
    "    ax.yaxis.set_major_formatter(mpl.ticker.FuncFormatter(lambda y, _: '{:.16g}'.format(y)))\n",
    "\n",
    "    axt = ax.twiny()\n",
    "    xlim1,xlim2 = ax.get_xlim()\n",
    "    axt.set_xticks(np.arange(np.ceil(xlim1+mu),np.floor(xlim2+mu)+1),minor=False)\n",
    "    axt.set(xlim   = [xlim1+mu,xlim2+mu])\n",
    "    \n",
    "    if i==0:\n",
    "        axt.set(xlabel = r'$m_{\\mathrm{[OIII]}}$')\n",
    "    \n",
    "    if i==nrows-1:\n",
    "        ax.set(xlabel=r'$M_{\\mathrm{[OIII]}}$')\n",
    "    if j==0:\n",
    "        ax.set(ylabel=r'[OIII] / $(\\mathrm{H}\\alpha + \\mathrm{[NII]})$')\n",
    "    ax.set_title(name)\n",
    "    \n",
    "    ax.xaxis.set_major_locator(mpl.ticker.MaxNLocator(integer=True))\n",
    "    \n",
    "    \n",
    "h,l = fig.axes[0].get_legend_handles_labels()\n",
    "fig.legend(h, l, bbox_to_anchor=(0., 1.01, 1., .051),loc = 'upper center',ncol=4)\n",
    "\n",
    "plt.tight_layout()\n",
    "filename = basedir / 'reports' / f'all_objects_line_diagnostics'\n",
    "plt.savefig(filename.with_suffix('.pdf'),bbox_inches='tight')\n",
    "plt.savefig(filename.with_suffix('.png'),bbox_inches='tight',dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot RGB image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.auxiliary import circular_mask\n",
    "from pnlf.plot.plot import create_RGB\n",
    "from pnlf.io import ReadLineMaps\n",
    "\n",
    "nrows = 5\n",
    "ncols = 4\n",
    "width = two_column\n",
    "fig, axes_arr = plt.subplots(nrows=nrows,ncols=ncols,figsize=(width,width/ncols*nrows))\n",
    "axes = iter(axes_arr.flatten())\n",
    "\n",
    "# loop over the galaxies we want to plot\n",
    "for name in results['name']:  \n",
    "        \n",
    "    # get the next axis\n",
    "    ax = next(axes)\n",
    "    # find current position on the grid\n",
    "    i, j = np.where(axes_arr == ax)\n",
    "    i,j=i[0],j[0]\n",
    "    \n",
    "    #galaxy = galaxies[name]\n",
    "    galaxy = ReadLineMaps(data_raw,name,**parameters[name])\n",
    "    \n",
    "    # define masks as slices\n",
    "    masks = {\n",
    "     'NGC1300' : circular_mask(*galaxy.shape,radius=50),\n",
    "     'NGC1365' : circular_mask(*galaxy.shape,(720,420),radius=200),\n",
    "     #'NGC1433' : circular_mask(*galaxy.shape,radius=100),\n",
    "     'NGC1512' : circular_mask(*galaxy.shape,radius=70),\n",
    "     'NGC1566' : circular_mask(*galaxy.shape,(450,450),radius=100)|circular_mask(*galaxy.shape,(350,150),radius=180),\n",
    "     'NGC1672' : circular_mask(*galaxy.shape,(600,310),radius=60),\n",
    "     #'NGC3627' : circular_mask(*galaxy.shape,(330,740),radius=100),\n",
    "     'NGC3351' : circular_mask(*galaxy.shape,radius=200),\n",
    "     'NGC4321' : circular_mask(*galaxy.shape,(550,450),radius=60),\n",
    "     'NGC4535' : circular_mask(*galaxy.shape,(300,520),radius=100)\n",
    "    }\n",
    "    \n",
    "    mask = np.zeros(galaxy.shape,dtype=bool)\n",
    "    mask |= galaxy.star_mask.astype(bool)\n",
    "    mask[masks.get(galaxy.name,(slice(-1,0),slice(-1,0)))] = True\n",
    "\n",
    "    #img = galaxy.OIII5006_DAP.copy()\n",
    "    img = create_RGB(galaxy.HA6562,galaxy.OIII5006_DAP,galaxy.SII6716,weights=[0.6,1,0.6],percentile=[95,99.,95])\n",
    "    img[mask,...] = (1,1,1) #(1, 165/255, 1/255) \n",
    "\n",
    "    ax.imshow(img,origin='lower')\n",
    "    ax.set_title(name)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "filename = basedir / 'reports' / f'all_objects_rgb'\n",
    "plt.savefig(filename.with_suffix('.pdf'),bbox_inches='tight')\n",
    "#plt.savefig(filename.with_suffix('.png'),bbox_inches='tight',dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.auxiliary import mu_to_parsec, parsec_to_mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsec_to_mu(9.01,0.38,0.38)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redo all distance plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.plot.pnlf import compare_distances\n",
    "\n",
    "name = results[14]['name']\n",
    "mu,mu_m,mu_p = results.loc[name][['(m-M)','err-(m-M)','err+(m-M)']]\n",
    "\n",
    "print(name)\n",
    "filename = basedir / 'reports' / name / f'{name}_distances'\n",
    "distances = compare_distances(name,mu,mu_p,mu_m,filename=filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PN Number vs Mass etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=ascii.read(basedir/'reports'/'sample.txt')\n",
    "sample['SkyCoord'] = SkyCoord(sample['R.A.'],sample['Dec.'])\n",
    "sample.add_index('Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxies = {}\n",
    "\n",
    "for n in result['name']:\n",
    "    print('are you sure that you want to run this?')\n",
    "    break\n",
    "    filename = data_raw / 'MUSEDAP' / f'{n}_MAPS.fits'\n",
    "\n",
    "    with fits.open(filename) as hdul:\n",
    "        d=hdul['STELLAR_MASS_DENSITY'].data\n",
    "        galaxies[n]= np.nansum(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['mass']=sample['mass']\n",
    "result['Survey Area'] = sample['Survey Area']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the survey area from number of pixels and distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in result:\n",
    "    N_pix = row['N_pixel']\n",
    "    d = Distance(distmod=parameters[row['name']]['mu'])\n",
    "    A_pix = ((d*(0.2/206265))**2).to(u.kpc**2)\n",
    "    \n",
    "    print(f'{row[\"name\"]}: {d:.2f}, {N_pix*A_pix:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax1,ax2,ax3)=plt.subplots(ncols=3,nrows=1,figsize=(12,4))\n",
    "\n",
    "for row in result:\n",
    "    if row['N_PN']>1:\n",
    "        ax1.scatter(row['mass'],row['N_PN'])\n",
    "        ax1.text(row['mass'],row['N_PN']+2,row['name'],horizontalalignment='center')\n",
    "        \n",
    "        \n",
    "        ax2.scatter(row['Survey Area'],row['N_PN'])\n",
    "        ax2.text(row['Survey Area'],row['N_PN']+2,row['name'],horizontalalignment='center') \n",
    "\n",
    "        ax3.scatter(row['N_pixel'],row['N_PN'])\n",
    "        ax3.text(row['N_pixel'],row['N_PN']+2,row['name'],horizontalalignment='center') \n",
    "        \n",
    "\n",
    "ax1.set(xlabel='stellar mass density',ylabel='N PN')\n",
    "ax2.set(xlabel='Survey Area')\n",
    "ax3.set(xlabel='Npixel')\n",
    "#ax3.set(xlabel='Npixel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other PNLF studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = ascii.read(basedir/'data'/'literature distances'/'latest.csv',delimiter=',',header_start=12,data_start=14)\n",
    "results = ascii.read(basedir/'data'/'interim'/'results.txt')\n",
    "print(f\"intial cagalogue has {len(np.unique(distances[distances['Method']=='PNLF']['Galaxy ID']))} objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnlf_distances = distances[distances[\"Method\"]=='PNLF']\n",
    "print(f\"excluding {len(np.unique(pnlf_distances[(pnlf_distances['m-M']<22.5) | (pnlf_distances['m-M']>32)]['Galaxy ID']))} objects\")\n",
    "pnlf_distances = pnlf_distances[(pnlf_distances['m-M']>22.5) & (pnlf_distances['m-M']<32)]  # exclude the many measurments of the LMC and SMC\n",
    "\n",
    "pnlf_distances['year'] = pnlf_distances['Date (Yr. - 1980)']+1980\n",
    "pnlf_distances.rename_column('Galaxy ID','name')\n",
    "pnlf_distances['name'] = [n.rstrip('a').rstrip('b') for n in pnlf_distances['name']]\n",
    "\n",
    "alias = {\n",
    "    'NGC 0628': 'MESSIER 074',\n",
    "    'NGC 3351': 'MESSIER 095',\n",
    "    'NGC 3627': 'MESSIER 066',\n",
    "    'NGC 4254': 'MESSIER 099',\n",
    "    'NGC 4303': 'MESSIER 061',\n",
    "    'NGC 4321': 'MESSIER 100'\n",
    "}\n",
    "\n",
    "alias_back = {v:k for k,v in alias.items()}\n",
    "\n",
    "phangs_sample = []\n",
    "for row in results:\n",
    "    name = row['name'].replace('NGC','NGC ').replace('IC','IC ')\n",
    "    name = alias.get(name,name)\n",
    "    phangs_sample.append(name)\n",
    "    new = ['',0,0,name,row['(m-M)'],row['err-(m-M)'],0,'PNLF','Schmnn+2020','',0,0,0,40,'',2020]\n",
    "    pnlf_distances.add_row(new)\n",
    "    \n",
    "galaxies = list(np.unique(pnlf_distances['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we sort by mean distance\n",
    "mean_dis = []\n",
    "for gal in galaxies:\n",
    "    mean_dis.append(pnlf_distances[pnlf_distances['name']==gal]['m-M'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnlf_distances.sort('year')\n",
    "important_papers = dict()\n",
    "is_measured = []\n",
    "for row in pnlf_distances:\n",
    "    #if row['name'] not in is_measured:\n",
    "    #    is_measured.append(row['name'])\n",
    "    if row['REFCODE'] in important_papers:\n",
    "        important_papers[row['REFCODE']] += 1\n",
    "    else:\n",
    "        important_papers[row['REFCODE']] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1,figsize=(10,6/1.618))\n",
    "\n",
    "x_pos  = []\n",
    "gal_names = [x for _,x in sorted(zip(mean_dis,galaxies))]\n",
    "\n",
    "print(f'{len(gal_names)} galaxies in sample')\n",
    "color_grid=[]\n",
    "for i,gal in enumerate(gal_names):\n",
    "    tmp = pnlf_distances[pnlf_distances['name']==gal]\n",
    "    ax.scatter(len(tmp)*[i+1],tmp['m-M'],marker=\"_\",color='gray')\n",
    "    # color the measured by me red\n",
    "    if len(tmp[tmp['REFCODE']=='Schmnn+2020'])>0:\n",
    "        ax.scatter([i+1],tmp[tmp['REFCODE']=='Schmnn+2020']['m-M'],marker=\"_\",color='tab:red')\n",
    "        color_grid.append(i)\n",
    "\n",
    "# create a legend with numbers only\n",
    "#legend_elements = [mpl.lines.Line2D([0], [0], color=tab10[i], lw=2, label=str(i+1)) for i in range(10)]\n",
    "#plt.legend(handles=legend_elements, loc='upper center',ncol=10)\n",
    "    \n",
    "ymin,ymax = 23,32\n",
    "# set the galaxy names as x-ticklabels\n",
    "ax.set(xticks=np.arange(1,len(galaxies)+1),\n",
    "       ylabel='($m-M$) / mag',\n",
    "       title='Galaxies with PNLF distances',\n",
    "       xlim=[0.5,len(galaxies)+0.5],\n",
    "       ylim=[ymin,ymax])\n",
    "ax.set_xticklabels(gal_names,rotation=90,color='gray')    \n",
    "\n",
    "# color the galaxies which are in the phangs sample \n",
    "for n in phangs_sample:\n",
    "    i = gal_names.index(n)\n",
    "    ax.get_xticklabels()[i].set_color(\"tab:red\")\n",
    "#for n in ['MESSIER 066','MESSIER 074','MESSIER 095','NGC 5068']:\n",
    "#    i = gal_names.index(n)\n",
    "#    ax.get_xticklabels()[i].set_color(\"tab:red\")    \n",
    "\n",
    "ax.grid(axis='x')\n",
    "#a = ax.get_xgridlines()\n",
    "#for i in color_grid:\n",
    "#    a[i].set_color('tab:red')\n",
    "\n",
    "yticks_mpc = np.logspace(np.log10(Distance(distmod=ymin).to(u.Mpc).value),np.log10(Distance(distmod=ymax).to(u.Mpc).value),10)\n",
    "yticks_mu  = Distance(yticks_mpc*u.Mpc).distmod\n",
    "    \n",
    "ax2 = ax.twinx()\n",
    "ax2.set_yticks(yticks_mu.value,minor=False)\n",
    "ax2.set_yticklabels([f'{x:.2f}' for x in yticks_mpc],ha=\"left\")\n",
    "ax2.set(ylim=[ymin,ymax],ylabel='$D$ / Mpc')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(basedir/'reports'/'PNstudies.png',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, (ax2,ax1) = plt.subplots(nrows=2,figsize=(two_column,two_column))\n",
    "\n",
    "gal_names = [x for _,x in sorted(zip(mean_dis,galaxies))]\n",
    "\n",
    "def literature_distances(labels,ax,ymin=23,ymax=32):\n",
    "    \n",
    "    # set the galaxy names as x-ticklabels\n",
    "    ax.set(xticks=np.arange(1,len(labels)+1),\n",
    "           ylabel='($m-M$) / mag',\n",
    "           xlim=[0.5,len(labels)+0.5],\n",
    "           ylim=[ymin,ymax])\n",
    "    labels_new = [alias_back.get(l,l) for l in labels]\n",
    "    ax.set_xticklabels(labels_new,rotation=90,color='gray')    \n",
    "    ax.grid(axis='x',ls='--',lw=0.4)\n",
    "    grid = ax.get_xgridlines()\n",
    "\n",
    "    for i,label in enumerate(labels):\n",
    "        tmp = pnlf_distances[pnlf_distances['name']==label]\n",
    "        ax.scatter(len(tmp)*[i+1],tmp['m-M'],marker=\"_\",color='gray')\n",
    "        # color the measured by me red\n",
    "        if len(tmp[tmp['REFCODE']=='Schmnn+2020'])>0:\n",
    "            ax.get_xticklabels()[i].set(color=\"tab:red\",fontweight='black')\n",
    "            ax.scatter([i+1],tmp[tmp['REFCODE']=='Schmnn+2020']['m-M'],marker=\"_\",color='tab:red')\n",
    "            grid[i].set(ls='-',lw=0.5)\n",
    "    \n",
    "    \n",
    "    yticks_mpc = np.logspace(np.log10(Distance(distmod=ymin).to(u.Mpc).value),np.log10(Distance(distmod=ymax).to(u.Mpc).value),10)\n",
    "    yticks_mu  = Distance(yticks_mpc*u.Mpc).distmod\n",
    "\n",
    "    axt = ax.twinx()\n",
    "    axt.set_yticks(yticks_mu.value,minor=False)\n",
    "    axt.set_yticklabels([f'{x:.2f}' for x in yticks_mpc],ha=\"left\")\n",
    "    axt.set(ylim=[ymin,ymax],ylabel='$D$ / Mpc')\n",
    "    \n",
    "    return ax\n",
    "    \n",
    "n = len(gal_names)\n",
    "ax1 = literature_distances(gal_names[:int(n/2)],ax1,ymin=23,ymax=30.5)\n",
    "ax2 = literature_distances(gal_names[int(n/2):],ax2,ymin=29.5,ymax=32.2)\n",
    "\n",
    "#ax2.set_title('Galaxies with PNLF distances')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.savefig(basedir/'reports'/'PNstudies.pdf',dpi=600)\n",
    "plt.savefig(basedir/'reports'/'PNstudies.png',dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode_only(array):\n",
    "    m,c = mode(array)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with Deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep   = ascii.read(basedir/'data'/'literature distances'/'deep_distances.csv')\n",
    "result = ascii.read(basedir/'data'/'interim'/'PHANGS_PNLF_distances.txt')\n",
    "\n",
    "deep.add_index(\"galaxy\")\n",
    "deep['d'] = [float(x[:-4]) for x in deep['distance']]\n",
    "deep['e'] = [float(x[:-4]) for x in deep['error']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(two_column,two_column/1.618))\n",
    "result.sort('d/Mpc')\n",
    "for i, row in enumerate(result):\n",
    "    dm,dp = row['err-d/Mpc'],row['err+d/Mpc']\n",
    "    ax.errorbar(i-0.1,row['d/Mpc'],yerr=([dm],[dp]),fmt='o',color='tab:red')\n",
    "    \n",
    "    tmp = deep.loc[row['name']]\n",
    "    ax.errorbar(i+0.1,tmp['d'],yerr=tmp['e'],fmt='o',color='black')\n",
    "    \n",
    "ax.set(xticks=np.arange(0,len(result)),\n",
    "       ylabel='$D$ / Mpc',\n",
    "       title='PHANGS distances',\n",
    "       xlim=[-0.5,len(result)-0.5])\n",
    "ax.set_xticklabels(result['name'],rotation=90)  \n",
    "ax.grid(axis='x')\n",
    "\n",
    "legend_elements = [mpl.lines.Line2D([0], [0], color=col, lw=2, label=l) for col,l in zip(['tab:red','black'],['PNLF','TRGB'])]\n",
    "plt.legend(handles=legend_elements, loc='lower center',ncol=10)\n",
    "plt.savefig(basedir/'reports'/'PNLF_vs_TRGB.png',dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot entire sky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = basedir / 'data' / 'catalogues' / 'sample.txt'\n",
    "sample = ascii.read(filename,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "sample['SkyCoord'] = SkyCoord(sample['R.A.'],sample['Dec.'])\n",
    "\n",
    "ra = sample['SkyCoord'].ra\n",
    "ra = ra.wrap_at(180*u.degree)\n",
    "dec = sample['SkyCoord'].dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mpl.use('pdf')\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fig.add_subplot(111, projection=\"mollweide\")\n",
    "ax.scatter(ra.radian,dec.radian,marker='.')\n",
    "#ax.set_xticklabels(['14h','16h','18h','20h','22h','0h','2h','4h','6h','8h','10h'])\n",
    "ax.grid(True)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "\n",
    "for x,y,s in zip(ra,dec,sample['Name']):\n",
    "    ax.annotate(s,(x.radian,y.radian),xycoords='data',size='x-small')\n",
    "\n",
    "fig.savefig(\"map.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Angular resolution of all galaxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in results['name']:\n",
    "    with fits.open(data_raw/'AUXILIARY'/'seeing_maps'/f'{name}_seeing.fits') as hdul:\n",
    "        PSF = hdul[0].data\n",
    "    \n",
    "    res_min = np.nanmin(PSF)/206265*results.loc[name]['d/Mpc']*1e6\n",
    "    res_max = np.nanmax(PSF)/206265*results.loc[name]['d/Mpc']*1e6\n",
    "    \n",
    "    ang_min = np.nanmin(PSF)\n",
    "    ang_max = np.nanmax(PSF)\n",
    "    \n",
    "    print(f'{name}: min={ang_min:.2f} pc, max={ang_max:.2f} pc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.auxiliary import mu_to_parsec, parsec_to_mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 18.72\n",
    "mu,mu_err = parsec_to_mu(d*u.Mpc,0.15*d*u.Mpc)\n",
    "print(f'{mu.value:.2f},{mu_err[0]:.2f},{d:.2f},NAM,2020AJ....159...67K,,,,,')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d,derr= 17.22, 2.58 \n",
    "mu,mu_err = parsec_to_mu( d*u.Mpc,derr*u.Mpc)\n",
    "print(f'{mu.value:.2f},{mu_err[0]:.2f},{d:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trgb['(m-M)'], trgb['err(m-M)'] = parsec_to_mu(trgb['Distance']*u.Mpc,trgb['Error']*u.Mpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trgb = ascii.read(basedir/'data'/'literature distances'/'PHANGSDistancesJuly23.txt',format='csv',delimiter='&')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogues = {}\n",
    "for name in results['name']:\n",
    "    filename = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "    catalogues[name] = ascii.read(filename,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.analyse import MaximumLikelihood1D, PNLF, pnlf\n",
    "from pnlf.plot.pnlf import plot_pnlf\n",
    "from pnlf.auxiliary import mu_to_parsec\n",
    "\n",
    "name = 'NGC1385'\n",
    "\n",
    "param = parameters[name]\n",
    "cl = param['completeness_limit']\n",
    "tbl = catalogues[name]\n",
    "if False:\n",
    "    data = tbl[((tbl['type']=='PN') | (tbl['SNRorPN']=='True')) & (tbl['exclude']==0)]['mOIII']\n",
    "    err = tbl[((tbl['type']=='PN') | (tbl['SNRorPN']=='True')) & (tbl['exclude']==0)]['dmOIII']\n",
    "else:\n",
    "    data = tbl[(tbl['type']=='PN') & (tbl['exclude']==0) & (tbl['v_SIGMA']<1000) ]['mOIII']\n",
    "    err  = tbl[(tbl['type']=='PN') & (tbl['exclude']==0)]['dmOIII']\n",
    "\n",
    "fitter = MaximumLikelihood1D(pnlf,data[data<cl],mhigh=cl,Mmax=-4.47)\n",
    "mu,mu_p,mu_m = fitter([28])\n",
    "mu_p = np.sqrt(mu_p**2+np.nanmean(err)**2+dPSF**2)\n",
    "mu_m = np.sqrt(mu_m**2+np.nanmean(err)**2+dPSF**2)\n",
    "d,(dp,dm)=mu_to_parsec(mu,[mu_p,mu_m])\n",
    "print('{:.2f} + {:.2f} - {:.2f}'.format(d,dp,dm))\n",
    "print('{:.2f} + {:.2f} - {:.2f}'.format(mu,mu_p,mu_m))\n",
    "\n",
    "#Plot PNLF\n",
    "axes = plot_pnlf(data,\n",
    "                 mu,\n",
    "                 cl,\n",
    "                 binsize=param['binsize'],\n",
    "                 #mhigh=29,\n",
    "                 filename=None,\n",
    "                 color=tab10[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tbl[(tbl['type']=='PN') & (tbl['mOIII']<29) & (tbl['exclude']==0)]\n",
    "tmp.sort('mOIII')\n",
    "\n",
    "plt.scatter(tmp['mOIII'],tmp['v_SIGMA'])\n",
    "plt.axvline(np.min(tmp['mOIII'])+1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.io import ReadLineMaps\n",
    "galaxy = ReadLineMaps(data_raw,name,**parameters[name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.plot.plot import plot_sky_with_detected_stars\n",
    "tmp = tbl[tbl['exclude']==1]\n",
    "positions = np.transpose((tmp['x'], tmp['y']))\n",
    "\n",
    "plot_sky_with_detected_stars(data=galaxy.OIII5006_DAP,\n",
    "                             wcs=galaxy.wcs,\n",
    "                             positions=positions\n",
    "                             )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "297.667px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
