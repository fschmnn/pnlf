{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project1 PNLF Postproduction <a class=\"tocSkip\">\n",
    "    \n",
    "After running the production notebook, this notebook can be used to create shared plots for the galaxies and LaTeX output tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "     \n",
    "First we load a bunch of common packages that are used across the project. More specific packages that are only used in one section are loaded later to make it clear where they belong to (this also applies to all custom moduls that were written for this project)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload modules after they have been modified\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pnlf.packages import *\n",
    "\n",
    "from pnlf.constants import tab10, single_column, two_column\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we use the `logging` module to handle informations and warnings (this does not always work as expected in jupyter notebooks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout,format='%(levelname)s: %(message)s',level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we need to specify the path to the raw data\n",
    "basedir = Path('..')\n",
    "data_raw = Path('a:')\n",
    "data_ext = Path('a:')\n",
    "\n",
    "with open(basedir / 'data' / 'interim' / 'parameters.yml') as yml_file:\n",
    "    parameters = yaml.load(yml_file,Loader=yaml.FullLoader)\n",
    "    \n",
    "results = ascii.read(basedir/'data'/'interim'/ 'results.txt',format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "results.add_index('name')\n",
    "#results.rename_columns(['(m-M)','err+(m-M)','err-(m-M)','mu_SNR','mu_SNR+','mu_SNR-'],['dis','dis_plus','dis_minus','dis_SNR','dis_SNR_plus','dis_SNR_minus'])\n",
    "\n",
    "with open(basedir / 'data' / 'interim' / 'parameters.yml') as yml_file:\n",
    "    parameters = yaml.load(yml_file,Loader=yaml.FullLoader)    \n",
    "    \n",
    "sample_table = ascii.read(basedir/'data'/'interim'/'sample.txt')\n",
    "sample_table.add_index('Name')\n",
    "sample_table['SkyCoord'] = SkyCoord(sample_table['R.A.'],sample_table['Dec.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in results[np.abs(results['(m-M)']-results['mu_SNR'])>0.1]:\n",
    "    print(row['name'], row['(m-M)']-row['mu_SNR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LaTeX sample table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_old = ascii.read(basedir/'data'/'interim'/'sample.txt')\n",
    "sample_old.add_index('Name')\n",
    "sample_old['SkyCoord'] = SkyCoord(sample_old['R.A.'],sample_old['Dec.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = sample_table[sample_table['survey_muse_status']!='not_in_survey']\n",
    "\n",
    "sub[['name', 'agn_veron_y_n',\n",
    " 'agn_veron_class',\n",
    " 'agn_milliquas_y_n',\n",
    " 'agn_milliquas_class_pQSO']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.auxiliary import search_table, parsec_to_mu\n",
    "\n",
    "def area(dic):\n",
    "    '''Calculate the area in an image\n",
    "    \n",
    "    from the number of pixels and the distance,\n",
    "    corrected for inclination\n",
    "    '''\n",
    "    \n",
    "    size_of_pixel = 0.2*u.arcsec\n",
    "\n",
    "    distance = Distance(distmod=dic['mu'])\n",
    "    pixel_area = (size_of_pixel/u.arcsec * distance/206265)**2\n",
    "        \n",
    "    return pixel_area.to(u.kpc**2) *dic['Npixel'] / np.cos(dic['inclination']*u.deg)\n",
    "\n",
    "\n",
    "filename = basedir / 'data' / 'external' / 'phangs_sample_table_v1p6.fits'\n",
    "with fits.open(filename) as hdul:\n",
    "    sample_table = Table(hdul[1].data)\n",
    "\n",
    "#galaxies = sample_table[sample_table['HAS_MUSE']==1]['NAME']\n",
    "galaxies = sample_table[sample_table['survey_muse_status']!='not_in_survey']['name']\n",
    "\n",
    "latexdict = {'tabletype': 'table*',\n",
    "'header_start': '\\\\toprule\\\\toprule',\n",
    "'header_end': '\\\\midrule',\n",
    "'data_end': '\\\\bottomrule',\n",
    "'caption': f'Galaxy sample',\n",
    "'units': {'R.A.':'(J2000)','Dec.':'(J2000)','Inclination':'deg','Distance':'$\\si{\\mega\\parsec}$',\n",
    "          'Survey Area':'$\\si{\\square\\kilo\\parsec}$'},\n",
    "'preamble': '\\\\centering',\n",
    "'tablefoot': f'\\\\label{{tbl:sample}}'\n",
    "            }\n",
    " \n",
    "sample_dict = {\n",
    "'Name': [],\n",
    "'Type':[],\n",
    "'R.A.': [],\n",
    "'Dec.': [],\n",
    "'Distance': [],\n",
    "'Distance_err': [],\n",
    "'(m-M)':[],\n",
    "'err(m-M)':[],\n",
    "'Inclination': [],\n",
    "'posang': [],\n",
    "'r25': [],\n",
    "'12+log(O/H)': [],\n",
    "'mass': [],\n",
    "'SFR': [],\n",
    "'Survey Area': [],\n",
    "'E(B-V)': [],\n",
    "'AO' : []\n",
    "}\n",
    "\n",
    "    \n",
    "for name in galaxies:\n",
    "    stbl = search_table(sample_table,name)\n",
    "    d = Distance(stbl[\"dist\"][0]*u.Mpc).distmod.value\n",
    "    d_unc = 5/(stbl[\"dist\"][0]*np.log(10)) * stbl[\"dist_unc\"][0]\n",
    "\n",
    "    sample_dict['Type'].append(stbl['morph_string'])    \n",
    "    sample_dict['Name'].append(name.upper())\n",
    "    sample_dict['R.A.'].append(stbl['orient_ra'])\n",
    "    sample_dict['Dec.'].append(stbl['orient_dec'])\n",
    "    sample_dict['Distance'].append(stbl[\"dist\"][0])\n",
    "    sample_dict['Distance_err'].append(stbl[\"dist_unc\"][0])\n",
    "    sample_dict['(m-M)'].append(0)\n",
    "    sample_dict['err(m-M)'].append(0)    \n",
    "    sample_dict['Inclination'].append(stbl['orient_incl'])\n",
    "    sample_dict['posang'].append(stbl['orient_posang'])\n",
    "    sample_dict['r25'].append((stbl['size_r25']*u.arcsec).to(u.arcmin).value)\n",
    "    sample_dict['12+log(O/H)'].append(0.00)\n",
    "    sample_dict['mass'].append(stbl['props_mstar'])\n",
    "    sample_dict['SFR'].append(stbl['props_sfr'])\n",
    "    sample_dict['E(B-V)'].append(sample_old.loc[name.upper()]['E(B-V)'])\n",
    "    if parameters[name.upper()]['power_index'] == 2.3:\n",
    "        sample_dict['AO'].append('\\checkmark')\n",
    "    else:\n",
    "        sample_dict['AO'].append('')\n",
    "\n",
    "    try:\n",
    "        sample_dict['Survey Area'].append(f'{area(parameters[name.upper()]).value:.1f}')\n",
    "    except:\n",
    "        sample_dict['Survey Area'].append('NaN')\n",
    "    '''\n",
    "    sample_dict['Name'].append(name)\n",
    "    sample_dict['R.A.'].append(stbl['ORIENT_RA'])\n",
    "    sample_dict['Dec.'].append(stbl['ORIENT_DEC'])\n",
    "    sample_dict['Distance'].append(stbl['DIST'])\n",
    "    sample_dict['Inclination'].append(stbl['ORIENT_INCL'])\n",
    "    sample_dict['$\\log_{10}(M_*)$'].append(stbl['MSTAR_LOGMSTAR'])\n",
    "    sample_dict['$\\log_{10}($SFR$)$'].append(stbl['SFR_LOGSFR'])\n",
    "    '''\n",
    "\n",
    "sample = Table(sample_dict)\n",
    "sample.add_index('Name')\n",
    "sample['mass'] = np.log10(sample['mass'])\n",
    "sample['SFR'] = np.log10(sample['SFR'])\n",
    "err_up = 10 ** (np.log10(sample['Distance']) + sample['Distance_err']) - sample['Distance']\n",
    "err_down = sample['Distance'] - 10 ** (np.log10(sample['Distance']) - sample['Distance_err'])\n",
    "\n",
    "sample['Distance_err'] = err_up\n",
    "sample['(m-M)'] = Distance(sample['Distance']*u.Mpc).distmod.value\n",
    "sample['err(m-M)'] = 5/np.log(10)*sample['Distance_err'] / sample['Distance']\n",
    "\n",
    "sample.loc['NGC1433']['(m-M)'] = 29.78\n",
    "sample.loc['NGC1433']['err(m-M)'] = 0.49\n",
    "sample.loc['NGC1512']['(m-M)'] = 30.33\n",
    "sample.loc['NGC1512']['err(m-M)'] = 0.40\n",
    "\n",
    "sample['Distance'].info.format = '%.2f' \n",
    "sample['Distance_err'].info.format = '%.2f' \n",
    "sample['(m-M)'].info.format = '%.2f' \n",
    "sample['err(m-M)'].info.format = '%.2f' \n",
    "sample['r25'].info.format = '%.2f' \n",
    "sample['mass'].info.format = '%.2f' \n",
    "sample['SFR'].info.format = '%.2f' \n",
    "coord = SkyCoord(sample['R.A.']*u.degree,sample['Dec.']*u.degree)\n",
    "sample['R.A.'], sample['Dec.'] = zip(*[x[0].split(' ') for x in coord.to_string(style='hmsdms',precision=2)])\n",
    "#sample.add_column('',index=1,name='Type')\n",
    "\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(basedir / 'data' / 'interim' / 'sample.txt','w',newline='\\n') as f:\n",
    "    ascii.write(sample,f,format='fixed_width_two_line',overwrite=True,delimiter_pad=' ',position_char='=')\n",
    "    \n",
    "sample.add_column([f'\\galaxyname{{NGC}}{{{row[\"Name\"][-4:]}}}' for row in sample],index=0,name='galname')\n",
    "\n",
    "sample.remove_columns(['mass','Survey Area','Distance','Distance_err','SFR'])\n",
    "#sample.rename_columns(['mass','SFR'],['$\\log_{10}(M_*/\\si{\\Msun})$','$\\log_{10}($SFR$/\\si{\\Msun \\per \\year})$'])\n",
    "with open(basedir / 'data' / 'interim' /'sample.tex','w',newline='\\n') as f:\n",
    "    ascii.write(sample,f,Writer=ascii.Latex, latexdict=latexdict,overwrite=True,exclude_names=['Name'])\n",
    "    \n",
    "#sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LaTeX result table\n",
    "\n",
    "this uses the result table and prints out a LaTeX table (only the data part) that can be used in the final document. In another step, we merge the individual catalogues for PN and SNR identifications. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['dis_Mpc'] = Distance(distmod=results['(m-M)']).to(u.Mpc)\n",
    "results['dis_Mpc_plus'] = (Distance(distmod=results['(m-M)']+results['err+(m-M)']) - results['dis_Mpc']).to(u.Mpc)\n",
    "results['dis_Mpc_minus'] = (results['dis_Mpc']-Distance(distmod=results['(m-M)']-results['err-(m-M)'])).to(u.Mpc)\n",
    "\n",
    "#results['dis_SNR_Mpc'] = (Distance(distmod=results['dis_SNR'])).to(u.Mpc)\n",
    "#results['dis_SNR_Mpc_plus'] = (Distance(distmod=results['dis_SNR']+results['dis_SNR_plus']) - results['dis_SNR_Mpc']).to(u.Mpc)\n",
    "#results['dis_SNR_Mpc_minus'] = (results['dis_SNR_Mpc']-Distance(distmod=results['dis_SNR']-results['dis_SNR_minus'])).to(u.Mpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "for col in ['(m-M)','err+(m-M)','err-(m-M)','dis_Mpc','dis_Mpc_plus','dis_Mpc_minus']:\n",
    "    results[col].info.format = '%.2f'\n",
    "\n",
    "distance_modulus = []\n",
    "distance_parsec = []\n",
    "for row in results:\n",
    "    distance_modulus.append(f'{row[\"(m-M)\"]:.2f} + {row[\"err-(m-M)\"]:.2f} - {row[\"err+(m-M)\"]:.2f}')\n",
    "    distance_parsec.append(f'{row[\"dis_Mpc\"]:.2f} + {row[\"dis_Mpc_plus\"]:.2f} - {row[\"dis_Mpc_plus\"]:.2f}')\n",
    "results['mu'] = distance_modulus\n",
    "results['d/Mpc'] = distance_parsec\n",
    "                           \n",
    "filename = basedir / 'data' / 'interim' / f'distances.txt'\n",
    "with open(filename,'w',newline='\\n') as f:\n",
    "    ascii.write(results[['name','mu','d/Mpc']],\n",
    "                f,format='fixed_width',delimiter='\\t',overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_out = ''\n",
    "results.sort('name')\n",
    "for row in results:\n",
    "    tbl_out += f'{row[\"name\"]} & {row[\"N_PN\"]} & {row[\"N_SNR\"]} ({row[\"N_SNRorPN\"]}) '\n",
    "    tbl_out += f'& $\\\\uncertainty{{{row[\"(m-M)\"]:.2f}}}{{{row[\"err+(m-M)\"]:.2f}}}{{{row[\"err-(m-M)\"]:.2f}}}$ '\n",
    "    tbl_out += f'& $\\\\uncertainty{{{row[\"dis_Mpc\"]:.2f}}}{{{row[\"dis_Mpc_plus\"]:.2f}}}{{{row[\"dis_Mpc_minus\"]:.2f}}}$ '\n",
    "    tbl_out += f'& {row[\"alpha\"]:.2f}\\\\\\\\\\n'\n",
    "    #tbl_out += f'& $\\\\uncertainty{{{row[\"dis_SNR\"]:.2f}}}{{{row[\"dis_SNR_plus\"]:.2f}}}{{{row[\"dis_SNR_minus\"]:.2f}}}$ '\n",
    "    #tbl_out += f'& $\\\\uncertainty{{{row[\"dis_SNR_Mpc\"]:.2f}}}{{{row[\"dis_SNR_Mpc_plus\"]:.2f}}}{{{row[\"dis_SNR_Mpc_minus\"]:.2f}}}$\\\\\\\\\\n'\n",
    "    \n",
    "    \n",
    "print(tbl_out)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_out = ''\n",
    "results.sort('name')\n",
    "for row in results:\n",
    "    print(f'\\\\setvalue{{mag/{row[\"name\"]} =\\\\SI{{\\\\uncertainty{{{row[\"(m-M)\"]:.2f}}}{{{row[\"err+(m-M)\"]:.2f}}}{{{row[\"err-(m-M)\"]:.2f}}}}}{{\\\\mag}}}}')\n",
    "print(' ')\n",
    "for row in results:\n",
    "    print(f'\\\\setvalue{{Mpc/{row[\"name\"]} =\\\\SI{{\\\\uncertainty{{{row[\"dis_Mpc\"]:.2f}}}{{{row[\"dis_Mpc_plus\"]:.2f}}}{{{row[\"dis_Mpc_minus\"]:.2f}}}}}{{\\\\mega\\\\parsec}}}}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Catalogues to single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_lst = []\n",
    "ID_lst = []\n",
    "notes_lst = []\n",
    "for name in results['name']:\n",
    "    tmp = ascii.read(basedir/'data'/'catalogues'/f'{name}_PN_candidates.txt',format='fixed_width_two_line')\n",
    "    ID_lst += list(tmp['ID'])\n",
    "    notes_lst += list(tmp['notes'])\n",
    "    \n",
    "    del tmp['ID']\n",
    "    del tmp['notes']\n",
    "    \n",
    "    tbl_lst.append(tmp)\n",
    "    \n",
    "tbl = vstack(tbl_lst)\n",
    "tbl.add_column(ID_lst,index=1,name='ID')\n",
    "tbl.add_column(notes_lst,index=1,name='notes')\n",
    "\n",
    "\n",
    "with open(basedir/'data'/'catalogues'/'PN_candidates.txt','w',newline='\\n') as f:\n",
    "    ascii.write(tbl,f,format='fixed_width_two_line',overwrite=True,delimiter_pad=' ',position_char='=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_lst = []\n",
    "for name in results['name']:\n",
    "    tmp = ascii.read(basedir/'data'/'catalogues'/f'{name}_nebulae.txt',format='fixed_width_two_line')\n",
    "    tmp['gal_name'] = name\n",
    "    tbl_lst.append(tmp)\n",
    "catalogue = vstack(tbl_lst)\n",
    "catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "catalogue['overluminous'] = catalogue['overluminous'].astype(bool)\n",
    "catalogue['SkyCoord'] = SkyCoord(catalogue['RaDec'])\n",
    "catalogue['RA'],catalogue['DEC'] = zip(*[x.split(' ') for x in catalogue['SkyCoord'].to_string(style='hmsdms',precision=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overluminous = catalogue[catalogue['overluminous']]\n",
    "\n",
    "for row in overluminous[['gal_name','id','type','RA','DEC','mOIII','dmOIII']]:\n",
    "    print('{} & {} & {} & {} & {} & {} & {} \\\\\\\\'.format(*row))\n",
    "    \n",
    "overluminous[['gal_name','id','type','RA','DEC','mOIII','dmOIII']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single PNLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.analyse import MaximumLikelihood1D, pnlf, cdf\n",
    "from pnlf.plot.pnlf import plot_pnlf\n",
    "from pnlf.auxiliary import mu_to_parsec\n",
    "from scipy.stats import kstest\n",
    "\n",
    "name = 'NGC1672'\n",
    "\n",
    "catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "if catalogue_file.is_file():\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "\n",
    "binsize = 0.4 #parameters[name]['binsize']\n",
    "completeness_limit = parameters[name]['completeness_limit']\n",
    "mu = parameters[name]['mu']\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# fit the data\n",
    "# ----------------------------------------------------------------------\n",
    "'''\n",
    "data = catalogue['mOIII'][(catalogue['type']=='PN') & (catalogue['mOIII']<completeness_limit)]\n",
    "err = catalogue['dmOIII'][(catalogue['type']=='PN') & (catalogue['mOIII']<completeness_limit)]\n",
    "\n",
    "fitter = MaximumLikelihood1D(pnlf,data,err=err,mhigh=completeness_limit,Mmax=-4.47)\n",
    "mu,mu_p,mu_m = fitter([29])\n",
    "\n",
    "d,(dp,dm)=mu_to_parsec(mu,[mu_p,mu_m])\n",
    "print('{:.2f} + {:.2f} - {:.2f}'.format(mu,mu_p,mu_m))\n",
    "print('{:.2f} + {:.2f} - {:.2f}'.format(d,dp,dm))\n",
    "\n",
    "ks,pv = kstest(data,cdf,args=(mu,completeness_limit))\n",
    "print(f'{name}: statistic={ks:.3f}, pvalue={pv:.3f}')\n",
    "'''\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "#plot PNLF\n",
    "# ----------------------------------------------------------------------\n",
    "filename = None #basedir / 'reports' / f'{galaxy.name}' / f'{galaxy.name}_PNLF'\n",
    "axes = plot_pnlf(catalogue['mOIII'][(catalogue['type']=='PN')],mu,completeness_limit,\n",
    "                 binsize=binsize,mhigh=29,filename=filename,color=tab10[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined PNLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we define possible lists of objects to plot\n",
    "DR2  = ['NGC1300','NGC1385','NGC1433','NGC4303','NGC4321','NGC7496']\n",
    "good = ['IC5332','NGC0628','NGC1566','NGC3351','NGC3627','NGC5068']\n",
    "PHANGS_sample = ['IC5332','NGC1087','NGC1300','NGC1365','NGC1385','NGC1433', 'NGC1512','NGC1566','NGC1672',\n",
    "                 'NGC2835','NGC3351','NGC3627','NGC4254','NGC4303','NGC4321','NGC4535','NGC5068','NGC7496']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.plot.pnlf import _plot_pnlf\n",
    "\n",
    "names = results['name']\n",
    "nrows = 5\n",
    "ncols = 4\n",
    "filename = basedir / 'reports' / f'all_galaxies_PNLF'\n",
    "\n",
    "#----------------------------------------------\n",
    "# DO NOT MODIFY BELOW\n",
    "#----------------------------------------------\n",
    "if nrows*ncols<len(names):\n",
    "    raise ValueError('not enough subplots for selected objects') \n",
    "width = two_column\n",
    "fig, axes = plt.subplots(nrows=nrows,ncols=ncols,figsize=(width,width/ncols*nrows))\n",
    "axes_iter = iter(axes.flatten())\n",
    "Mmax = -4.47\n",
    "    \n",
    "# loop over the galaxies we want to plot\n",
    "for name in names:  \n",
    "    # read in the data\n",
    "    catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "    if catalogue_file.is_file():\n",
    "        catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "        catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "        catalogue['overluminous'] = catalogue['overluminous'].astype(bool)\n",
    "\n",
    "    else:\n",
    "        print(f'no catalogue for {name}')\n",
    "        continue\n",
    "        \n",
    "    # get the next axis and find position on the grid\n",
    "    ax = next(axes_iter)\n",
    "    if nrows>1 and ncols>1:\n",
    "        i, j = np.where(axes == ax)\n",
    "        i,j=i[0],j[0]\n",
    "    elif ncols>1:\n",
    "        i,j = 0, np.where(axes==ax)[0]\n",
    "    elif nrows>1:\n",
    "        i,j = np.where(axes==ax)[0],0\n",
    "    else:\n",
    "        i,j=0,0\n",
    "        \n",
    "    # pre-process the data for the plot and read additional parameters\n",
    "    data = catalogue[(catalogue['type']=='PN') & (~catalogue['exclude']) & (~catalogue['overluminous'])]['mOIII']\n",
    "    mu = results.loc[name]['(m-M)']\n",
    "    completeness = parameters[name]['completeness_limit']\n",
    "    cut = parameters[name].get('cut',0)\n",
    "    if cut>0:\n",
    "        print(f'warning: using cut={cut} for {name}')\n",
    "    data = data[data>cut]\n",
    "    binsize = parameters[name]['binsize']\n",
    "    mlow = Mmax+mu\n",
    "    mhigh = 28.5\n",
    "\n",
    "    ax=_plot_pnlf(data,mu,completeness,binsize=binsize,mhigh=mhigh,ax=ax,ms=3)\n",
    "    ax.text(0.4,0.08,f'{name}', transform=ax.transAxes,fontsize=7)\n",
    "\n",
    "    #ax.set_xlim([mu-5,completeness+0.5])\n",
    "    # add labels to the axis\n",
    "    if i==nrows-1:\n",
    "        ax.set_xlabel(r'$m_{[\\mathrm{OIII}]}$ / mag')\n",
    "    if j==0:\n",
    "        ax.set_ylabel(r'N')\n",
    "    #ax.set_title(name)\n",
    "    #ax.set(xlim=[24,28.5])\n",
    "    \n",
    "axes[3,3].set_xlabel(r'$m_{[\\mathrm{OIII}]}$ / mag')\n",
    "ax = next(axes_iter)\n",
    "#ax.remove()\n",
    "h,l = fig.axes[0].get_legend_handles_labels()\n",
    "ax.axis('off')\n",
    "ax.legend(h,l,fontsize=7,loc='center left',frameon=False)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.15, hspace=0.15)\n",
    "#plt.tight_layout()\n",
    "plt.savefig(filename.with_suffix('.pdf'),bbox_inches='tight')\n",
    "plt.savefig(filename.with_suffix('.png'),bbox_inches='tight',dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined cumulative PNLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.plot.pnlf import _plot_cum_pnlf\n",
    "from pnlf.analyse import cdf\n",
    "from scipy.stats import kstest\n",
    "\n",
    "names = results['name']\n",
    "nrows = 5\n",
    "ncols = 4\n",
    "filename = basedir / 'reports' / f'all_galaxies_PNLF_cum'\n",
    "\n",
    "#----------------------------------------------\n",
    "# DO NOT MODIFY BELOW\n",
    "#----------------------------------------------\n",
    "if nrows*ncols<len(names):\n",
    "    raise ValueError('not enough subplots for selected objects')\n",
    "width = two_column\n",
    "fig, axes = plt.subplots(nrows=nrows,ncols=ncols,figsize=(width,width/ncols*nrows))\n",
    "axes_iter = iter(axes.flatten())\n",
    "\n",
    "binsize=0.1\n",
    "Mmax = -4.47\n",
    "color = 'tab:red'\n",
    "\n",
    "for name in names:  \n",
    "        \n",
    "    catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "    if catalogue_file.is_file():\n",
    "        catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "        catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "        catalogue['overluminous'] = catalogue['overluminous'].astype(bool)\n",
    "    else:\n",
    "        print(f'no catalogue for {name}')\n",
    "        continue\n",
    "    \n",
    "    # get the next axis\n",
    "    ax = next(axes_iter)\n",
    "    # find current position on the grid\n",
    "    i, j = np.where(axes == ax)\n",
    "    i,j=i[0],j[0]\n",
    "    \n",
    "    data = catalogue[(catalogue['type']=='PN') & (~catalogue['exclude']) & (~catalogue['overluminous'])]['mOIII']\n",
    "    mu = results.loc[name]['(m-M)']\n",
    "    completeness = parameters[name]['completeness_limit']\n",
    "    cut = parameters[name].get('cut',0)\n",
    "    if cut>0:\n",
    "        print(f'warning: using cut={cut} for {name}')\n",
    "    data = data[data>cut]\n",
    "\n",
    "    ks,pv = kstest(data[data<completeness],cdf,args=(mu,completeness))\n",
    "\n",
    "    ax=_plot_cum_pnlf(data,mu,completeness,ax=ax,binsize=None)\n",
    "    ax.text(0.55,0.08,f'{name}', transform=ax.transAxes,fontsize=7)\n",
    "    ax.text(0.1,0.78,f'$p$-value$={pv:.2f}$',transform=ax.transAxes,fontsize=7)\n",
    "    ax.text(0.1,0.88,f'$D_{{max}}={ks:.3f}$', transform=ax.transAxes,fontsize=7)\n",
    "\n",
    "    # add labels to the axis\n",
    "    if i==nrows-1:\n",
    "        ax.set_xlabel(r'$m_{[\\mathrm{OIII}]}$ / mag')\n",
    "    if j==0:\n",
    "        ax.set_ylabel(r'Cumulative N')\n",
    "    \n",
    "    #ax.set_title(name)\n",
    "axes[3,3].set_xlabel(r'$m_{[\\mathrm{OIII}]}$ / mag')\n",
    "ax = next(axes_iter)\n",
    "#ax.remove()\n",
    "\n",
    "h,l = fig.axes[0].get_legend_handles_labels()\n",
    "ax.axis('off')\n",
    "ax.legend(h,l,fontsize=7,loc='center left',frameon=False)\n",
    "    \n",
    "plt.subplots_adjust(wspace=0.22, hspace=0.22)\n",
    "#plt.tight_layout()\n",
    "plt.savefig(filename.with_suffix('.pdf'),bbox_inches='tight')\n",
    "plt.savefig(filename.with_suffix('.png'),bbox_inches='tight',dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Combine line diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pnlf.analyse import PNLF\n",
    "\n",
    "names = result['name']\n",
    "style = {'SNR':{\"marker\":'o',\"ms\":3,\"mfc\":'None',\"mec\":tab10[0],'ls':'none','ecolor':tab10[0]},\n",
    "         'SNRorPN':{\"marker\":'o',\"ms\":4,\"mfc\":'white',\"mec\":'tab:green','ls':'none','ecolor':'tab:green'},\n",
    "         'HII':{\"marker\":'+',\"ms\":3,\"mec\":tab10[1],'ls':'none'},\n",
    "         'PN':{\"marker\":'o',\"ms\":2,\"mfc\":'black','mec':'black','ls':'none','ecolor':'black'}\n",
    "        }\n",
    "Mmax=-4.47\n",
    "color = 'tab:red'\n",
    "\n",
    "# define the figure with the number of subplots\n",
    "nrows = 2\n",
    "ncols = 3\n",
    "width = two_column\n",
    "fig, axes_arr = plt.subplots(nrows=nrows,ncols=ncols,figsize=(width,width/ncols*nrows))\n",
    "axes = iter(axes_arr.flatten())\n",
    "\n",
    "\n",
    "names = ['IC5332','NGC0628','NGC1566','NGC3351','NGC3627','NGC5068']\n",
    "\n",
    "# loop over the galaxies we want to plot\n",
    "for name in names:  \n",
    "       \n",
    "    # read in the data\n",
    "    catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "    if catalogue_file.is_file():\n",
    "        catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "        catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "        for col in catalogue.columns:\n",
    "            if col.endswith('detection'):\n",
    "                catalogue[col] = catalogue[col]=='True'\n",
    "    else:\n",
    "        print(f'no catalogue for {name}')\n",
    "        continue\n",
    "        \n",
    "    # get the next axis\n",
    "    ax = next(axes)\n",
    "    # find current position on the grid\n",
    "    i, j = np.where(axes_arr == ax)\n",
    "    i,j=i[0],j[0]\n",
    "    \n",
    "    # pre-process the data for the plot and read additional parameters\n",
    "    mu = result.loc[name]['dis']\n",
    "    completeness = parameters[name]['completeness_limit']\n",
    "    \n",
    "    # draw line that we use seperate PN from HII\n",
    "    MOIII = np.linspace(-5,1)\n",
    "    OIII_Ha = 10**(-0.37*(MOIII)-1.16)\n",
    "    ax.plot(MOIII,OIII_Ha,c='black',lw=0.6)\n",
    "    ax.axhline(10**4)\n",
    "\n",
    "    if completeness:\n",
    "        ax.axvline(completeness-mu,ls='--',c='grey',lw=0.5)\n",
    "    ax.axvline(Mmax,ls='--',c='grey',lw=0.5)\n",
    "\n",
    "    for t in ['HII','PN','SNR']:\n",
    "        tbl = catalogue[catalogue['type']==t]        \n",
    "        ax.errorbar(tbl['mOIII']-mu,tbl['OIII5006']/(tbl['HA6562']+tbl['NII6583']),**style[t],label=t) \n",
    "\n",
    "        if t=='PN':\n",
    "            # indicate for which PN we don't have a detection in HA6562\n",
    "            tbl = tbl[~tbl['HA6562_detection']]\n",
    "            ax.errorbar(tbl['mOIII']-mu,1.11*tbl['OIII5006']/(tbl['HA6562']+tbl['NII6583']),\n",
    "                         marker=r'$\\uparrow$',ms=4,mec='black',ls='none') \n",
    "        if t=='SNR':\n",
    "            #tbl = tbl[tbl['SNRorPN']] \n",
    "            ax.errorbar(tbl['mOIII']-mu,tbl['OIII5006']/(tbl['HA6562']+tbl['NII6583']), marker='x',ms=2,mec=tab10[0],ls='none') \n",
    "   \n",
    "    # objects that were rejeceted by eye\n",
    "    tbl = catalogue[catalogue['exclude']]\n",
    "    ax.errorbar(tbl['mOIII']-mu,tbl['OIII5006']/(tbl['HA6562']+tbl['NII6583']),marker='o',ms=3,ls='none',color='tab:green',label='rejected') \n",
    "    \n",
    "    \n",
    "    # configure axes \n",
    "    ax.set(xlim=[-5,np.ceil(completeness-mu)],\n",
    "           ylim=[0.03,200],\n",
    "           yscale='log')\n",
    "    \n",
    "    ax.yaxis.set_major_formatter(mpl.ticker.FuncFormatter(lambda y, _: '{:.16g}'.format(y)))\n",
    "\n",
    "    axt = ax.twiny()\n",
    "    xlim1,xlim2 = ax.get_xlim()\n",
    "    axt.set_xticks(np.arange(np.ceil(xlim1+mu),np.floor(xlim2+mu)+1),minor=False)\n",
    "    axt.set(xlim   = [xlim1+mu,xlim2+mu])\n",
    "    \n",
    "    if i==0:\n",
    "        axt.set(xlabel = r'$m_{\\mathrm{[OIII]}}$')\n",
    "    \n",
    "    if i==nrows-1:\n",
    "        ax.set(xlabel=r'$M_{\\mathrm{[OIII]}}$')\n",
    "    if j==0:\n",
    "        ax.set(ylabel=r'[OIII] / $(\\mathrm{H}\\alpha + \\mathrm{[NII]})$')\n",
    "    ax.set_title(name)\n",
    "    \n",
    "    ax.xaxis.set_major_locator(mpl.ticker.MaxNLocator(integer=True))\n",
    "    \n",
    "    \n",
    "h,l = fig.axes[0].get_legend_handles_labels()\n",
    "fig.legend(h, l, bbox_to_anchor=(0., 1.01, 1., .051),loc = 'upper center',ncol=4)\n",
    "\n",
    "plt.tight_layout()\n",
    "filename = basedir / 'reports' / f'all_objects_line_diagnostics'\n",
    "plt.savefig(filename.with_suffix('.pdf'),bbox_inches='tight')\n",
    "plt.savefig(filename.with_suffix('.png'),bbox_inches='tight',dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Completeness limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = basedir/'data'/'interim'\n",
    "files = [x for x in path.iterdir() if x.stem.endswith('mock_sources')]\n",
    "\n",
    "limit   = 0.8\n",
    "max_sep = 0.3\n",
    "\n",
    "ncols = 5\n",
    "nrows = int(np.ceil(len(files)/ncols))\n",
    "\n",
    "width = 2*two_column\n",
    "fig, axes = plt.subplots(nrows=nrows,ncols=ncols,figsize=(width,width/ncols*nrows))\n",
    "axes_iter = iter(axes.flatten())\n",
    "\n",
    "for file in files:\n",
    "    \n",
    "    ax = next(axes_iter)\n",
    "    i, j = np.where(axes == ax)\n",
    "    i,j=i[0],j[0]\n",
    "    \n",
    "    name = file.stem.split('_')[0]\n",
    "    mock_sources = ascii.read(file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "  \n",
    "    hist = []\n",
    "    width = 0.5\n",
    "    bins = np.arange(26,30,width)\n",
    "\n",
    "    for center in bins:\n",
    "        tmp = mock_sources[(mock_sources['magnitude']>center-width/2) & (mock_sources['magnitude']<=center+width/2)]\n",
    "        if len(tmp)>0:\n",
    "            hist.append(np.sum(tmp['sep']<max_sep)/len(tmp))\n",
    "        else:\n",
    "            hist.append(0)\n",
    "    hist = np.array(hist)\n",
    "    \n",
    "    completeness_limit = np.max(bins[hist>=limit])\n",
    "    \n",
    "    ax.axhline(100*limit,color='black',lw=0.6)\n",
    "\n",
    "    ax.bar(bins[hist>=limit],hist[hist>=limit]*100,width=width*0.9,color=tab10[0])\n",
    "    ax.bar(bins[hist<limit],hist[hist<limit]*100,width=width*0.9,fc='white',ec=tab10[0])\n",
    "    \n",
    "    for b,h in zip(bins,hist):\n",
    "        if b>=26.5:\n",
    "            if h>=0.8:\n",
    "                ax.text(b,5,f'{h*100:.0f}\\%',horizontalalignment='center',color='white',fontsize=6)\n",
    "            else:\n",
    "                ax.text(b,5,f'{h*100:.0f}\\%',horizontalalignment='center',color=tab10[0],fontsize=6)\n",
    "    t = ax.text(0.75,0.92,f'{name}', transform=ax.transAxes,color='black',fontsize=7)\n",
    "    t = ax.text(0.75,0.82,f'cl={completeness_limit:.0f}', transform=ax.transAxes,color='black',fontsize=7)\n",
    "\n",
    "    ax.set(xlim=[26.2,29.8],\n",
    "           ylim=[0,100])\n",
    "    \n",
    "    if i==nrows-1:\n",
    "        ax.set(xlabel='m$_{[\\mathrm{OIII}]}$')\n",
    "    else:\n",
    "        ax.set_xticklabels([])\n",
    "    if j==0:\n",
    "        ax.set(ylabel='percentage of recovered objects')\n",
    "    else:\n",
    "        ax.set_yticklabels([])\n",
    "    \n",
    "    #ax.set_title(f'{name}: cl = {completeness_limit}')\n",
    "    \n",
    "for i in range(nrows*ncols-len(files)):\n",
    "\n",
    "    # remove the empty axes at the bottom\n",
    "    ax = next(axes_iter)\n",
    "    ax.remove()\n",
    "\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "\n",
    "filename = basedir / 'reports' / f'all_galaxies_completeness'\n",
    "plt.savefig(filename.with_suffix('.pdf'),bbox_inches='tight')\n",
    "plt.savefig(filename.with_suffix('.png'),bbox_inches='tight',dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.detection import plot_completeness_limit\n",
    "\n",
    "name = 'NGC0628'\n",
    "\n",
    "file = basedir/'data'/'interim'/f'{name}_mock_sources.txt'\n",
    "\n",
    "limit   = 0.8\n",
    "max_sep = 0.3\n",
    "\n",
    "mock_sources = ascii.read(file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "\n",
    "filename = basedir / 'reports' / name / f'{name}_completness.pdf'\n",
    "\n",
    "plot_completeness_limit(mock_sources,max_sep=max_sep,limit=limit,filename=filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot RGB image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.auxiliary import circular_mask\n",
    "from pnlf.plot.plot import create_RGB\n",
    "from pnlf.io import ReadLineMaps\n",
    "\n",
    "nrows = 5\n",
    "ncols = 4\n",
    "width = two_column\n",
    "fig, axes_arr = plt.subplots(nrows=nrows,ncols=ncols,figsize=(width,width/ncols*nrows))\n",
    "axes = iter(axes_arr.flatten())\n",
    "\n",
    "# loop over the galaxies we want to plot\n",
    "for name in results['name']:  \n",
    "        \n",
    "    # get the next axis\n",
    "    ax = next(axes)\n",
    "    # find current position on the grid\n",
    "    i, j = np.where(axes_arr == ax)\n",
    "    i,j=i[0],j[0]\n",
    "    \n",
    "    #galaxy = galaxies[name]\n",
    "    galaxy = ReadLineMaps(data_raw,name,**parameters[name])\n",
    "    \n",
    "    # define masks as slices\n",
    "    masks = {\n",
    "     'NGC1300' : circular_mask(*galaxy.shape,radius=50),\n",
    "     'NGC1365' : circular_mask(*galaxy.shape,(720,420),radius=200),\n",
    "     #'NGC1433' : circular_mask(*galaxy.shape,radius=100),\n",
    "     'NGC1512' : circular_mask(*galaxy.shape,radius=70),\n",
    "     'NGC1566' : circular_mask(*galaxy.shape,(450,450),radius=100)|circular_mask(*galaxy.shape,(350,150),radius=180),\n",
    "     'NGC1672' : circular_mask(*galaxy.shape,(600,310),radius=60),\n",
    "     #'NGC3627' : circular_mask(*galaxy.shape,(330,740),radius=100),\n",
    "     'NGC3351' : circular_mask(*galaxy.shape,radius=200),\n",
    "     'NGC4321' : circular_mask(*galaxy.shape,(550,450),radius=60),\n",
    "     'NGC4535' : circular_mask(*galaxy.shape,(300,520),radius=100)\n",
    "    }\n",
    "    \n",
    "    mask = np.zeros(galaxy.shape,dtype=bool)\n",
    "    mask |= galaxy.star_mask.astype(bool)\n",
    "    mask[masks.get(galaxy.name,(slice(-1,0),slice(-1,0)))] = True\n",
    "\n",
    "    #img = galaxy.OIII5006_DAP.copy()\n",
    "    img = create_RGB(galaxy.HA6562,galaxy.OIII5006_DAP,galaxy.SII6716,weights=[0.6,1,0.6],percentile=[95,99.,95])\n",
    "    img[mask,...] = (1,1,1) #(1, 165/255, 1/255) \n",
    "\n",
    "    ax.imshow(img,origin='lower')\n",
    "    ax.set_title(name)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "filename = basedir / 'reports' / f'all_objects_rgb'\n",
    "plt.savefig(filename.with_suffix('.pdf'),bbox_inches='tight')\n",
    "#plt.savefig(filename.with_suffix('.png'),bbox_inches='tight',dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overluminous sources\n",
    "\n",
    "### RGB image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = {\n",
    " 'IC5332'  : [1665,1335,618,538,615,876,665],\n",
    " 'NGC0628' : [882,307,527],\n",
    " 'NGC1300' : [1815,2704,2720],\n",
    " 'NGC1365' : [732,743],\n",
    " 'NGC1433' : [5657,4842], # both not at bright end\n",
    " 'NGC1566' : [26,392,398],\n",
    " 'NGC1672' : [138,198,273,154,257,136,169,162],\n",
    " 'NGC2835' : [178,788,276,416,723],\n",
    " 'NGC4254' : [1945,1944,2127,922],\n",
    " 'NGC4303' : [381,412,457,430],\n",
    " 'NGC5068' : [500,698,318,651,972,74,508,248,804,751],\n",
    " 'NGC7496' : [131,464,569,126,550,438]\n",
    "}\n",
    "\n",
    "overluminous = {\n",
    " 'NGC1512' : [277,272],\n",
    " 'NGC1566' : [119,565,222],\n",
    " 'NGC1672' : [203,211,124],\n",
    " 'NGC2835' : [673],\n",
    " 'NGC4303' : [371],\n",
    " 'NGC4321' : [2111],\n",
    " 'NGC7496' : [318,575],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.plot.plot import create_RGB\n",
    "from pnlf.io import ReadLineMaps\n",
    "from pnlf.auxiliary import filter_table\n",
    "from pnlf.plot.plot import radial_profile\n",
    "\n",
    "\n",
    "filename = basedir / 'reports' / f'all_galaxies_exclude'\n",
    "objects = exclude\n",
    "\n",
    "size = 40\n",
    "\n",
    "n_objects = sum([len(v) for k,v in objects.items()])\n",
    "print(f'plotting cutouts for {n_objects} objects')\n",
    "ncols = 4\n",
    "nrows = int(np.ceil(n_objects/ncols))\n",
    "\n",
    "width = two_column\n",
    "fig, axes = plt.subplots(nrows=nrows,ncols=ncols,figsize=(width,width/ncols*nrows))\n",
    "axes_iter = iter(axes.flatten())\n",
    "\n",
    "failed = 0\n",
    "for name, region_IDs in objects.items():\n",
    "    \n",
    "    galaxy = ReadLineMaps(data_raw/'MUSE_DR2'/'MUSEDAP',name,**parameters[name])\n",
    "    \n",
    "    catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "    if catalogue_file.is_file():\n",
    "        catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "        catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "    \n",
    "    for region_ID in region_IDs:\n",
    "            \n",
    "        try:\n",
    "            row = filter_table(catalogue,id=region_ID)[0]\n",
    "        except:\n",
    "            print(f'error for {name}: {region_ID}')\n",
    "            failed+=1\n",
    "            continue\n",
    "            \n",
    "        ax = next(axes_iter)\n",
    "        \n",
    "        x,y = row[['x','y']]\n",
    "        aperture_size=2.5*row['fwhm']/2\n",
    "        \n",
    "        star = Cutout2D(galaxy.OIII5006, (x,y), u.Quantity((size, size), u.pixel),wcs=galaxy.wcs)\n",
    "\n",
    "        rgb = create_RGB(galaxy.HA6562,galaxy.OIII5006,galaxy.SII6716,percentile=99)\n",
    "        yslice = slice(int(x-size/2),int(x+size/2))\n",
    "        xslice = slice(int(y-size/2),int(y+size/2))\n",
    "        \n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticks([])\n",
    "        \n",
    "        try:\n",
    "            im = ax.imshow(rgb[xslice,yslice,:],origin='lower')\n",
    "        except:\n",
    "            text = f'{name}: {row[\"id\"]}'\n",
    "            t = ax.text(0.06,0.87,text, transform=ax.transAxes,color='black',fontsize=7)\n",
    "            continue\n",
    "            \n",
    "        aperture = CircularAperture((size/2+(x-int(x)),size/2+(y-int(y))),aperture_size)\n",
    "        aperture.plot(color='tab:red',lw=0.8,axes=ax)\n",
    "        \n",
    "        profile = radial_profile(star.data,star.input_position_cutout)\n",
    "        \n",
    "        ax2 = ax.inset_axes([0.02, 0.02, 0.32, 0.25])\n",
    "        ax2.set_yticks([])\n",
    "        ax2.set_xticks([])  \n",
    "        \n",
    "        ax2.plot(profile,color='black')\n",
    "        ax2.axvline(aperture_size,color='tab:red',lw=0.5)\n",
    "  \n",
    "        text = f'{name}: ID={row[\"id\"]}'\n",
    "        t = ax.text(0.07,0.87,text, transform=ax.transAxes,color='black',fontsize=7)\n",
    "        t.set_bbox(dict(facecolor='white', alpha=1, ec='white'))\n",
    "        \n",
    "            \n",
    "        if row['mOIII']<results.loc[name]['(m-M)']-3.97:\n",
    "            for loc in ['bottom','top','right','left']:\n",
    "                ax.spines[loc].set_color('tab:orange')\n",
    "                ax.spines[loc].set_linewidth(1)\n",
    "        #t = ax.text(0.05,0.8,f'mOIII={row[\"mOIII\"]:.1f}', transform=ax.transAxes,color='black',fontsize=8)\n",
    "        #t.set_bbox(dict(facecolor='white', alpha=1, ec='white'))\n",
    "        \n",
    "for i in range(nrows*ncols-n_objects+failed):\n",
    "    # remove the empty axes at the bottom\n",
    "    ax = next(axes_iter)\n",
    "    ax.remove()\n",
    "    \n",
    "plt.subplots_adjust(wspace=-0.01,hspace=0.05)\n",
    "if filename:\n",
    "    #plt.savefig(filename.with_suffix('.png'),dpi=600)\n",
    "    plt.savefig(filename.with_suffix('.pdf'),dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectrum of those objects\n",
    "I only downloaded datacubes for the DR1 galaxies (IC5332,NGC0628,NGC1087,NGC1365,NGC1512,NGC1566,NGC1672,NGC2835,NGC3351,NGC3627,NGC4254,NGC4535,NGC5068)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.auxiliary import annulus_mask, circular_mask\n",
    "from pnlf.io import ReadLineMaps\n",
    "from pnlf.auxiliary import filter_table\n",
    "\n",
    "name = 'NGC0628'\n",
    "\n",
    "filename = basedir / 'reports' / name / f'{name}_exclude'\n",
    "region_IDs = exclude[name]\n",
    "xlim=[4750,7000]\n",
    "size = 40\n",
    "\n",
    "print(f'plot spectra for {len(region_IDs)} regions')\n",
    "\n",
    "cube_path = Path('g:\\Archive')/'MUSE'/'DR1'/'datacubes'\n",
    "if name not in [x.stem.split('_')[0] for x in cube_path.iterdir()]:\n",
    "    raise FileNotFoundError(f'no datacube for {name}')\n",
    "with fits.open(cube_path / f'{name}_DATACUBE_FINAL.fits' , memmap=True, mode='denywrite') as hdul:\n",
    "    data_cube   = hdul[1].data\n",
    "    cube_header = hdul[1].header\n",
    "    \n",
    "galaxy = ReadLineMaps(data_raw/'MUSE_DR2'/'MUSEDAP',name,**parameters[name])\n",
    "\n",
    "catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "if catalogue_file.is_file():\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "\n",
    "fig = plt.figure(figsize=(two_column,len(region_IDs)*two_column/4)) \n",
    "gs = mpl.gridspec.GridSpec(len(region_IDs), 2, width_ratios=[1,3]) \n",
    "\n",
    "spectra = {}\n",
    "for i,region_ID in enumerate(region_IDs):\n",
    "    \n",
    "    x,y = filter_table(catalogue,id=region_ID)[['x','y']][0]\n",
    "\n",
    "    ax1 = fig.add_subplot(gs[2*i])\n",
    "    ax2 = fig.add_subplot(gs[2*i+1])\n",
    "    \n",
    "    r = Cutout2D(galaxy.OIII5006, (x,y), u.Quantity((size, size), u.pixel),wcs=galaxy.wcs)\n",
    "    norm = simple_norm(r.data,'linear',clip=False,percent=95)\n",
    "    ax1.imshow(r.data, origin='lower',norm=norm,cmap='Greys')\n",
    "\n",
    "    aperture = CircularAperture(r.position_cutout,8)\n",
    "    aperture.plot(color='tab:red',lw=1,axes=ax1)\n",
    "\n",
    "    t = ax1.text(0.07,0.87,f'{region_ID}', transform=ax1.transAxes,color='black',fontsize=7)\n",
    "    t.set_bbox(dict(facecolor='white', alpha=1, ec='white'))\n",
    "    ax1.set_xticks([])\n",
    "    ax1.set_yticks([])\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        # there will be NaNs in the subcube that is used for the sigma clipping\n",
    "        # astropy will issue a warning which we ignore in this enviornment\n",
    "        circle  = circular_mask(*data_cube.shape[1:],(x,y),4)\n",
    "        annulus = annulus_mask(*data_cube.shape[1:],(x,y),8,12) \n",
    "        _, bkg, _ = sigma_clipped_stats(data_cube[...,annulus],axis=1)\n",
    "    \n",
    "    spectrum = np.sum(data_cube[...,circle],axis=1)    \n",
    "    # the background is the median * the number of non zero pixel\n",
    "    spectrum_without_bkg = spectrum - bkg * np.sum(circle)\n",
    "    \n",
    "    #spectra = np.sum(data_cube[...,int(x)-1:int(x)+1,int(y)-1:int(y)+1],axis=(1,2))    \n",
    "    # the wavelenght coverage of MUSE\n",
    "    wavelength = np.linspace(4749.88,9349.88,data_cube.shape[0]) \n",
    "    \n",
    "    ax2.plot(wavelength,spectrum,color=tab10[1],label='with background')\n",
    "    ax2.plot(wavelength,spectrum_without_bkg,color=tab10[0],label='background subtracted')\n",
    "    #ax2.legend() \n",
    "\n",
    "    ax2.set(xlim=xlim,\n",
    "            ylabel=r'erg\\,/\\,s\\,/\\,\\AA')\n",
    "    if i ==0 :\n",
    "        ax2.set_title(name)\n",
    "    if i == len(region_IDs)-1:\n",
    "        ax2.set(xlabel=r'$\\lambda$\\,/\\,\\AA')\n",
    "    else:\n",
    "        ax2.set_xticklabels([])\n",
    "        \n",
    "    ax2.yaxis.tick_right()\n",
    "    ax2.yaxis.set_ticks_position('both')\n",
    "    ax2.yaxis.set_label_position(\"right\")\n",
    "    \n",
    "    # save spectra\n",
    "    spectra[f'{region_ID}_wavelength'] = wavelength\n",
    "    spectra[f'{region_ID}_spectra'] = spectrum\n",
    "    spectra[f'{region_ID}_bkg'] = bkg * np.sum(circle)\n",
    "    \n",
    "plt.subplots_adjust(wspace=0,hspace=0.05)\n",
    "    \n",
    "if filename:\n",
    "    plt.savefig(filename.with_suffix('.pdf'),dpi=600)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.auxiliary import annulus_mask, circular_mask\n",
    "\n",
    "name = 'NGC0628'\n",
    "\n",
    "cube_path = Path('g:\\Archive')/'MUSE'/'DR1'/'datacubes'\n",
    "if name not in [x.stem.split('_')[0] for x in cube_path.iterdir()]:\n",
    "    raise FileNotFoundError(f'no datacube for {name}')\n",
    "with fits.open(cube_path / f'{name}_DATACUBE_FINAL.fits' , memmap=True, mode='denywrite') as hdul:\n",
    "    data_cube   = hdul[1].data\n",
    "    cube_header = hdul[1].header\n",
    "    \n",
    "catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "if catalogue_file.is_file():\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "    \n",
    "\n",
    "def extract_spectra(cube,header,positions,region_ID,filename):\n",
    "    '''extract spectra from a spectral cube at given positions'''\n",
    "    \n",
    "    logger.info(f'extracting spectrum for {len(positions)} objects')\n",
    "    \n",
    "    wavelength = []\n",
    "    spectrum   = []\n",
    "    background = []\n",
    "    \n",
    "    radii = [22.48, 21.42, 22.12]\n",
    "    \n",
    "    for i,pos in enumerate(positions):\n",
    "        print(f'{i+1} of {len(positions)}')\n",
    "        print(radii[i])\n",
    "        x,y=pos\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            # there will be NaNs in the subcube that is used for the sigma clipping\n",
    "            # astropy will issue a warning which we ignore in this enviornment\n",
    "            circle  = circular_mask(*cube.shape[1:],(x,y),radii[i])\n",
    "            annulus = annulus_mask(*cube.shape[1:],(x,y),23,24) \n",
    "            _, bkg, _ = sigma_clipped_stats(cube[...,annulus],axis=1)\n",
    "\n",
    "        spectrum.append(np.sum(data_cube[...,circle],axis=1))  \n",
    "        background.append(bkg * np.sum(circle))\n",
    "        wavelength.append(np.linspace(header['CRVAL3'],header['CRVAL3']+header['NAXIS3']*header['CD3_3'],header['NAXIS3']))\n",
    "    \n",
    "    spectra = Table(data=[region_ID,wavelength,spectrum,background],\n",
    "                    names=['region_ID','wavelenght','spectrum','bkg'])\n",
    "\n",
    "    hdu = fits.BinTableHDU(spectra,name='spectra')\n",
    "    hdu.writeto(filename,overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#positions = catalogue[catalogue['type']=='PN'][['x','y']]\n",
    "#filename = basedir/'data'/'suspicious'/f'{name}_spectra_liz.fits'\n",
    "#extract_spectra(data_cube,cube_header,positions[:50],catalogue[catalogue['type']=='PN']['id'][:50],filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with fits.open(basedir/'data'/'suspicious'/'{}_spectra.fits'.format(name)) as hdul:\n",
    "    spec = Table(hdul[1].data)\n",
    "spec.add_index('region_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dap_path = Path('g:\\Archive')/'MUSE'/'DR1'/'MUSEDAP'/'NGC0628_MAPS.fits'\n",
    "with fits.open(dap_path) as hdul:\n",
    "    wcs = WCS(hdul['FLUX'].header)\n",
    "    \n",
    "\n",
    "ra  = np.array([24.1623,24.1645,24.1888])\n",
    "dec = np.array([15.7701,15.7958,15.7968])\n",
    "\n",
    "p_sk = SkyCoord(ra*u.degree,dec*u.degree)\n",
    "\n",
    "for sk in p_sk:\n",
    "    p_xy.append(sk.to_pixel(wcs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = basedir/'data'/'suspicious'/f'{name}_spectra_liz.fits'\n",
    "extract_spectra(data_cube,cube_header,positions,[1,2,3],filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_xy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = p_xy[0]\n",
    "width = 30\n",
    "sub_cube = data_cube[:,int(x)-width:int(x)+width,int(y)-width:int(y)+width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with fits.open(basedir/'data'/'suspicious'/f'{name}_spectra_liz.fits') as hdul:\n",
    "    spec = Table(hdul[1].data)\n",
    "spec.add_index('region_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = positions[0]\n",
    "\n",
    "plt.plot(data_cube[:,int(p[0]),int(p[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = catalogue[(np.isin(catalogue['type'],['PN','SNR'])) & (catalogue['mOIII']<28)][['id','x','y','RaDec','mOIII','type']]\n",
    "\n",
    "with open(basedir / 'data' / f'{name}_PN_and_SNR.txt','w',newline='\\n') as f:\n",
    "    ascii.write(sub,f,format='fixed_width_two_line',overwrite=True,delimiter_pad=' ',position_char='=')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spectral_cube import SpectralCube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sk in p_sk:\n",
    "    sep=sk.separation(catalogue['SkyCoord'])\n",
    "    row = catalogue[np.argmin(sep)]\n",
    "    print(catalogue[sep.__lt__(Angle('10\"'))]['type'])\n",
    "    print(f'{np.min(sep.to(u.arcsec)):.2f}, {row[\"id\"]}, {row[\"type\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare measured magnitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.coordinates import match_coordinates_sky # match sources against existing catalog\n",
    "from astropy.coordinates import Angle                 # work with angles (e.g. 123)\n",
    "\n",
    "from pnlf.load_references import NGC628, \\\n",
    "                                 pn_NGC628_kreckel, \\\n",
    "                                 snr_NGC628_kreckel, \\\n",
    "                                 pn_NGC628_herrmann, \\\n",
    "                                 NGC628_kreckel, \\\n",
    "                                 pn_NGC5068_herrmann, \\\n",
    "                                 pn_NGC3351_ciardullo, \\\n",
    "                                 pn_NGC3627_ciardullo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax1,ax2) = plt.subplots(nrows=2,ncols=1,figsize=(single_column,single_column*1.8))\n",
    "\n",
    "'''\n",
    "   NGC0628\n",
    "'''\n",
    "\n",
    "name = 'NGC0628'\n",
    "catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "if catalogue_file.is_file():\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "catalogue['SkyCoord'] = SkyCoord(catalogue['RaDec'])\n",
    "catalogue = catalogue[(catalogue['type']=='PN') | ((catalogue['type']=='SNR') & (catalogue['SNRorPN']==True)) ]\n",
    "#catalogue = catalogue[np.isin(catalogue['type'],['PN','SNR'])]\n",
    "catalogue['R2'] = catalogue['OIII5006'] / (catalogue['HA6562']+catalogue['NII6583'])\n",
    "catalogue['dR2'] = catalogue['R2']  * np.sqrt(catalogue['OIII5006_err']/catalogue['OIII5006_err']**2 + 1/(catalogue['HA6562']+catalogue['NII6583'])**2 * (catalogue['HA6562_err']**2+catalogue['NII6583_err']**2) )                                  \n",
    "\n",
    "matchcoord = NGC628.copy()\n",
    "\n",
    "ID, sep, _  = match_coordinates_sky(matchcoord['SkyCoord'],catalogue['SkyCoord'])\n",
    "matchcoord['mOIII_measured'] = catalogue[ID]['mOIII']\n",
    "matchcoord['dmOIII_measured'] = catalogue[ID]['dmOIII']\n",
    "matchcoord['R_measured'] = catalogue[ID]['R2']\n",
    "matchcoord['dR_measured'] = catalogue[ID]['dR2']\n",
    "crit = sep.__lt__(Angle(\"0.5s\"))\n",
    "\n",
    "for s,c in zip(['Kreckel PN','Kreckel SNR','Herrmann PN'],['tab:red','tab:orange','tab:blue']):\n",
    "    tmp = matchcoord[(matchcoord['source']==s) & crit]\n",
    "    ax1.errorbar(tmp['mOIII'],tmp['mOIII_measured'],\n",
    "                 yerr = tmp['dmOIII_measured'],\n",
    "                 marker='o',ms=2,ls='none',mec=c,mfc=c,ecolor=c,label=s)\n",
    "    tmp = matchcoord[(matchcoord['source']==s) & crit]\n",
    "    ax2.errorbar(tmp['R'],tmp['R_measured'],\n",
    "                 #xerr = tmp['dR'],\n",
    "                 #yerr = tmp['dR_measured'],\n",
    "                 marker='o',ms=2,ls='none',mec=c,mfc=c,ecolor=c,label=s)\n",
    "\n",
    "\n",
    "'''\n",
    "   NGC5068\n",
    "'''\n",
    "name = 'NGC5068'\n",
    "catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "if catalogue_file.is_file():\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "catalogue['SkyCoord'] = SkyCoord(catalogue['RaDec'])\n",
    "catalogue = catalogue[np.isin(catalogue['type'],['PN','SNR'])]\n",
    "catalogue['R2'] = catalogue['OIII5006'] / (catalogue['HA6562']+catalogue['NII6583'])\n",
    "catalogue['dR2'] = catalogue['R2']  * np.sqrt(catalogue['OIII5006_err']/catalogue['OIII5006_err']**2 + 1/(catalogue['HA6562']+catalogue['NII6583'])**2 * (catalogue['HA6562_err']**2+catalogue['NII6583_err']**2) )                                  \n",
    "\n",
    "matchcoord = pn_NGC5068_herrmann.copy()\n",
    "\n",
    "ID, sep, _  = match_coordinates_sky(matchcoord['SkyCoord'],catalogue['SkyCoord'])\n",
    "matchcoord['mOIII_measured'] = catalogue[ID]['mOIII']\n",
    "matchcoord['dmOIII_measured'] = catalogue[ID]['dmOIII']\n",
    "matchcoord['R_measured'] = catalogue[ID]['R2']\n",
    "matchcoord['dR_measured'] = catalogue[ID]['dR2']\n",
    "crit = sep.__lt__(Angle(\"0.5s\"))\n",
    "\n",
    "tmp = matchcoord[(crit)]\n",
    "c = 'tab:green'\n",
    "ax1.errorbar(tmp['mOIII'],tmp['mOIII_measured'],\n",
    "             yerr = tmp['dmOIII_measured'],\n",
    "             #xerr = tmp['dmOIII'],\n",
    "             marker='o',ms=2,ls='none',mec=c,mfc=c,ecolor=c,label=s)\n",
    "ax2.errorbar(tmp['R'],tmp['R_measured'],\n",
    "             #xerr = tmp['sigma_R'],\n",
    "             #yerr = tmp['dR_measured'],\n",
    "             marker='o',ms=2,ls='none',mec=c,mfc=c,ecolor=c,label=s)\n",
    "\n",
    "\n",
    "'''\n",
    "   NGC3627\n",
    "'''\n",
    "name = 'NGC3627'\n",
    "catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "if catalogue_file.is_file():\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "catalogue['SkyCoord'] = SkyCoord(catalogue['RaDec'])\n",
    "catalogue = catalogue[np.isin(catalogue['type'],['PN','SNR'])]\n",
    "\n",
    "matchcoord = pn_NGC3627_ciardullo.copy()\n",
    "\n",
    "ID, sep, _  = match_coordinates_sky(matchcoord['SkyCoord'],catalogue['SkyCoord'])\n",
    "matchcoord['mOIII_measured'] = catalogue[ID]['mOIII']\n",
    "matchcoord['dmOIII_measured'] = catalogue[ID]['dmOIII']\n",
    "crit = sep.__lt__(Angle(\"0.5s\"))\n",
    "\n",
    "tmp = matchcoord[crit]\n",
    "c = 'cyan'\n",
    "ax1.errorbar(tmp['mOIII'],tmp['mOIII_measured'],\n",
    "             yerr = tmp['dmOIII_measured'],\n",
    "             marker='o',ms=2,ls='none',mec=c,mfc=c,ecolor=c,label='NGC3627')\n",
    "\n",
    "\n",
    "'''\n",
    "   NGC3351\n",
    "'''\n",
    "name = 'NGC3351'\n",
    "catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "if catalogue_file.is_file():\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "catalogue['SkyCoord'] = SkyCoord(catalogue['RaDec'])\n",
    "catalogue = catalogue[np.isin(catalogue['type'],['PN','SNR'])]\n",
    "catalogue['R2'] = catalogue['OIII5006'] / (catalogue['HA6562']+catalogue['NII6583'])\n",
    "catalogue['dR2'] = catalogue['R2']  * np.sqrt(catalogue['OIII5006_err']/catalogue['OIII5006_err']**2 + 1/(catalogue['HA6562']+catalogue['NII6583'])**2 * (catalogue['HA6562_err']**2+catalogue['NII6583_err']**2) )                                  \n",
    "\n",
    "matchcoord = pn_NGC3351_ciardullo.copy()\n",
    "\n",
    "ID, sep, _  = match_coordinates_sky(matchcoord['SkyCoord'],catalogue['SkyCoord'])\n",
    "matchcoord['mOIII_measured'] = catalogue[ID]['mOIII']\n",
    "matchcoord['dmOIII_measured'] = catalogue[ID]['dmOIII']\n",
    "crit = sep.__lt__(Angle(\"0.5s\"))\n",
    "\n",
    "tmp = matchcoord[crit]\n",
    "c = 'purple'\n",
    "ax1.errorbar(tmp['mOIII'],tmp['mOIII_measured'],\n",
    "             yerr = tmp['dmOIII_measured'],\n",
    "             marker='o',ms=2,ls='none',mec=c,mfc=c,ecolor=c,label='NGC3351')\n",
    "\n",
    "\n",
    "ax1.plot([25,27.5],[25,27.5],color='black',lw=0.4)\n",
    "ax1.set(xlim=[25,27.5],ylim=[25,27.5])\n",
    "ax1.set_xlabel(r'$\\mathrm{m}_{[\\mathrm{O}\\,\\tiny{\\textsc{iii}}]}$ existing studies')\n",
    "ax1.set_ylabel(r'$\\mathrm{m}_{[\\mathrm{O}\\,\\tiny{\\textsc{iii}}]}$ this work')\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "xmin,xmax = 0,7\n",
    "ymin,ymax = 0,7\n",
    "ax2.plot([xmin,xmax],[xmin,xmax],color='black',lw=0.4)\n",
    "ax2.set_xlim([xmin,xmax])\n",
    "ax2.set_ylim([ymin,ymax])\n",
    "ax2.set_xlabel(r'$I_{[\\mathrm{O}\\,\\tiny{\\textsc{iii}}]}\\;/\\;(I_{\\mathrm{H}\\,\\alpha}+I_{[\\mathrm{N}\\,\\tiny{\\textsc{ii}}]})$ existing studies')\n",
    "ax2.set_ylabel(r'$I_{[\\mathrm{O}\\,\\tiny{\\textsc{iii}}]}\\;/\\;(I_{\\mathrm{H}\\,\\alpha}+I_{[\\mathrm{N}\\,\\tiny{\\textsc{ii}}]})$ this work')\n",
    "#ax2.legend(loc=2)\n",
    "\n",
    "plt.savefig(basedir / 'reports' / f'flux_comparison.pdf',dpi=600)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'NGC0628'\n",
    "catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "if catalogue_file.is_file():\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "catalogue['SkyCoord'] = SkyCoord(catalogue['RaDec'])\n",
    "catalogue = catalogue[np.isin(catalogue['type'],['PN','SNR'])]\n",
    "catalogue['R2'] = catalogue['OIII5006'] / (catalogue['HA6562']+catalogue['NII6583'])\n",
    "catalogue['dR2'] = catalogue['R2']  * np.sqrt(catalogue['OIII5006_err']/catalogue['OIII5006_err']**2 + 1/(catalogue['HA6562']+catalogue['NII6583'])**2 * (catalogue['HA6562_err']**2+catalogue['NII6583_err']**2) )                                  \n",
    "\n",
    "matchcoord = NGC628.copy()\n",
    "\n",
    "ID, sep, _  = match_coordinates_sky(matchcoord['SkyCoord'],catalogue['SkyCoord'])\n",
    "matchcoord['IDf'] = ID\n",
    "matchcoord['mOIII_measured'] = catalogue[ID]['mOIII']\n",
    "matchcoord['dmOIII_measured'] = catalogue[ID]['dmOIII']\n",
    "matchcoord['R_measured'] = catalogue[ID]['R2']\n",
    "matchcoord['dR_measured'] = catalogue[ID]['dR2']\n",
    "crit = sep.__lt__(Angle(\"0.5s\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## measure (m-M) from inner and outer PNe\n",
    "\n",
    "the metallicity and with it $M*$ decreases in the outer regions of the galaxies. A smaller $M*$ should lead to a larger distance. Therefore the PNe in the outer parts should yield a larger distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abundance_gradients = ascii.read(basedir/'data'/'external'/'radial_abundance_gradients.txt',\n",
    "                                names=['name','R0','g_r25'])\n",
    "abundance_gradients.add_index('name')\n",
    "\n",
    "pnlf_io = ascii.read(basedir/'data'/'interim'/ 'pnlf_io.txt')\n",
    "pnlf_io.add_index('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regions import EllipseSkyRegion\n",
    "\n",
    "name = 'NGC0628'\n",
    "\n",
    "logOH_sun = 8.87\n",
    "deltaM = lambda OH: 0.928*OH**2+0.225*OH+0.014\n",
    "\n",
    "try:\n",
    "    mu_trgb = trgb.loc[name]['trgb_(m-M)']\n",
    "except:\n",
    "    print(f'no TRGB for {name}')\n",
    "    mu_trgb=0\n",
    "completeness = parameters[name]['completeness_limit']\n",
    "binsize = parameters[name]['binsize']\n",
    "\n",
    "catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "if catalogue_file.is_file():\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "    catalogue['overluminous'] = catalogue['overluminous'].astype(bool)\n",
    "\n",
    "catalogue['SkyCoord'] = SkyCoord(catalogue['RaDec'])\n",
    "catalogue = catalogue[(catalogue['type']=='PN') & (~catalogue['exclude']) & (~catalogue['overluminous']) & (catalogue['mOIII']<completeness)]\n",
    "\n",
    "center = sample_table.loc[name]['SkyCoord']\n",
    "posang = sample_table.loc[name]['posang']\n",
    "inclination = sample_table.loc[name]['Inclination']\n",
    "eccentricity = np.sin(inclination*u.deg).value\n",
    "\n",
    "r25 = sample_table.loc[name]['r25']*u.arcmin\n",
    "\n",
    "catalogue['r'] = catalogue['SkyCoord'].separation(center)\n",
    "rmean = np.mean(catalogue['r']/r25).decompose()\n",
    "logOH_rmean = abundance_gradients.loc[name]['R0']+rmean*abundance_gradients.loc[name]['g_r25']\n",
    "\n",
    "print(f'rmean = {rmean:.2f} r25')\n",
    "print(f'dM*={deltaM(logOH_rmean-logOH_sun):.3f}')\n",
    "\n",
    "with fits.open(data_ext/'MUSE_DR2'/'MUSEDAP'/f'{name}_MAPS.fits') as hdul:\n",
    "    wcs = WCS(hdul['OIII5006_FLUX '].header)\n",
    "    OIII = hdul['OIII5006_FLUX'].data\n",
    "    \n",
    "catalogue['region'] = '     '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split into inner/outer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "tried = set()\n",
    "while True: \n",
    "    width = threshold*r25\n",
    "    aperture = EllipseSkyRegion(center,\n",
    "                            width=width,\n",
    "                            height=np.sqrt((width)**2 * (1-eccentricity**2)),\n",
    "                            angle=(posang-90)*u.deg)\n",
    "    inside = aperture.contains(catalogue['SkyCoord'],wcs)\n",
    "    ratio = np.sum(inside)/np.sum(~inside)\n",
    "    \n",
    "    if threshold in tried:\n",
    "        break\n",
    "    tried.add(threshold)\n",
    "\n",
    "    if np.abs(ratio-1)<0.02:\n",
    "        break\n",
    "    elif ratio>1:\n",
    "        threshold/=1.02\n",
    "    elif ratio<1:\n",
    "        threshold*=1.02\n",
    "\n",
    "width = threshold*r25\n",
    "aperture = EllipseSkyRegion(center,\n",
    "                        width=width,\n",
    "                        height=np.sqrt((width)**2 * (1-eccentricity**2)),\n",
    "                        angle=(posang-90)*u.deg)\n",
    "catalogue['region'] = 'inner'\n",
    "catalogue['region'][~aperture.contains(catalogue['SkyCoord'],wcs)] = 'outer'\n",
    "    \n",
    "print(f'width={threshold:.3f} r25')\n",
    "\n",
    "r = width/r25\n",
    "\n",
    "logOH1 = abundance_gradients.loc[name]['R0']\n",
    "logOH2 = abundance_gradients.loc[name]['R0']+r*abundance_gradients.loc[name]['g_r25']\n",
    "\n",
    "print(f'inner dM*={deltaM(logOH1-logOH_sun):.3f}\\noutter dM*={deltaM(logOH2-logOH_sun):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or split into quadrants"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "catalogue['region'] = 'south'\n",
    "\n",
    "catalogue['region'][(center.ra<catalogue['SkyCoord'].ra) & (center.dec<catalogue['SkyCoord'].dec)] = 'north'\n",
    "catalogue['region'][(center.ra<catalogue['SkyCoord'].ra) & (center.dec>catalogue['SkyCoord'].dec)] = 'west'\n",
    "catalogue['region'][(center.ra>catalogue['SkyCoord'].ra) & (center.dec<catalogue['SkyCoord'].dec)] = 'east'\n",
    "catalogue['region'][(center.ra>catalogue['SkyCoord'].ra) & (center.dec>catalogue['SkyCoord'].dec)] = 'south'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue['region'] = 'west'\n",
    "\n",
    "catalogue['region'][(center.ra<catalogue['SkyCoord'].ra)] = 'west'\n",
    "catalogue['region'][(center.ra>catalogue['SkyCoord'].ra)] = 'east'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue['region'] = 'south'\n",
    "\n",
    "catalogue['region'][(center.dec<catalogue['SkyCoord'].dec)] = 'north'\n",
    "catalogue['region'][(center.dec>catalogue['SkyCoord'].dec)] = 'south'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue['region'] = 'south'\n",
    "x0,y0 = center.to_pixel(wcs)\n",
    "x,y = catalogue['x'],catalogue['y']\n",
    "\n",
    "north = (y>y0-np.sin((posang)/180*np.pi)*(x-x0))\n",
    "south = (y<y0-np.sin((posang)/180*np.pi)*(x-x0))\n",
    "east = (x<x0+np.cos((posang-90)/180*np.pi)*(y-y0))\n",
    "west = (x>x0+np.cos((posang-90)/180*np.pi)*(y-y0))\n",
    "\n",
    "catalogue['region'][north & west] = 'nw'\n",
    "catalogue['region'][north & east] = 'ne'\n",
    "catalogue['region'][south & west] = 'sw'\n",
    "catalogue['region'][south & east] = 'se'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compare central PNe to outer PNe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0,y0 = center.to_pixel(wcs)\n",
    "dx = 1000\n",
    "\n",
    "majx1 = x0-np.cos(posang/180*np.pi)*dx\n",
    "majx2 = x0+np.cos(posang/180*np.pi)*dx\n",
    "majy1 = y0-np.sin(posang/180*np.pi)*dx\n",
    "majy2 = y0+np.sin(posang/180*np.pi)*dx\n",
    "\n",
    "minx1 = x0-np.cos((posang-90)/180*np.pi)*dx\n",
    "minx2 = x0+np.cos((posang-90)/180*np.pi)*dx\n",
    "miny1 = y0-np.sin((posang-90)/180*np.pi)*dx\n",
    "miny2 = y0+np.sin((posang-90)/180*np.pi)*dx\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(projection=wcs)\n",
    "\n",
    "norm = simple_norm(OIII,clip=False,percent=97)\n",
    "ax.imshow(OIII,norm=norm,cmap=plt.cm.Greys)\n",
    "\n",
    "for region in np.unique(catalogue['region']):\n",
    "    tmp = catalogue[catalogue['region']==region]\n",
    "    ax.errorbar(tmp['x'],tmp['y'],fmt='o',ms=5,label=region)\n",
    "pixel_aperture = aperture.to_pixel(wcs)\n",
    "artist = pixel_aperture.as_artist(ec='black')\n",
    "ax.add_artist(artist)\n",
    "\n",
    "ax.plot([majx1,majx2],[majy1,majy2],color='black')\n",
    "ax.plot([minx1,minx2],[miny1,miny2],color='black')\n",
    "\n",
    "ax.set(xlim=(0,OIII.shape[1]),ylim=(0,OIII.shape[0]))\n",
    "ax.set_title(name)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.analyse import MaximumLikelihood1D, pnlf, cdf\n",
    "from pnlf.plot.pnlf import plot_pnlf\n",
    "from scipy.stats import kstest\n",
    "\n",
    "regions = np.unique(catalogue['region'])\n",
    "if 'axes' in locals():\n",
    "    del axes\n",
    "for i,region in enumerate(regions):\n",
    "    \n",
    "    data = catalogue[catalogue['region']==region]['mOIII']\n",
    "    err  = catalogue[catalogue['region']==region]['dmOIII']\n",
    "    \n",
    "    if len(data)<15:\n",
    "        print(f'not enough data points ({len(data)}) for region {region}')\n",
    "        continue\n",
    "        \n",
    "    fitter = MaximumLikelihood1D(pnlf,\n",
    "                                 data[data<completeness],\n",
    "                                 err=err[data<completeness],\n",
    "                                 mhigh=completeness,Mmax=-4.47)\n",
    "    mu,mu_p,mu_m = fitter([29])\n",
    "    print('{}: {:.2f} + {:.2f} - {:.2f}'.format(region,mu,mu_p,mu_m))\n",
    "\n",
    "\n",
    "    #Plot PNLF\n",
    "    if 'axes' not in locals():\n",
    "        axes = plot_pnlf(data,mu,completeness,\n",
    "                 binsize=binsize,mhigh=28.5,Mmax=-4.47,color=tab10[i])\n",
    "    else:\n",
    "        axes = plot_pnlf(data,mu,completeness,\n",
    "                         binsize=binsize,mhigh=28.5,Mmax=-4.47,filename=None,color=tab10[i],axes=axes)\n",
    "    \n",
    "ax1,ax2 = axes \n",
    "h, l = ax2.get_legend_handles_labels()\n",
    "ax2.legend(h,regions)\n",
    "filename=basedir/'reports'/name/f'{name}_PNLF_radial'\n",
    "plt.savefig(filename.with_suffix('.pdf'),bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = [name,threshold,mui,muo,deltaM(logOH1-logOH_sun),deltaM(logOH2-logOH_sun)]\n",
    "if name in pnlf_io['name']:\n",
    "    pnlf_io.loc[name] = row \n",
    "else:\n",
    "    pnlf_io.add_row(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in pnlf_io.columns[1:]:\n",
    "    pnlf_io[col].info.format='%.3f'\n",
    "    \n",
    "with open(basedir/'data'/'interim'/ 'pnlf_io.txt','w',newline='\\n') as f:\n",
    "    ascii.write(pnlf_io,f,format='fixed_width_two_line',overwrite=True,delimiter_pad=' ',position_char='=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnlf_io['err(m-M)'] = 0.0\n",
    "\n",
    "for row in pnlf_io:\n",
    "    row['err(m-M)'] = np.sqrt(2)*results.loc[row['name']]['err+(m-M)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(pnlf_io))\n",
    "\n",
    "pnlf_io.sort('r')\n",
    "fig,ax=plt.subplots()\n",
    "\n",
    "ax.axhline(0,color='black',lw=1)\n",
    "ax.errorbar(x,pnlf_io['(m-M)outer']-pnlf_io['(m-M)inner'],\n",
    "            yerr=pnlf_io['err(m-M)'],fmt='o',color='tab:red',label='(m-M)')\n",
    "ax.scatter(x,pnlf_io['dM*inner']-pnlf_io['dM*outer'],color='tab:blue',label='$\\Delta M*$')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(pnlf_io['name'],rotation=90)\n",
    "ax.set(ylabel=r'outer - inner')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnlf_io['d(m-M)'] = pnlf_io['(m-M)outer']-pnlf_io['(m-M)inner']\n",
    "pnlf_io['dM*'] = pnlf_io['dM*outer']-pnlf_io['dM*inner']\n",
    "\n",
    "for col in pnlf_io.columns[1:]:\n",
    "    pnlf_io[col].info.format='%.3f'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnlf_io.sort('name')\n",
    "ascii.write(pnlf_io[['name','r','d(m-M)','dM*']], sys.stdout, Writer = ascii.Latex,\n",
    "            latexdict = {'tabletype': 'table*'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metallicity dependance of the zero point\n",
    "\n",
    "the zeropoint $M*$ of the PNLF must be measured from galaxies with known distances. Ciardullo+2002 suggested a quadratic dependence on metallicity. Here we try to validate this assumption by comparing our measured distances to TRGB distances and infer $M*$. \n",
    "\n",
    "From **Ferrares+2000**\n",
    "\n",
    "The OIII5007 magnitude of the PNLF, m*, uncorrected for foreground extinction, is listed in column (9) of Table 3. Because PNLF distance moduli are calculated by tting the luminosity function with a standard template (e.g., Ciardullo et al. 1989b), only the nal distance moduli are published. From these we derived m* a posteriori by subtracting the zero point (and the extinction correction, if applied) adopted by the authors. The PNLF distances to the SMC, NGC 3109, and NGC 5253, listed in Table 3, are not well constrained. The planetary nebula (PN) sample in NGC 3109 (Richer & McCall 1992) includes only seven objects, and an upper limit to the distance is derived from the brightest of the PNs observed. Jacoby, Walker, & Ciardullo (1990) advise against the use of the PNLF distance to the SMC because of the small number of PNs dening the luminosity function. Finally, the small number of PNs detected in NGC 5253, the presence of strong internal dust extinction, and the galaxys very low metal abundance all conjoin to produce a very ill constrained PNLF magnitude cuto, unsuitable for distance determinations (Phillips et al. 1992). Uncertainties in the values of m* are summarized, for example, in Jacoby, Ciardullo, & Ford (1990). They include a contribution associated with the tting procedure (of the order of 0.10 mag), photometric zero points (D0.05 mag), the lter response calibration (D0.04 mag), and the uncertain denition of the empirical PNLF (D0.05 mag). Errors in the reddening estimate, which are sometimes included, have been removed (in quadrature) from the present analysis, since we only deal with uncorrected magnitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Kreckel+2019\n",
    "with open(basedir/'data'/'external'/'kreckel2019.txt') as f:\n",
    "    txt=f.read()\n",
    "txt = txt.replace('+or-','')\n",
    "rows = txt.split('\\n')\n",
    "rows = [row.split('\\t')[:-1] for row in rows]\n",
    "        \n",
    "new = []\n",
    "for r1,r2 in zip(rows[::2],rows[1::2]):\n",
    "    row = []\n",
    "    for c1,c2 in zip(r1,r2):\n",
    "        row.append(c1)\n",
    "        if c2:\n",
    "            row.append(c2)\n",
    "    new.append(row)\n",
    "\n",
    "names = ['name','R0_scal','R0_err_scal','g_r25_scal','g_r25_err_scal','g_kpc_scal','g_kpc_err_scal','sOH_scal',\n",
    "                'R0_N2S2','R0_err_N2S2','g_r25_N2S2','g_r25_err_N2S2','g_kpc_N2S2','g_kpc_err_N2S2','sOH_N2S2',\n",
    "                'R0_O3N2','R0_err_O3N2','g_r25_O3N2','g_r25_err_O3N2','g_kpc_O3N2','g_kpc_err_O3N2','sOH_O3N2',\n",
    "                'R0_N2','R0_err_N2','g_r25_N2','g_r25_err_N2','g_kpc_N2','g_kpc_err_N2','sOH_N2']\n",
    "met = Table( list(zip(*new)),names=names)\n",
    "for c in met.columns[1:]:\n",
    "    met[c] = met[c].astype(float)\n",
    "met.add_index('name')\n",
    "\n",
    "abundance_gradients = ascii.read(basedir/'data'/'external'/'radial_abundance_gradients.txt',\n",
    "                                names=['name','R0','g_r25'])\n",
    "abundance_gradients.add_index('name')\n",
    "\n",
    "from astropy.table import join\n",
    "\n",
    "trgb_distances = {'name':[],'trgb_(m-M)':[],'trgb_err(m-M)':[]}\n",
    "for name in results['name']:\n",
    "    litdist = distances = ascii.read(basedir / 'data' / 'literature distances' / f'{name}.csv',delimiter=',',comment='#')\n",
    "    \n",
    "    if 'TRGB' in litdist['Method']:\n",
    "        sub = litdist[litdist['Method']=='TRGB']\n",
    "        sub.sort('Refcode',reverse=True)\n",
    "        \n",
    "        trgb_distances['name'].append(name)\n",
    "        trgb_distances['trgb_(m-M)'].append(sub['(m-M)'][0])\n",
    "        trgb_distances['trgb_err(m-M)'].append(sub['err(m-M)'][0])\n",
    "trgb = Table(trgb_distances)      \n",
    "trgb = join(results[['name','(m-M)','err+(m-M)','err-(m-M)']],trgb,'name')\n",
    "trgb = join(trgb,abundance_gradients,'name')\n",
    "trgb.add_index('name')\n",
    "\n",
    "trgb['rmean'] = 0.0\n",
    "for name in trgb['name']:\n",
    "    tmp = catalogue[(catalogue['Galaxy']==name) & (catalogue['notes']!='OL')]\n",
    "    center = sample_table.loc[name]['SkyCoord']\n",
    "    r25 = sample_table.loc[name]['r25']*u.arcmin\n",
    "    trgb.loc[name]['rmean'] = np.mean(tmp['SkyCoord'].separation(center)/r25).decompose()\n",
    "trgb['logOH'] = trgb['R0']+trgb['rmean']*trgb['g_r25']\n",
    "trgb['dM*'] = trgb['(m-M)']-trgb['trgb_(m-M)']\n",
    "trgb['errM*'] = np.sqrt(trgb['err+(m-M)']**2 + trgb['trgb_err(m-M)'])\n",
    "trgb['errM*'].info.format = '%.2f'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prescription = 'O3N2'\n",
    "r = 0.5 # position in r25\n",
    "\n",
    "deltaM = lambda OH: 0.928*OH**2+0.225*OH+0.014\n",
    "\n",
    "logOH_sun = 8.87\n",
    "logOH = np.linspace(7.8,9.5)\n",
    "\n",
    "fig,((ax1,ax2),(ax3,ax4)) = plt.subplots(nrows=2,ncols=2,figsize=(two_column,two_column/1.618))\n",
    "\n",
    "for ax,prescription in zip([ax1,ax2,ax3,ax4],['scal','N2S2','O3N2','N2']):\n",
    "    ax.plot(logOH,-4.47+deltaM(logOH-logOH_sun),color='black',ls=':')\n",
    "\n",
    "    for n in list(met['name']):\n",
    "        row = met.loc[n]\n",
    "        x = row[f'R0_{prescription}']+r*row[f'g_r25_{prescription}']\n",
    "        y = -4.47+deltaM(x-logOH_sun)\n",
    "        xerr = np.sqrt(row[f'R0_err_{prescription}']**2+(r*row[f'g_r25_err_{prescription}'])**2)\n",
    "        yerr = np.sqrt((2*0.928*x+0.225)**2 *xerr**2)\n",
    "\n",
    "        ax.errorbar(x,y,fmt='o',ms=4,\n",
    "                    xerr=xerr,yerr=yerr,label=n)    \n",
    "    ax.axhline(-4.47,ls='--',lw=0.5)\n",
    "    ax.set(xlim=[8,9],ylim=[-4.6,-4.1],xlabel=f'12+log O/H (at {r} r25)',ylabel='M* (mag)')\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_title(prescription)\n",
    "    \n",
    "plt.legend(ncol=3)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(basedir/'reports'/'zero_point.pdf',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fix $(m-M)$ and fit $M*$\n",
    "\n",
    "we fix $(m-M)$ to the TRGB value and leave $M*$ as a free parameter \n",
    "\n",
    "IC5332,NGC0628,NGC1365,NGC1433,NGC1512,NGC1566,NGC2835,NGC3351,NGC3627,NGC4321,NGC5068"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'NGC3351'\n",
    "\n",
    "catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "if catalogue_file.is_file():\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "    catalogue['overluminous'] = catalogue['overluminous'].astype(bool)\n",
    "\n",
    "catalogue['SkyCoord'] = SkyCoord(catalogue['RaDec'])\n",
    "catalogue = catalogue[(catalogue['type']=='PN') & (~catalogue['exclude']) & (~catalogue['overluminous']) & (catalogue['mOIII']<completeness)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.plot.pnlf import plot_pnlf\n",
    "from pnlf.analyse import F\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def pnlf_Mmax(m,Mmax,mu,mhigh):\n",
    "\n",
    "    m = np.atleast_1d(m)\n",
    "    mlow = Mmax+mu\n",
    "    \n",
    "    normalization = 1/(F(mhigh,mu) - F(mlow,mu))    \n",
    "    out = normalization * np.exp(0.307*(m-mu)) * (1-np.exp(3*(Mmax-m+mu)))\n",
    "    out[(m>mhigh) | (m<mlow)] = 0\n",
    "    \n",
    "    return out\n",
    "\n",
    "def gaussian(x,mu,sig):\n",
    "    return 1/np.sqrt(2*np.pi*sig**2) * np.exp(-(x-mu)**2/(2*sig**2))\n",
    "\n",
    "def prior(param):\n",
    "    return gaussian(param,-4.47,0.08)\n",
    "\n",
    "# pre-process the data for the plot and read additional parameters\n",
    "data = catalogue[(catalogue['type']=='PN') & (~catalogue['exclude'])]['mOIII']\n",
    "err = catalogue[(catalogue['type']=='PN') & (~catalogue['exclude'])]['dmOIII']\n",
    "\n",
    "mu_trgb = trgb.loc[name]['trgb_(m-M)']\n",
    "completeness = parameters[name]['completeness_limit']\n",
    "binsize = parameters[name]['binsize']\n",
    "\n",
    "fitter = MaximumLikelihood1D(pnlf_Mmax,data[data<completeness],err=err[data<completeness],mu=mu_trgb,mhigh=completeness)\n",
    "Mmax = minimize(fitter.likelihood,[-4.47],method=fitter.method).x[0]\n",
    "\n",
    "mlow = Mmax+mu_trgb\n",
    "mhigh = 28.5\n",
    "\n",
    "print(f'{name}: Mmax={Mmax:.2f}, dMmax={Mmax+4.47:.2f}')\n",
    "\n",
    "axes = plot_pnlf(data,mu_trgb,completeness,binsize=binsize,mhigh=28.5,Mmax=Mmax,filename=None,color=tab10[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.analyse import MaximumLikelihood1D, F\n",
    "from pnlf.plot.pnlf import _plot_pnlf\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "names = list(trgb['name'])\n",
    "\n",
    "names.remove('NGC1433')\n",
    "names.remove('NGC1512')\n",
    "\n",
    "nrows = 3\n",
    "ncols = 3\n",
    "filename = None #basedir / 'reports' / f'all_galaxies_PNLF'\n",
    "\n",
    "#----------------------------------------------\n",
    "# DO NOT MODIFY BELOW\n",
    "#----------------------------------------------\n",
    "\n",
    "width = two_column\n",
    "fig, axes = plt.subplots(nrows=nrows,ncols=ncols,figsize=(width,width/ncols*nrows))\n",
    "axes_iter = iter(axes.flatten())\n",
    "\n",
    "trgb['dM*new'] = 0.0\n",
    "for name in names:\n",
    "    \n",
    "    catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "    if catalogue_file.is_file():\n",
    "        catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "        catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "    else:\n",
    "        print(f'no catalogue for {name}')\n",
    "        continue\n",
    "        \n",
    "    # get the next axis and find position on the grid\n",
    "    ax = next(axes_iter)\n",
    "    if nrows>1 and ncols>1:\n",
    "        i, j = np.where(axes == ax)\n",
    "        i,j=i[0],j[0]\n",
    "    elif ncols>1:\n",
    "        i,j = 0, np.where(axes==ax)[0]\n",
    "    elif nrows>1:\n",
    "        i,j = np.where(axes==ax)[0],0\n",
    "    else:\n",
    "        i,j=0,0\n",
    "        \n",
    "    # pre-process the data for the plot and read additional parameters\n",
    "    data = catalogue[(catalogue['type']=='PN') & (~catalogue['exclude'])]['mOIII']\n",
    "    err = catalogue[(catalogue['type']=='PN') & (~catalogue['exclude'])]['dmOIII']\n",
    "\n",
    "    mu_trgb = trgb.loc[name]['trgb_(m-M)']\n",
    "    completeness = parameters[name]['completeness_limit']\n",
    "\n",
    "    binsize = parameters[name]['binsize']\n",
    "\n",
    "    fitter = MaximumLikelihood1D(pnlf_Mmax,data[data<completeness],err=err[data<completeness],prior=prior,mu=mu_trgb,mhigh=completeness)\n",
    "    Mmax = minimize(fitter.likelihood,[-4.47],method=fitter.method).x[0]\n",
    "    \n",
    "    trgb.loc[name]['dM*new'] = Mmax+4.47\n",
    "    \n",
    "    mlow = Mmax+mu_trgb\n",
    "    mhigh = 28.5\n",
    "    \n",
    "    print(f'{name}: Mmax={Mmax:.2f}, dMmax={Mmax+4.47:.2f}')\n",
    "    \n",
    "    ax=_plot_pnlf(data,mu_trgb,completeness,binsize=binsize,mlow=mlow,mhigh=mhigh,ax=ax,ms=3)\n",
    "    ax.text(0.4,0.08,f'{name}', transform=ax.transAxes,fontsize=7)\n",
    "\n",
    "    #ax.set_xlim([mu-5,completeness+0.5])\n",
    "    # add labels to the axis\n",
    "    if i==nrows-1:\n",
    "        ax.set_xlabel(r'$m_{[\\mathrm{OIII}]}$ / mag')\n",
    "    if j==0:\n",
    "        ax.set_ylabel(r'N')\n",
    "    #ax.set_title(name)\n",
    "    #ax.set(xlim=[24,28.5])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit dM* to log (O/H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.modeling import models, fitting\n",
    "\n",
    "# OH = logOH-logOH_sun\n",
    "deltaM = lambda OH: 0.928*OH**2+0.225*OH+0.014\n",
    "\n",
    "logOH_sun = 8.87\n",
    "logOH = np.linspace(8,9)\n",
    "\n",
    "model  = models.Polynomial1D(degree=2,c0=0.014, c1=0.225, c2= 0.928)\n",
    "fitter = fitting.LinearLSQFitter()\n",
    "\n",
    "mask = np.isin(trgb['name'],['NGC1433','NGC1512'])\n",
    "\n",
    "fit = fitter(model,trgb[~mask]['logOH']-logOH_sun,trgb[~mask]['dM*'],weights=trgb[~mask]['errM*'])\n",
    "\n",
    "print('Ciardullo: c0=0.014, c1=0.225, c2= 0.928')\n",
    "print('Fit:       c0={:.3f}, c1={:.3f}, c2={:.3f}'.format(*fit.parameters))\n",
    "\n",
    "fig,ax = plt.subplots(nrows=1,ncols=1,figsize=(two_column,two_column/1.6))\n",
    "\n",
    "ax.errorbar(trgb[~mask]['logOH'],-4.47+trgb[~mask]['dM*'],yerr=trgb[~mask]['errM*'], fmt='ko',label='data')\n",
    "ax.errorbar(trgb[mask]['logOH'],-4.47+trgb[mask]['dM*'],yerr=trgb[mask]['errM*'], fmt='ro',label='excluded')\n",
    "ax.plot(logOH, -4.47+fit(logOH-logOH_sun), 'b-', lw=2,label='fit')\n",
    "ax.plot(logOH,-4.47+deltaM(logOH-logOH_sun),'k:',label='Ciarduollo+2002')\n",
    "\n",
    "ax.axhline(-4.47,ls='--',color='k')\n",
    "#ax.set(xlabel='12+log O/H',ylabel='M* (mag)')\n",
    "ax.set(xlim=[8,9],ylim=[-6.5,-2.5],xlabel=f'12+log O/H',ylabel='M* (mag)')\n",
    "ax.invert_yaxis()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cepheids = Table({\n",
    " 'name':['LMC','SMC','NGC224','NGC300','NGC598','NGC2403','NGC3031','NGC3351','NGC3368','NGC3627','NGC4258','NGC5253','NGC5457'],\n",
    " 'EBV' : [0.075,0.037,0.062,0.013,0.041,0.040,0.080,0.028,0.025,0.032,0.016,0.056,0.009],\n",
    " '(m-M)' : [18.50,19.01 ,24.38 ,26.53 ,24.56 ,27.48 ,27.75 ,29.85 ,29.97 ,29.86 ,29.44 ,27.56 ,29.13],\n",
    " 'err(m-M)' : [0.0,0.03,0.05,0.07,0.10,0.10,0.08,0.09,0.06,0.08,0.07,0.14,0.11],\n",
    " 'M*': [-4.56,-4.67,-4.66,-4.21,-4.08,-4.41,-4.52,-4.39,-4.65,-4.44,-4.51,-4.05,-4.28],\n",
    " '+M*': [0.13,0.40,0.14,0.67,0.16,0.16,0.12,0.19,0.12,0.12,0.13,0.63,0.15],\n",
    " '-M*' : [0.09,0.17,0.11,0.16,0.14,0.13,0.11,0.13,0.11,0.12,0.11,0.16,0.14],\n",
    " 'logOH': [8.50,8.03,8.98,8.35,8.82,8.80,8.75,9.24,9.20,9.25,8.85,8.15,8.50],\n",
    " 'dM*' : [0.06,0.48,0,0.15,0,0,0,0,0,0,0,0.33,0.06]\n",
    "})\n",
    "\n",
    "zeropoint = cepheids.copy()\n",
    "# dM* has a different meaning in the Cepheid table (some correction form Dopita+92)\n",
    "trgb['M*'] = -4.47+trgb['dM*']\n",
    "# add our own data\n",
    "for row in trgb:\n",
    "    if row['name'] not in ['NGC1433','NGC1512']:\n",
    "        new = [row['name'],0,row['(m-M)'],row['err+(m-M)'],row['M*'],row['errM*'],row['errM*'],row['logOH'],0]\n",
    "        zeropoint.add_row(new)\n",
    "    \n",
    "err_p,err_m = zeropoint['+M*'], zeropoint['-M*']\n",
    "\n",
    "zeropoint.sort('logOH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = models.Polynomial1D(degree=2,c0=0.014, c1=0.225, c2= 0.928)\n",
    "fitter = fitting.LinearLSQFitter()\n",
    "\n",
    "logOH = np.linspace(7.8,9.5)\n",
    "\n",
    "fig,ax = plt.subplots(nrows=1,ncols=1,figsize=(single_column,single_column/1.5))\n",
    "\n",
    "fit = fitter(model,cepheids['logOH']-logOH_sun,cepheids['M*']+cepheids['dM*']+4.47,weights=1/cepheids['+M*'])\n",
    "print('Ciardullo: c0=0.014, c1=0.225, c2= 0.928')\n",
    "print('Fit Cepheids: c0={:.3f}, c1={:.3f}, c2={:.3f}'.format(*fit.parameters))\n",
    "#ax.plot(logOH, -4.47+fit(logOH), 'b-', lw=2,label='fit Cepheids')\n",
    "\n",
    "fit = fitter(model,zeropoint['logOH']-logOH_sun,zeropoint['M*']+zeropoint['dM*']+4.47,weights=1/zeropoint['+M*'])\n",
    "print('Fit Cepheids+TRGB: c0={:.3f}, c1={:.3f}, c2={:.3f}'.format(*fit.parameters))\n",
    "\n",
    "ax.errorbar(cepheids['logOH'],cepheids['M*']+cepheids['dM*'],yerr=[cepheids['+M*'],cepheids['-M*']], fmt='o',color=tab10[1],ms=3,label='Cepheids')\n",
    "ax.errorbar(trgb[~mask]['logOH'],trgb[~mask]['M*'],yerr=trgb[~mask]['errM*'], fmt='o',color=tab10[0],ms=3,label='TRGB')\n",
    "\n",
    "ax.plot(logOH, -4.47+fit(logOH-logOH_sun), 'k-', lw=2,label='fit')\n",
    "ax.plot(logOH,-4.47+deltaM(logOH-logOH_sun),'k:',lw=2,label='Ciardullo+2002')\n",
    "plt.locator_params(axis='y',nbins=5)\n",
    "\n",
    "# and now with a constant line\n",
    "model  = models.Polynomial1D(degree=1,c0=-4.5, c1=0)\n",
    "model.c1.fixed=True\n",
    "fit = fitter(model,trgb[~mask]['logOH'],trgb[~mask]['M*'],weights=1/trgb[~mask]['errM*'])\n",
    "print(f'TRGB: M*={fit.c0.value:.2f}')\n",
    "\n",
    "fit = fitter(model,cepheids['logOH'],cepheids['M*'],weights=1/cepheids['+M*'])\n",
    "print(f'Cepheids: M*={fit.c0.value:.2f}')\n",
    "\n",
    "fit = fitter(model,zeropoint['logOH'],zeropoint['M*'],weights=1/zeropoint['+M*'])\n",
    "print(f'together: M*={fit.c0.value:.2f}')\n",
    "\n",
    "#for row in cepheids:\n",
    "#    ax.text(row['logOH'],row['M*']+row['dM*'],row['name'])\n",
    "ax.axhline(fit.c0.value,ls='--',lw=1,color='k')\n",
    "\n",
    "#ax.set(xlabel='12+log O/H',ylabel='M* (mag)')\n",
    "ax.set(xlim=[8,9.4],ylim=[-5.5,-3.5],xlabel=f'12+log O/H',ylabel='M* (mag)')\n",
    "ax.invert_yaxis()\n",
    "plt.legend(ncol=2)\n",
    "plt.savefig(basedir/'reports'/'zeropoint.pdf',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue = ascii.read(basedir/'data'/'catalogues'/'PN_candidates.txt')\n",
    "catalogue['SkyCoord'] = SkyCoord(catalogue['R.A.'],catalogue['Dec.'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redo all distance plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.plot.pnlf import compare_distances\n",
    "\n",
    "name = results[14]['name']\n",
    "mu,mu_m,mu_p = results.loc[name][['(m-M)','err-(m-M)','err+(m-M)']]\n",
    "\n",
    "print(name)\n",
    "filename = basedir / 'reports' / name / f'{name}_distances'\n",
    "distances = compare_distances(name,mu,mu_p,mu_m,filename=filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PN Number vs Mass etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=ascii.read(basedir/'reports'/'sample.txt')\n",
    "sample['SkyCoord'] = SkyCoord(sample['R.A.'],sample['Dec.'])\n",
    "sample.add_index('Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxies = {}\n",
    "\n",
    "for n in result['name']:\n",
    "    print('are you sure that you want to run this?')\n",
    "    break\n",
    "    filename = data_raw / 'MUSEDAP' / f'{n}_MAPS.fits'\n",
    "\n",
    "    with fits.open(filename) as hdul:\n",
    "        d=hdul['STELLAR_MASS_DENSITY'].data\n",
    "        galaxies[n]= np.nansum(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['mass']=sample['mass']\n",
    "result['Survey Area'] = sample['Survey Area']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the survey area from number of pixels and distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in result:\n",
    "    N_pix = row['N_pixel']\n",
    "    d = Distance(distmod=parameters[row['name']]['mu'])\n",
    "    A_pix = ((d*(0.2/206265))**2).to(u.kpc**2)\n",
    "    \n",
    "    print(f'{row[\"name\"]}: {d:.2f}, {N_pix*A_pix:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax1,ax2,ax3)=plt.subplots(ncols=3,nrows=1,figsize=(12,4))\n",
    "\n",
    "for row in result:\n",
    "    if row['N_PN']>1:\n",
    "        ax1.scatter(row['mass'],row['N_PN'])\n",
    "        ax1.text(row['mass'],row['N_PN']+2,row['name'],horizontalalignment='center')\n",
    "        \n",
    "        \n",
    "        ax2.scatter(row['Survey Area'],row['N_PN'])\n",
    "        ax2.text(row['Survey Area'],row['N_PN']+2,row['name'],horizontalalignment='center') \n",
    "\n",
    "        ax3.scatter(row['N_pixel'],row['N_PN'])\n",
    "        ax3.text(row['N_pixel'],row['N_PN']+2,row['name'],horizontalalignment='center') \n",
    "        \n",
    "\n",
    "ax1.set(xlabel='stellar mass density',ylabel='N PN')\n",
    "ax2.set(xlabel='Survey Area')\n",
    "ax3.set(xlabel='Npixel')\n",
    "#ax3.set(xlabel='Npixel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other PNLF studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = ascii.read(basedir/'data'/'literature distances'/'latest.csv',delimiter=',',header_start=12,data_start=14)\n",
    "results = ascii.read(basedir/'data'/'interim'/'results.txt')\n",
    "print(f\"intial cagalogue has {len(np.unique(distances[distances['Method']=='PNLF']['Galaxy ID']))} objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnlf_distances = distances[distances[\"Method\"]=='PNLF']\n",
    "print(f\"excluding {len(np.unique(pnlf_distances[(pnlf_distances['m-M']<22.5) | (pnlf_distances['m-M']>32)]['Galaxy ID']))} objects\")\n",
    "pnlf_distances = pnlf_distances[(pnlf_distances['m-M']>22.5) & (pnlf_distances['m-M']<32)]  # exclude the many measurments of the LMC and SMC\n",
    "\n",
    "pnlf_distances['year'] = pnlf_distances['Date (Yr. - 1980)']+1980\n",
    "pnlf_distances.rename_column('Galaxy ID','name')\n",
    "pnlf_distances['name'] = [n.rstrip('a').rstrip('b') for n in pnlf_distances['name']]\n",
    "\n",
    "alias = {\n",
    "    'NGC 0628': 'MESSIER 074',\n",
    "    'NGC 3351': 'MESSIER 095',\n",
    "    'NGC 3627': 'MESSIER 066',\n",
    "    'NGC 4254': 'MESSIER 099',\n",
    "    'NGC 4303': 'MESSIER 061',\n",
    "    'NGC 4321': 'MESSIER 100'\n",
    "}\n",
    "\n",
    "alias_back = {v:k for k,v in alias.items()}\n",
    "\n",
    "phangs_sample = []\n",
    "for row in results:\n",
    "    name = row['name'].replace('NGC','NGC ').replace('IC','IC ')\n",
    "    name = alias.get(name,name)\n",
    "    phangs_sample.append(name)\n",
    "    new = ['',0,0,name,row['(m-M)'],row['err-(m-M)'],0,'PNLF','Schmnn+2020','',0,0,0,40,'',2020]\n",
    "    pnlf_distances.add_row(new)\n",
    "    \n",
    "galaxies = list(np.unique(pnlf_distances['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we sort by mean distance\n",
    "mean_dis = []\n",
    "for gal in galaxies:\n",
    "    mean_dis.append(pnlf_distances[pnlf_distances['name']==gal]['m-M'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnlf_distances.sort('year')\n",
    "important_papers = dict()\n",
    "is_measured = []\n",
    "for row in pnlf_distances:\n",
    "    #if row['name'] not in is_measured:\n",
    "    #    is_measured.append(row['name'])\n",
    "    if row['REFCODE'] in important_papers:\n",
    "        important_papers[row['REFCODE']] += 1\n",
    "    else:\n",
    "        important_papers[row['REFCODE']] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1,figsize=(10,6/1.618))\n",
    "\n",
    "x_pos  = []\n",
    "gal_names = [x for _,x in sorted(zip(mean_dis,galaxies))]\n",
    "\n",
    "print(f'{len(gal_names)} galaxies in sample')\n",
    "color_grid=[]\n",
    "for i,gal in enumerate(gal_names):\n",
    "    tmp = pnlf_distances[pnlf_distances['name']==gal]\n",
    "    ax.scatter(len(tmp)*[i+1],tmp['m-M'],marker=\"_\",color='gray')\n",
    "    # color the measured by me red\n",
    "    if len(tmp[tmp['REFCODE']=='Schmnn+2020'])>0:\n",
    "        ax.scatter([i+1],tmp[tmp['REFCODE']=='Schmnn+2020']['m-M'],marker=\"_\",color='tab:red')\n",
    "        color_grid.append(i)\n",
    "\n",
    "# create a legend with numbers only\n",
    "#legend_elements = [mpl.lines.Line2D([0], [0], color=tab10[i], lw=2, label=str(i+1)) for i in range(10)]\n",
    "#plt.legend(handles=legend_elements, loc='upper center',ncol=10)\n",
    "    \n",
    "ymin,ymax = 23,32\n",
    "# set the galaxy names as x-ticklabels\n",
    "ax.set(xticks=np.arange(1,len(galaxies)+1),\n",
    "       ylabel='($m-M$) / mag',\n",
    "       title='Galaxies with PNLF distances',\n",
    "       xlim=[0.5,len(galaxies)+0.5],\n",
    "       ylim=[ymin,ymax])\n",
    "ax.set_xticklabels(gal_names,rotation=90,color='gray')    \n",
    "\n",
    "# color the galaxies which are in the phangs sample \n",
    "for n in phangs_sample:\n",
    "    i = gal_names.index(n)\n",
    "    ax.get_xticklabels()[i].set_color(\"tab:red\")\n",
    "#for n in ['MESSIER 066','MESSIER 074','MESSIER 095','NGC 5068']:\n",
    "#    i = gal_names.index(n)\n",
    "#    ax.get_xticklabels()[i].set_color(\"tab:red\")    \n",
    "\n",
    "ax.grid(axis='x')\n",
    "#a = ax.get_xgridlines()\n",
    "#for i in color_grid:\n",
    "#    a[i].set_color('tab:red')\n",
    "\n",
    "yticks_mpc = np.logspace(np.log10(Distance(distmod=ymin).to(u.Mpc).value),np.log10(Distance(distmod=ymax).to(u.Mpc).value),10)\n",
    "yticks_mu  = Distance(yticks_mpc*u.Mpc).distmod\n",
    "    \n",
    "ax2 = ax.twinx()\n",
    "ax2.set_yticks(yticks_mu.value,minor=False)\n",
    "ax2.set_yticklabels([f'{x:.2f}' for x in yticks_mpc],ha=\"left\")\n",
    "ax2.set(ylim=[ymin,ymax],ylabel='$D$ / Mpc')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(basedir/'reports'/'PNstudies.png',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, (ax2,ax1) = plt.subplots(nrows=2,figsize=(two_column,two_column))\n",
    "\n",
    "gal_names = [x for _,x in sorted(zip(mean_dis,galaxies))]\n",
    "\n",
    "def literature_distances(labels,ax,ymin=23,ymax=32):\n",
    "    \n",
    "    # set the galaxy names as x-ticklabels\n",
    "    ax.set(xticks=np.arange(1,len(labels)+1),\n",
    "           ylabel='($m-M$) / mag',\n",
    "           xlim=[0.5,len(labels)+0.5],\n",
    "           ylim=[ymin,ymax])\n",
    "    labels_new = [alias_back.get(l,l) for l in labels]\n",
    "    ax.set_xticklabels(labels_new,rotation=90,color='gray')    \n",
    "    ax.grid(axis='x',ls='--',lw=0.4)\n",
    "    grid = ax.get_xgridlines()\n",
    "\n",
    "    for i,label in enumerate(labels):\n",
    "        tmp = pnlf_distances[pnlf_distances['name']==label]\n",
    "        ax.scatter(len(tmp)*[i+1],tmp['m-M'],marker=\"_\",color='gray')\n",
    "        # color the measured by me red\n",
    "        if len(tmp[tmp['REFCODE']=='Schmnn+2020'])>0:\n",
    "            ax.get_xticklabels()[i].set(color=\"tab:red\",fontweight='black')\n",
    "            ax.scatter([i+1],tmp[tmp['REFCODE']=='Schmnn+2020']['m-M'],marker=\"_\",color='tab:red')\n",
    "            grid[i].set(ls='-',lw=0.5)\n",
    "    \n",
    "    \n",
    "    yticks_mpc = np.logspace(np.log10(Distance(distmod=ymin).to(u.Mpc).value),np.log10(Distance(distmod=ymax).to(u.Mpc).value),10)\n",
    "    yticks_mu  = Distance(yticks_mpc*u.Mpc).distmod\n",
    "\n",
    "    axt = ax.twinx()\n",
    "    axt.set_yticks(yticks_mu.value,minor=False)\n",
    "    axt.set_yticklabels([f'{x:.2f}' for x in yticks_mpc],ha=\"left\")\n",
    "    axt.set(ylim=[ymin,ymax],ylabel='$D$ / Mpc')\n",
    "    \n",
    "    return ax\n",
    "    \n",
    "n = len(gal_names)\n",
    "ax1 = literature_distances(gal_names[:int(n/2)],ax1,ymin=23,ymax=30.5)\n",
    "ax2 = literature_distances(gal_names[int(n/2):],ax2,ymin=29.5,ymax=32.2)\n",
    "\n",
    "#ax2.set_title('Galaxies with PNLF distances')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.savefig(basedir/'reports'/'PNstudies.pdf',dpi=600)\n",
    "plt.savefig(basedir/'reports'/'PNstudies.png',dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode_only(array):\n",
    "    m,c = mode(array)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with Deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep   = ascii.read(basedir/'data'/'literature distances'/'deep_distances.csv')\n",
    "result = ascii.read(basedir/'data'/'interim'/'results.txt')\n",
    "\n",
    "deep.add_index(\"galaxy\")\n",
    "deep['d'] = [float(x[:-4]) for x in deep['distance']]\n",
    "deep['e'] = [float(x[:-4]) for x in deep['error']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.auxiliary import mu_to_parsec\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(two_column,two_column/1.618))\n",
    "result.sort('d/Mpc')\n",
    "for i, row in enumerate(result):\n",
    "    d,(dp,dm) = mu_to_parsec(row['(m-M)'],[row['err+(m-M)'],row['err-(m-M)']])\n",
    "\n",
    "    ax.errorbar(i-0.1,row['d/Mpc'],yerr=([dm.value],[dp.value]),fmt='o',color='tab:red')\n",
    "    \n",
    "    tmp = deep.loc[row['name']]\n",
    "    ax.errorbar(i+0.1,tmp['d'],yerr=tmp['e'],fmt='o',color='black')\n",
    "    \n",
    "ax.set(xticks=np.arange(0,len(result)),\n",
    "       ylabel='$D$ / Mpc',\n",
    "       title='PHANGS distances',\n",
    "       xlim=[-0.5,len(result)-0.5])\n",
    "ax.set_xticklabels(result['name'],rotation=90)  \n",
    "ax.grid(axis='x')\n",
    "\n",
    "legend_elements = [mpl.lines.Line2D([0], [0], color=col, lw=2, label=l) for col,l in zip(['tab:red','black'],['PNLF','TRGB'])]\n",
    "plt.legend(handles=legend_elements, loc='lower center',ncol=10)\n",
    "plt.savefig(basedir/'reports'/'PNLF_vs_TRGB.png',dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot entire sky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = basedir / 'data' / 'interim' / 'sample.txt'\n",
    "sample = ascii.read(filename,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "sample['SkyCoord'] = SkyCoord(sample['R.A.'],sample['Dec.'])\n",
    "\n",
    "ra = sample['SkyCoord'].ra\n",
    "ra = ra.wrap_at(180*u.degree)\n",
    "dec = sample['SkyCoord'].dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mpl.use('pdf')\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fig.add_subplot(111, projection=\"mollweide\")\n",
    "ax.scatter(ra.radian,dec.radian,marker='.')\n",
    "#ax.set_xticklabels(['14h','16h','18h','20h','22h','0h','2h','4h','6h','8h','10h'])\n",
    "ax.grid(True)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "\n",
    "for x,y,s in zip(ra,dec,sample['Name']):\n",
    "    ax.annotate(s,(x.radian,y.radian),xycoords='data',size='x-small')\n",
    "\n",
    "fig.savefig(\"map.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/henrysky/milkyway_plot/blob/master/mw_plot/mw_plot_classes.py\n",
    "image_filename = basedir/'data'/'interim'/'MW_edgeon_unannotate.jpg'\n",
    "img = plt.imread(image_filename)\n",
    "img = img[1625:4875]  # so there are 3250px there\n",
    "\n",
    "center=(0, 0) * u.deg\n",
    "radius=(180, 90) * u.deg\n",
    "    \n",
    "y_img_center = 1625 - int((3250 / 180) * center[1].value)\n",
    "y_radious_px = int((3250 / 180) * radius[1].value)\n",
    "x_img_center = int((6500 / 360) * center[0].value) + 3250\n",
    "x_radious_px = int((6500 / 360) * radius[0].value)\n",
    "\n",
    "img = img[(y_img_center - y_radious_px):(y_img_center + y_radious_px),\n",
    "             (x_img_center - x_radious_px):(x_img_center + x_radious_px), :]\n",
    "\n",
    "'''\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='mollweide')\n",
    "\n",
    "lon = np.linspace(-np.pi, np.pi, 6500)\n",
    "lat = np.linspace(np.pi / 2., -np.pi / 2., 3250)\n",
    "Lon, Lat = np.meshgrid(lon, lat)\n",
    "\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = {'IC5332':(4,2),\n",
    "'NGC0628':(0,1),\n",
    "'NGC1087':(0,2),\n",
    "'NGC1300':(0,3),\n",
    "'NGC1365':(4,3),\n",
    "'NGC1385':(0,4),\n",
    "'NGC1433':(4,5),\n",
    "'NGC1512':(4,4),\n",
    "'NGC1566':(3,6),\n",
    "'NGC1672':(4,6),\n",
    "'NGC2835':(2,6),\n",
    "'NGC3351':(1,6),\n",
    "'NGC3627':(0,6),\n",
    "'NGC4254':(1,0),\n",
    "'NGC4303':(3,0),\n",
    "'NGC4321':(0, 0),\n",
    "'NGC4535':(2,0),\n",
    "'NGC5068':(4,0),\n",
    "'NGC7496':(4,1)}\n",
    "\n",
    "va = {\n",
    "'IC5332':'bottom',\n",
    "'NGC0628':'bottom',\n",
    "'NGC1087':'bottom',\n",
    "'NGC1300':'center',\n",
    "'NGC1365':'center',\n",
    "'NGC1385':'center',\n",
    "'NGC1433':'center',\n",
    "'NGC1512':'center',\n",
    "'NGC1566':'center',\n",
    "'NGC1672':'center',\n",
    "'NGC2835':'center',\n",
    "'NGC3351':'top',\n",
    "'NGC3627':'bottom',\n",
    "'NGC4254':'top',\n",
    "'NGC4303':'top',\n",
    "'NGC4321':'bottom',\n",
    "'NGC4535':'center',\n",
    "'NGC5068':'bottom',\n",
    "'NGC7496':'top'}\n",
    "ha = {\n",
    "'IC5332':'center',\n",
    "'NGC0628':'center',\n",
    "'NGC1087':'center',\n",
    "'NGC1300':'right',\n",
    "'NGC1365':'right',\n",
    "'NGC1385':'left',\n",
    "'NGC1433':'right',\n",
    "'NGC1512':'left',\n",
    "'NGC1566':'right',\n",
    "'NGC1672':'left',\n",
    "'NGC2835':'right',\n",
    "'NGC3351':'right',\n",
    "'NGC3627':'right',\n",
    "'NGC4254':'left',\n",
    "'NGC4303':'left',\n",
    "'NGC4321':'left',\n",
    "'NGC4535':'left',\n",
    "'NGC5068':'center',\n",
    "'NGC7496':'center'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.plot.plot import create_RGB\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(ncols=7, nrows=5,figsize=(1.5*two_column,two_column))\n",
    "gs = axs[1, 2].get_gridspec()\n",
    "\n",
    "path = data_raw / 'MUSE_DR2' / 'filterImages' \n",
    "\n",
    "# remove the underlying axes\n",
    "for ax in axs[1:-1,1:-1].flatten():\n",
    "    ax.remove()\n",
    "ax = fig.add_subplot(gs[1:-1,1:-1],projection=\"mollweide\")\n",
    "ax.pcolormesh(Lon, Lat,img[:, :, 0], cmap='gray', zorder=2, alpha=0.85, rasterized=True)\n",
    "ax.plot(ra.radian,dec.radian,'.r',ms=1)\n",
    "\n",
    "#ax.set_xticklabels(['14h','16h','18h','20h','22h','0h','2h','4h','6h','8h','10h'])\n",
    "ax.grid(True)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "\n",
    "for x,y,name in zip(ra,dec,sample['Name']):\n",
    "    #ax.annotate(s,(x.radian,y.radian),xycoords='data',size='x-small',position='top')\n",
    "    ax.text(x.radian,y.radian,name,\n",
    "            horizontalalignment=ha[name],\n",
    "            verticalalignment=va[name],\n",
    "            fontsize=6,\n",
    "            color='white')\n",
    "\n",
    "for name,idx in positions.items():\n",
    "\n",
    "    sdss_g, h = fits.getdata(path / f'{name}_IMAGE_FOV_SDSS_g_WCS_Pall_mad.fits',header=True)\n",
    "    sdss_r, h = fits.getdata(path / f'{name}_IMAGE_FOV_SDSS_r_WCS_Pall_mad.fits',header=True)\n",
    "    sdss_i, h = fits.getdata(path / f'{name}_IMAGE_FOV_SDSS_i_WCS_Pall_mad.fits',header=True)\n",
    "    \n",
    "    #ax=axs[idx]\n",
    "    axs[idx].remove()\n",
    "    ax = fig.add_subplot(gs[idx],projection=WCS(h))\n",
    "    \n",
    "    gri = create_RGB(sdss_i,sdss_r,sdss_g,weights=[1,1,1],percentile=[99,99,99])\n",
    "    gri[sdss_g==0] = (1,1,1)\n",
    "    ax.imshow(gri)\n",
    "    \n",
    "    #ax.annotate(f'{k}',(0.1, 0.5),xycoords='axes fraction', va='center')\n",
    "    ax.set_title(name,fontsize=6)\n",
    "    \n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "axs[(0,5)].remove()\n",
    "\n",
    "#fig.tight_layout()\n",
    "plt.subplots_adjust(wspace=0,hspace=0.3)\n",
    "\n",
    "plt.savefig(basedir/'reports'/'all_galaxies_sky.pdf',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Angular resolution of all galaxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in results['name']:\n",
    "    with fits.open(data_raw/'AUXILIARY'/'seeing_maps'/f'{name}_seeing.fits') as hdul:\n",
    "        PSF = hdul[0].data\n",
    "    \n",
    "    res_min = np.nanmin(PSF)/206265*results.loc[name]['d/Mpc']*1e6\n",
    "    res_max = np.nanmax(PSF)/206265*results.loc[name]['d/Mpc']*1e6\n",
    "    \n",
    "    ang_min = np.nanmin(PSF)\n",
    "    ang_max = np.nanmax(PSF)\n",
    "    \n",
    "    print(f'{name}: min={ang_min:.2f} pc, max={ang_max:.2f} pc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.auxiliary import mu_to_parsec, parsec_to_mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 18.72\n",
    "mu,mu_err = parsec_to_mu(d*u.Mpc,0.15*d*u.Mpc)\n",
    "print(f'{mu.value:.2f},{mu_err[0]:.2f},{d:.2f},NAM,2020AJ....159...67K,,,,,')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d,derr= 17.22, 2.58 \n",
    "mu,mu_err = parsec_to_mu( d*u.Mpc,derr*u.Mpc)\n",
    "print(f'{mu.value:.2f},{mu_err[0]:.2f},{d:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trgb['(m-M)'], trgb['err(m-M)'] = parsec_to_mu(trgb['Distance']*u.Mpc,trgb['Error']*u.Mpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trgb = ascii.read(basedir/'data'/'literature distances'/'PHANGSDistancesJuly23.txt',format='csv',delimiter='&')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogues = {}\n",
    "for name in results['name']:\n",
    "    filename = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "    catalogues[name] = ascii.read(filename,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.analyse import MaximumLikelihood1D, PNLF, pnlf\n",
    "from pnlf.plot.pnlf import plot_pnlf\n",
    "from pnlf.auxiliary import mu_to_parsec\n",
    "\n",
    "name = 'NGC1385'\n",
    "\n",
    "param = parameters[name]\n",
    "cl = param['completeness_limit']\n",
    "tbl = catalogues[name]\n",
    "if False:\n",
    "    data = tbl[((tbl['type']=='PN') | (tbl['SNRorPN']=='True')) & (tbl['exclude']==0)]['mOIII']\n",
    "    err = tbl[((tbl['type']=='PN') | (tbl['SNRorPN']=='True')) & (tbl['exclude']==0)]['dmOIII']\n",
    "else:\n",
    "    data = tbl[(tbl['type']=='PN') & (tbl['exclude']==0) & (tbl['v_SIGMA']<1000) ]['mOIII']\n",
    "    err  = tbl[(tbl['type']=='PN') & (tbl['exclude']==0)]['dmOIII']\n",
    "\n",
    "fitter = MaximumLikelihood1D(pnlf,data[data<cl],mhigh=cl,Mmax=-4.47)\n",
    "mu,mu_p,mu_m = fitter([28])\n",
    "mu_p = np.sqrt(mu_p**2+np.nanmean(err)**2+dPSF**2)\n",
    "mu_m = np.sqrt(mu_m**2+np.nanmean(err)**2+dPSF**2)\n",
    "d,(dp,dm)=mu_to_parsec(mu,[mu_p,mu_m])\n",
    "print('{:.2f} + {:.2f} - {:.2f}'.format(d,dp,dm))\n",
    "print('{:.2f} + {:.2f} - {:.2f}'.format(mu,mu_p,mu_m))\n",
    "\n",
    "#Plot PNLF\n",
    "axes = plot_pnlf(data,\n",
    "                 mu,\n",
    "                 cl,\n",
    "                 binsize=param['binsize'],\n",
    "                 #mhigh=29,\n",
    "                 filename=None,\n",
    "                 color=tab10[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tbl[(tbl['type']=='PN') & (tbl['mOIII']<29) & (tbl['exclude']==0)]\n",
    "tmp.sort('mOIII')\n",
    "\n",
    "plt.scatter(tmp['mOIII'],tmp['v_SIGMA'])\n",
    "plt.axvline(np.min(tmp['mOIII'])+1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.io import ReadLineMaps\n",
    "galaxy = ReadLineMaps(data_raw,name,**parameters[name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnlf.plot.plot import plot_sky_with_detected_stars\n",
    "tmp = tbl[tbl['exclude']==1]\n",
    "positions = np.transpose((tmp['x'], tmp['y']))\n",
    "\n",
    "plot_sky_with_detected_stars(data=galaxy.OIII5006_DAP,\n",
    "                             wcs=galaxy.wcs,\n",
    "                             positions=positions\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'NGC0628'\n",
    "catalogue_file = basedir / 'data' / 'catalogues' / f'{name}_nebulae.txt'\n",
    "if catalogue_file.is_file():\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['exclude'] = catalogue['exclude'].astype(bool)\n",
    "catalogue['SkyCoord'] = SkyCoord(catalogue['RaDec'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RA=24.1888\n",
    "DEC=15.7968\n",
    "\n",
    "coord = SkyCoord(RA*u.degree,DEC*u.degree)\n",
    "\n",
    "sep = coord.separation(catalogue['SkyCoord'])\n",
    "\n",
    "catalogue[np.argmin(sep)][['id','type']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "708.667px",
    "left": "28px",
    "top": "110.283px",
    "width": "237.533px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
