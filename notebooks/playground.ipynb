{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query NASA/Ads from python\n",
    "\n",
    "https://github.com/adsabs/adsabs-dev-api/blob/master/README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroquery.ned import Ned\n",
    "from astroquery.nasa_ads import ADS\n",
    "ADS.TOKEN = open('ADS_DEV_KEY','r').read()\n",
    "token = open('ADS_DEV_KEY','r').read()\n",
    "import requests\n",
    "import urllib\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymuse.constants import tab10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table = Ned.get_table(\"NGC628\", table='positions')\n",
    "\n",
    "result_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_type(func):\n",
    "    def inner(x,y):\n",
    "        print()\n",
    "\n",
    "\n",
    "@check_type\n",
    "def add(x,y):\n",
    "    return x+y\n",
    "\n",
    "\n",
    "add(1,\"2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'id:2019ApJ...887...80K'\n",
    "query = urllib.parse.quote(query)\n",
    "\n",
    "start=0\n",
    "cache_rows=200\n",
    "sort='pubdate+desc'\n",
    "\n",
    "r = requests.get('https://api.adsabs.harvard.edu/v1/search/query?'\n",
    "              f'q={query}&start={start}&rows={cache_rows}'\n",
    "               f'&sort={sort}&fl=title,author,year,bibcode,pub',\n",
    "               headers={'Authorization': f'Bearer {token}'})\n",
    "    \n",
    "resp = r.json()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bibtex(bibcodes):\n",
    "    '''retrive the bibtex entry from ads\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    if not isinstance(bibcodes,list):\n",
    "        bibcodes = [bibcodes]\n",
    "        \n",
    "    bibcode = {\"bibcode\":bibcodes}\n",
    "    r = requests.post(\"https://api.adsabs.harvard.edu/v1/export/bibtex\", \\\n",
    "                     headers={\"Authorization\": \"Bearer \" + token, \"Content-type\": \"application/json\"}, \\\n",
    "                     data=json.dumps(bibcode))\n",
    "    \n",
    "    # in case of an error\n",
    "    if not r.ok:\n",
    "        if r.status_code == 401:\n",
    "            raise ValueError('Unauthorized access to ADS. Check that the ADS token is valid.')\n",
    "        try:\n",
    "            reason = r.json()['error']\n",
    "        except:\n",
    "            reason = r.text\n",
    "        raise ValueError(f'HTTP request failed ({r.status_code}): {reason}')\n",
    "    \n",
    "    return r.json()['export']\n",
    "\n",
    "bib = get_bibtex(['2019ApJ...887...80K'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"https://api.adsabs.harvard.edu/v1/search/query?q='references(id:2019ApJ...887...80K)'\",\\\n",
    "                headers={'Authorization': 'Bearer ' + token})\n",
    "# the requests package returns an object; to get just the JSON API response, you have to specify this\n",
    "#print(r.json())\n",
    "r.ok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/andycasey/ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads.config.token = open('ADS_DEV_KEY','r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bibcode = '2019ApJ...887...80K'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads.SearchQuery?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(ads.SearchQuery(bibcode=bibcode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = [list(ads.SearchQuery(bibcode=bibcode))[0] for bibcode in bibcodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,10)\n",
    "\n",
    "y1 = (1-np.exp(3*(-4.47-x)))\n",
    "y2 = np.exp(0.307*x)\n",
    "\n",
    "y = y1*y2\n",
    "plt.plot(x,y1)\n",
    "plt.plot(x,y2)\n",
    "plt.plot(x,y)\n",
    "\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from astropy.wcs import WCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reproject import reproject_interp, reproject_exact\n",
    "\n",
    "\n",
    "z = 0.0028906664\n",
    "\n",
    "def combine_fits(folder,output_projection):\n",
    "    '''combine the different linemaps into one fits file\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    if not folder.is_dir():\n",
    "        raise IOError('folder does not exist')\n",
    "\n",
    "    data = []\n",
    "    data_header = []\n",
    "    err  = []\n",
    "    err_header = []\n",
    "    \n",
    "    # so astropy doesn't warn us that the wcs contains unused sip information\n",
    "    logger = logging.getLogger('astropy')\n",
    "    logger.setLevel(logging.WARNING)  \n",
    "    \n",
    "    for flux_file in [x for x in (folder / 'MAPS').iterdir() if x.name.endswith('flux.fits')]:\n",
    "        err_file = flux_file.with_name(flux_file.stem + '-err.fits')\n",
    "        \n",
    "        with fits.open(flux_file) as hdul:\n",
    "            linemap, _ = reproject_exact(hdul, output_projection)\n",
    "            data.append(linemap)\n",
    "            data_header.append(hdul[0].header)\n",
    "            \n",
    "        with fits.open(err_file) as hdul:\n",
    "            linemap, _ = reproject_exact(hdul, output_projection)\n",
    "            err.append(linemap)\n",
    "            err_header.append(hdul[0].header)         \n",
    "         \n",
    "    object_name = str(folder).split('_')[0]\n",
    "    print(str(len(data)) + ' linemaps found for ' + object_name)\n",
    "\n",
    "    \n",
    "    keywords = ['PROGRAM','DATE','OBSERVAT','TELESCOP','INSTRUME','MJD-OBS','DATE-OBS']\n",
    "\n",
    "    primary_header = fits.Header()\n",
    "    for card in data_header[0].cards:\n",
    "        if card[0] in keywords:\n",
    "            primary_header.append(card)\n",
    "    \n",
    "    l = float(data_header[0]['FILETYPE'].split(' ')[-1])/(1+z)\n",
    "    \n",
    "    # get this from somewhere else\n",
    "    primary_header.insert('PROGRAM ',('OBJECT',object_name,'Object Name'))\n",
    "        \n",
    "    primary_hdu = fits.PrimaryHDU(header=primary_header)\n",
    "    hdul = fits.HDUList([primary_hdu]) \n",
    "    print('primary extension created')\n",
    "    \n",
    "    for d,dh,e,eh in zip(data,data_header,err,err_header):\n",
    "        \n",
    "        # get the original wavelength of the line\n",
    "        l = float(dh['FILETYPE'].split(' ')[-1])/(1+z)\n",
    "        header = WCS(output_projection).to_header()\n",
    "        header['BITPIX'] = (-32,'array data type')\n",
    "        header.insert(0,('FILETYPE','Map flux {:.0f}'.format(l)))\n",
    "        header.append()\n",
    "        \n",
    "        hdu = fits.ImageHDU(data=d,header=header,name='OII{:.0f}'.format(l))\n",
    "        hdul.append(hdu)\n",
    "        \n",
    "        header['FILETYPE'] = 'Map flux error {:.0f}'.format(l)\n",
    "        hdu = fits.ImageHDU(data=e,header=header,name='OII{:.0f}_err'.format(l))\n",
    "        hdul.append(hdu)\n",
    "        \n",
    "        #single = fits.PrimaryHDU(d)\n",
    "        #single.writeto('[OII]{:.0f}.fits'.format(l))\n",
    "        \n",
    "    print('all extensions created')\n",
    "    \n",
    "    filename = '{}_[OII]_maps.fits'.format(object_name)\n",
    "    hdul.writeto(filename,overwrite=True)\n",
    "    print('saved to {}'.format(filename))\n",
    "    \n",
    "    return hdul\n",
    "\n",
    "\n",
    "folder = Path('d:/Documents/university/PhD/sitelle/NGC2835_SN1.1.0.ORCS')\n",
    "data_raw = Path('d:\\downloads\\MUSEDAP')\n",
    "muse_header = fits.getheader(data_raw/'MUSEDAP'/'NGC2835_MAPS.fits',ext=1)\n",
    "\n",
    "#combine_fits(Path('NGC2835_SN1.1.0.ORCS'),muse_header)\n",
    "hdul = combine_fits(folder,muse_header)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## masks to contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import measure\n",
    "from skimage.draw import polygon\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "from astropy import wcs\n",
    "from astropy.io import fits\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "from pathlib import Path\n",
    "\n",
    "data_raw = Path('g:\\Archive')\n",
    "\n",
    "mask_file = data_raw/'MUSE'/'DR1'/'AUXILIARY'/'Nebulae catalogue'/'spatial_masks'/'NGC2835_HIIreg_mask.fits' \n",
    "with fits.open(mask_file) as hdul:\n",
    "    mask = hdul[0].data\n",
    "    mask_header = hdul[0].header\n",
    "\n",
    "basedir = Path('d:\\Documents') / 'university' / 'PhD' / 'sitelle'\n",
    "with fits.open(basedir/'NGC2835_deepframe.fits') as hdul:\n",
    "    target_data = hdul[0].data\n",
    "    target_header = hdul[0].header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask)\n",
    "plt.savefig('test.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "props = measure.regionprops(mask.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_columns(array):\n",
    "    \"\"\"This function reverses the order of the columns\n",
    "    \n",
    "    old: \n",
    "    temp = coordinates[:,0]\n",
    "    temp2 = coordinates[:,1]\n",
    "\n",
    "    return np.column_stack([temp2, temp])\n",
    "\n",
    "    new:\n",
    "    faster because we do not create two new arrays\n",
    "    also works with shapes other than (n,2)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    array : ndarray\n",
    "    \"\"\"\n",
    "\n",
    "    return array.T[::-1].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymuse.masks_to_contours import get_contours, \\\n",
    "                                     convert_pixel2world,convert_world2pixel,\\\n",
    "                                     create_masks_from_wcs_contours\n",
    "\n",
    "###\n",
    "# at 0.5, contours will perfectly line up with mask boundaries, so\n",
    "# in current wcs projection use 0.5. But at 0, boundaries as inflated (dilated)\n",
    "# slightly by half a pixel, which, will not plot nice for touching masks\n",
    "# (as not the contours will overlap a little), but might help masking\n",
    "# new wcs projections which have bigger pixels. I recommend just using 0.5\n",
    "contour_dilation = 0.5\n",
    "\n",
    "contours_y_x,  contour_id = get_contours(labeled_image=mask,\n",
    "                                         contour_dilation=contour_dilation,\n",
    "                                         get_contour_id=True,\n",
    "                                         touching_masks=False) #if masks do not touch, change this to False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.imshow(mask, origin='lower')\n",
    "for cont in contours_y_x:\n",
    "    plt.plot(cont[:,1]+1, cont[:,0]+1, 'k-',lw=0.2) #to make lines look thinner, set lw=0.8 in plt.plot\n",
    "    \n",
    "plt.savefig('test.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "print(f'{len(touching)} touching regions found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax1,ax2) =plt.subplots(1,2)\n",
    "\n",
    "ax1.imshow(mask)\n",
    "\n",
    "im = ax2.imshow(touching_regions)\n",
    "plt.savefig('test.pdf',dpi=800)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.wcs import WCS\n",
    "from skimage.measure import regionprops, find_contours\n",
    "\n",
    "class regions:\n",
    "    \n",
    "    def __init__(self,data,header=None):\n",
    "        '''\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data : ndarray \n",
    "            array with labeld regions\n",
    "        header : \n",
    "        '''\n",
    "        \n",
    "        self.data = data\n",
    "        self.header = header\n",
    "        self.wcs = WCS(header)\n",
    "        \n",
    "        self.regions = {reg.label: reg for reg in regionprops(self.data.astype(int))}\n",
    "        \n",
    "        with np.errstate(invalid='ignore'):\n",
    "            self.regions_id = set(np.unique(mask[mask>=0]).flatten())\n",
    "        \n",
    "\n",
    "        \n",
    "    def find_touching(self,bkg=0):\n",
    "        '''find all regions that touch another region'''\n",
    "    \n",
    "        touching = set()\n",
    "\n",
    "        # for each row up to the second last one we subtract the row below\n",
    "        difference = np.zeros_like(self.data)\n",
    "        difference[:-1,...] = self.data[:-1,...] - self.data[1:,...]\n",
    "        difference[self.data==bkg] = 0\n",
    "        difference[difference==self.data+bkg] = 0\n",
    "        touching |= set(self.data[(difference!=0) & ~np.isnan(difference)])\n",
    "\n",
    "        # now going the other way around\n",
    "        difference = np.zeros_like(self.data)\n",
    "        difference[1:,...] = self.data[1:,...] - self.data[:-1,...]\n",
    "        difference[self.data==-bkg] = 0\n",
    "        difference[difference==self.data+bkg] = 0\n",
    "        touching |= set(self.data[(difference!=0) & ~np.isnan(difference)])\n",
    "        \n",
    "        # left to right\n",
    "        difference = np.zeros_like(self.data)\n",
    "        difference[...,1:] = self.data[...,1:] - self.data[...,:-1]\n",
    "        difference[self.data==-bkg] = 0\n",
    "        difference[difference==self.data+bkg] = 0\n",
    "        touching |= set(self.data[(difference!=0) & ~np.isnan(difference)])\n",
    "\n",
    "        # right to left\n",
    "        difference = np.zeros_like(self.data)\n",
    "        difference[...,:-1] = self.data[...,:-1] - self.data[...,1:]\n",
    "        difference[self.data==-bkg] = 0\n",
    "        difference[difference==self.data+bkg] = 0\n",
    "        touching |= set(self.data[(difference!=0) & ~np.isnan(difference)])\n",
    "        \n",
    "        return touching\n",
    "\n",
    "    def select_regions(self,regions_id):\n",
    "        '''create an image that contains only the regions in region_id'''\n",
    "        \n",
    "        if not isinstance(regions_id,list): regions_id = list(regions_id)\n",
    "            \n",
    "        data = np.zeros_like(self.data)\n",
    "\n",
    "        for i in regions_id:\n",
    "            data[self.data==i] = i\n",
    "        data[np.isnan(self.data)] = np.nan\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def construct_separated_regions(self):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        # the regions that touch another region will be handled later\n",
    "        remaining = self.find_touching()\n",
    "        \n",
    "        batches = []\n",
    "        \n",
    "        batches.append(self.select_regions(self.regions_id-remaining))\n",
    "        \n",
    "        while len\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    def plot_regions(self,regions_id,filename=None):\n",
    "        \n",
    "        data = self.select_regions(regions_id)\n",
    "\n",
    "        fig = plt.figure()\n",
    "        ax  = fig.add_subplot(111,projection=self.wcs)\n",
    "        ax.imshow(data)\n",
    "\n",
    "        if filename:\n",
    "            plt.savefig(filename,dpi=800)\n",
    "        plt.show()\n",
    "        \n",
    "region = regions(mask+1,mask_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = int(np.ceil(max([v.major_axis_length for k,v in region.regions.items()])))\n",
    "x_n = int(np.ceil(mask.shape[0]/l))\n",
    "y_n = int(np.ceil(mask.shape[1]/l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_list = []\n",
    "for n in range(x_n):\n",
    "    for m in range(y_n):\n",
    "        \n",
    "        masked_region = np.zeros_like(mask)\n",
    "        \n",
    "        masked_region[n*l:(n+1)*l,m*l:(m+1)*l] = 1\n",
    "        \n",
    "        masked_list.append(masked_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "touching = region.find_touching()\n",
    "region.plot_regions(touching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(region.regions_id-touching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level=0.5\n",
    "contours = []\n",
    "for region_id in regions_id:\n",
    "    array = np.zeros_like(mask)\n",
    "    array[mask==region_id] = 1\n",
    "    \n",
    "    contour = measure.find_contours(array,level)\n",
    "    contours += contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "touching.update([1,2,3,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.imshow(mask, origin='lower')\n",
    "for cont in contours:\n",
    "    plt.plot(cont[:,1]+1, cont[:,0]+1, 'k-',lw=0.2) #to make lines look thinner, set lw=0.8 in plt.plot\n",
    "    \n",
    "plt.savefig('test.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boundaries saved as wsc so can be loaded into whatever wcs projection you want\n",
    "contours_WCS = []\n",
    "for j in range(len(contours_y_x)):\n",
    "    contour_x_y = reverse_columns(contours_y_x[j])\n",
    "    contours_WCS.append(convert_pixel2world(contour_x_y, galaxy_header))\n",
    "\n",
    "\n",
    "contours_x_y_new = []\n",
    "for j in range(len(contours_WCS)):\n",
    "    contours_x_y_new.append(convert_world2pixel(contours_WCS[j],\n",
    "                                                different_galaxy_wcs_header))\n",
    "\n",
    "\n",
    "plt.figure(2)\n",
    "plt.clf()\n",
    "plt.imshow(different_galaxy_wcs, origin='lower', cmap=plt.cm.coolwarm)\n",
    "for cont in contours_x_y_new:\n",
    "    plt.plot(cont[:,0], cont[:,1], 'k-')\n",
    "\n",
    "masks_new_wcs = create_masks_from_wcs_contours(contours_WCS=contours_WCS,\n",
    "                                              contourIDs=contour_id,\n",
    "                                              header=different_galaxy_wcs_header,\n",
    "                                              image=different_galaxy_wcs,\n",
    "                                              binary_mask_out=False)\n",
    "\n",
    "# just rerunning this to show that I only want binary mask out\n",
    "masks_new_wcs_binary = create_masks_from_wcs_contours(contours_WCS=contours_WCS,\n",
    "                                                      contourIDs=contour_id,\n",
    "                                                      header=different_galaxy_wcs_header,\n",
    "                                                      image=different_galaxy_wcs,\n",
    "                                                      binary_mask_out=True)\n",
    "\n",
    "plt.figure(3)\n",
    "plt.imshow(masks_new_wcs_binary * different_galaxy_wcs, origin='lower', cmap=plt.cm.coolwarm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Sankey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Produces simple Sankey Diagrams with matplotlib.\n",
    "@author: Anneya Golob & marcomanz & pierre-sassoulas & jorwoods\n",
    "                      .-.\n",
    "                 .--.(   ).--.\n",
    "      <-.  .-.-.(.->          )_  .--.\n",
    "       `-`(     )-'             `)    )\n",
    "         (o  o  )                `)`-'\n",
    "        (      )                ,)\n",
    "        ( ()  )                 )\n",
    "         `---\"\\    ,    ,    ,/`\n",
    "               `--' `--' `--'\n",
    "                |  |   |   |\n",
    "                |  |   |   |\n",
    "                '  |   '   |\n",
    "https://github.com/anazalea/pySankey\n",
    "\"\"\"\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "tab10 = ['#e15759','#4e79a7','#f28e2b','#76b7b2','#59a14e','#edc949','#b07aa2','#ff9da7','#9c755f','#bab0ac']   \n",
    "\n",
    "class PySankeyException(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class NullsInFrame(PySankeyException):\n",
    "    pass\n",
    "\n",
    "\n",
    "class LabelMismatch(PySankeyException):\n",
    "    pass\n",
    "\n",
    "\n",
    "def check_data_matches_labels(labels, data, side):\n",
    "    if len(labels > 0):\n",
    "        if isinstance(data, list):\n",
    "            data = set(data)\n",
    "        if isinstance(data, pd.Series):\n",
    "            data = set(data.unique().tolist())\n",
    "        if isinstance(labels, list):\n",
    "            labels = set(labels)\n",
    "        if labels != data:\n",
    "            msg = \"\\n\"\n",
    "            if len(labels) <= 20:\n",
    "                msg = \"Labels: \" + \",\".join(labels) + \"\\n\"\n",
    "            if len(data) < 20:\n",
    "                msg += \"Data: \" + \",\".join(data)\n",
    "            raise LabelMismatch('{0} labels and data do not match.{1}'.format(side, msg))\n",
    "\n",
    "\n",
    "def sankey(left, right, leftWeight=None, rightWeight=None, colorDict=None,\n",
    "           leftLabels=None, rightLabels=None, aspect=4, rightColor=False,\n",
    "           fontsize=14, filename=None, closePlot=False):\n",
    "    '''\n",
    "    Make Sankey Diagram showing flow from left-->right\n",
    "    Inputs:\n",
    "        left = NumPy array of object labels on the left of the diagram\n",
    "        right = NumPy array of corresponding labels on the right of the diagram\n",
    "            len(right) == len(left)\n",
    "        leftWeight = NumPy array of weights for each strip starting from the\n",
    "            left of the diagram, if not specified 1 is assigned\n",
    "        rightWeight = NumPy array of weights for each strip starting from the\n",
    "            right of the diagram, if not specified the corresponding leftWeight\n",
    "            is assigned\n",
    "        colorDict = Dictionary of colors to use for each label\n",
    "            {'label':'color'}\n",
    "        leftLabels = order of the left labels in the diagram\n",
    "        rightLabels = order of the right labels in the diagram\n",
    "        aspect = vertical extent of the diagram in units of horizontal extent\n",
    "        rightColor = If true, each strip in the diagram will be be colored\n",
    "                    according to its left label\n",
    "    Ouput:\n",
    "        None\n",
    "    '''\n",
    "    if leftWeight is None:\n",
    "        leftWeight = []\n",
    "    if rightWeight is None:\n",
    "        rightWeight = []\n",
    "    if leftLabels is None:\n",
    "        leftLabels = []\n",
    "    if rightLabels is None:\n",
    "        rightLabels = []\n",
    "    # Check weights\n",
    "    if len(leftWeight) == 0:\n",
    "        leftWeight = np.ones(len(left))\n",
    "\n",
    "    if len(rightWeight) == 0:\n",
    "        rightWeight = leftWeight\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    # Create Dataframe\n",
    "    if isinstance(left, pd.Series):\n",
    "        left = left.reset_index(drop=True)\n",
    "    if isinstance(right, pd.Series):\n",
    "        right = right.reset_index(drop=True)\n",
    "    dataFrame = pd.DataFrame({'left': left, 'right': right, 'leftWeight': leftWeight,\n",
    "                              'rightWeight': rightWeight}, index=range(len(left)))\n",
    "\n",
    "    if len(dataFrame[(dataFrame.left.isnull()) | (dataFrame.right.isnull())]):\n",
    "        raise NullsInFrame('Sankey graph does not support null values.')\n",
    "\n",
    "    # Identify all labels that appear 'left' or 'right'\n",
    "    allLabels = pd.Series(np.r_[dataFrame.left.unique(), dataFrame.right.unique()]).unique()\n",
    "\n",
    "    # Identify left labels\n",
    "    if len(leftLabels) == 0:\n",
    "        leftLabels = pd.Series(dataFrame.left.unique()).unique()\n",
    "    else:\n",
    "        check_data_matches_labels(leftLabels, dataFrame['left'], 'left')\n",
    "\n",
    "    # Identify right labels\n",
    "    if len(rightLabels) == 0:\n",
    "        rightLabels = pd.Series(dataFrame.right.unique()).unique()\n",
    "    else:\n",
    "        check_data_matches_labels(leftLabels, dataFrame['right'], 'right')\n",
    "    # If no colorDict given, make one\n",
    "    if colorDict is None:\n",
    "        colorDict = {}\n",
    "        for i, label in enumerate(allLabels):\n",
    "            colorDict[label] = tab10[i]\n",
    "    else:\n",
    "        missing = [label for label in allLabels if label not in colorDict.keys()]\n",
    "        if missing:\n",
    "            msg = \"The colorDict parameter is missing values for the following labels : \"\n",
    "            msg += '{}'.format(', '.join(missing))\n",
    "            raise ValueError(msg)\n",
    "\n",
    "    # Determine widths of individual strips\n",
    "    ns_l = defaultdict()\n",
    "    ns_r = defaultdict()\n",
    "    for leftLabel in leftLabels:\n",
    "        leftDict = {}\n",
    "        rightDict = {}\n",
    "        for rightLabel in rightLabels:\n",
    "            leftDict[rightLabel] = dataFrame[(dataFrame.left == leftLabel) & (dataFrame.right == rightLabel)].leftWeight.sum()\n",
    "            rightDict[rightLabel] = dataFrame[(dataFrame.left == leftLabel) & (dataFrame.right == rightLabel)].rightWeight.sum()\n",
    "        ns_l[leftLabel] = leftDict\n",
    "        ns_r[leftLabel] = rightDict\n",
    "\n",
    "    # Determine positions of left label patches and total widths\n",
    "    leftWidths = defaultdict()\n",
    "    for i, leftLabel in enumerate(leftLabels):\n",
    "        myD = {}\n",
    "        myD['left'] = dataFrame[dataFrame.left == leftLabel].leftWeight.sum()\n",
    "        if i == 0:\n",
    "            myD['bottom'] = 0\n",
    "            myD['top'] = myD['left']\n",
    "        else:\n",
    "            myD['bottom'] = leftWidths[leftLabels[i - 1]]['top'] + 0.02 * dataFrame.leftWeight.sum()\n",
    "            myD['top'] = myD['bottom'] + myD['left']\n",
    "            topEdge = myD['top']\n",
    "        leftWidths[leftLabel] = myD\n",
    "\n",
    "    # Determine positions of right label patches and total widths\n",
    "    rightWidths = defaultdict()\n",
    "    for i, rightLabel in enumerate(rightLabels):\n",
    "        myD = {}\n",
    "        myD['right'] = dataFrame[dataFrame.right == rightLabel].rightWeight.sum()\n",
    "        if i == 0:\n",
    "            myD['bottom'] = 0\n",
    "            myD['top'] = myD['right']\n",
    "        else:\n",
    "            myD['bottom'] = rightWidths[rightLabels[i - 1]]['top'] + 0.02 * dataFrame.rightWeight.sum()\n",
    "            myD['top'] = myD['bottom'] + myD['right']\n",
    "            topEdge = myD['top']\n",
    "        rightWidths[rightLabel] = myD\n",
    "\n",
    "    # Total vertical extent of diagram\n",
    "    xMax = topEdge / aspect\n",
    "\n",
    "    # Draw vertical bars on left and right of each  label's section & print label\n",
    "    for leftLabel in leftLabels:\n",
    "        plt.fill_between(\n",
    "            [-0.02 * xMax, 0],\n",
    "            2 * [leftWidths[leftLabel]['bottom']],\n",
    "            2 * [leftWidths[leftLabel]['bottom'] + leftWidths[leftLabel]['left']],\n",
    "            color=colorDict[leftLabel],\n",
    "            alpha=0.99\n",
    "        )\n",
    "        plt.text(\n",
    "            -0.05 * xMax,\n",
    "            leftWidths[leftLabel]['bottom'] + 0.5 * leftWidths[leftLabel]['left'],\n",
    "            leftLabel,\n",
    "            {'ha': 'right', 'va': 'center'},\n",
    "            fontsize=fontsize\n",
    "        )\n",
    "    for rightLabel in rightLabels:\n",
    "        plt.fill_between(\n",
    "            [xMax, 1.02 * xMax], 2 * [rightWidths[rightLabel]['bottom']],\n",
    "            2 * [rightWidths[rightLabel]['bottom'] + rightWidths[rightLabel]['right']],\n",
    "            color=colorDict[rightLabel],\n",
    "            alpha=0.99\n",
    "        )\n",
    "        plt.text(\n",
    "            1.05 * xMax,\n",
    "            rightWidths[rightLabel]['bottom'] + 0.5 * rightWidths[rightLabel]['right'],\n",
    "            rightLabel,\n",
    "            {'ha': 'left', 'va': 'center'},\n",
    "            fontsize=fontsize\n",
    "        )\n",
    "\n",
    "    # Plot strips\n",
    "    for leftLabel in leftLabels:\n",
    "        for rightLabel in rightLabels:\n",
    "            labelColor = leftLabel\n",
    "            if rightColor:\n",
    "                labelColor = rightLabel\n",
    "            if len(dataFrame[(dataFrame.left == leftLabel) & (dataFrame.right == rightLabel)]) > 0:\n",
    "                # Create array of y values for each strip, half at left value,\n",
    "                # half at right, convolve\n",
    "                ys_d = np.array(50 * [leftWidths[leftLabel]['bottom']] + 50 * [rightWidths[rightLabel]['bottom']])\n",
    "                ys_d = np.convolve(ys_d, 0.05 * np.ones(20), mode='valid')\n",
    "                ys_d = np.convolve(ys_d, 0.05 * np.ones(20), mode='valid')\n",
    "                ys_u = np.array(50 * [leftWidths[leftLabel]['bottom'] + ns_l[leftLabel][rightLabel]] + 50 * [rightWidths[rightLabel]['bottom'] + ns_r[leftLabel][rightLabel]])\n",
    "                ys_u = np.convolve(ys_u, 0.05 * np.ones(20), mode='valid')\n",
    "                ys_u = np.convolve(ys_u, 0.05 * np.ones(20), mode='valid')\n",
    "\n",
    "                # Update bottom edges at each label so next strip starts at the right place\n",
    "                leftWidths[leftLabel]['bottom'] += ns_l[leftLabel][rightLabel]\n",
    "                rightWidths[rightLabel]['bottom'] += ns_r[leftLabel][rightLabel]\n",
    "                plt.fill_between(\n",
    "                    np.linspace(0, xMax, len(ys_d)), ys_d, ys_u, alpha=0.65,\n",
    "                    color=colorDict[labelColor]\n",
    "                )\n",
    "    plt.gca().axis('off')\n",
    "    plt.gcf().set_size_inches(8, 6)\n",
    "    plt.show()\n",
    "    if filename != None:\n",
    "        plt.savefig(filename, bbox_inches='tight', dpi=600)\n",
    "    if closePlot:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = ['Fahrrad','Fahrrad','Auto','Auto','ÖPNV','Auto','Fahrrad']\n",
    "b = ['Auto','ÖPNV','Auto','Auto','ÖPNV','Auto','Fahrrad']\n",
    "\n",
    "colorDict = {\n",
    "    'Fahrrad':'#f71b1b',\n",
    "    'Auto':'#1b7ef7',\n",
    "    'ÖPNV':'#f3f71b',\n",
    "    'lime':'#12e23f',\n",
    "    'orange':'#f78c1b'\n",
    "}\n",
    "\n",
    "sankey(a,b, aspect=20, colorDict=colorDict,fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
