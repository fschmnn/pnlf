{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESO Phase 3 for PHANGS <a class=\"tocSkip\">\n",
    "    \n",
    "The details are outlined [here](https://www.eso.org/sci/observing/phase3.html)\n",
    "\n",
    "* 1. [Register](https://www.eso.org/sci/observing/phase3/rm.html) your Phase 3 submission\n",
    "* 2. Preparing your data.\n",
    "  \n",
    "      - List of Keywords for header (FS)\n",
    "      - Filename (<68 characters), unique name across all folders\n",
    "      - mosaicked images require a weight map image to be associated$^1$\n",
    "      - optional: preview images, graphics, reports from DR (must be referenced in main SDP header)\n",
    "      - should include an exposure map (EXPTIME set to median of non 0 pixels), unless standard offset pattern with constant integration time is used.\n",
    "\n",
    "      * **for IFU Cubes do the following things**:\n",
    "      * astrometric calibration\n",
    "      * calibration of the dispersion axis to physical wavelength scale\n",
    "      * removal/correction for instrumental and sky background signal (if applicable)\n",
    "      * calibration of the detected signal to physical scale (spectral flux density)\n",
    "      * re-sampling to a regular 3-dimensional grid \n",
    "      * signal combination of multiple exposures (if applicable)\n",
    "      * error propagation in each processing step to obtain a final error estimate for the science data\n",
    "      * propagation of pixel quality information\n",
    "\n",
    "$^1$ statistical significance of each pixel in terms of a number that is proportional to the inverse variance of the background signal, i.e. not including the Poisson noise of sources. This additional data array is often called weight map or confidence map. It has the same dimensions as the image array and can be submitted as an associated data product with product category declared in the header of the science file as follows:      \n",
    "\n",
    "**IFU 3D Cubes Page 1**: Storing several sets of HDU's with associated science data, error and data quality in a single FITS file, though permitted in [3], is not supported by the ESO/SDP\n",
    "standard. Only three HDU’s are permitted of which one must be the science data and spectral flux density (physical units declared in `BUNIT`)\n",
    "\n",
    "* 3. Uploading your data to ESO: Press `CLOSE` and hope for the best.\n",
    "\n",
    "* 4. Verifying compliance with data format requirements\n",
    "\n",
    "* 5. Uploading the data [release description](https://www.eso.org/sci/observing/phase3/release_description.html)\n",
    "\n",
    "     https://www.eso.org/sci/observing/phase3/release-description-tmpl.doc\n",
    "\n",
    "* 6. Finalizing your data submission\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    " \n",
    "### Load Basic Packages\n",
    "    \n",
    "First we load a bunch of common packages that are used across the project. More specific packages that are only used in one section are loaded later to make it clear where they belong to (this also applies to all custom moduls that were written for this project)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload modules after they have been modified\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# some basic packages\n",
    "import os                 # filesystem related stuff\n",
    "import json\n",
    "from pathlib import Path  # use instead of os.path and glob\n",
    "import sys                # mostly replaced by pathlib\n",
    "import re\n",
    "\n",
    "import errno      # more detailed error messages\n",
    "import warnings   # handles warnings\n",
    "import logging    # use logging instead of print\n",
    "\n",
    "from collections import OrderedDict  \n",
    "\n",
    "# packages for scientific computing\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "# packages for creating plots and figures\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# special functions for astronomy \n",
    "from astropy.table import Table  # useful datastructure\n",
    "from astropy.table import vstack # combine multiple tables\n",
    "\n",
    "from astropy.io import fits      # open fits files\n",
    "from astropy.io import ascii     # handle normal files\n",
    "\n",
    "from astropy.wcs import WCS               # handle coordinates\n",
    "from astropy.coordinates import SkyCoord  # convert pixel to sky coordinates\n",
    "from astropy.visualization import simple_norm\n",
    "\n",
    "from astropy.stats import sigma_clipped_stats  # calcualte statistics of images\n",
    "\n",
    "import astropy.units as u        # handle units\n",
    "from astropy.time import Time\n",
    "\n",
    "from spectral_cube import SpectralCube\n",
    "\n",
    "tab10 = ['#e15759','#4e79a7','#f28e2b','#76b7b2','#59a14e','#edc949','#b07aa2','#ff9da7','#9c755f','#bab0ac']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we need to specify the path to the raw data\n",
    "data_raw = Path('g:\\Archive')\n",
    "basedir = Path('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Headers of Raw files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from astropy.time import Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(basedir / 'data' / 'ESO' / 'headers_P01_NGC0628.pkl', 'rb') as f:\n",
    "    headers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n'.join(list(headers.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = headers['Raw/M.MUSE.2014-12-08T12:30:51.293.fits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum = ('key',Time('2020-02-01'))\n",
    "\n",
    "for filename in headers.keys():\n",
    "\n",
    "    header = headers[filename]\n",
    "    for key in header.keys():\n",
    "        if 'MJD-OBS' in header[key].keys():\n",
    "            date = Time(header[key]['MJD-OBS'],format='mjd')\n",
    "            if date < minimum[1]:\n",
    "                print(date.iso)\n",
    "                minimum = (filename,date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers['Raw/M.MUSE.2014-12-08T12:30:51.293.fits']['LINES']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GASP Files\n",
    "\n",
    "It might be useful to look at [existing data realeases](https://www.eso.org/rm/publicAccess#/dataReleases) like the [GASP DR1](https://www.eso.org/sci/publications/announcements/sciann17080.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io.fits.header import Card, Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(basedir / 'data' / 'ESO' / 'GASPheader.txt') as f:\n",
    "    raw = f.read()\n",
    "\n",
    "extensions = raw.split('\\nEND')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cards_raw = [[x.strip() for x in re.split('=| / ',line)] for line in extensions[0].split('\\n')]\n",
    "\n",
    "for card in Cards_raw:\n",
    "    \n",
    "    if card[1] == 'T':\n",
    "        card[1] = True\n",
    "        continue\n",
    "    elif card[1] == 'F':\n",
    "        card[1] = False\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        i = int(card[1])\n",
    "        card[1] = i\n",
    "        continue\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        f = float(card[1])\n",
    "        card[1] = f\n",
    "        continue\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    \n",
    "    card[1] = card[1].strip(\"'\").strip(' ')\n",
    "    \n",
    "header = Header([Card(*card) for card in Cards_raw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with fits.open(data_raw / 'MUSE' / 'GASP' / 'ADP.2017-10-20T13_29_03.027.fits') as hdul:\n",
    "    header = hdul[0].header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ascii.read(basedir / '..' / 'PHANGS' / 'ESO' / 'keywords.csv',delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with fits.open(data_raw / 'MUSE' / 'MOSAIC' / 'NGC628' / 'NGC628_DATACUBE_FINAL.fits') as hdul:\n",
    "    header2 = hdul[0].header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adopted = ['ORIGIN',\n",
    " 'TELESCOP',\n",
    " 'INSTRUME',\n",
    " 'FILTER',\n",
    " 'OBJECT',\n",
    " 'EQUINOX',\n",
    " 'RADESYS',\n",
    " 'EXPTIME',\n",
    " 'TEXPTIME',\n",
    " 'MJD-OBS',\n",
    " 'MJD-END',\n",
    " 'PROG_ID',\n",
    " 'OBIDi',\n",
    " 'NCOMBINE',\n",
    " 'OBSTECH',\n",
    " 'REFERENC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Time(57280.20875754,format='mjd').iso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Time(header['DATE-OBS']).iso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Time(header['MJD-OBS'],format='mjd').iso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Path tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisplayablePath(object):\n",
    "    display_filename_prefix_middle = '├──'\n",
    "    display_filename_prefix_last = '└──'\n",
    "    display_parent_prefix_middle = '    '\n",
    "    display_parent_prefix_last = '│   '\n",
    "\n",
    "    def __init__(self, path, parent_path, is_last):\n",
    "        self.path = Path(str(path))\n",
    "        self.parent = parent_path\n",
    "        self.is_last = is_last\n",
    "        if self.parent:\n",
    "            self.depth = self.parent.depth + 1\n",
    "        else:\n",
    "            self.depth = 0\n",
    "\n",
    "    @property\n",
    "    def displayname(self):\n",
    "        if self.path.is_dir():\n",
    "            return self.path.name + '/'\n",
    "        return self.path.name\n",
    "\n",
    "    @classmethod\n",
    "    def make_tree(cls, root, parent=None, is_last=False, criteria=None):\n",
    "        root = Path(str(root))\n",
    "        criteria = criteria or cls._default_criteria\n",
    "\n",
    "        displayable_root = cls(root, parent, is_last)\n",
    "        yield displayable_root\n",
    "\n",
    "        children = sorted(list(path\n",
    "                               for path in root.iterdir()\n",
    "                               if criteria(path)),\n",
    "                          key=lambda s: str(s).lower())\n",
    "        count = 1\n",
    "        for path in children:\n",
    "            is_last = count == len(children)\n",
    "            if path.is_dir():\n",
    "                yield from cls.make_tree(path,\n",
    "                                         parent=displayable_root,\n",
    "                                         is_last=is_last,\n",
    "                                         criteria=criteria)\n",
    "            else:\n",
    "                yield cls(path, displayable_root, is_last)\n",
    "            count += 1\n",
    "\n",
    "    @classmethod\n",
    "    def _default_criteria(cls, path):\n",
    "        return True\n",
    "\n",
    "    @property\n",
    "    def displayname(self):\n",
    "        if self.path.is_dir():\n",
    "            return self.path.name + '/'\n",
    "        return self.path.name\n",
    "\n",
    "    def displayable(self):\n",
    "        if self.parent is None:\n",
    "            return self.displayname\n",
    "\n",
    "        _filename_prefix = (self.display_filename_prefix_last\n",
    "                            if self.is_last\n",
    "                            else self.display_filename_prefix_middle)\n",
    "\n",
    "        parts = ['{!s} {!s}'.format(_filename_prefix,\n",
    "                                    self.displayname)]\n",
    "\n",
    "        parent = self.parent\n",
    "        while parent and parent.parent is not None:\n",
    "            parts.append(self.display_parent_prefix_middle\n",
    "                         if parent.is_last\n",
    "                         else self.display_parent_prefix_last)\n",
    "            parent = parent.parent\n",
    "\n",
    "        return ''.join(reversed(parts))\n",
    "    \n",
    "paths = DisplayablePath.make_tree(Path('..'))\n",
    "for path in paths:\n",
    "    print(path.displayable())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open datacubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = Path('g:\\Archive')\n",
    "name = 'NGC1087'\n",
    "filename = data_raw / 'MUSE' / 'MOSAIC' / name / f'{name}_DATACUBE_FINAL.fits'\n",
    "\n",
    "with fits.open(filename , memmap=True, mode='denywrite') as hdul:\n",
    "    cube=SpectralCube(data=hdul[1].data,wcs=WCS(hdul[1].header))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cube[:,0,0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube = SpectralCube.read(filename,format='fits',hdu=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "SIMPLE = T / file does conform to FITS standard\n",
    "BITPIX = 8 / number of bits per data pixel\n",
    "NAXIS = 0 / number of data axes\n",
    "EXTEND = T / FITS dataset may contain extensions\n",
    "DATE = '2015-05-20T10:20:35' / file creation date (YYYY-MM-DDThh:mm:ss UT)\n",
    "ORIGIN = 'ESO-PARANAL' / European Southern Observatory\n",
    "TELESCOP= 'ESO-VLT-U4' / ESO Telescope\n",
    "INSTRUME= 'MUSE ' / ESO Instrument name\n",
    "RA = 183.46028 / [deg] Image centre (J2000.0)\n",
    "DEC = 7.20120 / [deg] Image centre (J2000.0)\n",
    "EQUINOX = 2000. / Standard FK5\n",
    "RADECSYS= 'FK5 ' / Coordinate system\n",
    "EXPTIME = 2520.0 / Total integration time per pixel\n",
    "TEXPTIME= 2520.0 / Total integration time all exposures\n",
    "NCOMBINE= 3 / # of combined raw science data files\n",
    "MJD-OBS = 57126.04953770 / 2015-04-14T01:11:20.1\n",
    "MJD-END = 57126.08556889 / 2015-04-14T02:03:13.2\n",
    "DATE-OBS= '2015-04-14T01:11:20.057' / Observing date\n",
    "OBJECT = 'NGC 4191' / Target designation\n",
    "OBID1 = 1164690 / Observation block ID\n",
    "PROG_ID = '095.B-0686(A)' / ESO programme identification code\n",
    "PROV1 = 'MUSE.2015-04-14T01:11:20.057.fits' / Original science file\n",
    "PROV2 = 'MUSE.2015-04-14T01:27:10.371.fits' / Original science file\n",
    "PROV3 = 'MUSE.2015-04-14T01:49:13.152.fits' / Original science file\n",
    "OBSTECH = 'IFU ' / Technique of observation\n",
    "PRODCATG= 'SCIENCE.CUBE.IFS' / Data product category\n",
    "ASSON1 = 'IMAGE_FOV_0001.fits' / Collapsed data cube\n",
    "ASSOC1 = 'ANCILLARY.IMAGE' / Category of associated file\n",
    "WAVELMIN= 475.0 / [nm] Minimum wavelength\n",
    "WAVELMAX= 843.0 / [nm] Maximum wavelength\n",
    "SPEC_RES= 2500 / Spectral resolving power at central wavelength\n",
    "SKY_RES = 0.94 / [arcsec] FWHM effective spatial resolution (mea\n",
    "SKY_RERR= 0.10 / [arcsec] Error of SKY_RES (estimated)\n",
    "ABMAGLIM= 22.5 / 5-sigma magnitude limit for point sources\n",
    "PIXNOISE= 4.50E-20 / [erg/s/cm**2/Angstrom] pixel-to-pixel noise\n",
    "FLUXCAL = 'ABSOLUTE' / Certifies the validity of BUNIT\n",
    "PROCSOFT= 'muse/1.0.4' / Data reduction software/version no.\n",
    "REFERENC= ' ' / Bibliographic reference\n",
    "CHECKSUM= 'RGhHRGhGRGhGRGhG' / HDU checksum updated 2015-07-15T16:27:36\n",
    "DATASUM = ' 0' / data unit checksum updated 2015-05-20T10:20:48\n",
    "END\n",
    "\n",
    "\t\t\t\t\t\tExtension 1\n",
    "\n",
    "XTENSION= 'IMAGE ' / IMAGE extension\n",
    "BITPIX = -32 / number of bits per data pixel\n",
    "NAXIS = 3 / number of data axes\n",
    "NAXIS1 = 329 / length of data axis 1\n",
    "NAXIS2 = 317 / length of data axis 2\n",
    "NAXIS3 = 3681 / length of data axis 3\n",
    "NAXIS1 = 329 / length of data axis 1\n",
    "NAXIS2 = 317 / length of data axis 2\n",
    "NAXIS3 = 3681 / length of data axis 3\n",
    "PCOUNT = 0 / required keyword; must = 0\n",
    "GCOUNT = 1 / required keyword; must = 1\n",
    "EXTNAME = 'DATA ' / This extension contains data values\n",
    "HDUCLASS= 'ESO ' / class name (ESO format)\n",
    "HDUDOC = 'DICD ' / document with class description\n",
    "HDUVERS = 'DICD version 6' / version number (according to spec v2.5.1)\n",
    "HDUCLAS1= 'IMAGE ' / Image data format\n",
    "HDUCLAS2= 'DATA ' / this extension contains the data itself\n",
    "ERRDATA = 'STAT ' / pointer to the variance extension\n",
    "OBJECT = 'NGC 4191 (DATA)'\n",
    "BUNIT = '10**(-20)*erg/s/cm**2/Angstrom'\n",
    "CRPIX1 = 170.061496799859 / Pixel coordinate of reference point\n",
    "CRPIX2 = 152.429853570976 / Pixel coordinate of reference point\n",
    "CD1_1 = -5.55555555555556E-05 / Coordinate transformation matrix element\n",
    "CD1_2 = 0. / Coordinate transformation matrix element\n",
    "CD2_1 = 0. / Coordinate transformation matrix element\n",
    "CD2_2 = 5.55555555555556E-05 / Coordinate transformation matrix element\n",
    "CUNIT1 = 'deg ' / Units of coordinate increment and value\n",
    "CUNIT2 = 'deg ' / Units of coordinate increment and value\n",
    "CTYPE1 = 'RA---TAN' / Right ascension, gnomonic projection\n",
    "CTYPE2 = 'DEC--TAN' / Declination, gnomonic projection\n",
    "CSYER1 = 1.66499066997E-05 / [deg] Systematic error in coordinate\n",
    "CSYER2 = 6.60827614552E-06 / [deg] Systematic error in coordinate\n",
    "CRVAL1 = 183.46\n",
    "CRVAL2 = 7.20083\n",
    "CTYPE3 = 'AWAV '\n",
    "CUNIT3 = 'Angstrom'\n",
    "CD3_3 = 1.25\n",
    "CRPIX3 = 1.\n",
    "CRVAL3 = 4749.81640625\n",
    "CD1_3 = 0.\n",
    "CD2_3 = 0.\n",
    "CD3_1 = 0.\n",
    "CD3_2 = 0.\n",
    "CRDER3 = 0.026 / [Angstrom] Random error in spectral coordinate\n",
    "CHECKSUM= 'ZUJFZS9DZSGDZS9D' / HDU checksum updated 2015-07-15T16:27:36\n",
    "DATASUM = '39318882' / data unit checksum updated 2015-05-20T10:20:54\n",
    "END\n",
    "\n",
    "\t\t\t\t\t\t\t\tExtension 2\n",
    "\n",
    "XTENSION= 'IMAGE ' / IMAGE extension\n",
    "BITPIX = -32 / number of bits per data pixel\n",
    "NAXIS = 3 / number of data axes\n",
    "NAXIS1 = 329 / length of data axis 1\n",
    "NAXIS2 = 317 / length of data axis 2\n",
    "NAXIS3 = 3681 / length of data axis 3\n",
    "NAXIS1 = 329 / length of data axis 1\n",
    "NAXIS2 = 317 / length of data axis 2\n",
    "NAXIS3 = 3681 / length of data axis 3\n",
    "PCOUNT = 0 / required keyword; must = 0\n",
    "GCOUNT = 1 / required keyword; must = 1\n",
    "EXTNAME = 'STAT ' / This extension contains data variance\n",
    "HDUCLASS= 'ESO ' / class name (ESO format)\n",
    "HDUDOC = 'DICD ' / document with class description\n",
    "HDUVERS = 'DICD version 6' / version number (according to spec v2.5.1)\n",
    "HDUCLAS1= 'IMAGE ' / Image data format\n",
    "HDUCLAS2= 'ERROR ' / this extension contains variance\n",
    "HDUCLAS3= 'MSE ' / the extension contains variances (sigma**2)\n",
    "SCIDATA = 'DATA ' / pointer to the data extension\n",
    "OBJECT = 'NGC 4191 (STAT)'\n",
    "BUNIT = '(10**(-20)*erg/s/cm**2/Angstrom)**2'\n",
    "CRPIX1 = 170.061496799859 / Pixel coordinate of reference point\n",
    "CRPIX2 = 152.429853570976 / Pixel coordinate of reference point\n",
    "CD1_1 = -5.55555555555556E-05 / Coordinate transformation matrix element\n",
    "CD1_2 = 0. / Coordinate transformation matrix element\n",
    "CD2_1 = 0. / Coordinate transformation matrix element\n",
    "CD2_2 = 5.55555555555556E-05 / Coordinate transformation matrix element\n",
    "CUNIT1 = 'deg ' / Units of coordinate increment and value\n",
    "CUNIT2 = 'deg ' / Units of coordinate increment and value\n",
    "CTYPE1 = 'RA---TAN' / Right ascension, gnomonic projection\n",
    "CTYPE2 = 'DEC--TAN' / Declination, gnomonic projection\n",
    "CSYER1 = 1.66499066997E-05 / [deg] Systematic error in coordinate\n",
    "CSYER2 = 6.60827614552E-06 / [deg] Systematic error in coordinate\n",
    "CRVAL1 = 183.46\n",
    "CRVAL2 = 7.20083\n",
    "CTYPE3 = 'AWAV '\n",
    "CUNIT3 = 'Angstrom'\n",
    "CD3_3 = 1.25\n",
    "CRPIX3 = 1.\n",
    "CRVAL3 = 4749.81640625\n",
    "CD1_3 = 0.\n",
    "CD2_3 = 0.\n",
    "CD3_1 = 0.\n",
    "CD3_2 = 0.\n",
    "CHECKSUM= 'JfcaJeZYJeaaJeYW' / HDU checksum updated 2015-05-20T10:20:55\n",
    "DATASUM = '2131780454' / data unit checksum updated 2015-05-20T10:20:55\n",
    "END\n",
    "\n",
    "\n",
    "```\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "297.667px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
